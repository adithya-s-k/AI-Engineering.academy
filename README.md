# LLM Alchemy Chamber ğŸ§™â€â™‚ï¸âœ¨

Welcome to a friendly neighborhood repository featuring diverse experiments and adventures in the world of LLMs. This collection is no ordinary repository; it's an alchemical blend of scripts, notebooks, and experiments dedicated to the mystical realm of Language Models (LLMs).


## Alchemical Scripts

<table border="1">
    <tr>
        <th>Projects</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Youtube Cloner</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/tree/main/Projects/YT_Clones">Folder</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Projects/YT_Clones/Fireship_clone.ipynb">Fireship GPT</a></td>
        <td>Blog coming soon</td>
        <td>An Attempt at cloning youtubers using LLMs by Finetuning</td>
    </tr>
</table>



<table border="1">
    <tr>
        <th>Finetuning</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Gemma Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Gemma_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Gemma_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://medium.com/@adithyask/a-beginners-guide-to-fine-tuning-gemma-0444d46d821c">A Beginnerâ€™s Guide to Fine-Tuning Gemma</a></td>
        <td>Notebook to Finetune Gemma Models</td>
    </tr>
    <tr>
        <td>Mistral-7b Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mistral_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mistral_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe">A Beginnerâ€™s Guide to Fine-Tuning Mistral 7B Instruct Model</a></td>
        <td>Notebook to Finetune Mistral-7b Model</td>
    </tr>
    <tr>
        <td>Mixtral Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mixtral_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Mixtral_finetuning_notebook.ipynb">Colab</a></td>
        <td><a href="https://generativeai.pub/a-beginners-guide-to-fine-tuning-mixtral-instruct-model-7f6a30aacf61">A Beginnerâ€™s Guide to Fine-Tuning Mixtral Instruct Model</a></td>
        <td>Notebook to Finetune Mixtral-7b Models</td>
    </tr>
    <tr>
        <td>LLama2 Finetuning</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Llama2_finetuning_notebook.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/Finetuning/Llama2_finetuning_notebook.ipynb">Colab</a></td>
        <td></td>
        <td>Notebook to Finetune Llama2-7b Model</td>
    </tr>
</table>

<table border="1">
    <tr>
        <th>Quantization</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Blog Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>AWQ Quantization</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/AWQ_Quantization.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/AWQ_Quantization.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/squeeze-every-drop-of-performance-from-your-llm-with-awq-activation-aware-quantization-53973365eaaa?sk=43ddb56748cab819777c1ccad39eb9ee">Squeeze Every Drop of Performance from Your LLM with AWQ</a></td>
        <td>quantise LLM using AWQ.</td>
    </tr>
    <tr>
        <td>GGUF Quantization</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/GGUF_Quantization.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Alchemy-Chamber/blob/main/Quantization/GGUF_Quantization.ipynb">Colab</a></td>
        <td><a href="https://adithyask.medium.com/run-any-huggingface-model-locally-6bf817fdaff3?sk=46eea5f41270342bbc513a108fe6e57e">Run any Huggingface model locally</a></td>
        <td>quantise LLM to GGUF formate.</td>
    </tr>
</table>

<table border="1">
    <tr>
        <th>Data Prep</th>
        <th>GitHub Link</th>
        <th>Colab Link</th>
        <th>Description</th>
    </tr>
    <tr>
        <td>Documents -> Dataset</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_documents.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_documents.ipynb">Colab</a></td>
        <td>Given Documents generate Instruction/QA dataset for finetuning LLMs</td>
    </tr>
    <tr>
        <td>Topic -> Dataset</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_topic.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/dataset_generator_from_topic.ipynb">Colab</a></td>
        <td>Given a Topic generate a dataset to finetune LLMs</td>
    </tr>
    <tr>
        <td>Alpaca Dataset Generation</td>
        <td><a href="https://github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/instruction_dataset_generator.ipynb">GitHub</a></td>
        <td><a href="https://colab.research.google.com/github.com/adithya-s-k/LLM-Cookbook/blob/main/DataPrep/instruction_dataset_generator.ipynb">Colab</a></td>
        <td>The original implementation of generating instruction dataset followed in the alpaca paper</td>
    </tr>
</table>


## Repo Structure

```
â”œâ”€â”€ DataPrep(Notebook to generate synthetic data)
â”‚   â”œâ”€â”€ dataset_prep.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Deployment(TGI/VLLM scripts for testing)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Finetuning(Finalised Finetuning Scripts)
â”‚   â”œâ”€â”€ Gemma_finetuning_notebook.ipynb
â”‚   â”œâ”€â”€ Llama2_finetuning_notebook.ipynb
â”‚   â”œâ”€â”€ Mistral_finetuning_notebook.ipynb
â”‚   â”œâ”€â”€ Mixtral_finetuning_notebook.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ LLMS(LLM experiments)
â”‚   â”œâ”€â”€ ambari
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ CodeLLama
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Gemma
â”‚   â”‚   â”œâ”€â”€ finetune-gemma.ipynb
â”‚   â”‚   â””â”€â”€ gemma-sft.py
â”‚   â”œâ”€â”€ Llama2
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Mistral-7b
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Mixtral
â”‚       â””â”€â”€ ...
â”œâ”€â”€ Projects(Upsurd ideas i want to try out)
â”‚   â””â”€â”€ YT_Clones
â”‚       â”œâ”€â”€ Fireship_clone.ipynb
â”‚       â”œâ”€â”€ youtube_channel_scraper.py
â”‚       â””â”€â”€ ...
â”œâ”€â”€ Quantization
â”‚   â””â”€â”€ ...
â”œâ”€â”€ utils
â”‚   â””â”€â”€ streaming_inference_hf.ipynb
```

<p align="center">
  <a href="https://adithyask.com">
    <img src="https://api.star-history.com/svg?repos=adithya-s-k/LLM-Alchemy-Chamber&type=Date" alt="Star History Chart">
  </a>
</p>
