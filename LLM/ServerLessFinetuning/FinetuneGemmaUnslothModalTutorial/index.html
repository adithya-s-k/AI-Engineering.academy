<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial/ rel=canonical><link href=../TrainNanochatModalTutorial/ rel=prev><link href=../FinetuneLlamaAxolotlGPUModalTutorial/ rel=next><link rel=icon href=../../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.21"><title>Fine-tuning Gemma with Unsloth - AI Engineering Academy</title><link rel=stylesheet href=../../../assets/stylesheets/main.2a3383ac.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta property=og:type content=website><meta property=og:title content="Fine-tuning Gemma with Unsloth - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Fine-tuning Gemma with Unsloth - AI Engineering Academy"><meta name=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta name=twitter:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial.png><link rel=stylesheet href=../../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#fine-tuning-gemma-3-4b-with-unsloth-on-modal-production-ready-vision-language-training class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class=md-tabs__item> <a href=../../../RAG/ class=md-tabs__link> RAG </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../RAG/ class=md-nav__link> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> LLM </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex> <span class=md-ellipsis> Finetuning Techniques </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Finetuning Techniques </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PreTrain/ class=md-nav__link> <span class=md-ellipsis> PreTraining LLMs </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/SFT/ class=md-nav__link> <span class=md-ellipsis> SFT </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PPO/ class=md-nav__link> <span class=md-ellipsis> PPO(Proximal Policy Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/DPO/ class=md-nav__link> <span class=md-ellipsis> DPO(Direct Preference Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/ORPO/ class=md-nav__link> <span class=md-ellipsis> ORPO(Odds Ratio Preference Optimization) </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/GRPO/ class=md-nav__link> <span class=md-ellipsis> GRPO(Group Relative Policy Optimization) </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex> <span class=md-ellipsis> LLM Finetuning Hands on </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> LLM Finetuning Hands on </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Gemma/ class=md-nav__link> <span class=md-ellipsis> Gemma </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../LLama2/Llama2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Llama2 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Llama3_finetuning_notebook.ipynb class=md-nav__link> <span class=md-ellipsis> Llama3 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Mistral-7b/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex> <span class=md-ellipsis> VLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> VLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../VLM/Florence2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Florence2 </span> </a> </li> <li class=md-nav__item> <a href=../../VLM/PaliGemma_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> PaliGemma </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Serverless Finetuning with Modal </span> </a> <label class="md-nav__link " for=__nav_4_5 id=__nav_4_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_5_label aria-expanded=true> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Serverless Finetuning with Modal </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../TrainNanoGPTModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training NanoGPT on Modal </span> </a> </li> <li class=md-nav__item> <a href=../TrainNanochatModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training Nanochat on Modal </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-unsloth class=md-nav__link> <span class=md-ellipsis> Why Unsloth? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#set-up-your-secrets class=md-nav__link> <span class=md-ellipsis> Set Up Your Secrets </span> </a> <nav class=md-nav aria-label="Set Up Your Secrets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-env-file-easiest-for-local-development class=md-nav__link> <span class=md-ellipsis> Option 1: .env file (easiest for local development) </span> </a> </li> <li class=md-nav__item> <a href=#option-2-modal-secrets-better-for-production class=md-nav__link> <span class=md-ellipsis> Option 2: Modal Secrets (better for production) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#project-structure class=md-nav__link> <span class=md-ellipsis> Project Structure </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-pipeline class=md-nav__link> <span class=md-ellipsis> Understanding the Pipeline </span> </a> <nav class=md-nav aria-label="Understanding the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stage-overview class=md-nav__link> <span class=md-ellipsis> Stage Overview </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#configuration-and-setup class=md-nav__link> <span class=md-ellipsis> Configuration and Setup </span> </a> <nav class=md-nav aria-label="Configuration and Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-volume-and-secrets class=md-nav__link> <span class=md-ellipsis> App, Volume, and Secrets </span> </a> </li> <li class=md-nav__item> <a href=#configuration-constants class=md-nav__link> <span class=md-ellipsis> Configuration Constants </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-the-training-image class=md-nav__link> <span class=md-ellipsis> Building the Training Image </span> </a> <nav class=md-nav aria-label="Building the Training Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-cuda-devel class=md-nav__link> <span class=md-ellipsis> Why CUDA "devel"? </span> </a> </li> <li class=md-nav__item> <a href=#complete-image-definition class=md-nav__link> <span class=md-ellipsis> Complete Image Definition </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-1-downloading-datasets class=md-nav__link> <span class=md-ellipsis> Stage 1: Downloading Datasets </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-downloading-models class=md-nav__link> <span class=md-ellipsis> Stage 2: Downloading Models </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-fine-tuning-with-lora class=md-nav__link> <span class=md-ellipsis> Stage 3: Fine-tuning with LoRA </span> </a> <nav class=md-nav aria-label="Stage 3: Fine-tuning with LoRA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-configuration class=md-nav__link> <span class=md-ellipsis> GPU Configuration </span> </a> </li> <li class=md-nav__item> <a href=#the-training-function class=md-nav__link> <span class=md-ellipsis> The Training Function </span> </a> </li> <li class=md-nav__item> <a href=#running-training class=md-nav__link> <span class=md-ellipsis> Running Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-4-export-and-merge-model-optional class=md-nav__link> <span class=md-ellipsis> Stage 4: Export and Merge Model (Optional) </span> </a> </li> <li class=md-nav__item> <a href=#stage-5-serving-with-vllm class=md-nav__link> <span class=md-ellipsis> Stage 5: Serving with vLLM </span> </a> <nav class=md-nav aria-label="Stage 5: Serving with vLLM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#vllm-image-separate-from-training class=md-nav__link> <span class=md-ellipsis> vLLM Image (Separate from Training) </span> </a> </li> <li class=md-nav__item> <a href=#serving-configuration class=md-nav__link> <span class=md-ellipsis> Serving Configuration </span> </a> </li> <li class=md-nav__item> <a href=#the-serve-function class=md-nav__link> <span class=md-ellipsis> The Serve Function </span> </a> </li> <li class=md-nav__item> <a href=#deploying-the-server class=md-nav__link> <span class=md-ellipsis> Deploying the Server </span> </a> </li> <li class=md-nav__item> <a href=#using-the-api class=md-nav__link> <span class=md-ellipsis> Using the API </span> </a> </li> <li class=md-nav__item> <a href=#testing-the-deployment class=md-nav__link> <span class=md-ellipsis> Testing the Deployment </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-6-evaluation class=md-nav__link> <span class=md-ellipsis> Stage 6: Evaluation </span> </a> <nav class=md-nav aria-label="Stage 6: Evaluation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#evaluation-image-lightweight-cpu-only class=md-nav__link> <span class=md-ellipsis> Evaluation Image (Lightweight, CPU-only) </span> </a> </li> <li class=md-nav__item> <a href=#the-evaluation-function class=md-nav__link> <span class=md-ellipsis> The Evaluation Function </span> </a> </li> <li class=md-nav__item> <a href=#running-evaluation class=md-nav__link> <span class=md-ellipsis> Running Evaluation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#complete-workflow-example class=md-nav__link> <span class=md-ellipsis> Complete Workflow Example </span> </a> <nav class=md-nav aria-label="Complete Workflow Example"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-download-everything-one-time class=md-nav__link> <span class=md-ellipsis> 1. Download Everything (One Time) </span> </a> </li> <li class=md-nav__item> <a href=#2-quick-test-run-make-sure-it-works class=md-nav__link> <span class=md-ellipsis> 2. Quick Test Run (Make Sure It Works) </span> </a> </li> <li class=md-nav__item> <a href=#3-full-training-run class=md-nav__link> <span class=md-ellipsis> 3. Full Training Run </span> </a> </li> <li class=md-nav__item> <a href=#4-deploy-for-serving class=md-nav__link> <span class=md-ellipsis> 4. Deploy for Serving </span> </a> </li> <li class=md-nav__item> <a href=#5-evaluate class=md-nav__link> <span class=md-ellipsis> 5. Evaluate </span> </a> </li> <li class=md-nav__item> <a href=#6-use-in-production class=md-nav__link> <span class=md-ellipsis> 6. Use in Production </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning-tips class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning Tips </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning Tips"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#for-better-accuracy class=md-nav__link> <span class=md-ellipsis> For Better Accuracy </span> </a> </li> <li class=md-nav__item> <a href=#for-faster-iteration class=md-nav__link> <span class=md-ellipsis> For Faster Iteration </span> </a> </li> <li class=md-nav__item> <a href=#for-memory-issues class=md-nav__link> <span class=md-ellipsis> For Memory Issues </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> Common Issues and Solutions </span> </a> <nav class=md-nav aria-label="Common Issues and Solutions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#secret-not-found class=md-nav__link> <span class=md-ellipsis> "Secret not found" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> CUDA Out of Memory </span> </a> </li> <li class=md-nav__item> <a href=#image-build-timeout class=md-nav__link> <span class=md-ellipsis> Image Build Timeout </span> </a> </li> <li class=md-nav__item> <a href=#vllm-server-not-responding class=md-nav__link> <span class=md-ellipsis> vLLM Server Not Responding </span> </a> </li> <li class=md-nav__item> <a href=#evaluation-fails class=md-nav__link> <span class=md-ellipsis> Evaluation Fails </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cost-breakdown class=md-nav__link> <span class=md-ellipsis> Cost Breakdown </span> </a> <nav class=md-nav aria-label="Cost Breakdown"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#training class=md-nav__link> <span class=md-ellipsis> Training </span> </a> </li> <li class=md-nav__item> <a href=#serving-pay-per-use class=md-nav__link> <span class=md-ellipsis> Serving (pay per use) </span> </a> </li> <li class=md-nav__item> <a href=#evaluation class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#storage class=md-nav__link> <span class=md-ellipsis> Storage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> <li class=md-nav__item> <a href=#wrapping-up class=md-nav__link> <span class=md-ellipsis> Wrapping Up </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../FinetuneLlamaAxolotlGPUModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Multi-GPU Training with Axolotl </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_6> <div class="md-nav__link md-nav__container"> <a href=../../LLMArchitecture/ParameterCount/ class="md-nav__link "> <span class=md-ellipsis> LLM Architecture </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> LLM Architecture </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-unsloth class=md-nav__link> <span class=md-ellipsis> Why Unsloth? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#set-up-your-secrets class=md-nav__link> <span class=md-ellipsis> Set Up Your Secrets </span> </a> <nav class=md-nav aria-label="Set Up Your Secrets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-env-file-easiest-for-local-development class=md-nav__link> <span class=md-ellipsis> Option 1: .env file (easiest for local development) </span> </a> </li> <li class=md-nav__item> <a href=#option-2-modal-secrets-better-for-production class=md-nav__link> <span class=md-ellipsis> Option 2: Modal Secrets (better for production) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#project-structure class=md-nav__link> <span class=md-ellipsis> Project Structure </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-pipeline class=md-nav__link> <span class=md-ellipsis> Understanding the Pipeline </span> </a> <nav class=md-nav aria-label="Understanding the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stage-overview class=md-nav__link> <span class=md-ellipsis> Stage Overview </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#configuration-and-setup class=md-nav__link> <span class=md-ellipsis> Configuration and Setup </span> </a> <nav class=md-nav aria-label="Configuration and Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-volume-and-secrets class=md-nav__link> <span class=md-ellipsis> App, Volume, and Secrets </span> </a> </li> <li class=md-nav__item> <a href=#configuration-constants class=md-nav__link> <span class=md-ellipsis> Configuration Constants </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-the-training-image class=md-nav__link> <span class=md-ellipsis> Building the Training Image </span> </a> <nav class=md-nav aria-label="Building the Training Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-cuda-devel class=md-nav__link> <span class=md-ellipsis> Why CUDA "devel"? </span> </a> </li> <li class=md-nav__item> <a href=#complete-image-definition class=md-nav__link> <span class=md-ellipsis> Complete Image Definition </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-1-downloading-datasets class=md-nav__link> <span class=md-ellipsis> Stage 1: Downloading Datasets </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-downloading-models class=md-nav__link> <span class=md-ellipsis> Stage 2: Downloading Models </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-fine-tuning-with-lora class=md-nav__link> <span class=md-ellipsis> Stage 3: Fine-tuning with LoRA </span> </a> <nav class=md-nav aria-label="Stage 3: Fine-tuning with LoRA"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-configuration class=md-nav__link> <span class=md-ellipsis> GPU Configuration </span> </a> </li> <li class=md-nav__item> <a href=#the-training-function class=md-nav__link> <span class=md-ellipsis> The Training Function </span> </a> </li> <li class=md-nav__item> <a href=#running-training class=md-nav__link> <span class=md-ellipsis> Running Training </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-4-export-and-merge-model-optional class=md-nav__link> <span class=md-ellipsis> Stage 4: Export and Merge Model (Optional) </span> </a> </li> <li class=md-nav__item> <a href=#stage-5-serving-with-vllm class=md-nav__link> <span class=md-ellipsis> Stage 5: Serving with vLLM </span> </a> <nav class=md-nav aria-label="Stage 5: Serving with vLLM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#vllm-image-separate-from-training class=md-nav__link> <span class=md-ellipsis> vLLM Image (Separate from Training) </span> </a> </li> <li class=md-nav__item> <a href=#serving-configuration class=md-nav__link> <span class=md-ellipsis> Serving Configuration </span> </a> </li> <li class=md-nav__item> <a href=#the-serve-function class=md-nav__link> <span class=md-ellipsis> The Serve Function </span> </a> </li> <li class=md-nav__item> <a href=#deploying-the-server class=md-nav__link> <span class=md-ellipsis> Deploying the Server </span> </a> </li> <li class=md-nav__item> <a href=#using-the-api class=md-nav__link> <span class=md-ellipsis> Using the API </span> </a> </li> <li class=md-nav__item> <a href=#testing-the-deployment class=md-nav__link> <span class=md-ellipsis> Testing the Deployment </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-6-evaluation class=md-nav__link> <span class=md-ellipsis> Stage 6: Evaluation </span> </a> <nav class=md-nav aria-label="Stage 6: Evaluation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#evaluation-image-lightweight-cpu-only class=md-nav__link> <span class=md-ellipsis> Evaluation Image (Lightweight, CPU-only) </span> </a> </li> <li class=md-nav__item> <a href=#the-evaluation-function class=md-nav__link> <span class=md-ellipsis> The Evaluation Function </span> </a> </li> <li class=md-nav__item> <a href=#running-evaluation class=md-nav__link> <span class=md-ellipsis> Running Evaluation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#complete-workflow-example class=md-nav__link> <span class=md-ellipsis> Complete Workflow Example </span> </a> <nav class=md-nav aria-label="Complete Workflow Example"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-download-everything-one-time class=md-nav__link> <span class=md-ellipsis> 1. Download Everything (One Time) </span> </a> </li> <li class=md-nav__item> <a href=#2-quick-test-run-make-sure-it-works class=md-nav__link> <span class=md-ellipsis> 2. Quick Test Run (Make Sure It Works) </span> </a> </li> <li class=md-nav__item> <a href=#3-full-training-run class=md-nav__link> <span class=md-ellipsis> 3. Full Training Run </span> </a> </li> <li class=md-nav__item> <a href=#4-deploy-for-serving class=md-nav__link> <span class=md-ellipsis> 4. Deploy for Serving </span> </a> </li> <li class=md-nav__item> <a href=#5-evaluate class=md-nav__link> <span class=md-ellipsis> 5. Evaluate </span> </a> </li> <li class=md-nav__item> <a href=#6-use-in-production class=md-nav__link> <span class=md-ellipsis> 6. Use in Production </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning-tips class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning Tips </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning Tips"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#for-better-accuracy class=md-nav__link> <span class=md-ellipsis> For Better Accuracy </span> </a> </li> <li class=md-nav__item> <a href=#for-faster-iteration class=md-nav__link> <span class=md-ellipsis> For Faster Iteration </span> </a> </li> <li class=md-nav__item> <a href=#for-memory-issues class=md-nav__link> <span class=md-ellipsis> For Memory Issues </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> Common Issues and Solutions </span> </a> <nav class=md-nav aria-label="Common Issues and Solutions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#secret-not-found class=md-nav__link> <span class=md-ellipsis> "Secret not found" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> CUDA Out of Memory </span> </a> </li> <li class=md-nav__item> <a href=#image-build-timeout class=md-nav__link> <span class=md-ellipsis> Image Build Timeout </span> </a> </li> <li class=md-nav__item> <a href=#vllm-server-not-responding class=md-nav__link> <span class=md-ellipsis> vLLM Server Not Responding </span> </a> </li> <li class=md-nav__item> <a href=#evaluation-fails class=md-nav__link> <span class=md-ellipsis> Evaluation Fails </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cost-breakdown class=md-nav__link> <span class=md-ellipsis> Cost Breakdown </span> </a> <nav class=md-nav aria-label="Cost Breakdown"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#training class=md-nav__link> <span class=md-ellipsis> Training </span> </a> </li> <li class=md-nav__item> <a href=#serving-pay-per-use class=md-nav__link> <span class=md-ellipsis> Serving (pay per use) </span> </a> </li> <li class=md-nav__item> <a href=#evaluation class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#storage class=md-nav__link> <span class=md-ellipsis> Storage </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> <li class=md-nav__item> <a href=#wrapping-up class=md-nav__link> <span class=md-ellipsis> Wrapping Up </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModalTutorial.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=fine-tuning-gemma-3-4b-with-unsloth-on-modal-production-ready-vision-language-training>Fine-tuning Gemma 3-4B with Unsloth on Modal: Production-Ready Vision-Language Training<a class=headerlink href=#fine-tuning-gemma-3-4b-with-unsloth-on-modal-production-ready-vision-language-training title="Permanent link">¶</a></h1> <p>📄 <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModal.py>View Complete Python Script</a></strong></p> <p>🔗 <strong><a href=https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision.ipynb>Original Unsloth Colab Notebook</a></strong></p> <p>So you've mastered the basics with nanoGPT. Now let's level up and build a production-grade ML pipeline - we're talking dataset management, LoRA fine-tuning, model evaluation, and deployment. All on Modal's serverless infrastructure.</p> <p>We'll fine-tune Google's Gemma 3-4B vision model to read LaTeX equations from images. By the end, you'll have a fully deployed API that can look at a math equation and spit out the LaTeX code for it.</p> <h2 id=why-unsloth>Why Unsloth?<a class=headerlink href=#why-unsloth title="Permanent link">¶</a></h2> <p>Here's the thing - training large language models is expensive and slow. Unsloth changes that game completely.</p> <p>I discovered Unsloth when I was trying to fine-tune Llama models and getting frustrated with how slow everything was. Then I found this library that claimed "2x faster training" and I was skeptical. But holy shit, it actually delivers.</p> <p><strong>What makes Unsloth special:</strong> - <strong>2-5x faster training</strong> than standard Hugging Face Transformers (no joke, you'll see the difference) - <strong>60-80% less memory usage</strong> - fits bigger models on smaller GPUs - <strong>Built-in LoRA and QLoRA support</strong> - efficient fine-tuning out of the box - <strong>Optimized kernels</strong> for vision-language models like Gemma, Llama, Qwen - <strong>Drop-in replacement</strong> for Hugging Face - same API, just faster</p> <p>The original Colab notebook from Unsloth shows you how to do this on a single GPU. We're taking that exact workflow and making it run on Modal, so you can: - Train on any GPU type (A100-80GB? Sure!) - Separate data prep from training (save money) - Deploy with vLLM for high-throughput inference - Scale to production without changing your code</p> <p>Think of this as "the Unsloth Colab notebook, but productionized".</p> <h2 id=what-were-building>What We're Building<a class=headerlink href=#what-were-building title="Permanent link">¶</a></h2> <p>This isn't just a training script. We're building a complete ML pipeline that handles everything from data to deployment:</p> <ol> <li><strong>Download datasets</strong> (on CPU, because why waste GPU money?)</li> <li><strong>Download and cache models</strong> (one time cost, reuse forever)</li> <li><strong>Fine-tune with LoRA</strong> (the actual training)</li> <li><strong>Evaluate performance</strong> (with real metrics, not vibes)</li> <li><strong>Deploy with vLLM</strong> (production-ready serving with auto-scaling)</li> </ol> <p>The cool part? Each stage is independent. Screw up training? Just re-run that step. Want to evaluate a different checkpoint? Easy.</p> <p>Here's what the flow looks like:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>┌─────────────────┐
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>│  Download Data  │  (CPU - $0.00001/hr)
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>└────────┬────────┘
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>         │
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>┌────────▼────────┐
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>│ Download Model  │  (L40S - $1/hr, one time)
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>└────────┬────────┘
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>         │
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>┌────────▼────────┐
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>│   Fine-tune     │  (A100-80GB - $3.50/hr)
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>│   with LoRA     │
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>└────────┬────────┘
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>         │
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>┌────────▼────────┐
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>│  Export/Merge   │  (A100-80GB - ~10 min)
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>└────────┬────────┘
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>         │
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>    ┌────┴────┐
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>    │         │
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>┌───▼───┐ ┌──▼──────┐
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>│ Serve │ │ Evaluate│  (Both use the deployed model)
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>│ vLLM  │ │  Model  │
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>└───────┘ └─────────┘
</span></code></pre></div> <h2 id=getting-started>Getting Started<a class=headerlink href=#getting-started title="Permanent link">¶</a></h2> <h3 id=install-modal>Install Modal<a class=headerlink href=#install-modal title="Permanent link">¶</a></h3> <p>Same as before:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>pip<span class=w> </span>install<span class=w> </span>modal
</span></code></pre></div> <h3 id=authenticate>Authenticate<a class=headerlink href=#authenticate title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>modal<span class=w> </span>setup
</span></code></pre></div> <p>Or use API keys:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_ID</span><span class=o>=</span>&lt;your_token_id&gt;
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_SECRET</span><span class=o>=</span>&lt;your_token_secret&gt;
</span></code></pre></div> <h3 id=set-up-your-secrets>Set Up Your Secrets<a class=headerlink href=#set-up-your-secrets title="Permanent link">¶</a></h3> <p>This time we actually need some secrets because we're downloading from Hugging Face and (optionally) logging to Weights &amp; Biases.</p> <p><strong>You'll need:</strong> - A Hugging Face token (get it from <a href=https://huggingface.co/settings/tokens>hf.co/settings/tokens</a>) - A Weights &amp; Biases API key (optional but highly recommended - get it from <a href=https://wandb.ai/authorize>wandb.ai/authorize</a>)</p> <h4 id=option-1-env-file-easiest-for-local-development>Option 1: .env file (easiest for local development)<a class=headerlink href=#option-1-env-file-easiest-for-local-development title="Permanent link">¶</a></h4> <p>Create a <code>.env</code> file in your project:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_xxxxxxxxxxxxx
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=nv>WANDB_API_KEY</span><span class=o>=</span>xxxxxxxxxxxxx
</span></code></pre></div> <h4 id=option-2-modal-secrets-better-for-production>Option 2: Modal Secrets (better for production)<a class=headerlink href=#option-2-modal-secrets-better-for-production title="Permanent link">¶</a></h4> <div class="language-bash highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>modal<span class=w> </span>secret<span class=w> </span>create<span class=w> </span>secrets-hf-wandb<span class=w> </span><span class=se>\</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=w>  </span><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_xxxxxxxxxxxxx<span class=w> </span><span class=se>\</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=w>  </span><span class=nv>WANDB_API_KEY</span><span class=o>=</span>xxxxxxxxxxxxx
</span></code></pre></div> <blockquote> <p><strong>Note:</strong> The script looks for a secret named <code>secrets-hf-wandb</code>. If you use a different name, just update the code where it says <code>Secret.from_name("secrets-hf-wandb")</code>.</p> </blockquote> <h3 id=project-structure>Project Structure<a class=headerlink href=#project-structure title="Permanent link">¶</a></h3> <p>Beautiful thing about this? It's just one file:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a>ServerLessFinetuning/
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>├── FinetuneGemmaUnslothModal.py    # Everything lives here
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>└── .env                             # Optional: your secrets
</span></code></pre></div> <p>No cloning repos, no juggling dependencies. Just one Python file that does it all.</p> <h2 id=understanding-the-pipeline>Understanding the Pipeline<a class=headerlink href=#understanding-the-pipeline title="Permanent link">¶</a></h2> <p>Let's break down what we're building. This is a <strong>production-grade</strong> ML pipeline with 6 independent stages. You can run any stage separately, which is huge for development and debugging.</p> <h3 id=stage-overview>Stage Overview<a class=headerlink href=#stage-overview title="Permanent link">¶</a></h3> <ol> <li><strong>Dataset Download</strong> - Grab the LaTeX OCR dataset (images of equations + LaTeX code)</li> <li><strong>Model Download</strong> - Download Gemma 3-4B and cache it (so we don't re-download every time)</li> <li><strong>LoRA Fine-tuning</strong> - Train adapters to teach Gemma to read equations</li> <li><strong>Model Export</strong> - Merge LoRA adapters into the base model (makes deployment easier)</li> <li><strong>vLLM Serving</strong> - Deploy as an OpenAI-compatible API with auto-scaling</li> <li><strong>Evaluation</strong> - Measure accuracy with real metrics (character error rate, exact match, etc.)</li> </ol> <p>Each stage saves its outputs to a Modal volume, so the next stage can pick up where the last one left off.</p> <h2 id=configuration-and-setup>Configuration and Setup<a class=headerlink href=#configuration-and-setup title="Permanent link">¶</a></h2> <p>Alright, let's dive into the code. I'll walk you through each piece and explain why it matters.</p> <h3 id=app-volume-and-secrets>App, Volume, and Secrets<a class=headerlink href=#app-volume-and-secrets title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>from</span><span class=w> </span><span class=nn>modal</span><span class=w> </span><span class=kn>import</span> <span class=n>App</span><span class=p>,</span> <span class=n>Image</span> <span class=k>as</span> <span class=n>ModalImage</span><span class=p>,</span> <span class=n>Volume</span><span class=p>,</span> <span class=n>Secret</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=c1># Create the Modal app - this is our project namespace</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>app</span> <span class=o>=</span> <span class=n>App</span><span class=p>(</span><span class=s2>"Finetuned_Gemma_3_4b_it"</span><span class=p>)</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=c1># Create persistent storage - everything goes here</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=c1># Models, datasets, checkpoints, evaluation results - all in one volume</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=n>exp_volume</span> <span class=o>=</span> <span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"Finetuned_Gemma_3_4b_it"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Mount the volume at /data in all our containers</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>VOLUME_CONFIG</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>    <span class=s2>"/data"</span><span class=p>:</span> <span class=n>exp_volume</span><span class=p>,</span>  <span class=c1># Single volume for the entire experiment</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a><span class=p>}</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=c1># Load secrets for Hugging Face and Weights &amp; Biases</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=c1># This injects HUGGINGFACE_TOKEN and WANDB_API_KEY as environment variables</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=n>huggingface_secret</span> <span class=o>=</span> <span class=n>Secret</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"secrets-hf-wandb"</span><span class=p>)</span>
</span></code></pre></div> <p><strong>What's happening here:</strong></p> <ul> <li><strong>Volume strategy</strong>: I use a single volume for the entire experiment. Models in <code>/data/.cache</code>, checkpoints in <code>/data/Finetuned_Gemma_3_4b_it</code>, datasets in <code>/data/.cache</code>. Keeps everything organized and makes debugging easier.</li> <li><strong>Secrets</strong>: Modal injects these as environment variables. So inside our functions, we can just do <code>os.environ["HUGGINGFACE_TOKEN"]</code>.</li> </ul> <h3 id=configuration-constants>Configuration Constants<a class=headerlink href=#configuration-constants title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Time constants</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=n>HOURS</span> <span class=o>=</span> <span class=mi>60</span> <span class=o>*</span> <span class=mi>60</span>  <span class=c1># Makes timeouts more readable</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a><span class=c1># Model configuration</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=n>BASE_MODEL_NAME</span> <span class=o>=</span> <span class=s2>"unsloth/gemma-3-4b-it"</span>  <span class=c1># Unsloth's optimized Gemma</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=n>WANDB_PROJECT_DEFAULT</span> <span class=o>=</span> <span class=s2>"GemmaFinetuning"</span>   <span class=c1># W&amp;B project name</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=n>OUTPUT_DIR_DEFAULT</span> <span class=o>=</span> <span class=s2>"/data/Finetuned_Gemma_3_4b_it"</span>  <span class=c1># Where to save checkpoints</span>
</span></code></pre></div> <p>These constants make it easy to swap models or change output directories. Want to try Llama instead? Just change <code>BASE_MODEL_NAME</code>.</p> <h2 id=building-the-training-image>Building the Training Image<a class=headerlink href=#building-the-training-image title="Permanent link">¶</a></h2> <p>This is where things get interesting. We need a container with CUDA, PyTorch, Unsloth, and a bunch of other stuff.</p> <h3 id=why-cuda-devel>Why CUDA "devel"?<a class=headerlink href=#why-cuda-devel title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=n>CUDA_VERSION</span> <span class=o>=</span> <span class=s2>"12.8.1"</span>     <span class=c1># Latest CUDA version</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>CUDA_FLAVOR</span> <span class=o>=</span> <span class=s2>"devel"</span>        <span class=c1># "devel" includes nvcc compiler</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=n>CUDA_OS</span> <span class=o>=</span> <span class=s2>"ubuntu24.04"</span>      <span class=c1># Ubuntu 24.04 LTS</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>CUDA_TAG</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>CUDA_VERSION</span><span class=si>}</span><span class=s2>-</span><span class=si>{</span><span class=n>CUDA_FLAVOR</span><span class=si>}</span><span class=s2>-</span><span class=si>{</span><span class=n>CUDA_OS</span><span class=si>}</span><span class=s2>"</span>
</span></code></pre></div> <p>Here's the deal: some packages like <code>flash-attn</code> and <code>triton</code> need to compile CUDA code during installation. If you use the <code>runtime</code> image, you'll get cryptic errors about missing <code>nvcc</code>. Trust me, I learned this the hard way.</p> <p>The <code>devel</code> image includes the full CUDA toolkit with the compiler. It's bigger, but it Just Works™.</p> <h3 id=complete-image-definition>Complete Image Definition<a class=headerlink href=#complete-image-definition title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=n>FINETUNING_GPU_IMAGE</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>    <span class=c1># Start with NVIDIA's official CUDA image</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=n>ModalImage</span><span class=o>.</span><span class=n>from_registry</span><span class=p>(</span><span class=sa>f</span><span class=s2>"nvidia/cuda:</span><span class=si>{</span><span class=n>CUDA_TAG</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span> <span class=n>add_python</span><span class=o>=</span><span class=s2>"3.12"</span><span class=p>)</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=c1># Install system dependencies</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=c1># git: for cloning repos if needed</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=c1># build-essential: gcc, make, etc. for compiling Python extensions</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=o>.</span><span class=n>apt_install</span><span class=p>(</span><span class=s2>"git"</span><span class=p>,</span> <span class=s2>"build-essential"</span><span class=p>)</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=c1># Install PyTorch first (required by most other packages)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=c1># Using uv for faster installs (it's like pip but 10-100x faster)</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=o>.</span><span class=n>uv_pip_install</span><span class=p>([</span><span class=s2>"torch"</span><span class=p>,</span> <span class=s2>"torchvision"</span><span class=p>,</span> <span class=s2>"torchaudio"</span><span class=p>])</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=c1># Now install the ML ecosystem</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>    <span class=o>.</span><span class=n>uv_pip_install</span><span class=p>([</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>        <span class=c1># === Unsloth core ===</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>        <span class=s2>"unsloth"</span><span class=p>,</span>              <span class=c1># The star of the show - optimized training</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>        <span class=s2>"unsloth_zoo"</span><span class=p>,</span>          <span class=c1># Pre-configured models</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>        <span class=c1># === Quantization and efficiency ===</span>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>        <span class=s2>"bitsandbytes"</span><span class=p>,</span>         <span class=c1># 8-bit optimizers, quantization</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>        <span class=s2>"accelerate"</span><span class=p>,</span>           <span class=c1># Multi-GPU support, mixed precision</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>        <span class=s2>"xformers"</span><span class=p>,</span>             <span class=c1># Memory-efficient attention</span>
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>        <span class=s2>"peft"</span><span class=p>,</span>                 <span class=c1># LoRA and other parameter-efficient methods</span>
</span><span id=__span-10-25><a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>        <span class=s2>"trl"</span><span class=p>,</span>                  <span class=c1># Transformer Reinforcement Learning</span>
</span><span id=__span-10-26><a id=__codelineno-10-26 name=__codelineno-10-26 href=#__codelineno-10-26></a>        <span class=s2>"triton"</span><span class=p>,</span>               <span class=c1># GPU kernel language (used by flash-attn)</span>
</span><span id=__span-10-27><a id=__codelineno-10-27 name=__codelineno-10-27 href=#__codelineno-10-27></a>        <span class=s2>"cut_cross_entropy"</span><span class=p>,</span>    <span class=c1># Optimized loss computation</span>
</span><span id=__span-10-28><a id=__codelineno-10-28 name=__codelineno-10-28 href=#__codelineno-10-28></a>
</span><span id=__span-10-29><a id=__codelineno-10-29 name=__codelineno-10-29 href=#__codelineno-10-29></a>        <span class=c1># === Transformers ecosystem ===</span>
</span><span id=__span-10-30><a id=__codelineno-10-30 name=__codelineno-10-30 href=#__codelineno-10-30></a>        <span class=s2>"transformers"</span><span class=p>,</span>         <span class=c1># Hugging Face transformers</span>
</span><span id=__span-10-31><a id=__codelineno-10-31 name=__codelineno-10-31 href=#__codelineno-10-31></a>        <span class=s2>"timm"</span><span class=p>,</span>                 <span class=c1># Vision model utilities</span>
</span><span id=__span-10-32><a id=__codelineno-10-32 name=__codelineno-10-32 href=#__codelineno-10-32></a>
</span><span id=__span-10-33><a id=__codelineno-10-33 name=__codelineno-10-33 href=#__codelineno-10-33></a>        <span class=c1># === Training tools ===</span>
</span><span id=__span-10-34><a id=__codelineno-10-34 name=__codelineno-10-34 href=#__codelineno-10-34></a>        <span class=s2>"wandb"</span><span class=p>,</span>                <span class=c1># Experiment tracking (highly recommend!)</span>
</span><span id=__span-10-35><a id=__codelineno-10-35 name=__codelineno-10-35 href=#__codelineno-10-35></a>        <span class=s2>"weave"</span><span class=p>,</span>                <span class=c1># W&amp;B's LLM eval framework</span>
</span><span id=__span-10-36><a id=__codelineno-10-36 name=__codelineno-10-36 href=#__codelineno-10-36></a>        <span class=s2>"deepspeed"</span><span class=p>,</span>            <span class=c1># For multi-GPU training (optional here)</span>
</span><span id=__span-10-37><a id=__codelineno-10-37 name=__codelineno-10-37 href=#__codelineno-10-37></a>
</span><span id=__span-10-38><a id=__codelineno-10-38 name=__codelineno-10-38 href=#__codelineno-10-38></a>        <span class=c1># === Evaluation metrics ===</span>
</span><span id=__span-10-39><a id=__codelineno-10-39 name=__codelineno-10-39 href=#__codelineno-10-39></a>        <span class=s2>"nltk"</span><span class=p>,</span>                 <span class=c1># NLP toolkit</span>
</span><span id=__span-10-40><a id=__codelineno-10-40 name=__codelineno-10-40 href=#__codelineno-10-40></a>        <span class=s2>"rouge_score"</span><span class=p>,</span>          <span class=c1># ROUGE metrics</span>
</span><span id=__span-10-41><a id=__codelineno-10-41 name=__codelineno-10-41 href=#__codelineno-10-41></a>        <span class=s2>"bert_score"</span><span class=p>,</span>           <span class=c1># BERTScore</span>
</span><span id=__span-10-42><a id=__codelineno-10-42 name=__codelineno-10-42 href=#__codelineno-10-42></a>        <span class=s2>"jiwer"</span><span class=p>,</span>                <span class=c1># Word/Character Error Rate</span>
</span><span id=__span-10-43><a id=__codelineno-10-43 name=__codelineno-10-43 href=#__codelineno-10-43></a>        <span class=s2>"scikit-learn"</span><span class=p>,</span>         <span class=c1># General ML utilities</span>
</span><span id=__span-10-44><a id=__codelineno-10-44 name=__codelineno-10-44 href=#__codelineno-10-44></a>
</span><span id=__span-10-45><a id=__codelineno-10-45 name=__codelineno-10-45 href=#__codelineno-10-45></a>        <span class=c1># === Utilities ===</span>
</span><span id=__span-10-46><a id=__codelineno-10-46 name=__codelineno-10-46 href=#__codelineno-10-46></a>        <span class=s2>"pillow"</span><span class=p>,</span>               <span class=c1># Image processing</span>
</span><span id=__span-10-47><a id=__codelineno-10-47 name=__codelineno-10-47 href=#__codelineno-10-47></a>        <span class=s2>"opencv-python-headless"</span><span class=p>,</span>  <span class=c1># More image processing</span>
</span><span id=__span-10-48><a id=__codelineno-10-48 name=__codelineno-10-48 href=#__codelineno-10-48></a>        <span class=s2>"gradio"</span><span class=p>,</span>               <span class=c1># Quick UI demos</span>
</span><span id=__span-10-49><a id=__codelineno-10-49 name=__codelineno-10-49 href=#__codelineno-10-49></a>        <span class=s2>"hf_transfer"</span><span class=p>,</span>          <span class=c1># Faster Hugging Face downloads</span>
</span><span id=__span-10-50><a id=__codelineno-10-50 name=__codelineno-10-50 href=#__codelineno-10-50></a>    <span class=p>])</span>
</span><span id=__span-10-51><a id=__codelineno-10-51 name=__codelineno-10-51 href=#__codelineno-10-51></a>
</span><span id=__span-10-52><a id=__codelineno-10-52 name=__codelineno-10-52 href=#__codelineno-10-52></a>    <span class=c1># Set environment variables</span>
</span><span id=__span-10-53><a id=__codelineno-10-53 name=__codelineno-10-53 href=#__codelineno-10-53></a>    <span class=o>.</span><span class=n>env</span><span class=p>({</span>
</span><span id=__span-10-54><a id=__codelineno-10-54 name=__codelineno-10-54 href=#__codelineno-10-54></a>        <span class=c1># Enable fast multi-threaded downloads from Hugging Face</span>
</span><span id=__span-10-55><a id=__codelineno-10-55 name=__codelineno-10-55 href=#__codelineno-10-55></a>        <span class=c1># This can be 5-10x faster for large models!</span>
</span><span id=__span-10-56><a id=__codelineno-10-56 name=__codelineno-10-56 href=#__codelineno-10-56></a>        <span class=s2>"HF_HUB_ENABLE_HF_TRANSFER"</span><span class=p>:</span> <span class=s2>"1"</span><span class=p>,</span>
</span><span id=__span-10-57><a id=__codelineno-10-57 name=__codelineno-10-57 href=#__codelineno-10-57></a>
</span><span id=__span-10-58><a id=__codelineno-10-58 name=__codelineno-10-58 href=#__codelineno-10-58></a>        <span class=c1># Cache everything in the volume (so it persists)</span>
</span><span id=__span-10-59><a id=__codelineno-10-59 name=__codelineno-10-59 href=#__codelineno-10-59></a>        <span class=c1># This means we download models once, use them forever</span>
</span><span id=__span-10-60><a id=__codelineno-10-60 name=__codelineno-10-60 href=#__codelineno-10-60></a>        <span class=s2>"HF_HOME"</span><span class=p>:</span> <span class=s2>"/data/.cache"</span><span class=p>,</span>
</span><span id=__span-10-61><a id=__codelineno-10-61 name=__codelineno-10-61 href=#__codelineno-10-61></a>    <span class=p>})</span>
</span><span id=__span-10-62><a id=__codelineno-10-62 name=__codelineno-10-62 href=#__codelineno-10-62></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Key points:</strong></p> <ol> <li> <p><strong>uv_pip_install</strong>: Modal uses <code>uv</code> under the hood, which is stupid fast. Installing 20+ packages takes like 2 minutes instead of 10.</p> </li> <li> <p><strong>HF_HUB_ENABLE_HF_TRANSFER</strong>: This enables Hugging Face's <code>hf_transfer</code> library which downloads models in parallel. For a 16GB model, this can cut download time from 10 minutes to 2 minutes.</p> </li> <li> <p><strong>HF_HOME in volume</strong>: By setting this to <code>/data/.cache</code>, all Hugging Face downloads get cached in our volume. Download a model once, use it in all future runs.</p> </li> </ol> <blockquote> <p><strong>⏰ Build time warning</strong>: The first time you run this, Modal will build the image. It takes 10-15 minutes because of all the compilation (flash-attn especially). Grab a coffee. But here's the magic - Modal caches the image. Every subsequent run? Instant.</p> </blockquote> <h2 id=stage-1-downloading-datasets>Stage 1: Downloading Datasets<a class=headerlink href=#stage-1-downloading-datasets title="Permanent link">¶</a></h2> <p>Let's start with data. We're using Unsloth's LaTeX OCR dataset - images of math equations paired with their LaTeX code.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>FINETUNING_GPU_IMAGE</span><span class=p>,</span>     <span class=c1># Our big image with all dependencies</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>           <span class=c1># Mount /data volume</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>],</span>   <span class=c1># Inject HF token</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>24</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>              <span class=c1># Give it up to 24 hours (large datasets)</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=c1># Notice: No GPU! This runs on CPU to save money</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=p>)</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=k>def</span><span class=w> </span><span class=nf>download_datasets</span><span class=p>(</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=n>dataset_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"unsloth/LaTeX_OCR"</span><span class=p>,</span>  <span class=c1># HuggingFace dataset ID</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>    <span class=n>split</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"train"</span><span class=p>,</span>                      <span class=c1># Which split to download</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>    <span class=n>cache_dir</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"/data/.cache"</span><span class=p>,</span>           <span class=c1># Where to cache it</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a><span class=p>):</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=sd>    Download and cache a dataset from Hugging Face.</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a><span class=sd>    Runs on CPU (no GPU wasted on downloading files).</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a><span class=sd>    Dataset gets cached in the volume, so we only download once.</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a><span class=sd>    """</span>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a>    <span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_dataset</span>
</span><span id=__span-11-20><a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-11-21><a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a>
</span><span id=__span-11-22><a id=__codelineno-11-22 name=__codelineno-11-22 href=#__codelineno-11-22></a>    <span class=c1># Set HF token from our secret</span>
</span><span id=__span-11-23><a id=__codelineno-11-23 name=__codelineno-11-23 href=#__codelineno-11-23></a>    <span class=c1># Modal injects HUGGINGFACE_TOKEN from the secret we passed in</span>
</span><span id=__span-11-24><a id=__codelineno-11-24 name=__codelineno-11-24 href=#__codelineno-11-24></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-11-25><a id=__codelineno-11-25 name=__codelineno-11-25 href=#__codelineno-11-25></a>
</span><span id=__span-11-26><a id=__codelineno-11-26 name=__codelineno-11-26 href=#__codelineno-11-26></a>    <span class=c1># Make sure cache directory exists</span>
</span><span id=__span-11-27><a id=__codelineno-11-27 name=__codelineno-11-27 href=#__codelineno-11-27></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>cache_dir</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-11-28><a id=__codelineno-11-28 name=__codelineno-11-28 href=#__codelineno-11-28></a>
</span><span id=__span-11-29><a id=__codelineno-11-29 name=__codelineno-11-29 href=#__codelineno-11-29></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Downloading </span><span class=si>{</span><span class=n>dataset_name</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>split</span><span class=si>}</span><span class=s2> split)..."</span><span class=p>)</span>
</span><span id=__span-11-30><a id=__codelineno-11-30 name=__codelineno-11-30 href=#__codelineno-11-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Cache dir: </span><span class=si>{</span><span class=n>cache_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-11-31><a id=__codelineno-11-31 name=__codelineno-11-31 href=#__codelineno-11-31></a>
</span><span id=__span-11-32><a id=__codelineno-11-32 name=__codelineno-11-32 href=#__codelineno-11-32></a>    <span class=c1># Download the dataset</span>
</span><span id=__span-11-33><a id=__codelineno-11-33 name=__codelineno-11-33 href=#__codelineno-11-33></a>    <span class=c1># cache_dir tells it to save in our volume (persists across runs)</span>
</span><span id=__span-11-34><a id=__codelineno-11-34 name=__codelineno-11-34 href=#__codelineno-11-34></a>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>dataset_name</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=n>split</span><span class=p>,</span> <span class=n>cache_dir</span><span class=o>=</span><span class=n>cache_dir</span><span class=p>)</span>
</span><span id=__span-11-35><a id=__codelineno-11-35 name=__codelineno-11-35 href=#__codelineno-11-35></a>
</span><span id=__span-11-36><a id=__codelineno-11-36 name=__codelineno-11-36 href=#__codelineno-11-36></a>    <span class=c1># Print some info</span>
</span><span id=__span-11-37><a id=__codelineno-11-37 name=__codelineno-11-37 href=#__codelineno-11-37></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>✓ Dataset loaded successfully!"</span><span class=p>)</span>
</span><span id=__span-11-38><a id=__codelineno-11-38 name=__codelineno-11-38 href=#__codelineno-11-38></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Name: </span><span class=si>{</span><span class=n>dataset_name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-11-39><a id=__codelineno-11-39 name=__codelineno-11-39 href=#__codelineno-11-39></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Split: </span><span class=si>{</span><span class=n>split</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-11-40><a id=__codelineno-11-40 name=__codelineno-11-40 href=#__codelineno-11-40></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Number of samples: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-11-41><a id=__codelineno-11-41 name=__codelineno-11-41 href=#__codelineno-11-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Features: </span><span class=si>{</span><span class=n>dataset</span><span class=o>.</span><span class=n>features</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-11-42><a id=__codelineno-11-42 name=__codelineno-11-42 href=#__codelineno-11-42></a>
</span><span id=__span-11-43><a id=__codelineno-11-43 name=__codelineno-11-43 href=#__codelineno-11-43></a>    <span class=c1># CRITICAL: Commit changes to the volume</span>
</span><span id=__span-11-44><a id=__codelineno-11-44 name=__codelineno-11-44 href=#__codelineno-11-44></a>    <span class=c1># This persists the downloaded data</span>
</span><span id=__span-11-45><a id=__codelineno-11-45 name=__codelineno-11-45 href=#__codelineno-11-45></a>    <span class=n>exp_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-11-46><a id=__codelineno-11-46 name=__codelineno-11-46 href=#__codelineno-11-46></a>
</span><span id=__span-11-47><a id=__codelineno-11-47 name=__codelineno-11-47 href=#__codelineno-11-47></a>    <span class=c1># Return metadata</span>
</span><span id=__span-11-48><a id=__codelineno-11-48 name=__codelineno-11-48 href=#__codelineno-11-48></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-11-49><a id=__codelineno-11-49 name=__codelineno-11-49 href=#__codelineno-11-49></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-11-50><a id=__codelineno-11-50 name=__codelineno-11-50 href=#__codelineno-11-50></a>        <span class=s2>"dataset_name"</span><span class=p>:</span> <span class=n>dataset_name</span><span class=p>,</span>
</span><span id=__span-11-51><a id=__codelineno-11-51 name=__codelineno-11-51 href=#__codelineno-11-51></a>        <span class=s2>"num_samples"</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>),</span>
</span><span id=__span-11-52><a id=__codelineno-11-52 name=__codelineno-11-52 href=#__codelineno-11-52></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Why download separately?</strong></p> <p>You might be thinking "why not just download during training?" Here's why this is better:</p> <ol> <li><strong>No GPU waste</strong>: Downloading files doesn't need a GPU. Why pay $3.50/hr for an A100 when a CPU costs pennies?</li> <li><strong>Faster iteration</strong>: Download once, train many times with different hyperparameters</li> <li><strong>Debugging</strong>: If download fails, you know immediately. Not after 10 minutes of training setup.</li> </ol> <p><strong>Running it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Download the default dataset (LaTeX OCR)</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::download_datasets
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=c1># Or download a custom dataset</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::download_datasets<span class=w> </span><span class=se>\</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=w>  </span>--dataset-name<span class=o>=</span><span class=s2>"your-username/your-dataset"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a><span class=w>  </span>--split<span class=o>=</span><span class=s2>"train"</span>
</span></code></pre></div> <p>The first time you run this, it downloads and caches the dataset. Second time? Instant, because it's already in the volume.</p> <h2 id=stage-2-downloading-models>Stage 2: Downloading Models<a class=headerlink href=#stage-2-downloading-models title="Permanent link">¶</a></h2> <p>Same idea as datasets - download once, use forever.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>FINETUNING_GPU_IMAGE</span><span class=p>,</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=s2>"l40s:1"</span><span class=p>,</span>                   <span class=c1># Use a cheap GPU (L40S is ~$1/hr)</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>           <span class=c1># Mount our volume</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>],</span>   <span class=c1># Need HF token for model access</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>24</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=p>)</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=k>def</span><span class=w> </span><span class=nf>download_models</span><span class=p>(</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>BASE_MODEL_NAME</span><span class=p>,</span>      <span class=c1># "unsloth/gemma-3-4b-it"</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>    <span class=n>cache_dir</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"/data/.cache"</span><span class=p>,</span>        <span class=c1># Cache in volume</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=p>):</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a><span class=sd>    Download and cache the base model using Unsloth's FastVisionModel.</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a><span class=sd>    Why L40S GPU? Some models need a GPU just to load (for safety checks, etc.)</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a><span class=sd>    L40S is cheaper than A100, perfect for this one-time download.</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a><span class=sd>    """</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>    <span class=kn>from</span><span class=w> </span><span class=nn>unsloth</span><span class=w> </span><span class=kn>import</span> <span class=n>FastVisionModel</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>    <span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a>    <span class=c1># Set HF token</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Downloading model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Cache dir: </span><span class=si>{</span><span class=n>cache_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-27><a id=__codelineno-13-27 name=__codelineno-13-27 href=#__codelineno-13-27></a>
</span><span id=__span-13-28><a id=__codelineno-13-28 name=__codelineno-13-28 href=#__codelineno-13-28></a>    <span class=c1># Load the model with Unsloth's optimized loader</span>
</span><span id=__span-13-29><a id=__codelineno-13-29 name=__codelineno-13-29 href=#__codelineno-13-29></a>    <span class=c1># This downloads and caches the model weights</span>
</span><span id=__span-13-30><a id=__codelineno-13-30 name=__codelineno-13-30 href=#__codelineno-13-30></a>    <span class=n>model</span><span class=p>,</span> <span class=n>processor</span> <span class=o>=</span> <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-13-31><a id=__codelineno-13-31 name=__codelineno-13-31 href=#__codelineno-13-31></a>        <span class=n>model_name</span><span class=p>,</span>
</span><span id=__span-13-32><a id=__codelineno-13-32 name=__codelineno-13-32 href=#__codelineno-13-32></a>        <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>                    <span class=c1># Full precision for now</span>
</span><span id=__span-13-33><a id=__codelineno-13-33 name=__codelineno-13-33 href=#__codelineno-13-33></a>        <span class=n>use_gradient_checkpointing</span><span class=o>=</span><span class=s2>"unsloth"</span><span class=p>,</span>  <span class=c1># Unsloth's optimized checkpointing</span>
</span><span id=__span-13-34><a id=__codelineno-13-34 name=__codelineno-13-34 href=#__codelineno-13-34></a>        <span class=n>max_seq_length</span><span class=o>=</span><span class=mi>8000</span><span class=p>,</span>                    <span class=c1># Max context length</span>
</span><span id=__span-13-35><a id=__codelineno-13-35 name=__codelineno-13-35 href=#__codelineno-13-35></a>        <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>                   <span class=c1># Use bfloat16 (good balance)</span>
</span><span id=__span-13-36><a id=__codelineno-13-36 name=__codelineno-13-36 href=#__codelineno-13-36></a>    <span class=p>)</span>
</span><span id=__span-13-37><a id=__codelineno-13-37 name=__codelineno-13-37 href=#__codelineno-13-37></a>
</span><span id=__span-13-38><a id=__codelineno-13-38 name=__codelineno-13-38 href=#__codelineno-13-38></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>✓ Model downloaded and cached!"</span><span class=p>)</span>
</span><span id=__span-13-39><a id=__codelineno-13-39 name=__codelineno-13-39 href=#__codelineno-13-39></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-40><a id=__codelineno-13-40 name=__codelineno-13-40 href=#__codelineno-13-40></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Parameters: </span><span class=si>{</span><span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>p</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-41><a id=__codelineno-13-41 name=__codelineno-13-41 href=#__codelineno-13-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Cache: </span><span class=si>{</span><span class=n>cache_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-42><a id=__codelineno-13-42 name=__codelineno-13-42 href=#__codelineno-13-42></a>
</span><span id=__span-13-43><a id=__codelineno-13-43 name=__codelineno-13-43 href=#__codelineno-13-43></a>    <span class=c1># Commit to volume</span>
</span><span id=__span-13-44><a id=__codelineno-13-44 name=__codelineno-13-44 href=#__codelineno-13-44></a>    <span class=n>exp_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-13-45><a id=__codelineno-13-45 name=__codelineno-13-45 href=#__codelineno-13-45></a>
</span><span id=__span-13-46><a id=__codelineno-13-46 name=__codelineno-13-46 href=#__codelineno-13-46></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-13-47><a id=__codelineno-13-47 name=__codelineno-13-47 href=#__codelineno-13-47></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-13-48><a id=__codelineno-13-48 name=__codelineno-13-48 href=#__codelineno-13-48></a>        <span class=s2>"model_name"</span><span class=p>:</span> <span class=n>model_name</span><span class=p>,</span>
</span><span id=__span-13-49><a id=__codelineno-13-49 name=__codelineno-13-49 href=#__codelineno-13-49></a>        <span class=s2>"cache_dir"</span><span class=p>:</span> <span class=n>cache_dir</span><span class=p>,</span>
</span><span id=__span-13-50><a id=__codelineno-13-50 name=__codelineno-13-50 href=#__codelineno-13-50></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Why use a GPU for downloading?</strong></p> <p>Some models (especially gated ones like Gemma) run initialization code that requires a GPU. It's annoying, but that's how it is. We use an L40S because it's cheap (~$1/hr) and we only do this once.</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::download_models
</span></code></pre></div> <p>First run downloads ~16GB (takes a few minutes with <code>hf_transfer</code>). Every subsequent run? Instant.</p> <h2 id=stage-3-fine-tuning-with-lora>Stage 3: Fine-tuning with LoRA<a class=headerlink href=#stage-3-fine-tuning-with-lora title="Permanent link">¶</a></h2> <p>Alright, here's where the magic happens. We're going to fine-tune Gemma 3-4B to read LaTeX equations from images.</p> <h3 id=gpu-configuration>GPU Configuration<a class=headerlink href=#gpu-configuration title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=n>TRAIN_GPU</span> <span class=o>=</span> <span class=s2>"a100-80gb"</span>    <span class=c1># For 4B vision models, A100-80GB is ideal</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>NUM_GPUS</span> <span class=o>=</span> <span class=mi>1</span>                <span class=c1># Unsloth is optimized for single-GPU</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=n>TRAINING_GPU_CONFIG</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>TRAIN_GPU</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS</span><span class=si>}</span><span class=s2>"</span>
</span></code></pre></div> <p><strong>Why A100-80GB?</strong> - Vision-language models are memory-hungry (images take a lot of VRAM) - 4B model + images + gradients = needs ~40-60GB - A100-40GB might OOM, A100-80GB is comfortable</p> <p><strong>Why single GPU?</strong> - Unsloth is insanely optimized for single-GPU training - Multi-GPU adds communication overhead - For most fine-tuning, single A100 is faster than 2-4 smaller GPUs</p> <h3 id=the-training-function>The Training Function<a class=headerlink href=#the-training-function title="Permanent link">¶</a></h3> <p>This is a big one, so I'll break it into pieces:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>FINETUNING_GPU_IMAGE</span><span class=p>,</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>,</span> <span class=n>Secret</span><span class=o>.</span><span class=n>from_dotenv</span><span class=p>()],</span>  <span class=c1># Both Modal secrets and .env</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>TRAINING_GPU_CONFIG</span><span class=p>,</span>                              <span class=c1># "a100-80gb:1"</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>24</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>                                   <span class=c1># Long timeout for big datasets</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=k>def</span><span class=w> </span><span class=nf>fine_tune_unsloth</span><span class=p>(</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>    <span class=c1># Model and dataset config</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>    <span class=n>model_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>BASE_MODEL_NAME</span><span class=p>,</span>                 <span class=c1># Which model to fine-tune</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>    <span class=n>dataset_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"unsloth/LaTeX_OCR"</span><span class=p>,</span>          <span class=c1># Which dataset to use</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a>    <span class=n>dataset_split</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"train"</span><span class=p>,</span>                      <span class=c1># Which split</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>    <span class=n>output_dir</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>OUTPUT_DIR_DEFAULT</span><span class=p>,</span>              <span class=c1># Where to save checkpoints</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a>    <span class=n>hub_id</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                                <span class=c1># Push to HF Hub? (optional)</span>
</span><span id=__span-16-15><a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a>    <span class=n>max_samples</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                           <span class=c1># Limit dataset (for testing)</span>
</span><span id=__span-16-16><a id=__codelineno-16-16 name=__codelineno-16-16 href=#__codelineno-16-16></a>
</span><span id=__span-16-17><a id=__codelineno-16-17 name=__codelineno-16-17 href=#__codelineno-16-17></a>    <span class=c1># LoRA hyperparameters</span>
</span><span id=__span-16-18><a id=__codelineno-16-18 name=__codelineno-16-18 href=#__codelineno-16-18></a>    <span class=n>lora_r</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>32</span><span class=p>,</span>                                  <span class=c1># LoRA rank (higher = more capacity)</span>
</span><span id=__span-16-19><a id=__codelineno-16-19 name=__codelineno-16-19 href=#__codelineno-16-19></a>    <span class=n>lora_alpha</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>64</span><span class=p>,</span>                              <span class=c1># LoRA scaling (usually 2x rank)</span>
</span><span id=__span-16-20><a id=__codelineno-16-20 name=__codelineno-16-20 href=#__codelineno-16-20></a>    <span class=n>lora_dropout</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.0</span><span class=p>,</span>                         <span class=c1># Dropout in LoRA layers</span>
</span><span id=__span-16-21><a id=__codelineno-16-21 name=__codelineno-16-21 href=#__codelineno-16-21></a>
</span><span id=__span-16-22><a id=__codelineno-16-22 name=__codelineno-16-22 href=#__codelineno-16-22></a>    <span class=c1># Training hyperparameters</span>
</span><span id=__span-16-23><a id=__codelineno-16-23 name=__codelineno-16-23 href=#__codelineno-16-23></a>    <span class=n>per_device_train_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>              <span class=c1># Batch size per GPU</span>
</span><span id=__span-16-24><a id=__codelineno-16-24 name=__codelineno-16-24 href=#__codelineno-16-24></a>    <span class=n>gradient_accumulation_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>              <span class=c1># Effective batch = 4 * 4 = 16</span>
</span><span id=__span-16-25><a id=__codelineno-16-25 name=__codelineno-16-25 href=#__codelineno-16-25></a>    <span class=n>num_train_epochs</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>                         <span class=c1># How many epochs</span>
</span><span id=__span-16-26><a id=__codelineno-16-26 name=__codelineno-16-26 href=#__codelineno-16-26></a>    <span class=n>learning_rate</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>3e-4</span><span class=p>,</span>                       <span class=c1># Learning rate</span>
</span><span id=__span-16-27><a id=__codelineno-16-27 name=__codelineno-16-27 href=#__codelineno-16-27></a>    <span class=n>warmup_ratio</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.2</span><span class=p>,</span>                         <span class=c1># Warmup 20% of steps</span>
</span><span id=__span-16-28><a id=__codelineno-16-28 name=__codelineno-16-28 href=#__codelineno-16-28></a>    <span class=n>max_seq_length</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8000</span><span class=p>,</span>                        <span class=c1># Max tokens per sample</span>
</span><span id=__span-16-29><a id=__codelineno-16-29 name=__codelineno-16-29 href=#__codelineno-16-29></a>
</span><span id=__span-16-30><a id=__codelineno-16-30 name=__codelineno-16-30 href=#__codelineno-16-30></a>    <span class=c1># Checkpointing</span>
</span><span id=__span-16-31><a id=__codelineno-16-31 name=__codelineno-16-31 href=#__codelineno-16-31></a>    <span class=n>save_strategy</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"steps"</span><span class=p>,</span>                      <span class=c1># Save by steps (not epochs)</span>
</span><span id=__span-16-32><a id=__codelineno-16-32 name=__codelineno-16-32 href=#__codelineno-16-32></a>    <span class=n>save_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>250</span><span class=p>,</span>                             <span class=c1># Save every 250 steps</span>
</span><span id=__span-16-33><a id=__codelineno-16-33 name=__codelineno-16-33 href=#__codelineno-16-33></a>    <span class=n>save_total_limit</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span><span class=p>,</span>                        <span class=c1># Keep only 20 checkpoints</span>
</span><span id=__span-16-34><a id=__codelineno-16-34 name=__codelineno-16-34 href=#__codelineno-16-34></a>    <span class=n>logging_steps</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10</span><span class=p>,</span>                           <span class=c1># Log every 10 steps</span>
</span><span id=__span-16-35><a id=__codelineno-16-35 name=__codelineno-16-35 href=#__codelineno-16-35></a>
</span><span id=__span-16-36><a id=__codelineno-16-36 name=__codelineno-16-36 href=#__codelineno-16-36></a>    <span class=c1># Weights &amp; Biases</span>
</span><span id=__span-16-37><a id=__codelineno-16-37 name=__codelineno-16-37 href=#__codelineno-16-37></a>    <span class=n>wandb_project</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>WANDB_PROJECT_DEFAULT</span><span class=p>,</span>        <span class=c1># W&amp;B project name</span>
</span><span id=__span-16-38><a id=__codelineno-16-38 name=__codelineno-16-38 href=#__codelineno-16-38></a>    <span class=n>wandb_run_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                        <span class=c1># W&amp;B run name (auto-generated)</span>
</span><span id=__span-16-39><a id=__codelineno-16-39 name=__codelineno-16-39 href=#__codelineno-16-39></a><span class=p>):</span>
</span><span id=__span-16-40><a id=__codelineno-16-40 name=__codelineno-16-40 href=#__codelineno-16-40></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-16-41><a id=__codelineno-16-41 name=__codelineno-16-41 href=#__codelineno-16-41></a><span class=sd>    Fine-tune Gemma 3-4B vision model with LoRA using Unsloth.</span>
</span><span id=__span-16-42><a id=__codelineno-16-42 name=__codelineno-16-42 href=#__codelineno-16-42></a>
</span><span id=__span-16-43><a id=__codelineno-16-43 name=__codelineno-16-43 href=#__codelineno-16-43></a><span class=sd>    This is based on Unsloth's Colab notebook but productionized for Modal.</span>
</span><span id=__span-16-44><a id=__codelineno-16-44 name=__codelineno-16-44 href=#__codelineno-16-44></a><span class=sd>    """</span>
</span><span id=__span-16-45><a id=__codelineno-16-45 name=__codelineno-16-45 href=#__codelineno-16-45></a>    <span class=kn>from</span><span class=w> </span><span class=nn>unsloth</span><span class=w> </span><span class=kn>import</span> <span class=n>FastVisionModel</span><span class=p>,</span> <span class=n>get_chat_template</span>
</span><span id=__span-16-46><a id=__codelineno-16-46 name=__codelineno-16-46 href=#__codelineno-16-46></a>    <span class=kn>from</span><span class=w> </span><span class=nn>unsloth.trainer</span><span class=w> </span><span class=kn>import</span> <span class=n>UnslothVisionDataCollator</span>
</span><span id=__span-16-47><a id=__codelineno-16-47 name=__codelineno-16-47 href=#__codelineno-16-47></a>    <span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_dataset</span>
</span><span id=__span-16-48><a id=__codelineno-16-48 name=__codelineno-16-48 href=#__codelineno-16-48></a>    <span class=kn>from</span><span class=w> </span><span class=nn>trl</span><span class=w> </span><span class=kn>import</span> <span class=n>SFTTrainer</span><span class=p>,</span> <span class=n>SFTConfig</span>
</span><span id=__span-16-49><a id=__codelineno-16-49 name=__codelineno-16-49 href=#__codelineno-16-49></a>    <span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-16-50><a id=__codelineno-16-50 name=__codelineno-16-50 href=#__codelineno-16-50></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-16-51><a id=__codelineno-16-51 name=__codelineno-16-51 href=#__codelineno-16-51></a>    <span class=kn>from</span><span class=w> </span><span class=nn>datetime</span><span class=w> </span><span class=kn>import</span> <span class=n>datetime</span>
</span></code></pre></div> <p>Let me continue with the rest of the training function with detailed comments:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>    <span class=c1># === Environment Setup ===</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"SETTING UP TRAINING ENVIRONMENT"</span><span class=p>)</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>    <span class=c1># Set up authentication tokens</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"WANDB_API_KEY"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"WANDB_API_KEY"</span><span class=p>]</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"WANDB_PROJECT"</span><span class=p>]</span> <span class=o>=</span> <span class=n>wandb_project</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>    <span class=c1># Auto-generate W&amp;B run name if not provided</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>    <span class=c1># Format: finetune_gemma-3-4b-it_20250110_143022</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>    <span class=k>if</span> <span class=n>wandb_run_name</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>        <span class=n>timestamp</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s2>"%Y%m</span><span class=si>%d</span><span class=s2>_%H%M%S"</span><span class=p>)</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>        <span class=n>model_short</span> <span class=o>=</span> <span class=n>model_path</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>"/"</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>  <span class=c1># Extract "gemma-3-4b-it" from path</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>        <span class=n>wandb_run_name</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"finetune_</span><span class=si>{</span><span class=n>model_short</span><span class=si>}</span><span class=s2>_</span><span class=si>{</span><span class=n>timestamp</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"WANDB_RUN_NAME"</span><span class=p>]</span> <span class=o>=</span> <span class=n>wandb_run_name</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a>    <span class=c1># Memory optimization: only use GPU 0</span>
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a>    <span class=c1># (In single-GPU setup, this prevents memory fragmentation)</span>
</span><span id=__span-17-22><a id=__codelineno-17-22 name=__codelineno-17-22 href=#__codelineno-17-22></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"CUDA_VISIBLE_DEVICES"</span><span class=p>]</span> <span class=o>=</span> <span class=s2>"0"</span>
</span><span id=__span-17-23><a id=__codelineno-17-23 name=__codelineno-17-23 href=#__codelineno-17-23></a>
</span><span id=__span-17-24><a id=__codelineno-17-24 name=__codelineno-17-24 href=#__codelineno-17-24></a>    <span class=c1># Disable torch compile (can cause issues with some models)</span>
</span><span id=__span-17-25><a id=__codelineno-17-25 name=__codelineno-17-25 href=#__codelineno-17-25></a>    <span class=n>torch</span><span class=o>.</span><span class=n>_dynamo</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>disable</span> <span class=o>=</span> <span class=kc>True</span>
</span><span id=__span-17-26><a id=__codelineno-17-26 name=__codelineno-17-26 href=#__codelineno-17-26></a>
</span><span id=__span-17-27><a id=__codelineno-17-27 name=__codelineno-17-27 href=#__codelineno-17-27></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model: </span><span class=si>{</span><span class=n>model_path</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-28><a id=__codelineno-17-28 name=__codelineno-17-28 href=#__codelineno-17-28></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Dataset: </span><span class=si>{</span><span class=n>dataset_name</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>dataset_split</span><span class=si>}</span><span class=s2>)"</span><span class=p>)</span>
</span><span id=__span-17-29><a id=__codelineno-17-29 name=__codelineno-17-29 href=#__codelineno-17-29></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Output: </span><span class=si>{</span><span class=n>output_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-30><a id=__codelineno-17-30 name=__codelineno-17-30 href=#__codelineno-17-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"W&amp;B: </span><span class=si>{</span><span class=n>wandb_project</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>wandb_run_name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-31><a id=__codelineno-17-31 name=__codelineno-17-31 href=#__codelineno-17-31></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-32><a id=__codelineno-17-32 name=__codelineno-17-32 href=#__codelineno-17-32></a>
</span><span id=__span-17-33><a id=__codelineno-17-33 name=__codelineno-17-33 href=#__codelineno-17-33></a>    <span class=c1># === Load Model with LoRA ===</span>
</span><span id=__span-17-34><a id=__codelineno-17-34 name=__codelineno-17-34 href=#__codelineno-17-34></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-35><a id=__codelineno-17-35 name=__codelineno-17-35 href=#__codelineno-17-35></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"LOADING MODEL AND ADDING LORA ADAPTERS"</span><span class=p>)</span>
</span><span id=__span-17-36><a id=__codelineno-17-36 name=__codelineno-17-36 href=#__codelineno-17-36></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-37><a id=__codelineno-17-37 name=__codelineno-17-37 href=#__codelineno-17-37></a>
</span><span id=__span-17-38><a id=__codelineno-17-38 name=__codelineno-17-38 href=#__codelineno-17-38></a>    <span class=c1># Load base model</span>
</span><span id=__span-17-39><a id=__codelineno-17-39 name=__codelineno-17-39 href=#__codelineno-17-39></a>    <span class=c1># Unsloth's FastVisionModel is a drop-in replacement for HF's model</span>
</span><span id=__span-17-40><a id=__codelineno-17-40 name=__codelineno-17-40 href=#__codelineno-17-40></a>    <span class=c1># but with optimized kernels and memory usage</span>
</span><span id=__span-17-41><a id=__codelineno-17-41 name=__codelineno-17-41 href=#__codelineno-17-41></a>    <span class=n>model</span><span class=p>,</span> <span class=n>processor</span> <span class=o>=</span> <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-17-42><a id=__codelineno-17-42 name=__codelineno-17-42 href=#__codelineno-17-42></a>        <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-17-43><a id=__codelineno-17-43 name=__codelineno-17-43 href=#__codelineno-17-43></a>        <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>                    <span class=c1># Use full precision (more accurate)</span>
</span><span id=__span-17-44><a id=__codelineno-17-44 name=__codelineno-17-44 href=#__codelineno-17-44></a>        <span class=n>use_gradient_checkpointing</span><span class=o>=</span><span class=s2>"unsloth"</span><span class=p>,</span>  <span class=c1># Unsloth's optimized checkpointing</span>
</span><span id=__span-17-45><a id=__codelineno-17-45 name=__codelineno-17-45 href=#__codelineno-17-45></a>        <span class=n>max_seq_length</span><span class=o>=</span><span class=n>max_seq_length</span><span class=p>,</span>         <span class=c1># Context window</span>
</span><span id=__span-17-46><a id=__codelineno-17-46 name=__codelineno-17-46 href=#__codelineno-17-46></a>        <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>                   <span class=c1># bfloat16 is great for training</span>
</span><span id=__span-17-47><a id=__codelineno-17-47 name=__codelineno-17-47 href=#__codelineno-17-47></a>    <span class=p>)</span>
</span><span id=__span-17-48><a id=__codelineno-17-48 name=__codelineno-17-48 href=#__codelineno-17-48></a>
</span><span id=__span-17-49><a id=__codelineno-17-49 name=__codelineno-17-49 href=#__codelineno-17-49></a>    <span class=c1># Add LoRA adapters</span>
</span><span id=__span-17-50><a id=__codelineno-17-50 name=__codelineno-17-50 href=#__codelineno-17-50></a>    <span class=c1># LoRA (Low-Rank Adaptation) trains small adapter layers instead of the full model</span>
</span><span id=__span-17-51><a id=__codelineno-17-51 name=__codelineno-17-51 href=#__codelineno-17-51></a>    <span class=c1># This is WAY more efficient - we only train ~1% of parameters!</span>
</span><span id=__span-17-52><a id=__codelineno-17-52 name=__codelineno-17-52 href=#__codelineno-17-52></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>get_peft_model</span><span class=p>(</span>
</span><span id=__span-17-53><a id=__codelineno-17-53 name=__codelineno-17-53 href=#__codelineno-17-53></a>        <span class=n>model</span><span class=p>,</span>
</span><span id=__span-17-54><a id=__codelineno-17-54 name=__codelineno-17-54 href=#__codelineno-17-54></a>        <span class=n>finetune_vision_layers</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>      <span class=c1># Keep vision encoder frozen</span>
</span><span id=__span-17-55><a id=__codelineno-17-55 name=__codelineno-17-55 href=#__codelineno-17-55></a>        <span class=n>finetune_language_layers</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>     <span class=c1># Train the language model part</span>
</span><span id=__span-17-56><a id=__codelineno-17-56 name=__codelineno-17-56 href=#__codelineno-17-56></a>        <span class=n>finetune_attention_modules</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>   <span class=c1># Add LoRA to attention</span>
</span><span id=__span-17-57><a id=__codelineno-17-57 name=__codelineno-17-57 href=#__codelineno-17-57></a>        <span class=n>finetune_mlp_modules</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>         <span class=c1># Add LoRA to MLPs</span>
</span><span id=__span-17-58><a id=__codelineno-17-58 name=__codelineno-17-58 href=#__codelineno-17-58></a>
</span><span id=__span-17-59><a id=__codelineno-17-59 name=__codelineno-17-59 href=#__codelineno-17-59></a>        <span class=c1># LoRA config</span>
</span><span id=__span-17-60><a id=__codelineno-17-60 name=__codelineno-17-60 href=#__codelineno-17-60></a>        <span class=n>r</span><span class=o>=</span><span class=n>lora_r</span><span class=p>,</span>                          <span class=c1># Rank (32 is a good default)</span>
</span><span id=__span-17-61><a id=__codelineno-17-61 name=__codelineno-17-61 href=#__codelineno-17-61></a>        <span class=n>lora_alpha</span><span class=o>=</span><span class=n>lora_alpha</span><span class=p>,</span>             <span class=c1># Scaling (usually 2x rank)</span>
</span><span id=__span-17-62><a id=__codelineno-17-62 name=__codelineno-17-62 href=#__codelineno-17-62></a>        <span class=n>lora_dropout</span><span class=o>=</span><span class=n>lora_dropout</span><span class=p>,</span>         <span class=c1># Dropout (0.0 often works fine)</span>
</span><span id=__span-17-63><a id=__codelineno-17-63 name=__codelineno-17-63 href=#__codelineno-17-63></a>        <span class=n>bias</span><span class=o>=</span><span class=s2>"none"</span><span class=p>,</span>                       <span class=c1># Don't train bias terms</span>
</span><span id=__span-17-64><a id=__codelineno-17-64 name=__codelineno-17-64 href=#__codelineno-17-64></a>        <span class=n>random_state</span><span class=o>=</span><span class=mi>3407</span><span class=p>,</span>                 <span class=c1># For reproducibility</span>
</span><span id=__span-17-65><a id=__codelineno-17-65 name=__codelineno-17-65 href=#__codelineno-17-65></a>        <span class=n>target_modules</span><span class=o>=</span><span class=s2>"all-linear"</span><span class=p>,</span>       <span class=c1># Apply to all linear layers</span>
</span><span id=__span-17-66><a id=__codelineno-17-66 name=__codelineno-17-66 href=#__codelineno-17-66></a>        <span class=n>modules_to_save</span><span class=o>=</span><span class=p>[</span><span class=s2>"lm_head"</span><span class=p>,</span> <span class=s2>"embed_tokens"</span><span class=p>],</span>  <span class=c1># Also train these</span>
</span><span id=__span-17-67><a id=__codelineno-17-67 name=__codelineno-17-67 href=#__codelineno-17-67></a>    <span class=p>)</span>
</span><span id=__span-17-68><a id=__codelineno-17-68 name=__codelineno-17-68 href=#__codelineno-17-68></a>
</span><span id=__span-17-69><a id=__codelineno-17-69 name=__codelineno-17-69 href=#__codelineno-17-69></a>    <span class=c1># Set up chat template for the model</span>
</span><span id=__span-17-70><a id=__codelineno-17-70 name=__codelineno-17-70 href=#__codelineno-17-70></a>    <span class=c1># This formats inputs/outputs correctly for Gemma</span>
</span><span id=__span-17-71><a id=__codelineno-17-71 name=__codelineno-17-71 href=#__codelineno-17-71></a>    <span class=n>processor</span> <span class=o>=</span> <span class=n>get_chat_template</span><span class=p>(</span><span class=n>processor</span><span class=p>,</span> <span class=s2>"gemma-3"</span><span class=p>)</span>
</span><span id=__span-17-72><a id=__codelineno-17-72 name=__codelineno-17-72 href=#__codelineno-17-72></a>
</span><span id=__span-17-73><a id=__codelineno-17-73 name=__codelineno-17-73 href=#__codelineno-17-73></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Model loaded with LoRA adapters"</span><span class=p>)</span>
</span><span id=__span-17-74><a id=__codelineno-17-74 name=__codelineno-17-74 href=#__codelineno-17-74></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Base model: </span><span class=si>{</span><span class=n>model_path</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-75><a id=__codelineno-17-75 name=__codelineno-17-75 href=#__codelineno-17-75></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - LoRA rank: </span><span class=si>{</span><span class=n>lora_r</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-76><a id=__codelineno-17-76 name=__codelineno-17-76 href=#__codelineno-17-76></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Trainable params: ~1-2% of total"</span><span class=p>)</span>
</span><span id=__span-17-77><a id=__codelineno-17-77 name=__codelineno-17-77 href=#__codelineno-17-77></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-78><a id=__codelineno-17-78 name=__codelineno-17-78 href=#__codelineno-17-78></a>
</span><span id=__span-17-79><a id=__codelineno-17-79 name=__codelineno-17-79 href=#__codelineno-17-79></a>    <span class=c1># === Load and Prepare Dataset ===</span>
</span><span id=__span-17-80><a id=__codelineno-17-80 name=__codelineno-17-80 href=#__codelineno-17-80></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-81><a id=__codelineno-17-81 name=__codelineno-17-81 href=#__codelineno-17-81></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"LOADING DATASET"</span><span class=p>)</span>
</span><span id=__span-17-82><a id=__codelineno-17-82 name=__codelineno-17-82 href=#__codelineno-17-82></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-83><a id=__codelineno-17-83 name=__codelineno-17-83 href=#__codelineno-17-83></a>
</span><span id=__span-17-84><a id=__codelineno-17-84 name=__codelineno-17-84 href=#__codelineno-17-84></a>    <span class=c1># Load dataset from cache (downloaded in Stage 1)</span>
</span><span id=__span-17-85><a id=__codelineno-17-85 name=__codelineno-17-85 href=#__codelineno-17-85></a>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>dataset_name</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=n>dataset_split</span><span class=p>)</span>
</span><span id=__span-17-86><a id=__codelineno-17-86 name=__codelineno-17-86 href=#__codelineno-17-86></a>
</span><span id=__span-17-87><a id=__codelineno-17-87 name=__codelineno-17-87 href=#__codelineno-17-87></a>    <span class=c1># Limit dataset size if specified (useful for testing)</span>
</span><span id=__span-17-88><a id=__codelineno-17-88 name=__codelineno-17-88 href=#__codelineno-17-88></a>    <span class=k>if</span> <span class=n>max_samples</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>max_samples</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-17-89><a id=__codelineno-17-89 name=__codelineno-17-89 href=#__codelineno-17-89></a>        <span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>min</span><span class=p>(</span><span class=n>max_samples</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>))))</span>
</span><span id=__span-17-90><a id=__codelineno-17-90 name=__codelineno-17-90 href=#__codelineno-17-90></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"⚠️  Limited to </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2> samples for testing"</span><span class=p>)</span>
</span><span id=__span-17-91><a id=__codelineno-17-91 name=__codelineno-17-91 href=#__codelineno-17-91></a>
</span><span id=__span-17-92><a id=__codelineno-17-92 name=__codelineno-17-92 href=#__codelineno-17-92></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Dataset loaded: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2> samples"</span><span class=p>)</span>
</span><span id=__span-17-93><a id=__codelineno-17-93 name=__codelineno-17-93 href=#__codelineno-17-93></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-94><a id=__codelineno-17-94 name=__codelineno-17-94 href=#__codelineno-17-94></a>
</span><span id=__span-17-95><a id=__codelineno-17-95 name=__codelineno-17-95 href=#__codelineno-17-95></a>    <span class=c1># === Format Dataset ===</span>
</span><span id=__span-17-96><a id=__codelineno-17-96 name=__codelineno-17-96 href=#__codelineno-17-96></a>    <span class=c1># Convert dataset to chat format that Gemma expects</span>
</span><span id=__span-17-97><a id=__codelineno-17-97 name=__codelineno-17-97 href=#__codelineno-17-97></a>    <span class=c1># Each sample has an image and corresponding LaTeX code</span>
</span><span id=__span-17-98><a id=__codelineno-17-98 name=__codelineno-17-98 href=#__codelineno-17-98></a>
</span><span id=__span-17-99><a id=__codelineno-17-99 name=__codelineno-17-99 href=#__codelineno-17-99></a>    <span class=n>instruction</span> <span class=o>=</span> <span class=s2>"Write the LaTeX representation for this image."</span>
</span><span id=__span-17-100><a id=__codelineno-17-100 name=__codelineno-17-100 href=#__codelineno-17-100></a>
</span><span id=__span-17-101><a id=__codelineno-17-101 name=__codelineno-17-101 href=#__codelineno-17-101></a>    <span class=k>def</span><span class=w> </span><span class=nf>convert_to_conversation</span><span class=p>(</span><span class=n>sample</span><span class=p>):</span>
</span><span id=__span-17-102><a id=__codelineno-17-102 name=__codelineno-17-102 href=#__codelineno-17-102></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-17-103><a id=__codelineno-17-103 name=__codelineno-17-103 href=#__codelineno-17-103></a><span class=sd>        Convert a dataset sample to chat format.</span>
</span><span id=__span-17-104><a id=__codelineno-17-104 name=__codelineno-17-104 href=#__codelineno-17-104></a>
</span><span id=__span-17-105><a id=__codelineno-17-105 name=__codelineno-17-105 href=#__codelineno-17-105></a><span class=sd>        Input sample has:</span>
</span><span id=__span-17-106><a id=__codelineno-17-106 name=__codelineno-17-106 href=#__codelineno-17-106></a><span class=sd>          - "image": PIL Image of equation</span>
</span><span id=__span-17-107><a id=__codelineno-17-107 name=__codelineno-17-107 href=#__codelineno-17-107></a><span class=sd>          - "text": LaTeX code for that equation</span>
</span><span id=__span-17-108><a id=__codelineno-17-108 name=__codelineno-17-108 href=#__codelineno-17-108></a>
</span><span id=__span-17-109><a id=__codelineno-17-109 name=__codelineno-17-109 href=#__codelineno-17-109></a><span class=sd>        Output format:</span>
</span><span id=__span-17-110><a id=__codelineno-17-110 name=__codelineno-17-110 href=#__codelineno-17-110></a><span class=sd>          - User message: instruction + image</span>
</span><span id=__span-17-111><a id=__codelineno-17-111 name=__codelineno-17-111 href=#__codelineno-17-111></a><span class=sd>          - Assistant message: LaTeX code</span>
</span><span id=__span-17-112><a id=__codelineno-17-112 name=__codelineno-17-112 href=#__codelineno-17-112></a><span class=sd>        """</span>
</span><span id=__span-17-113><a id=__codelineno-17-113 name=__codelineno-17-113 href=#__codelineno-17-113></a>        <span class=n>conversation</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-17-114><a id=__codelineno-17-114 name=__codelineno-17-114 href=#__codelineno-17-114></a>            <span class=p>{</span>
</span><span id=__span-17-115><a id=__codelineno-17-115 name=__codelineno-17-115 href=#__codelineno-17-115></a>                <span class=s2>"role"</span><span class=p>:</span> <span class=s2>"user"</span><span class=p>,</span>
</span><span id=__span-17-116><a id=__codelineno-17-116 name=__codelineno-17-116 href=#__codelineno-17-116></a>                <span class=s2>"content"</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-17-117><a id=__codelineno-17-117 name=__codelineno-17-117 href=#__codelineno-17-117></a>                    <span class=p>{</span><span class=s2>"type"</span><span class=p>:</span> <span class=s2>"text"</span><span class=p>,</span> <span class=s2>"text"</span><span class=p>:</span> <span class=n>instruction</span><span class=p>},</span>
</span><span id=__span-17-118><a id=__codelineno-17-118 name=__codelineno-17-118 href=#__codelineno-17-118></a>                    <span class=p>{</span><span class=s2>"type"</span><span class=p>:</span> <span class=s2>"image"</span><span class=p>,</span> <span class=s2>"image"</span><span class=p>:</span> <span class=n>sample</span><span class=p>[</span><span class=s2>"image"</span><span class=p>]},</span>
</span><span id=__span-17-119><a id=__codelineno-17-119 name=__codelineno-17-119 href=#__codelineno-17-119></a>                <span class=p>],</span>
</span><span id=__span-17-120><a id=__codelineno-17-120 name=__codelineno-17-120 href=#__codelineno-17-120></a>            <span class=p>},</span>
</span><span id=__span-17-121><a id=__codelineno-17-121 name=__codelineno-17-121 href=#__codelineno-17-121></a>            <span class=p>{</span>
</span><span id=__span-17-122><a id=__codelineno-17-122 name=__codelineno-17-122 href=#__codelineno-17-122></a>                <span class=s2>"role"</span><span class=p>:</span> <span class=s2>"assistant"</span><span class=p>,</span>
</span><span id=__span-17-123><a id=__codelineno-17-123 name=__codelineno-17-123 href=#__codelineno-17-123></a>                <span class=s2>"content"</span><span class=p>:</span> <span class=p>[{</span><span class=s2>"type"</span><span class=p>:</span> <span class=s2>"text"</span><span class=p>,</span> <span class=s2>"text"</span><span class=p>:</span> <span class=n>sample</span><span class=p>[</span><span class=s2>"text"</span><span class=p>]}],</span>
</span><span id=__span-17-124><a id=__codelineno-17-124 name=__codelineno-17-124 href=#__codelineno-17-124></a>            <span class=p>},</span>
</span><span id=__span-17-125><a id=__codelineno-17-125 name=__codelineno-17-125 href=#__codelineno-17-125></a>        <span class=p>]</span>
</span><span id=__span-17-126><a id=__codelineno-17-126 name=__codelineno-17-126 href=#__codelineno-17-126></a>        <span class=k>return</span> <span class=p>{</span><span class=s2>"messages"</span><span class=p>:</span> <span class=n>conversation</span><span class=p>}</span>
</span><span id=__span-17-127><a id=__codelineno-17-127 name=__codelineno-17-127 href=#__codelineno-17-127></a>
</span><span id=__span-17-128><a id=__codelineno-17-128 name=__codelineno-17-128 href=#__codelineno-17-128></a>    <span class=c1># Convert all samples</span>
</span><span id=__span-17-129><a id=__codelineno-17-129 name=__codelineno-17-129 href=#__codelineno-17-129></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Converting dataset to chat format..."</span><span class=p>)</span>
</span><span id=__span-17-130><a id=__codelineno-17-130 name=__codelineno-17-130 href=#__codelineno-17-130></a>    <span class=n>converted_dataset</span> <span class=o>=</span> <span class=p>[</span><span class=n>convert_to_conversation</span><span class=p>(</span><span class=n>sample</span><span class=p>)</span> <span class=k>for</span> <span class=n>sample</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>]</span>
</span><span id=__span-17-131><a id=__codelineno-17-131 name=__codelineno-17-131 href=#__codelineno-17-131></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Converted </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>converted_dataset</span><span class=p>)</span><span class=si>}</span><span class=s2> samples"</span><span class=p>)</span>
</span><span id=__span-17-132><a id=__codelineno-17-132 name=__codelineno-17-132 href=#__codelineno-17-132></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-133><a id=__codelineno-17-133 name=__codelineno-17-133 href=#__codelineno-17-133></a>
</span><span id=__span-17-134><a id=__codelineno-17-134 name=__codelineno-17-134 href=#__codelineno-17-134></a>    <span class=c1># === Training Setup ===</span>
</span><span id=__span-17-135><a id=__codelineno-17-135 name=__codelineno-17-135 href=#__codelineno-17-135></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-136><a id=__codelineno-17-136 name=__codelineno-17-136 href=#__codelineno-17-136></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"STARTING TRAINING"</span><span class=p>)</span>
</span><span id=__span-17-137><a id=__codelineno-17-137 name=__codelineno-17-137 href=#__codelineno-17-137></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-138><a id=__codelineno-17-138 name=__codelineno-17-138 href=#__codelineno-17-138></a>
</span><span id=__span-17-139><a id=__codelineno-17-139 name=__codelineno-17-139 href=#__codelineno-17-139></a>    <span class=c1># Enable training mode (sets up gradient computation)</span>
</span><span id=__span-17-140><a id=__codelineno-17-140 name=__codelineno-17-140 href=#__codelineno-17-140></a>    <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>for_training</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-17-141><a id=__codelineno-17-141 name=__codelineno-17-141 href=#__codelineno-17-141></a>
</span><span id=__span-17-142><a id=__codelineno-17-142 name=__codelineno-17-142 href=#__codelineno-17-142></a>    <span class=c1># Create trainer</span>
</span><span id=__span-17-143><a id=__codelineno-17-143 name=__codelineno-17-143 href=#__codelineno-17-143></a>    <span class=c1># SFTTrainer is from TRL library - supervised fine-tuning trainer</span>
</span><span id=__span-17-144><a id=__codelineno-17-144 name=__codelineno-17-144 href=#__codelineno-17-144></a>    <span class=n>trainer</span> <span class=o>=</span> <span class=n>SFTTrainer</span><span class=p>(</span>
</span><span id=__span-17-145><a id=__codelineno-17-145 name=__codelineno-17-145 href=#__codelineno-17-145></a>        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span><span id=__span-17-146><a id=__codelineno-17-146 name=__codelineno-17-146 href=#__codelineno-17-146></a>        <span class=n>train_dataset</span><span class=o>=</span><span class=n>converted_dataset</span><span class=p>,</span>
</span><span id=__span-17-147><a id=__codelineno-17-147 name=__codelineno-17-147 href=#__codelineno-17-147></a>        <span class=n>processing_class</span><span class=o>=</span><span class=n>processor</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span>
</span><span id=__span-17-148><a id=__codelineno-17-148 name=__codelineno-17-148 href=#__codelineno-17-148></a>
</span><span id=__span-17-149><a id=__codelineno-17-149 name=__codelineno-17-149 href=#__codelineno-17-149></a>        <span class=c1># Data collator handles batching images + text</span>
</span><span id=__span-17-150><a id=__codelineno-17-150 name=__codelineno-17-150 href=#__codelineno-17-150></a>        <span class=c1># Unsloth's collator is optimized for vision-language models</span>
</span><span id=__span-17-151><a id=__codelineno-17-151 name=__codelineno-17-151 href=#__codelineno-17-151></a>        <span class=n>data_collator</span><span class=o>=</span><span class=n>UnslothVisionDataCollator</span><span class=p>(</span>
</span><span id=__span-17-152><a id=__codelineno-17-152 name=__codelineno-17-152 href=#__codelineno-17-152></a>            <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span><span id=__span-17-153><a id=__codelineno-17-153 name=__codelineno-17-153 href=#__codelineno-17-153></a>            <span class=n>processor</span><span class=o>=</span><span class=n>processor</span>
</span><span id=__span-17-154><a id=__codelineno-17-154 name=__codelineno-17-154 href=#__codelineno-17-154></a>        <span class=p>),</span>
</span><span id=__span-17-155><a id=__codelineno-17-155 name=__codelineno-17-155 href=#__codelineno-17-155></a>
</span><span id=__span-17-156><a id=__codelineno-17-156 name=__codelineno-17-156 href=#__codelineno-17-156></a>        <span class=c1># Training arguments</span>
</span><span id=__span-17-157><a id=__codelineno-17-157 name=__codelineno-17-157 href=#__codelineno-17-157></a>        <span class=n>args</span><span class=o>=</span><span class=n>SFTConfig</span><span class=p>(</span>
</span><span id=__span-17-158><a id=__codelineno-17-158 name=__codelineno-17-158 href=#__codelineno-17-158></a>            <span class=c1># === Batch size config ===</span>
</span><span id=__span-17-159><a id=__codelineno-17-159 name=__codelineno-17-159 href=#__codelineno-17-159></a>            <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=n>per_device_train_batch_size</span><span class=p>,</span>
</span><span id=__span-17-160><a id=__codelineno-17-160 name=__codelineno-17-160 href=#__codelineno-17-160></a>            <span class=n>gradient_accumulation_steps</span><span class=o>=</span><span class=n>gradient_accumulation_steps</span><span class=p>,</span>
</span><span id=__span-17-161><a id=__codelineno-17-161 name=__codelineno-17-161 href=#__codelineno-17-161></a>            <span class=c1># Effective batch size = 4 * 4 = 16</span>
</span><span id=__span-17-162><a id=__codelineno-17-162 name=__codelineno-17-162 href=#__codelineno-17-162></a>
</span><span id=__span-17-163><a id=__codelineno-17-163 name=__codelineno-17-163 href=#__codelineno-17-163></a>            <span class=c1># === Learning rate schedule ===</span>
</span><span id=__span-17-164><a id=__codelineno-17-164 name=__codelineno-17-164 href=#__codelineno-17-164></a>            <span class=n>warmup_ratio</span><span class=o>=</span><span class=n>warmup_ratio</span><span class=p>,</span>         <span class=c1># Warm up for 20% of training</span>
</span><span id=__span-17-165><a id=__codelineno-17-165 name=__codelineno-17-165 href=#__codelineno-17-165></a>            <span class=n>num_train_epochs</span><span class=o>=</span><span class=n>num_train_epochs</span><span class=p>,</span>
</span><span id=__span-17-166><a id=__codelineno-17-166 name=__codelineno-17-166 href=#__codelineno-17-166></a>            <span class=n>learning_rate</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span>
</span><span id=__span-17-167><a id=__codelineno-17-167 name=__codelineno-17-167 href=#__codelineno-17-167></a>            <span class=n>lr_scheduler_type</span><span class=o>=</span><span class=s2>"linear"</span><span class=p>,</span>        <span class=c1># Linear decay after warmup</span>
</span><span id=__span-17-168><a id=__codelineno-17-168 name=__codelineno-17-168 href=#__codelineno-17-168></a>
</span><span id=__span-17-169><a id=__codelineno-17-169 name=__codelineno-17-169 href=#__codelineno-17-169></a>            <span class=c1># === Logging ===</span>
</span><span id=__span-17-170><a id=__codelineno-17-170 name=__codelineno-17-170 href=#__codelineno-17-170></a>            <span class=n>logging_steps</span><span class=o>=</span><span class=n>logging_steps</span><span class=p>,</span>       <span class=c1># Log every 10 steps</span>
</span><span id=__span-17-171><a id=__codelineno-17-171 name=__codelineno-17-171 href=#__codelineno-17-171></a>            <span class=n>report_to</span><span class=o>=</span><span class=s2>"wandb"</span><span class=p>,</span>                 <span class=c1># Log to W&amp;B</span>
</span><span id=__span-17-172><a id=__codelineno-17-172 name=__codelineno-17-172 href=#__codelineno-17-172></a>
</span><span id=__span-17-173><a id=__codelineno-17-173 name=__codelineno-17-173 href=#__codelineno-17-173></a>            <span class=c1># === Checkpointing ===</span>
</span><span id=__span-17-174><a id=__codelineno-17-174 name=__codelineno-17-174 href=#__codelineno-17-174></a>            <span class=n>save_strategy</span><span class=o>=</span><span class=n>save_strategy</span><span class=p>,</span>       <span class=c1># Save by steps</span>
</span><span id=__span-17-175><a id=__codelineno-17-175 name=__codelineno-17-175 href=#__codelineno-17-175></a>            <span class=n>save_steps</span><span class=o>=</span><span class=n>save_steps</span><span class=p>,</span>             <span class=c1># Every 250 steps</span>
</span><span id=__span-17-176><a id=__codelineno-17-176 name=__codelineno-17-176 href=#__codelineno-17-176></a>            <span class=n>save_total_limit</span><span class=o>=</span><span class=n>save_total_limit</span><span class=p>,</span> <span class=c1># Keep only 20 checkpoints</span>
</span><span id=__span-17-177><a id=__codelineno-17-177 name=__codelineno-17-177 href=#__codelineno-17-177></a>            <span class=n>output_dir</span><span class=o>=</span><span class=n>output_dir</span><span class=p>,</span>             <span class=c1># Where to save</span>
</span><span id=__span-17-178><a id=__codelineno-17-178 name=__codelineno-17-178 href=#__codelineno-17-178></a>
</span><span id=__span-17-179><a id=__codelineno-17-179 name=__codelineno-17-179 href=#__codelineno-17-179></a>            <span class=c1># === Optimization ===</span>
</span><span id=__span-17-180><a id=__codelineno-17-180 name=__codelineno-17-180 href=#__codelineno-17-180></a>            <span class=n>gradient_checkpointing</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>       <span class=c1># Trade compute for memory</span>
</span><span id=__span-17-181><a id=__codelineno-17-181 name=__codelineno-17-181 href=#__codelineno-17-181></a>            <span class=n>gradient_checkpointing_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>"use_reentrant"</span><span class=p>:</span> <span class=kc>False</span><span class=p>},</span>
</span><span id=__span-17-182><a id=__codelineno-17-182 name=__codelineno-17-182 href=#__codelineno-17-182></a>            <span class=n>max_grad_norm</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span>                 <span class=c1># Gradient clipping</span>
</span><span id=__span-17-183><a id=__codelineno-17-183 name=__codelineno-17-183 href=#__codelineno-17-183></a>            <span class=n>optim</span><span class=o>=</span><span class=s2>"adamw_torch_fused"</span><span class=p>,</span>         <span class=c1># Fastest AdamW implementation</span>
</span><span id=__span-17-184><a id=__codelineno-17-184 name=__codelineno-17-184 href=#__codelineno-17-184></a>            <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>                 <span class=c1># L2 regularization</span>
</span><span id=__span-17-185><a id=__codelineno-17-185 name=__codelineno-17-185 href=#__codelineno-17-185></a>
</span><span id=__span-17-186><a id=__codelineno-17-186 name=__codelineno-17-186 href=#__codelineno-17-186></a>            <span class=c1># === Precision ===</span>
</span><span id=__span-17-187><a id=__codelineno-17-187 name=__codelineno-17-187 href=#__codelineno-17-187></a>            <span class=n>bf16</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                         <span class=c1># Use bfloat16 (faster + stable)</span>
</span><span id=__span-17-188><a id=__codelineno-17-188 name=__codelineno-17-188 href=#__codelineno-17-188></a>            <span class=n>tf32</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>                        <span class=c1># Don't need TF32</span>
</span><span id=__span-17-189><a id=__codelineno-17-189 name=__codelineno-17-189 href=#__codelineno-17-189></a>
</span><span id=__span-17-190><a id=__codelineno-17-190 name=__codelineno-17-190 href=#__codelineno-17-190></a>            <span class=c1># === Vision-specific settings ===</span>
</span><span id=__span-17-191><a id=__codelineno-17-191 name=__codelineno-17-191 href=#__codelineno-17-191></a>            <span class=n>remove_unused_columns</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>       <span class=c1># Keep all columns (need images!)</span>
</span><span id=__span-17-192><a id=__codelineno-17-192 name=__codelineno-17-192 href=#__codelineno-17-192></a>            <span class=n>dataset_text_field</span><span class=o>=</span><span class=s2>""</span><span class=p>,</span>             <span class=c1># We handle formatting ourselves</span>
</span><span id=__span-17-193><a id=__codelineno-17-193 name=__codelineno-17-193 href=#__codelineno-17-193></a>            <span class=n>dataset_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>"skip_prepare_dataset"</span><span class=p>:</span> <span class=kc>True</span><span class=p>},</span>
</span><span id=__span-17-194><a id=__codelineno-17-194 name=__codelineno-17-194 href=#__codelineno-17-194></a>            <span class=n>max_length</span><span class=o>=</span><span class=n>max_seq_length</span><span class=p>,</span>
</span><span id=__span-17-195><a id=__codelineno-17-195 name=__codelineno-17-195 href=#__codelineno-17-195></a>        <span class=p>),</span>
</span><span id=__span-17-196><a id=__codelineno-17-196 name=__codelineno-17-196 href=#__codelineno-17-196></a>    <span class=p>)</span>
</span><span id=__span-17-197><a id=__codelineno-17-197 name=__codelineno-17-197 href=#__codelineno-17-197></a>
</span><span id=__span-17-198><a id=__codelineno-17-198 name=__codelineno-17-198 href=#__codelineno-17-198></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Training config:"</span><span class=p>)</span>
</span><span id=__span-17-199><a id=__codelineno-17-199 name=__codelineno-17-199 href=#__codelineno-17-199></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Effective batch size: </span><span class=si>{</span><span class=n>per_device_train_batch_size</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>gradient_accumulation_steps</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-200><a id=__codelineno-17-200 name=__codelineno-17-200 href=#__codelineno-17-200></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Learning rate: </span><span class=si>{</span><span class=n>learning_rate</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-201><a id=__codelineno-17-201 name=__codelineno-17-201 href=#__codelineno-17-201></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Epochs: </span><span class=si>{</span><span class=n>num_train_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-202><a id=__codelineno-17-202 name=__codelineno-17-202 href=#__codelineno-17-202></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  - Total steps: ~</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>converted_dataset</span><span class=p>)</span><span class=w> </span><span class=o>//</span><span class=w> </span><span class=p>(</span><span class=n>per_device_train_batch_size</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>gradient_accumulation_steps</span><span class=p>)</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>num_train_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-203><a id=__codelineno-17-203 name=__codelineno-17-203 href=#__codelineno-17-203></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-204><a id=__codelineno-17-204 name=__codelineno-17-204 href=#__codelineno-17-204></a>
</span><span id=__span-17-205><a id=__codelineno-17-205 name=__codelineno-17-205 href=#__codelineno-17-205></a>    <span class=c1># === TRAIN! ===</span>
</span><span id=__span-17-206><a id=__codelineno-17-206 name=__codelineno-17-206 href=#__codelineno-17-206></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"🚀 Starting training..."</span><span class=p>)</span>
</span><span id=__span-17-207><a id=__codelineno-17-207 name=__codelineno-17-207 href=#__codelineno-17-207></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-208><a id=__codelineno-17-208 name=__codelineno-17-208 href=#__codelineno-17-208></a>    <span class=n>trainer_stats</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-17-209><a id=__codelineno-17-209 name=__codelineno-17-209 href=#__codelineno-17-209></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-210><a id=__codelineno-17-210 name=__codelineno-17-210 href=#__codelineno-17-210></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"✓ Training completed!"</span><span class=p>)</span>
</span><span id=__span-17-211><a id=__codelineno-17-211 name=__codelineno-17-211 href=#__codelineno-17-211></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-212><a id=__codelineno-17-212 name=__codelineno-17-212 href=#__codelineno-17-212></a>
</span><span id=__span-17-213><a id=__codelineno-17-213 name=__codelineno-17-213 href=#__codelineno-17-213></a>    <span class=c1># === Save Model ===</span>
</span><span id=__span-17-214><a id=__codelineno-17-214 name=__codelineno-17-214 href=#__codelineno-17-214></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-215><a id=__codelineno-17-215 name=__codelineno-17-215 href=#__codelineno-17-215></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"SAVING MODEL"</span><span class=p>)</span>
</span><span id=__span-17-216><a id=__codelineno-17-216 name=__codelineno-17-216 href=#__codelineno-17-216></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-217><a id=__codelineno-17-217 name=__codelineno-17-217 href=#__codelineno-17-217></a>
</span><span id=__span-17-218><a id=__codelineno-17-218 name=__codelineno-17-218 href=#__codelineno-17-218></a>    <span class=c1># Create output directories</span>
</span><span id=__span-17-219><a id=__codelineno-17-219 name=__codelineno-17-219 href=#__codelineno-17-219></a>    <span class=n>final_weights_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>output_dir</span><span class=p>,</span> <span class=s2>"final_weights"</span><span class=p>)</span>  <span class=c1># Merged model</span>
</span><span id=__span-17-220><a id=__codelineno-17-220 name=__codelineno-17-220 href=#__codelineno-17-220></a>    <span class=n>final_lora_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>output_dir</span><span class=p>,</span> <span class=s2>"final_lora"</span><span class=p>)</span>        <span class=c1># LoRA adapters only</span>
</span><span id=__span-17-221><a id=__codelineno-17-221 name=__codelineno-17-221 href=#__codelineno-17-221></a>
</span><span id=__span-17-222><a id=__codelineno-17-222 name=__codelineno-17-222 href=#__codelineno-17-222></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>final_weights_dir</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-17-223><a id=__codelineno-17-223 name=__codelineno-17-223 href=#__codelineno-17-223></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>final_lora_dir</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-17-224><a id=__codelineno-17-224 name=__codelineno-17-224 href=#__codelineno-17-224></a>
</span><span id=__span-17-225><a id=__codelineno-17-225 name=__codelineno-17-225 href=#__codelineno-17-225></a>    <span class=c1># Save LoRA adapters (small, ~100MB)</span>
</span><span id=__span-17-226><a id=__codelineno-17-226 name=__codelineno-17-226 href=#__codelineno-17-226></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Saving LoRA adapters..."</span><span class=p>)</span>
</span><span id=__span-17-227><a id=__codelineno-17-227 name=__codelineno-17-227 href=#__codelineno-17-227></a>    <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>final_lora_dir</span><span class=p>)</span>
</span><span id=__span-17-228><a id=__codelineno-17-228 name=__codelineno-17-228 href=#__codelineno-17-228></a>    <span class=n>processor</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>final_lora_dir</span><span class=p>)</span>
</span><span id=__span-17-229><a id=__codelineno-17-229 name=__codelineno-17-229 href=#__codelineno-17-229></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  ✓ LoRA adapters saved to </span><span class=si>{</span><span class=n>final_lora_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-230><a id=__codelineno-17-230 name=__codelineno-17-230 href=#__codelineno-17-230></a>
</span><span id=__span-17-231><a id=__codelineno-17-231 name=__codelineno-17-231 href=#__codelineno-17-231></a>    <span class=c1># Optionally push LoRA to Hugging Face Hub</span>
</span><span id=__span-17-232><a id=__codelineno-17-232 name=__codelineno-17-232 href=#__codelineno-17-232></a>    <span class=k>if</span> <span class=n>hub_id</span><span class=p>:</span>
</span><span id=__span-17-233><a id=__codelineno-17-233 name=__codelineno-17-233 href=#__codelineno-17-233></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Pushing LoRA to Hub: </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>_lora"</span><span class=p>)</span>
</span><span id=__span-17-234><a id=__codelineno-17-234 name=__codelineno-17-234 href=#__codelineno-17-234></a>        <span class=n>model</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>(</span>
</span><span id=__span-17-235><a id=__codelineno-17-235 name=__codelineno-17-235 href=#__codelineno-17-235></a>            <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>_lora"</span><span class=p>,</span>
</span><span id=__span-17-236><a id=__codelineno-17-236 name=__codelineno-17-236 href=#__codelineno-17-236></a>            <span class=n>token</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-17-237><a id=__codelineno-17-237 name=__codelineno-17-237 href=#__codelineno-17-237></a>        <span class=p>)</span>
</span><span id=__span-17-238><a id=__codelineno-17-238 name=__codelineno-17-238 href=#__codelineno-17-238></a>        <span class=n>processor</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>(</span>
</span><span id=__span-17-239><a id=__codelineno-17-239 name=__codelineno-17-239 href=#__codelineno-17-239></a>            <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>_lora"</span><span class=p>,</span>
</span><span id=__span-17-240><a id=__codelineno-17-240 name=__codelineno-17-240 href=#__codelineno-17-240></a>            <span class=n>token</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-17-241><a id=__codelineno-17-241 name=__codelineno-17-241 href=#__codelineno-17-241></a>        <span class=p>)</span>
</span><span id=__span-17-242><a id=__codelineno-17-242 name=__codelineno-17-242 href=#__codelineno-17-242></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  ✓ Pushed to </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>_lora"</span><span class=p>)</span>
</span><span id=__span-17-243><a id=__codelineno-17-243 name=__codelineno-17-243 href=#__codelineno-17-243></a>
</span><span id=__span-17-244><a id=__codelineno-17-244 name=__codelineno-17-244 href=#__codelineno-17-244></a>    <span class=c1># Save merged model (base + LoRA combined, ready to deploy)</span>
</span><span id=__span-17-245><a id=__codelineno-17-245 name=__codelineno-17-245 href=#__codelineno-17-245></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Saving merged model (this takes a few minutes)..."</span><span class=p>)</span>
</span><span id=__span-17-246><a id=__codelineno-17-246 name=__codelineno-17-246 href=#__codelineno-17-246></a>    <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained_merged</span><span class=p>(</span>
</span><span id=__span-17-247><a id=__codelineno-17-247 name=__codelineno-17-247 href=#__codelineno-17-247></a>        <span class=n>final_weights_dir</span><span class=p>,</span>
</span><span id=__span-17-248><a id=__codelineno-17-248 name=__codelineno-17-248 href=#__codelineno-17-248></a>        <span class=n>processor</span><span class=p>,</span>
</span><span id=__span-17-249><a id=__codelineno-17-249 name=__codelineno-17-249 href=#__codelineno-17-249></a>        <span class=n>save_method</span><span class=o>=</span><span class=s2>"merged_16bit"</span>  <span class=c1># Save in 16-bit precision</span>
</span><span id=__span-17-250><a id=__codelineno-17-250 name=__codelineno-17-250 href=#__codelineno-17-250></a>    <span class=p>)</span>
</span><span id=__span-17-251><a id=__codelineno-17-251 name=__codelineno-17-251 href=#__codelineno-17-251></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  ✓ Merged model saved to </span><span class=si>{</span><span class=n>final_weights_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-252><a id=__codelineno-17-252 name=__codelineno-17-252 href=#__codelineno-17-252></a>
</span><span id=__span-17-253><a id=__codelineno-17-253 name=__codelineno-17-253 href=#__codelineno-17-253></a>    <span class=c1># Optionally push merged model to Hub</span>
</span><span id=__span-17-254><a id=__codelineno-17-254 name=__codelineno-17-254 href=#__codelineno-17-254></a>    <span class=k>if</span> <span class=n>hub_id</span><span class=p>:</span>
</span><span id=__span-17-255><a id=__codelineno-17-255 name=__codelineno-17-255 href=#__codelineno-17-255></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Pushing merged model to Hub: </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-256><a id=__codelineno-17-256 name=__codelineno-17-256 href=#__codelineno-17-256></a>        <span class=n>model</span><span class=o>.</span><span class=n>push_to_hub_merged</span><span class=p>(</span>
</span><span id=__span-17-257><a id=__codelineno-17-257 name=__codelineno-17-257 href=#__codelineno-17-257></a>            <span class=n>hub_id</span><span class=p>,</span>
</span><span id=__span-17-258><a id=__codelineno-17-258 name=__codelineno-17-258 href=#__codelineno-17-258></a>            <span class=n>processor</span><span class=p>,</span>
</span><span id=__span-17-259><a id=__codelineno-17-259 name=__codelineno-17-259 href=#__codelineno-17-259></a>            <span class=n>token</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>],</span>
</span><span id=__span-17-260><a id=__codelineno-17-260 name=__codelineno-17-260 href=#__codelineno-17-260></a>            <span class=n>save_method</span><span class=o>=</span><span class=s2>"merged_16bit"</span>
</span><span id=__span-17-261><a id=__codelineno-17-261 name=__codelineno-17-261 href=#__codelineno-17-261></a>        <span class=p>)</span>
</span><span id=__span-17-262><a id=__codelineno-17-262 name=__codelineno-17-262 href=#__codelineno-17-262></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  ✓ Pushed to </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-263><a id=__codelineno-17-263 name=__codelineno-17-263 href=#__codelineno-17-263></a>
</span><span id=__span-17-264><a id=__codelineno-17-264 name=__codelineno-17-264 href=#__codelineno-17-264></a>    <span class=c1># CRITICAL: Commit everything to the volume</span>
</span><span id=__span-17-265><a id=__codelineno-17-265 name=__codelineno-17-265 href=#__codelineno-17-265></a>    <span class=c1># This persists checkpoints, final models, everything</span>
</span><span id=__span-17-266><a id=__codelineno-17-266 name=__codelineno-17-266 href=#__codelineno-17-266></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Committing to volume..."</span><span class=p>)</span>
</span><span id=__span-17-267><a id=__codelineno-17-267 name=__codelineno-17-267 href=#__codelineno-17-267></a>    <span class=n>exp_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-17-268><a id=__codelineno-17-268 name=__codelineno-17-268 href=#__codelineno-17-268></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"✓ Volume committed"</span><span class=p>)</span>
</span><span id=__span-17-269><a id=__codelineno-17-269 name=__codelineno-17-269 href=#__codelineno-17-269></a>
</span><span id=__span-17-270><a id=__codelineno-17-270 name=__codelineno-17-270 href=#__codelineno-17-270></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-271><a id=__codelineno-17-271 name=__codelineno-17-271 href=#__codelineno-17-271></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-272><a id=__codelineno-17-272 name=__codelineno-17-272 href=#__codelineno-17-272></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"🎉 FINE-TUNING COMPLETE!"</span><span class=p>)</span>
</span><span id=__span-17-273><a id=__codelineno-17-273 name=__codelineno-17-273 href=#__codelineno-17-273></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-17-274><a id=__codelineno-17-274 name=__codelineno-17-274 href=#__codelineno-17-274></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"LoRA adapters: </span><span class=si>{</span><span class=n>final_lora_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-275><a id=__codelineno-17-275 name=__codelineno-17-275 href=#__codelineno-17-275></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Merged model: </span><span class=si>{</span><span class=n>final_weights_dir</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-17-276><a id=__codelineno-17-276 name=__codelineno-17-276 href=#__codelineno-17-276></a>    <span class=k>if</span> <span class=n>hub_id</span><span class=p>:</span>
</span><span id=__span-17-277><a id=__codelineno-17-277 name=__codelineno-17-277 href=#__codelineno-17-277></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Hugging Face: </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2> and </span><span class=si>{</span><span class=n>hub_id</span><span class=si>}</span><span class=s2>_lora"</span><span class=p>)</span>
</span><span id=__span-17-278><a id=__codelineno-17-278 name=__codelineno-17-278 href=#__codelineno-17-278></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-17-279><a id=__codelineno-17-279 name=__codelineno-17-279 href=#__codelineno-17-279></a>
</span><span id=__span-17-280><a id=__codelineno-17-280 name=__codelineno-17-280 href=#__codelineno-17-280></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-17-281><a id=__codelineno-17-281 name=__codelineno-17-281 href=#__codelineno-17-281></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-17-282><a id=__codelineno-17-282 name=__codelineno-17-282 href=#__codelineno-17-282></a>        <span class=s2>"output_dir"</span><span class=p>:</span> <span class=n>output_dir</span><span class=p>,</span>
</span><span id=__span-17-283><a id=__codelineno-17-283 name=__codelineno-17-283 href=#__codelineno-17-283></a>        <span class=s2>"lora_dir"</span><span class=p>:</span> <span class=n>final_lora_dir</span><span class=p>,</span>
</span><span id=__span-17-284><a id=__codelineno-17-284 name=__codelineno-17-284 href=#__codelineno-17-284></a>        <span class=s2>"merged_dir"</span><span class=p>:</span> <span class=n>final_weights_dir</span><span class=p>,</span>
</span><span id=__span-17-285><a id=__codelineno-17-285 name=__codelineno-17-285 href=#__codelineno-17-285></a>        <span class=s2>"hub_id"</span><span class=p>:</span> <span class=n>hub_id</span><span class=p>,</span>
</span><span id=__span-17-286><a id=__codelineno-17-286 name=__codelineno-17-286 href=#__codelineno-17-286></a>    <span class=p>}</span>
</span></code></pre></div> <p>Phew! That's a lot of code, but it's all there for a reason. Let me highlight the key points:</p> <p><strong>LoRA Strategy:</strong> - We freeze the vision encoder (it's already good at seeing images) - We only train LoRA adapters on the language model - This trains ~1-2% of parameters instead of 100% - Massively faster and more memory efficient</p> <p><strong>Batch Size Math:</strong> </p><div class="language-text highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>Effective batch size = per_device_batch_size × gradient_accumulation_steps × num_gpus
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>                    = 4 × 4 × 1
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>                    = 16
</span></code></pre></div> <p><strong>Two Save Formats:</strong> 1. <strong>LoRA adapters</strong> (~100MB): Just the trained adapters. Requires base model to use. 2. <strong>Merged model</strong> (full size): Base model + adapters combined. Ready to deploy.</p> <p>For serving, we use the merged model. For sharing or storage, LoRA adapters are more efficient.</p> <h3 id=running-training>Running Training<a class=headerlink href=#running-training title="Permanent link">¶</a></h3> <p><strong>Basic run (test on small subset):</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>100</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>1</span>
</span></code></pre></div> <p>This trains on 100 samples for 1 epoch - great for making sure everything works.</p> <p><strong>Full training run:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>3</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=w>  </span>--learning-rate<span class=o>=</span><span class=m>0</span>.0003
</span></code></pre></div> <p><strong>Train and push to Hugging Face:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a><span class=w>  </span>--hub-id<span class=o>=</span><span class=s2>"your-username/gemma-latex-ocr"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>3</span>
</span></code></pre></div> <p>This pushes both the LoRA adapters and merged model to your HF account.</p> <p><strong>Custom hyperparameters:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a><span class=w>  </span>--lora-r<span class=o>=</span><span class=m>64</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a><span class=w>  </span>--lora-alpha<span class=o>=</span><span class=m>128</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=w>  </span>--per-device-train-batch-size<span class=o>=</span><span class=m>2</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a><span class=w>  </span>--gradient-accumulation-steps<span class=o>=</span><span class=m>8</span>
</span></code></pre></div> <p>While training runs, you'll see logs streaming in real-time. And if you set up W&amp;B, check <code>wandb.ai/&lt;your-username&gt;/GemmaFinetuning</code> to see beautiful charts of loss curves, learning rate schedules, GPU utilization, everything.</p> <h2 id=stage-4-export-and-merge-model-optional>Stage 4: Export and Merge Model (Optional)<a class=headerlink href=#stage-4-export-and-merge-model-optional title="Permanent link">¶</a></h2> <p>Okay, so after training, you have LoRA adapters saved. The training function already saves both LoRA adapters AND the merged model. But let's say you only saved LoRA adapters (to save space), and now you want to create a standalone merged model. That's what this stage is for.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>FINETUNING_GPU_IMAGE</span><span class=p>,</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>TRAINING_GPU_CONFIG</span><span class=p>,</span>              <span class=c1># Need same GPU as training</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>,</span> <span class=n>Secret</span><span class=o>.</span><span class=n>from_dotenv</span><span class=p>()],</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>                    <span class=c1># Merging takes ~10-30 minutes</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=p>)</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a><span class=k>def</span><span class=w> </span><span class=nf>export_model</span><span class=p>(</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a>    <span class=n>lora_model_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>OUTPUT_DIR_DEFAULT</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>  <span class=c1># Where LoRA adapters are</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a>    <span class=n>output_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                          <span class=c1># Where to save merged model</span>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a>    <span class=n>hub_model_id</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                         <span class=c1># Optional: push to HF Hub</span>
</span><span id=__span-23-12><a id=__codelineno-23-12 name=__codelineno-23-12 href=#__codelineno-23-12></a>    <span class=n>push_to_hub</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>                         <span class=c1># Whether to push</span>
</span><span id=__span-23-13><a id=__codelineno-23-13 name=__codelineno-23-13 href=#__codelineno-23-13></a><span class=p>):</span>
</span><span id=__span-23-14><a id=__codelineno-23-14 name=__codelineno-23-14 href=#__codelineno-23-14></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-23-15><a id=__codelineno-23-15 name=__codelineno-23-15 href=#__codelineno-23-15></a><span class=sd>    Export LoRA adapters and merge them with base model.</span>
</span><span id=__span-23-16><a id=__codelineno-23-16 name=__codelineno-23-16 href=#__codelineno-23-16></a>
</span><span id=__span-23-17><a id=__codelineno-23-17 name=__codelineno-23-17 href=#__codelineno-23-17></a><span class=sd>    Why? Two reasons:</span>
</span><span id=__span-23-18><a id=__codelineno-23-18 name=__codelineno-23-18 href=#__codelineno-23-18></a><span class=sd>    1. Merged models are easier to deploy (no need to load base + adapters separately)</span>
</span><span id=__span-23-19><a id=__codelineno-23-19 name=__codelineno-23-19 href=#__codelineno-23-19></a><span class=sd>    2. Merged models can be quantized for faster inference</span>
</span><span id=__span-23-20><a id=__codelineno-23-20 name=__codelineno-23-20 href=#__codelineno-23-20></a><span class=sd>    """</span>
</span><span id=__span-23-21><a id=__codelineno-23-21 name=__codelineno-23-21 href=#__codelineno-23-21></a>    <span class=kn>from</span><span class=w> </span><span class=nn>unsloth</span><span class=w> </span><span class=kn>import</span> <span class=n>FastVisionModel</span>
</span><span id=__span-23-22><a id=__codelineno-23-22 name=__codelineno-23-22 href=#__codelineno-23-22></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-23-23><a id=__codelineno-23-23 name=__codelineno-23-23 href=#__codelineno-23-23></a>
</span><span id=__span-23-24><a id=__codelineno-23-24 name=__codelineno-23-24 href=#__codelineno-23-24></a>    <span class=c1># Set HF token for pushing to Hub</span>
</span><span id=__span-23-25><a id=__codelineno-23-25 name=__codelineno-23-25 href=#__codelineno-23-25></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-23-26><a id=__codelineno-23-26 name=__codelineno-23-26 href=#__codelineno-23-26></a>
</span><span id=__span-23-27><a id=__codelineno-23-27 name=__codelineno-23-27 href=#__codelineno-23-27></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-28><a id=__codelineno-23-28 name=__codelineno-23-28 href=#__codelineno-23-28></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"LOADING LORA MODEL AND MERGING"</span><span class=p>)</span>
</span><span id=__span-23-29><a id=__codelineno-23-29 name=__codelineno-23-29 href=#__codelineno-23-29></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-30><a id=__codelineno-23-30 name=__codelineno-23-30 href=#__codelineno-23-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"LoRA path: </span><span class=si>{</span><span class=n>lora_model_path</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-31><a id=__codelineno-23-31 name=__codelineno-23-31 href=#__codelineno-23-31></a>
</span><span id=__span-23-32><a id=__codelineno-23-32 name=__codelineno-23-32 href=#__codelineno-23-32></a>    <span class=c1># Load the LoRA model</span>
</span><span id=__span-23-33><a id=__codelineno-23-33 name=__codelineno-23-33 href=#__codelineno-23-33></a>    <span class=c1># This loads base model + LoRA adapters</span>
</span><span id=__span-23-34><a id=__codelineno-23-34 name=__codelineno-23-34 href=#__codelineno-23-34></a>    <span class=n>model</span><span class=p>,</span> <span class=n>processor</span> <span class=o>=</span> <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-23-35><a id=__codelineno-23-35 name=__codelineno-23-35 href=#__codelineno-23-35></a>        <span class=n>lora_model_path</span><span class=p>,</span>           <span class=c1># Path to LoRA adapters</span>
</span><span id=__span-23-36><a id=__codelineno-23-36 name=__codelineno-23-36 href=#__codelineno-23-36></a>        <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>        <span class=c1># Load in full precision</span>
</span><span id=__span-23-37><a id=__codelineno-23-37 name=__codelineno-23-37 href=#__codelineno-23-37></a>    <span class=p>)</span>
</span><span id=__span-23-38><a id=__codelineno-23-38 name=__codelineno-23-38 href=#__codelineno-23-38></a>
</span><span id=__span-23-39><a id=__codelineno-23-39 name=__codelineno-23-39 href=#__codelineno-23-39></a>    <span class=c1># Prepare for inference</span>
</span><span id=__span-23-40><a id=__codelineno-23-40 name=__codelineno-23-40 href=#__codelineno-23-40></a>    <span class=c1># This merges the LoRA weights into the base model</span>
</span><span id=__span-23-41><a id=__codelineno-23-41 name=__codelineno-23-41 href=#__codelineno-23-41></a>    <span class=n>FastVisionModel</span><span class=o>.</span><span class=n>for_inference</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span><span id=__span-23-42><a id=__codelineno-23-42 name=__codelineno-23-42 href=#__codelineno-23-42></a>
</span><span id=__span-23-43><a id=__codelineno-23-43 name=__codelineno-23-43 href=#__codelineno-23-43></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"✓ Model loaded and LoRA weights merged"</span><span class=p>)</span>
</span><span id=__span-23-44><a id=__codelineno-23-44 name=__codelineno-23-44 href=#__codelineno-23-44></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-23-45><a id=__codelineno-23-45 name=__codelineno-23-45 href=#__codelineno-23-45></a>
</span><span id=__span-23-46><a id=__codelineno-23-46 name=__codelineno-23-46 href=#__codelineno-23-46></a>    <span class=c1># === Save or Push ===</span>
</span><span id=__span-23-47><a id=__codelineno-23-47 name=__codelineno-23-47 href=#__codelineno-23-47></a>    <span class=k>if</span> <span class=n>push_to_hub</span> <span class=ow>and</span> <span class=n>hub_model_id</span><span class=p>:</span>
</span><span id=__span-23-48><a id=__codelineno-23-48 name=__codelineno-23-48 href=#__codelineno-23-48></a>        <span class=c1># Push merged model to Hugging Face Hub</span>
</span><span id=__span-23-49><a id=__codelineno-23-49 name=__codelineno-23-49 href=#__codelineno-23-49></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Pushing merged model to Hub: </span><span class=si>{</span><span class=n>hub_model_id</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-50><a id=__codelineno-23-50 name=__codelineno-23-50 href=#__codelineno-23-50></a>        <span class=n>model</span><span class=o>.</span><span class=n>push_to_hub_merged</span><span class=p>(</span>
</span><span id=__span-23-51><a id=__codelineno-23-51 name=__codelineno-23-51 href=#__codelineno-23-51></a>            <span class=n>hub_model_id</span><span class=p>,</span>
</span><span id=__span-23-52><a id=__codelineno-23-52 name=__codelineno-23-52 href=#__codelineno-23-52></a>            <span class=n>processor</span><span class=p>,</span>
</span><span id=__span-23-53><a id=__codelineno-23-53 name=__codelineno-23-53 href=#__codelineno-23-53></a>            <span class=n>token</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>],</span>
</span><span id=__span-23-54><a id=__codelineno-23-54 name=__codelineno-23-54 href=#__codelineno-23-54></a>            <span class=n>save_method</span><span class=o>=</span><span class=s2>"merged_16bit"</span><span class=p>,</span>  <span class=c1># Save in 16-bit (good balance)</span>
</span><span id=__span-23-55><a id=__codelineno-23-55 name=__codelineno-23-55 href=#__codelineno-23-55></a>        <span class=p>)</span>
</span><span id=__span-23-56><a id=__codelineno-23-56 name=__codelineno-23-56 href=#__codelineno-23-56></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Pushed to https://huggingface.co/</span><span class=si>{</span><span class=n>hub_model_id</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-57><a id=__codelineno-23-57 name=__codelineno-23-57 href=#__codelineno-23-57></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-23-58><a id=__codelineno-23-58 name=__codelineno-23-58 href=#__codelineno-23-58></a>        <span class=c1># Save locally to volume</span>
</span><span id=__span-23-59><a id=__codelineno-23-59 name=__codelineno-23-59 href=#__codelineno-23-59></a>        <span class=k>if</span> <span class=n>output_path</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-23-60><a id=__codelineno-23-60 name=__codelineno-23-60 href=#__codelineno-23-60></a>            <span class=n>output_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>lora_model_path</span><span class=si>}</span><span class=s2>_merged"</span>
</span><span id=__span-23-61><a id=__codelineno-23-61 name=__codelineno-23-61 href=#__codelineno-23-61></a>
</span><span id=__span-23-62><a id=__codelineno-23-62 name=__codelineno-23-62 href=#__codelineno-23-62></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Saving merged model to: </span><span class=si>{</span><span class=n>output_path</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-63><a id=__codelineno-23-63 name=__codelineno-23-63 href=#__codelineno-23-63></a>        <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained_merged</span><span class=p>(</span>
</span><span id=__span-23-64><a id=__codelineno-23-64 name=__codelineno-23-64 href=#__codelineno-23-64></a>            <span class=n>output_path</span><span class=p>,</span>
</span><span id=__span-23-65><a id=__codelineno-23-65 name=__codelineno-23-65 href=#__codelineno-23-65></a>            <span class=n>processor</span><span class=p>,</span>
</span><span id=__span-23-66><a id=__codelineno-23-66 name=__codelineno-23-66 href=#__codelineno-23-66></a>            <span class=n>save_method</span><span class=o>=</span><span class=s2>"merged_16bit"</span>
</span><span id=__span-23-67><a id=__codelineno-23-67 name=__codelineno-23-67 href=#__codelineno-23-67></a>        <span class=p>)</span>
</span><span id=__span-23-68><a id=__codelineno-23-68 name=__codelineno-23-68 href=#__codelineno-23-68></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Saved to </span><span class=si>{</span><span class=n>output_path</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-69><a id=__codelineno-23-69 name=__codelineno-23-69 href=#__codelineno-23-69></a>
</span><span id=__span-23-70><a id=__codelineno-23-70 name=__codelineno-23-70 href=#__codelineno-23-70></a>    <span class=c1># Commit to volume</span>
</span><span id=__span-23-71><a id=__codelineno-23-71 name=__codelineno-23-71 href=#__codelineno-23-71></a>    <span class=n>exp_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-23-72><a id=__codelineno-23-72 name=__codelineno-23-72 href=#__codelineno-23-72></a>
</span><span id=__span-23-73><a id=__codelineno-23-73 name=__codelineno-23-73 href=#__codelineno-23-73></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-23-74><a id=__codelineno-23-74 name=__codelineno-23-74 href=#__codelineno-23-74></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-75><a id=__codelineno-23-75 name=__codelineno-23-75 href=#__codelineno-23-75></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"✓ EXPORT COMPLETE!"</span><span class=p>)</span>
</span><span id=__span-23-76><a id=__codelineno-23-76 name=__codelineno-23-76 href=#__codelineno-23-76></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-77><a id=__codelineno-23-77 name=__codelineno-23-77 href=#__codelineno-23-77></a>
</span><span id=__span-23-78><a id=__codelineno-23-78 name=__codelineno-23-78 href=#__codelineno-23-78></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-23-79><a id=__codelineno-23-79 name=__codelineno-23-79 href=#__codelineno-23-79></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-23-80><a id=__codelineno-23-80 name=__codelineno-23-80 href=#__codelineno-23-80></a>        <span class=s2>"lora_path"</span><span class=p>:</span> <span class=n>lora_model_path</span><span class=p>,</span>
</span><span id=__span-23-81><a id=__codelineno-23-81 name=__codelineno-23-81 href=#__codelineno-23-81></a>        <span class=s2>"merged_path"</span><span class=p>:</span> <span class=n>output_path</span> <span class=k>if</span> <span class=ow>not</span> <span class=n>push_to_hub</span> <span class=k>else</span> <span class=n>hub_model_id</span><span class=p>,</span>
</span><span id=__span-23-82><a id=__codelineno-23-82 name=__codelineno-23-82 href=#__codelineno-23-82></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>When to use this:</strong> - You only saved LoRA adapters during training (to save disk space) - You want to create a standalone model for deployment - You want to push to HuggingFace Hub after training</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># Export and save to volume</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::export_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a><span class=w>  </span>--lora-model-path<span class=o>=</span><span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_lora"</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a><span class=c1># Export and push to HuggingFace</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::export_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a><span class=w>  </span>--lora-model-path<span class=o>=</span><span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_lora"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a><span class=w>  </span>--hub-model-id<span class=o>=</span><span class=s2>"your-username/gemma-latex-merged"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a><span class=w>  </span>--push-to-hub<span class=o>=</span>True
</span></code></pre></div> <h2 id=stage-5-serving-with-vllm>Stage 5: Serving with vLLM<a class=headerlink href=#stage-5-serving-with-vllm title="Permanent link">¶</a></h2> <p>Alright, now let's deploy our model for real-time inference. We're using vLLM, which is basically the industry standard for serving LLMs at scale.</p> <p><strong>Why vLLM?</strong> - <strong>Fast</strong>: Optimized attention kernels, continuous batching - <strong>Scalable</strong>: Handles thousands of requests per second - <strong>Compatible</strong>: OpenAI-compatible API (drop-in replacement) - <strong>Auto-scaling</strong>: Modal handles spinning up/down instances based on load</p> <h3 id=vllm-image-separate-from-training>vLLM Image (Separate from Training)<a class=headerlink href=#vllm-image-separate-from-training title="Permanent link">¶</a></h3> <p>We use a different image for serving because vLLM has different dependencies than training.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=n>VLLM_CUDA_VERSION</span> <span class=o>=</span> <span class=s2>"12.8.1"</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a><span class=n>VLLM_CUDA_TAG</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>VLLM_CUDA_VERSION</span><span class=si>}</span><span class=s2>-devel-ubuntu24.04"</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a><span class=n>VLLM_GPU_IMAGE</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>    <span class=c1># Start with CUDA base</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>    <span class=n>ModalImage</span><span class=o>.</span><span class=n>from_registry</span><span class=p>(</span><span class=sa>f</span><span class=s2>"nvidia/cuda:</span><span class=si>{</span><span class=n>VLLM_CUDA_TAG</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span> <span class=n>add_python</span><span class=o>=</span><span class=s2>"3.12"</span><span class=p>)</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>    <span class=c1># Install system dependencies for vLLM</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a>    <span class=o>.</span><span class=n>apt_install</span><span class=p>(</span><span class=s2>"libopenmpi-dev"</span><span class=p>,</span> <span class=s2>"libnuma-dev"</span><span class=p>)</span>  <span class=c1># For distributed inference</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a>    <span class=c1># Upgrade pip and install uv</span>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12 href=#__codelineno-25-12></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span><span class=s2>"pip install --upgrade pip"</span><span class=p>)</span>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13 href=#__codelineno-25-13></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span><span class=s2>"pip install uv"</span><span class=p>)</span>
</span><span id=__span-25-14><a id=__codelineno-25-14 name=__codelineno-25-14 href=#__codelineno-25-14></a>
</span><span id=__span-25-15><a id=__codelineno-25-15 name=__codelineno-25-15 href=#__codelineno-25-15></a>    <span class=c1># Install vLLM (latest version)</span>
</span><span id=__span-25-16><a id=__codelineno-25-16 name=__codelineno-25-16 href=#__codelineno-25-16></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span><span class=s2>"uv pip install vllm -U --system"</span><span class=p>)</span>
</span><span id=__span-25-17><a id=__codelineno-25-17 name=__codelineno-25-17 href=#__codelineno-25-17></a>
</span><span id=__span-25-18><a id=__codelineno-25-18 name=__codelineno-25-18 href=#__codelineno-25-18></a>    <span class=c1># Install supporting packages</span>
</span><span id=__span-25-19><a id=__codelineno-25-19 name=__codelineno-25-19 href=#__codelineno-25-19></a>    <span class=o>.</span><span class=n>pip_install</span><span class=p>(</span>
</span><span id=__span-25-20><a id=__codelineno-25-20 name=__codelineno-25-20 href=#__codelineno-25-20></a>        <span class=s2>"datasets"</span><span class=p>,</span>                       <span class=c1># For eval/testing</span>
</span><span id=__span-25-21><a id=__codelineno-25-21 name=__codelineno-25-21 href=#__codelineno-25-21></a>        <span class=s2>"pillow"</span><span class=p>,</span>                         <span class=c1># Image handling</span>
</span><span id=__span-25-22><a id=__codelineno-25-22 name=__codelineno-25-22 href=#__codelineno-25-22></a>        <span class=s2>"huggingface_hub[hf_transfer]"</span><span class=p>,</span>  <span class=c1># Fast model downloads</span>
</span><span id=__span-25-23><a id=__codelineno-25-23 name=__codelineno-25-23 href=#__codelineno-25-23></a>        <span class=s2>"requests"</span><span class=p>,</span>                       <span class=c1># HTTP requests</span>
</span><span id=__span-25-24><a id=__codelineno-25-24 name=__codelineno-25-24 href=#__codelineno-25-24></a>        <span class=s2>"numpy"</span><span class=p>,</span>                          <span class=c1># Numerical ops</span>
</span><span id=__span-25-25><a id=__codelineno-25-25 name=__codelineno-25-25 href=#__codelineno-25-25></a>    <span class=p>)</span>
</span><span id=__span-25-26><a id=__codelineno-25-26 name=__codelineno-25-26 href=#__codelineno-25-26></a>
</span><span id=__span-25-27><a id=__codelineno-25-27 name=__codelineno-25-27 href=#__codelineno-25-27></a>    <span class=c1># Install flash-attention (required for vLLM)</span>
</span><span id=__span-25-28><a id=__codelineno-25-28 name=__codelineno-25-28 href=#__codelineno-25-28></a>    <span class=c1># Must be installed separately with --no-build-isolation</span>
</span><span id=__span-25-29><a id=__codelineno-25-29 name=__codelineno-25-29 href=#__codelineno-25-29></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span>
</span><span id=__span-25-30><a id=__codelineno-25-30 name=__codelineno-25-30 href=#__codelineno-25-30></a>        <span class=s2>"uv pip install 'flash-attn&gt;=2.7.1,&lt;=2.8.0' --no-build-isolation --system"</span>
</span><span id=__span-25-31><a id=__codelineno-25-31 name=__codelineno-25-31 href=#__codelineno-25-31></a>    <span class=p>)</span>
</span><span id=__span-25-32><a id=__codelineno-25-32 name=__codelineno-25-32 href=#__codelineno-25-32></a>
</span><span id=__span-25-33><a id=__codelineno-25-33 name=__codelineno-25-33 href=#__codelineno-25-33></a>    <span class=c1># Enable fast HF downloads</span>
</span><span id=__span-25-34><a id=__codelineno-25-34 name=__codelineno-25-34 href=#__codelineno-25-34></a>    <span class=o>.</span><span class=n>env</span><span class=p>({</span><span class=s2>"HF_HUB_ENABLE_HF_TRANSFER"</span><span class=p>:</span> <span class=s2>"1"</span><span class=p>})</span>
</span><span id=__span-25-35><a id=__codelineno-25-35 name=__codelineno-25-35 href=#__codelineno-25-35></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Why separate image?</strong> - vLLM and training have overlapping dependencies that can conflict - vLLM image is lighter (no training frameworks) - Faster to build and deploy</p> <h3 id=serving-configuration>Serving Configuration<a class=headerlink href=#serving-configuration title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=c1># Which model to serve (path on volume)</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=n>DEFAULT_SERVE_MODEL</span> <span class=o>=</span> <span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_weights"</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a><span class=c1># GPU for serving (can be different from training!)</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a><span class=n>SERVE_GPU</span> <span class=o>=</span> <span class=s2>"L40S"</span>        <span class=c1># L40S is great for inference (~$1/hr)</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a><span class=n>SERVE_NUM_GPUS</span> <span class=o>=</span> <span class=mi>1</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=n>SERVE_GPU_CONFIG</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>SERVE_GPU</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>SERVE_NUM_GPUS</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a><span class=n>VLLM_PORT</span> <span class=o>=</span> <span class=mi>8000</span>          <span class=c1># Internal port</span>
</span></code></pre></div> <p><strong>GPU choice for serving:</strong> - <strong>L40S</strong>: Best price/performance for inference (<span class=arithmatex>\(1/hr) - **A100-40GB**: If you need higher throughput (\)</span>2.50/hr) - <strong>A100-80GB</strong>: For very large models or high batch sizes ($3.50/hr)</p> <h3 id=the-serve-function>The Serve Function<a class=headerlink href=#the-serve-function title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>VLLM_GPU_IMAGE</span><span class=p>,</span>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>SERVE_GPU_CONFIG</span><span class=p>,</span>                <span class=c1># L40S for serving</span>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a>    <span class=n>scaledown_window</span><span class=o>=</span><span class=mi>3</span> <span class=o>*</span> <span class=mi>60</span><span class=p>,</span>             <span class=c1># Scale to 0 after 3 min idle (saves $$$)</span>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>],</span>        <span class=c1># Need HF token</span>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>                <span class=c1># Mount our volume (has the model)</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a>    <span class=n>max_containers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>                     <span class=c1># Auto-scale up to 2 instances</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>24</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a><span class=p>)</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a><span class=nd>@modal</span><span class=o>.</span><span class=n>concurrent</span><span class=p>(</span><span class=n>max_inputs</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>         <span class=c1># Handle 50 concurrent requests per instance</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a><span class=nd>@modal</span><span class=o>.</span><span class=n>web_server</span><span class=p>(</span><span class=n>port</span><span class=o>=</span><span class=mi>8000</span><span class=p>,</span> <span class=n>startup_timeout</span><span class=o>=</span><span class=mi>5</span> <span class=o>*</span> <span class=mi>60</span><span class=p>)</span>  <span class=c1># Expose as web server</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a><span class=k>def</span><span class=w> </span><span class=nf>serve_vllm</span><span class=p>():</span>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a><span class=sd>    Serve the fine-tuned model using vLLM.</span>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a>
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16 href=#__codelineno-27-16></a><span class=sd>    This creates an OpenAI-compatible API endpoint that:</span>
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17 href=#__codelineno-27-17></a><span class=sd>    - Auto-scales from 0 to max_containers based on load</span>
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18 href=#__codelineno-27-18></a><span class=sd>    - Shuts down after 3 minutes of inactivity (cost optimization!)</span>
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19 href=#__codelineno-27-19></a><span class=sd>    - Handles up to 50 concurrent requests per container</span>
</span><span id=__span-27-20><a id=__codelineno-27-20 name=__codelineno-27-20 href=#__codelineno-27-20></a><span class=sd>    """</span>
</span><span id=__span-27-21><a id=__codelineno-27-21 name=__codelineno-27-21 href=#__codelineno-27-21></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-27-22><a id=__codelineno-27-22 name=__codelineno-27-22 href=#__codelineno-27-22></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-27-23><a id=__codelineno-27-23 name=__codelineno-27-23 href=#__codelineno-27-23></a>
</span><span id=__span-27-24><a id=__codelineno-27-24 name=__codelineno-27-24 href=#__codelineno-27-24></a>    <span class=c1># Set HF token (might need to download model files)</span>
</span><span id=__span-27-25><a id=__codelineno-27-25 name=__codelineno-27-25 href=#__codelineno-27-25></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-27-26><a id=__codelineno-27-26 name=__codelineno-27-26 href=#__codelineno-27-26></a>
</span><span id=__span-27-27><a id=__codelineno-27-27 name=__codelineno-27-27 href=#__codelineno-27-27></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-27-28><a id=__codelineno-27-28 name=__codelineno-27-28 href=#__codelineno-27-28></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"STARTING VLLM SERVER"</span><span class=p>)</span>
</span><span id=__span-27-29><a id=__codelineno-27-29 name=__codelineno-27-29 href=#__codelineno-27-29></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-27-30><a id=__codelineno-27-30 name=__codelineno-27-30 href=#__codelineno-27-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model: </span><span class=si>{</span><span class=n>DEFAULT_SERVE_MODEL</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-27-31><a id=__codelineno-27-31 name=__codelineno-27-31 href=#__codelineno-27-31></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Port: </span><span class=si>{</span><span class=n>VLLM_PORT</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-27-32><a id=__codelineno-27-32 name=__codelineno-27-32 href=#__codelineno-27-32></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"GPU: </span><span class=si>{</span><span class=n>SERVE_GPU_CONFIG</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-27-33><a id=__codelineno-27-33 name=__codelineno-27-33 href=#__codelineno-27-33></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-27-34><a id=__codelineno-27-34 name=__codelineno-27-34 href=#__codelineno-27-34></a>
</span><span id=__span-27-35><a id=__codelineno-27-35 name=__codelineno-27-35 href=#__codelineno-27-35></a>    <span class=c1># Build vLLM command</span>
</span><span id=__span-27-36><a id=__codelineno-27-36 name=__codelineno-27-36 href=#__codelineno-27-36></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-27-37><a id=__codelineno-27-37 name=__codelineno-27-37 href=#__codelineno-27-37></a>        <span class=s2>"vllm"</span><span class=p>,</span> <span class=s2>"serve"</span><span class=p>,</span>                           <span class=c1># vLLM serve command</span>
</span><span id=__span-27-38><a id=__codelineno-27-38 name=__codelineno-27-38 href=#__codelineno-27-38></a>        <span class=s2>"--uvicorn-log-level=info"</span><span class=p>,</span>                <span class=c1># Logging level</span>
</span><span id=__span-27-39><a id=__codelineno-27-39 name=__codelineno-27-39 href=#__codelineno-27-39></a>        <span class=n>DEFAULT_SERVE_MODEL</span><span class=p>,</span>                       <span class=c1># Path to model</span>
</span><span id=__span-27-40><a id=__codelineno-27-40 name=__codelineno-27-40 href=#__codelineno-27-40></a>        <span class=s2>"--host"</span><span class=p>,</span> <span class=s2>"0.0.0.0"</span><span class=p>,</span>                       <span class=c1># Listen on all interfaces</span>
</span><span id=__span-27-41><a id=__codelineno-27-41 name=__codelineno-27-41 href=#__codelineno-27-41></a>        <span class=s2>"--port"</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>VLLM_PORT</span><span class=p>),</span>                  <span class=c1># Port to serve on</span>
</span><span id=__span-27-42><a id=__codelineno-27-42 name=__codelineno-27-42 href=#__codelineno-27-42></a>        <span class=s2>"--enforce-eager"</span><span class=p>,</span>                         <span class=c1># Faster startup (skip torch.compile)</span>
</span><span id=__span-27-43><a id=__codelineno-27-43 name=__codelineno-27-43 href=#__codelineno-27-43></a>        <span class=s2>"--tensor-parallel-size"</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>SERVE_NUM_GPUS</span><span class=p>),</span>  <span class=c1># How many GPUs to use</span>
</span><span id=__span-27-44><a id=__codelineno-27-44 name=__codelineno-27-44 href=#__codelineno-27-44></a>        <span class=s2>"--gpu-memory-utilization"</span><span class=p>,</span> <span class=s2>"0.4"</span><span class=p>,</span>         <span class=c1># Use 40% of GPU memory (be conservative)</span>
</span><span id=__span-27-45><a id=__codelineno-27-45 name=__codelineno-27-45 href=#__codelineno-27-45></a>        <span class=s2>"--trust-remote-code"</span><span class=p>,</span>                     <span class=c1># Allow custom model code</span>
</span><span id=__span-27-46><a id=__codelineno-27-46 name=__codelineno-27-46 href=#__codelineno-27-46></a>    <span class=p>]</span>
</span><span id=__span-27-47><a id=__codelineno-27-47 name=__codelineno-27-47 href=#__codelineno-27-47></a>
</span><span id=__span-27-48><a id=__codelineno-27-48 name=__codelineno-27-48 href=#__codelineno-27-48></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Command: </span><span class=si>{</span><span class=s1>' '</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-27-49><a id=__codelineno-27-49 name=__codelineno-27-49 href=#__codelineno-27-49></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-27-50><a id=__codelineno-27-50 name=__codelineno-27-50 href=#__codelineno-27-50></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"🚀 Starting vLLM server..."</span><span class=p>)</span>
</span><span id=__span-27-51><a id=__codelineno-27-51 name=__codelineno-27-51 href=#__codelineno-27-51></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-27-52><a id=__codelineno-27-52 name=__codelineno-27-52 href=#__codelineno-27-52></a>
</span><span id=__span-27-53><a id=__codelineno-27-53 name=__codelineno-27-53 href=#__codelineno-27-53></a>    <span class=c1># Start vLLM in background</span>
</span><span id=__span-27-54><a id=__codelineno-27-54 name=__codelineno-27-54 href=#__codelineno-27-54></a>    <span class=c1># Popen returns immediately, server keeps running</span>
</span><span id=__span-27-55><a id=__codelineno-27-55 name=__codelineno-27-55 href=#__codelineno-27-55></a>    <span class=n>subprocess</span><span class=o>.</span><span class=n>Popen</span><span class=p>(</span><span class=s2>" "</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>),</span> <span class=n>shell</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Key configuration options:</strong></p> <ol> <li> <p><strong><code>scaledown_window=3*60</code></strong>: This is HUGE for cost savings. If there are no requests for 3 minutes, Modal shuts down the container. You pay $0 when idle!</p> </li> <li> <p><strong><code>max_containers=2</code></strong>: Modal will automatically spin up a second instance if the first one gets too many requests. Load balancing happens automatically.</p> </li> <li> <p><strong><code>@modal.concurrent(max_inputs=50)</code></strong>: Each instance can handle 50 concurrent requests. If you get more than 50, Modal queues them or spins up instance <a class="magiclink magiclink-github magiclink-issue" href=https://github.com/adithya-s-k/AI-Engineering.academy/issues/2 title="GitHub Issue: adithya-s-k/AI-Engineering.academy #2">#2</a>.</p> </li> <li> <p><strong><code>gpu-memory-utilization=0.4</code></strong>: Use only 40% of GPU memory. vLLM is memory-efficient, and this leaves headroom for request spikes.</p> </li> </ol> <h3 id=deploying-the-server>Deploying the Server<a class=headerlink href=#deploying-the-server title="Permanent link">¶</a></h3> <p>To deploy and keep it running:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a>modal<span class=w> </span>deploy<span class=w> </span>FinetuneGemmaUnslothModal.py
</span></code></pre></div> <p>This creates a persistent deployment that stays alive (but auto-scales to 0 when idle).</p> <p><strong>Get the URL:</strong></p> <p>After deploying, Modal prints the URL. Or find it with:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a>modal<span class=w> </span>app<span class=w> </span>list
</span></code></pre></div> <p>You'll get something like: <code>https://your-username--finetuned-gemma-3-4b-it-serve-vllm.modal.run</code></p> <h3 id=using-the-api>Using the API<a class=headerlink href=#using-the-api title="Permanent link">¶</a></h3> <p>The server exposes an OpenAI-compatible API. Here's how to use it:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=kn>from</span><span class=w> </span><span class=nn>openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a><span class=kn>import</span><span class=w> </span><span class=nn>base64</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a><span class=c1># Create client pointing to your Modal endpoint</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a>    <span class=n>base_url</span><span class=o>=</span><span class=s2>"https://your-endpoint.modal.run/v1"</span><span class=p>,</span>  <span class=c1># Your Modal URL + /v1</span>
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a>    <span class=n>api_key</span><span class=o>=</span><span class=s2>"EMPTY"</span>  <span class=c1># Modal doesn't require API key (it's behind Modal auth)</span>
</span><span id=__span-30-8><a id=__codelineno-30-8 name=__codelineno-30-8 href=#__codelineno-30-8></a><span class=p>)</span>
</span><span id=__span-30-9><a id=__codelineno-30-9 name=__codelineno-30-9 href=#__codelineno-30-9></a>
</span><span id=__span-30-10><a id=__codelineno-30-10 name=__codelineno-30-10 href=#__codelineno-30-10></a><span class=c1># Encode image to base64</span>
</span><span id=__span-30-11><a id=__codelineno-30-11 name=__codelineno-30-11 href=#__codelineno-30-11></a><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>"equation.jpg"</span><span class=p>,</span> <span class=s2>"rb"</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-30-12><a id=__codelineno-30-12 name=__codelineno-30-12 href=#__codelineno-30-12></a>    <span class=n>image_b64</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>()</span>
</span><span id=__span-30-13><a id=__codelineno-30-13 name=__codelineno-30-13 href=#__codelineno-30-13></a>
</span><span id=__span-30-14><a id=__codelineno-30-14 name=__codelineno-30-14 href=#__codelineno-30-14></a><span class=c1># Make request (just like OpenAI!)</span>
</span><span id=__span-30-15><a id=__codelineno-30-15 name=__codelineno-30-15 href=#__codelineno-30-15></a><span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-30-16><a id=__codelineno-30-16 name=__codelineno-30-16 href=#__codelineno-30-16></a>    <span class=n>model</span><span class=o>=</span><span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_weights"</span><span class=p>,</span>  <span class=c1># Model path</span>
</span><span id=__span-30-17><a id=__codelineno-30-17 name=__codelineno-30-17 href=#__codelineno-30-17></a>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-30-18><a id=__codelineno-30-18 name=__codelineno-30-18 href=#__codelineno-30-18></a>        <span class=p>{</span>
</span><span id=__span-30-19><a id=__codelineno-30-19 name=__codelineno-30-19 href=#__codelineno-30-19></a>            <span class=s2>"role"</span><span class=p>:</span> <span class=s2>"user"</span><span class=p>,</span>
</span><span id=__span-30-20><a id=__codelineno-30-20 name=__codelineno-30-20 href=#__codelineno-30-20></a>            <span class=s2>"content"</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-30-21><a id=__codelineno-30-21 name=__codelineno-30-21 href=#__codelineno-30-21></a>                <span class=c1># Send image as base64</span>
</span><span id=__span-30-22><a id=__codelineno-30-22 name=__codelineno-30-22 href=#__codelineno-30-22></a>                <span class=p>{</span>
</span><span id=__span-30-23><a id=__codelineno-30-23 name=__codelineno-30-23 href=#__codelineno-30-23></a>                    <span class=s2>"type"</span><span class=p>:</span> <span class=s2>"image_url"</span><span class=p>,</span>
</span><span id=__span-30-24><a id=__codelineno-30-24 name=__codelineno-30-24 href=#__codelineno-30-24></a>                    <span class=s2>"image_url"</span><span class=p>:</span> <span class=p>{</span><span class=s2>"url"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"data:image/jpeg;base64,</span><span class=si>{</span><span class=n>image_b64</span><span class=si>}</span><span class=s2>"</span><span class=p>}</span>
</span><span id=__span-30-25><a id=__codelineno-30-25 name=__codelineno-30-25 href=#__codelineno-30-25></a>                <span class=p>},</span>
</span><span id=__span-30-26><a id=__codelineno-30-26 name=__codelineno-30-26 href=#__codelineno-30-26></a>                <span class=c1># Send text prompt</span>
</span><span id=__span-30-27><a id=__codelineno-30-27 name=__codelineno-30-27 href=#__codelineno-30-27></a>                <span class=p>{</span>
</span><span id=__span-30-28><a id=__codelineno-30-28 name=__codelineno-30-28 href=#__codelineno-30-28></a>                    <span class=s2>"type"</span><span class=p>:</span> <span class=s2>"text"</span><span class=p>,</span>
</span><span id=__span-30-29><a id=__codelineno-30-29 name=__codelineno-30-29 href=#__codelineno-30-29></a>                    <span class=s2>"text"</span><span class=p>:</span> <span class=s2>"Write the LaTeX representation for this image."</span>
</span><span id=__span-30-30><a id=__codelineno-30-30 name=__codelineno-30-30 href=#__codelineno-30-30></a>                <span class=p>},</span>
</span><span id=__span-30-31><a id=__codelineno-30-31 name=__codelineno-30-31 href=#__codelineno-30-31></a>            <span class=p>],</span>
</span><span id=__span-30-32><a id=__codelineno-30-32 name=__codelineno-30-32 href=#__codelineno-30-32></a>        <span class=p>},</span>
</span><span id=__span-30-33><a id=__codelineno-30-33 name=__codelineno-30-33 href=#__codelineno-30-33></a>    <span class=p>],</span>
</span><span id=__span-30-34><a id=__codelineno-30-34 name=__codelineno-30-34 href=#__codelineno-30-34></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>      <span class=c1># Low temp for deterministic output</span>
</span><span id=__span-30-35><a id=__codelineno-30-35 name=__codelineno-30-35 href=#__codelineno-30-35></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>       <span class=c1># Max length of response</span>
</span><span id=__span-30-36><a id=__codelineno-30-36 name=__codelineno-30-36 href=#__codelineno-30-36></a><span class=p>)</span>
</span><span id=__span-30-37><a id=__codelineno-30-37 name=__codelineno-30-37 href=#__codelineno-30-37></a>
</span><span id=__span-30-38><a id=__codelineno-30-38 name=__codelineno-30-38 href=#__codelineno-30-38></a><span class=c1># Print the LaTeX code</span>
</span><span id=__span-30-39><a id=__codelineno-30-39 name=__codelineno-30-39 href=#__codelineno-30-39></a><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Example output:</strong> </p><div class="language-text highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a>\frac{d}{dx} \left( x^2 + 2x + 1 \right) = 2x + 2
</span></code></pre></div> <h3 id=testing-the-deployment>Testing the Deployment<a class=headerlink href=#testing-the-deployment title="Permanent link">¶</a></h3> <p>Quick test script:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=kn>import</span><span class=w> </span><span class=nn>requests</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a><span class=kn>import</span><span class=w> </span><span class=nn>base64</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a><span class=c1># Your Modal endpoint</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a><span class=n>url</span> <span class=o>=</span> <span class=s2>"https://your-endpoint.modal.run/v1/chat/completions"</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a><span class=c1># Load and encode image</span>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=s2>"test_equation.jpg"</span><span class=p>,</span> <span class=s2>"rb"</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a>    <span class=n>img_b64</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>()</span>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a>
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11 href=#__codelineno-32-11></a><span class=c1># Make request</span>
</span><span id=__span-32-12><a id=__codelineno-32-12 name=__codelineno-32-12 href=#__codelineno-32-12></a><span class=n>response</span> <span class=o>=</span> <span class=n>requests</span><span class=o>.</span><span class=n>post</span><span class=p>(</span>
</span><span id=__span-32-13><a id=__codelineno-32-13 name=__codelineno-32-13 href=#__codelineno-32-13></a>    <span class=n>url</span><span class=p>,</span>
</span><span id=__span-32-14><a id=__codelineno-32-14 name=__codelineno-32-14 href=#__codelineno-32-14></a>    <span class=n>json</span><span class=o>=</span><span class=p>{</span>
</span><span id=__span-32-15><a id=__codelineno-32-15 name=__codelineno-32-15 href=#__codelineno-32-15></a>        <span class=s2>"model"</span><span class=p>:</span> <span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_weights"</span><span class=p>,</span>
</span><span id=__span-32-16><a id=__codelineno-32-16 name=__codelineno-32-16 href=#__codelineno-32-16></a>        <span class=s2>"messages"</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-32-17><a id=__codelineno-32-17 name=__codelineno-32-17 href=#__codelineno-32-17></a>            <span class=p>{</span>
</span><span id=__span-32-18><a id=__codelineno-32-18 name=__codelineno-32-18 href=#__codelineno-32-18></a>                <span class=s2>"role"</span><span class=p>:</span> <span class=s2>"user"</span><span class=p>,</span>
</span><span id=__span-32-19><a id=__codelineno-32-19 name=__codelineno-32-19 href=#__codelineno-32-19></a>                <span class=s2>"content"</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-32-20><a id=__codelineno-32-20 name=__codelineno-32-20 href=#__codelineno-32-20></a>                    <span class=p>{</span><span class=s2>"type"</span><span class=p>:</span> <span class=s2>"image_url"</span><span class=p>,</span> <span class=s2>"image_url"</span><span class=p>:</span> <span class=p>{</span><span class=s2>"url"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"data:image/jpeg;base64,</span><span class=si>{</span><span class=n>img_b64</span><span class=si>}</span><span class=s2>"</span><span class=p>}},</span>
</span><span id=__span-32-21><a id=__codelineno-32-21 name=__codelineno-32-21 href=#__codelineno-32-21></a>                    <span class=p>{</span><span class=s2>"type"</span><span class=p>:</span> <span class=s2>"text"</span><span class=p>,</span> <span class=s2>"text"</span><span class=p>:</span> <span class=s2>"Write the LaTeX representation for this image."</span><span class=p>}</span>
</span><span id=__span-32-22><a id=__codelineno-32-22 name=__codelineno-32-22 href=#__codelineno-32-22></a>                <span class=p>]</span>
</span><span id=__span-32-23><a id=__codelineno-32-23 name=__codelineno-32-23 href=#__codelineno-32-23></a>            <span class=p>}</span>
</span><span id=__span-32-24><a id=__codelineno-32-24 name=__codelineno-32-24 href=#__codelineno-32-24></a>        <span class=p>],</span>
</span><span id=__span-32-25><a id=__codelineno-32-25 name=__codelineno-32-25 href=#__codelineno-32-25></a>        <span class=s2>"temperature"</span><span class=p>:</span> <span class=mf>0.1</span><span class=p>,</span>
</span><span id=__span-32-26><a id=__codelineno-32-26 name=__codelineno-32-26 href=#__codelineno-32-26></a>        <span class=s2>"max_tokens"</span><span class=p>:</span> <span class=mi>512</span>
</span><span id=__span-32-27><a id=__codelineno-32-27 name=__codelineno-32-27 href=#__codelineno-32-27></a>    <span class=p>}</span>
</span><span id=__span-32-28><a id=__codelineno-32-28 name=__codelineno-32-28 href=#__codelineno-32-28></a><span class=p>)</span>
</span><span id=__span-32-29><a id=__codelineno-32-29 name=__codelineno-32-29 href=#__codelineno-32-29></a>
</span><span id=__span-32-30><a id=__codelineno-32-30 name=__codelineno-32-30 href=#__codelineno-32-30></a><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>json</span><span class=p>()[</span><span class=s2>"choices"</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s2>"message"</span><span class=p>][</span><span class=s2>"content"</span><span class=p>])</span>
</span></code></pre></div> <p><strong>Pro tip:</strong> The first request after the server scales from 0 will take 30-60 seconds (model loading). Subsequent requests are instant.</p> <h2 id=stage-6-evaluation>Stage 6: Evaluation<a class=headerlink href=#stage-6-evaluation title="Permanent link">¶</a></h2> <p>Alright, let's measure how good our model actually is. We'll use real metrics: exact match accuracy, character error rate, and word error rate.</p> <h3 id=evaluation-image-lightweight-cpu-only>Evaluation Image (Lightweight, CPU-only)<a class=headerlink href=#evaluation-image-lightweight-cpu-only title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=n>EVAL_IMAGE</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a>    <span class=c1># Lightweight Debian base (no CUDA needed for eval)</span>
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3 href=#__codelineno-33-3></a>    <span class=n>ModalImage</span><span class=o>.</span><span class=n>debian_slim</span><span class=p>(</span><span class=n>python_version</span><span class=o>=</span><span class=s2>"3.12"</span><span class=p>)</span>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4 href=#__codelineno-33-4></a>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5 href=#__codelineno-33-5></a>    <span class=c1># Install evaluation dependencies</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6 href=#__codelineno-33-6></a>    <span class=o>.</span><span class=n>pip_install</span><span class=p>(</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7 href=#__codelineno-33-7></a>        <span class=s2>"openai"</span><span class=p>,</span>                         <span class=c1># To call our vLLM endpoint</span>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8 href=#__codelineno-33-8></a>        <span class=s2>"datasets"</span><span class=p>,</span>                       <span class=c1># Load test dataset</span>
</span><span id=__span-33-9><a id=__codelineno-33-9 name=__codelineno-33-9 href=#__codelineno-33-9></a>        <span class=s2>"pillow"</span><span class=p>,</span>                         <span class=c1># Image processing</span>
</span><span id=__span-33-10><a id=__codelineno-33-10 name=__codelineno-33-10 href=#__codelineno-33-10></a>        <span class=s2>"numpy"</span><span class=p>,</span>                          <span class=c1># Numerical ops</span>
</span><span id=__span-33-11><a id=__codelineno-33-11 name=__codelineno-33-11 href=#__codelineno-33-11></a>        <span class=s2>"jiwer"</span><span class=p>,</span>                          <span class=c1># Word/Character Error Rate metrics</span>
</span><span id=__span-33-12><a id=__codelineno-33-12 name=__codelineno-33-12 href=#__codelineno-33-12></a>        <span class=s2>"nltk"</span><span class=p>,</span>                           <span class=c1># NLP utilities</span>
</span><span id=__span-33-13><a id=__codelineno-33-13 name=__codelineno-33-13 href=#__codelineno-33-13></a>        <span class=s2>"tqdm"</span><span class=p>,</span>                           <span class=c1># Progress bars</span>
</span><span id=__span-33-14><a id=__codelineno-33-14 name=__codelineno-33-14 href=#__codelineno-33-14></a>        <span class=s2>"huggingface_hub[hf_transfer]"</span><span class=p>,</span>  <span class=c1># Fast dataset downloads</span>
</span><span id=__span-33-15><a id=__codelineno-33-15 name=__codelineno-33-15 href=#__codelineno-33-15></a>    <span class=p>)</span>
</span><span id=__span-33-16><a id=__codelineno-33-16 name=__codelineno-33-16 href=#__codelineno-33-16></a>
</span><span id=__span-33-17><a id=__codelineno-33-17 name=__codelineno-33-17 href=#__codelineno-33-17></a>    <span class=c1># Enable fast downloads</span>
</span><span id=__span-33-18><a id=__codelineno-33-18 name=__codelineno-33-18 href=#__codelineno-33-18></a>    <span class=o>.</span><span class=n>env</span><span class=p>({</span><span class=s2>"HF_HUB_ENABLE_HF_TRANSFER"</span><span class=p>:</span> <span class=s2>"1"</span><span class=p>})</span>
</span><span id=__span-33-19><a id=__codelineno-33-19 name=__codelineno-33-19 href=#__codelineno-33-19></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Why CPU for evaluation?</strong> - Evaluation just calls our API endpoint (which has the GPU) - Processing responses doesn't need GPU - Saves money!</p> <h3 id=the-evaluation-function>The Evaluation Function<a class=headerlink href=#the-evaluation-function title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>EVAL_IMAGE</span><span class=p>,</span>                <span class=c1># Lightweight CPU image</span>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>            <span class=c1># Access cached datasets</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>huggingface_secret</span><span class=p>],</span>    <span class=c1># HF token for datasets</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>                <span class=c1># Eval can take a while</span>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a>    <span class=c1># No GPU! Runs on CPU</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a><span class=p>)</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a><span class=k>def</span><span class=w> </span><span class=nf>evaluate_model</span><span class=p>(</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>    <span class=n>endpoint_url</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>,</span>                                  <span class=c1># vLLM endpoint (auto-detected)</span>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a>    <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"/data/Finetuned_Gemma_3_4b_it/final_weights"</span><span class=p>,</span>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11 href=#__codelineno-34-11></a>    <span class=n>dataset_name</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"unsloth/LaTeX_OCR"</span><span class=p>,</span>                  <span class=c1># Test dataset</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12 href=#__codelineno-34-12></a>    <span class=n>dataset_split</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"test"</span><span class=p>,</span>                              <span class=c1># Use test split</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13 href=#__codelineno-34-13></a>    <span class=n>max_samples</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>100</span><span class=p>,</span>                                    <span class=c1># How many to evaluate</span>
</span><span id=__span-34-14><a id=__codelineno-34-14 name=__codelineno-34-14 href=#__codelineno-34-14></a>    <span class=n>max_parallel_requests</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8</span><span class=p>,</span>                           <span class=c1># Concurrent requests</span>
</span><span id=__span-34-15><a id=__codelineno-34-15 name=__codelineno-34-15 href=#__codelineno-34-15></a>    <span class=n>temperature</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.1</span><span class=p>,</span>                                 <span class=c1># Low temp for consistency</span>
</span><span id=__span-34-16><a id=__codelineno-34-16 name=__codelineno-34-16 href=#__codelineno-34-16></a>    <span class=n>max_tokens</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>512</span><span class=p>,</span>                                    <span class=c1># Max response length</span>
</span><span id=__span-34-17><a id=__codelineno-34-17 name=__codelineno-34-17 href=#__codelineno-34-17></a><span class=p>):</span>
</span><span id=__span-34-18><a id=__codelineno-34-18 name=__codelineno-34-18 href=#__codelineno-34-18></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-34-19><a id=__codelineno-34-19 name=__codelineno-34-19 href=#__codelineno-34-19></a><span class=sd>    Evaluate the fine-tuned model on LaTeX OCR test set.</span>
</span><span id=__span-34-20><a id=__codelineno-34-20 name=__codelineno-34-20 href=#__codelineno-34-20></a>
</span><span id=__span-34-21><a id=__codelineno-34-21 name=__codelineno-34-21 href=#__codelineno-34-21></a><span class=sd>    Metrics:</span>
</span><span id=__span-34-22><a id=__codelineno-34-22 name=__codelineno-34-22 href=#__codelineno-34-22></a><span class=sd>    - Exact Match Accuracy: % of perfect predictions</span>
</span><span id=__span-34-23><a id=__codelineno-34-23 name=__codelineno-34-23 href=#__codelineno-34-23></a><span class=sd>    - Character Error Rate (CER): Edit distance at character level</span>
</span><span id=__span-34-24><a id=__codelineno-34-24 name=__codelineno-34-24 href=#__codelineno-34-24></a><span class=sd>    - Word Error Rate (WER): Edit distance at word level</span>
</span><span id=__span-34-25><a id=__codelineno-34-25 name=__codelineno-34-25 href=#__codelineno-34-25></a><span class=sd>    """</span>
</span><span id=__span-34-26><a id=__codelineno-34-26 name=__codelineno-34-26 href=#__codelineno-34-26></a>    <span class=kn>from</span><span class=w> </span><span class=nn>concurrent.futures</span><span class=w> </span><span class=kn>import</span> <span class=n>ThreadPoolExecutor</span><span class=p>,</span> <span class=n>as_completed</span>
</span><span id=__span-34-27><a id=__codelineno-34-27 name=__codelineno-34-27 href=#__codelineno-34-27></a>    <span class=kn>from</span><span class=w> </span><span class=nn>openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-34-28><a id=__codelineno-34-28 name=__codelineno-34-28 href=#__codelineno-34-28></a>    <span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_dataset</span>
</span><span id=__span-34-29><a id=__codelineno-34-29 name=__codelineno-34-29 href=#__codelineno-34-29></a>    <span class=kn>from</span><span class=w> </span><span class=nn>jiwer</span><span class=w> </span><span class=kn>import</span> <span class=n>wer</span><span class=p>,</span> <span class=n>cer</span>
</span><span id=__span-34-30><a id=__codelineno-34-30 name=__codelineno-34-30 href=#__codelineno-34-30></a>    <span class=kn>from</span><span class=w> </span><span class=nn>tqdm</span><span class=w> </span><span class=kn>import</span> <span class=n>tqdm</span>
</span><span id=__span-34-31><a id=__codelineno-34-31 name=__codelineno-34-31 href=#__codelineno-34-31></a>    <span class=kn>import</span><span class=w> </span><span class=nn>base64</span>
</span><span id=__span-34-32><a id=__codelineno-34-32 name=__codelineno-34-32 href=#__codelineno-34-32></a>    <span class=kn>from</span><span class=w> </span><span class=nn>io</span><span class=w> </span><span class=kn>import</span> <span class=n>BytesIO</span>
</span><span id=__span-34-33><a id=__codelineno-34-33 name=__codelineno-34-33 href=#__codelineno-34-33></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-34-34><a id=__codelineno-34-34 name=__codelineno-34-34 href=#__codelineno-34-34></a>
</span><span id=__span-34-35><a id=__codelineno-34-35 name=__codelineno-34-35 href=#__codelineno-34-35></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-36><a id=__codelineno-34-36 name=__codelineno-34-36 href=#__codelineno-34-36></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"EVALUATING MODEL"</span><span class=p>)</span>
</span><span id=__span-34-37><a id=__codelineno-34-37 name=__codelineno-34-37 href=#__codelineno-34-37></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-38><a id=__codelineno-34-38 name=__codelineno-34-38 href=#__codelineno-34-38></a>
</span><span id=__span-34-39><a id=__codelineno-34-39 name=__codelineno-34-39 href=#__codelineno-34-39></a>    <span class=c1># === Get endpoint URL ===</span>
</span><span id=__span-34-40><a id=__codelineno-34-40 name=__codelineno-34-40 href=#__codelineno-34-40></a>    <span class=k>if</span> <span class=n>endpoint_url</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-34-41><a id=__codelineno-34-41 name=__codelineno-34-41 href=#__codelineno-34-41></a>        <span class=c1># Auto-retrieve the vLLM endpoint URL</span>
</span><span id=__span-34-42><a id=__codelineno-34-42 name=__codelineno-34-42 href=#__codelineno-34-42></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Auto-detecting vLLM endpoint..."</span><span class=p>)</span>
</span><span id=__span-34-43><a id=__codelineno-34-43 name=__codelineno-34-43 href=#__codelineno-34-43></a>        <span class=n>endpoint_url</span> <span class=o>=</span> <span class=n>serve_vllm</span><span class=o>.</span><span class=n>get_web_url</span><span class=p>()</span><span class=o>.</span><span class=n>rstrip</span><span class=p>(</span><span class=s2>"/"</span><span class=p>)</span> <span class=o>+</span> <span class=s2>"/v1"</span>
</span><span id=__span-34-44><a id=__codelineno-34-44 name=__codelineno-34-44 href=#__codelineno-34-44></a>
</span><span id=__span-34-45><a id=__codelineno-34-45 name=__codelineno-34-45 href=#__codelineno-34-45></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Endpoint: </span><span class=si>{</span><span class=n>endpoint_url</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-46><a id=__codelineno-34-46 name=__codelineno-34-46 href=#__codelineno-34-46></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model: </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-47><a id=__codelineno-34-47 name=__codelineno-34-47 href=#__codelineno-34-47></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Dataset: </span><span class=si>{</span><span class=n>dataset_name</span><span class=si>}</span><span class=s2> (</span><span class=si>{</span><span class=n>dataset_split</span><span class=si>}</span><span class=s2>)"</span><span class=p>)</span>
</span><span id=__span-34-48><a id=__codelineno-34-48 name=__codelineno-34-48 href=#__codelineno-34-48></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Max samples: </span><span class=si>{</span><span class=n>max_samples</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-49><a id=__codelineno-34-49 name=__codelineno-34-49 href=#__codelineno-34-49></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-50><a id=__codelineno-34-50 name=__codelineno-34-50 href=#__codelineno-34-50></a>
</span><span id=__span-34-51><a id=__codelineno-34-51 name=__codelineno-34-51 href=#__codelineno-34-51></a>    <span class=c1># === Load test dataset ===</span>
</span><span id=__span-34-52><a id=__codelineno-34-52 name=__codelineno-34-52 href=#__codelineno-34-52></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Loading test dataset..."</span><span class=p>)</span>
</span><span id=__span-34-53><a id=__codelineno-34-53 name=__codelineno-34-53 href=#__codelineno-34-53></a>    <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-34-54><a id=__codelineno-34-54 name=__codelineno-34-54 href=#__codelineno-34-54></a>
</span><span id=__span-34-55><a id=__codelineno-34-55 name=__codelineno-34-55 href=#__codelineno-34-55></a>    <span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=n>dataset_name</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=n>dataset_split</span><span class=p>)</span>
</span><span id=__span-34-56><a id=__codelineno-34-56 name=__codelineno-34-56 href=#__codelineno-34-56></a>
</span><span id=__span-34-57><a id=__codelineno-34-57 name=__codelineno-34-57 href=#__codelineno-34-57></a>    <span class=c1># Limit to max_samples</span>
</span><span id=__span-34-58><a id=__codelineno-34-58 name=__codelineno-34-58 href=#__codelineno-34-58></a>    <span class=k>if</span> <span class=n>max_samples</span> <span class=ow>and</span> <span class=n>max_samples</span> <span class=o>&lt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>):</span>
</span><span id=__span-34-59><a id=__codelineno-34-59 name=__codelineno-34-59 href=#__codelineno-34-59></a>        <span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=n>max_samples</span><span class=p>))</span>
</span><span id=__span-34-60><a id=__codelineno-34-60 name=__codelineno-34-60 href=#__codelineno-34-60></a>
</span><span id=__span-34-61><a id=__codelineno-34-61 name=__codelineno-34-61 href=#__codelineno-34-61></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"✓ Loaded </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2> samples"</span><span class=p>)</span>
</span><span id=__span-34-62><a id=__codelineno-34-62 name=__codelineno-34-62 href=#__codelineno-34-62></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-63><a id=__codelineno-34-63 name=__codelineno-34-63 href=#__codelineno-34-63></a>
</span><span id=__span-34-64><a id=__codelineno-34-64 name=__codelineno-34-64 href=#__codelineno-34-64></a>    <span class=c1># === Set up OpenAI client ===</span>
</span><span id=__span-34-65><a id=__codelineno-34-65 name=__codelineno-34-65 href=#__codelineno-34-65></a>    <span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span><span id=__span-34-66><a id=__codelineno-34-66 name=__codelineno-34-66 href=#__codelineno-34-66></a>        <span class=n>base_url</span><span class=o>=</span><span class=n>endpoint_url</span><span class=p>,</span>
</span><span id=__span-34-67><a id=__codelineno-34-67 name=__codelineno-34-67 href=#__codelineno-34-67></a>        <span class=n>api_key</span><span class=o>=</span><span class=s2>"EMPTY"</span>  <span class=c1># Modal doesn't require API key</span>
</span><span id=__span-34-68><a id=__codelineno-34-68 name=__codelineno-34-68 href=#__codelineno-34-68></a>    <span class=p>)</span>
</span><span id=__span-34-69><a id=__codelineno-34-69 name=__codelineno-34-69 href=#__codelineno-34-69></a>
</span><span id=__span-34-70><a id=__codelineno-34-70 name=__codelineno-34-70 href=#__codelineno-34-70></a>    <span class=c1># === Helper function to encode images ===</span>
</span><span id=__span-34-71><a id=__codelineno-34-71 name=__codelineno-34-71 href=#__codelineno-34-71></a>    <span class=k>def</span><span class=w> </span><span class=nf>encode_image_to_base64</span><span class=p>(</span><span class=n>image</span><span class=p>):</span>
</span><span id=__span-34-72><a id=__codelineno-34-72 name=__codelineno-34-72 href=#__codelineno-34-72></a><span class=w>        </span><span class=sd>"""Convert PIL Image to base64 string."""</span>
</span><span id=__span-34-73><a id=__codelineno-34-73 name=__codelineno-34-73 href=#__codelineno-34-73></a>        <span class=n>buffered</span> <span class=o>=</span> <span class=n>BytesIO</span><span class=p>()</span>
</span><span id=__span-34-74><a id=__codelineno-34-74 name=__codelineno-34-74 href=#__codelineno-34-74></a>        <span class=n>image</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>buffered</span><span class=p>,</span> <span class=nb>format</span><span class=o>=</span><span class=s2>"PNG"</span><span class=p>)</span>
</span><span id=__span-34-75><a id=__codelineno-34-75 name=__codelineno-34-75 href=#__codelineno-34-75></a>        <span class=n>img_bytes</span> <span class=o>=</span> <span class=n>buffered</span><span class=o>.</span><span class=n>getvalue</span><span class=p>()</span>
</span><span id=__span-34-76><a id=__codelineno-34-76 name=__codelineno-34-76 href=#__codelineno-34-76></a>        <span class=k>return</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>img_bytes</span><span class=p>)</span><span class=o>.</span><span class=n>decode</span><span class=p>()</span>
</span><span id=__span-34-77><a id=__codelineno-34-77 name=__codelineno-34-77 href=#__codelineno-34-77></a>
</span><span id=__span-34-78><a id=__codelineno-34-78 name=__codelineno-34-78 href=#__codelineno-34-78></a>    <span class=c1># === Run inference on all samples (in parallel) ===</span>
</span><span id=__span-34-79><a id=__codelineno-34-79 name=__codelineno-34-79 href=#__codelineno-34-79></a>    <span class=k>def</span><span class=w> </span><span class=nf>run_inference</span><span class=p>(</span><span class=n>sample</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span><span id=__span-34-80><a id=__codelineno-34-80 name=__codelineno-34-80 href=#__codelineno-34-80></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-34-81><a id=__codelineno-34-81 name=__codelineno-34-81 href=#__codelineno-34-81></a><span class=sd>        Run inference on a single sample.</span>
</span><span id=__span-34-82><a id=__codelineno-34-82 name=__codelineno-34-82 href=#__codelineno-34-82></a>
</span><span id=__span-34-83><a id=__codelineno-34-83 name=__codelineno-34-83 href=#__codelineno-34-83></a><span class=sd>        Returns:</span>
</span><span id=__span-34-84><a id=__codelineno-34-84 name=__codelineno-34-84 href=#__codelineno-34-84></a><span class=sd>            dict with "prediction" and "ground_truth"</span>
</span><span id=__span-34-85><a id=__codelineno-34-85 name=__codelineno-34-85 href=#__codelineno-34-85></a><span class=sd>        """</span>
</span><span id=__span-34-86><a id=__codelineno-34-86 name=__codelineno-34-86 href=#__codelineno-34-86></a>        <span class=k>try</span><span class=p>:</span>
</span><span id=__span-34-87><a id=__codelineno-34-87 name=__codelineno-34-87 href=#__codelineno-34-87></a>            <span class=c1># Encode image</span>
</span><span id=__span-34-88><a id=__codelineno-34-88 name=__codelineno-34-88 href=#__codelineno-34-88></a>            <span class=n>image_base64</span> <span class=o>=</span> <span class=n>encode_image_to_base64</span><span class=p>(</span><span class=n>sample</span><span class=p>[</span><span class=s2>"image"</span><span class=p>])</span>
</span><span id=__span-34-89><a id=__codelineno-34-89 name=__codelineno-34-89 href=#__codelineno-34-89></a>
</span><span id=__span-34-90><a id=__codelineno-34-90 name=__codelineno-34-90 href=#__codelineno-34-90></a>            <span class=c1># Call API</span>
</span><span id=__span-34-91><a id=__codelineno-34-91 name=__codelineno-34-91 href=#__codelineno-34-91></a>            <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-34-92><a id=__codelineno-34-92 name=__codelineno-34-92 href=#__codelineno-34-92></a>                <span class=n>model</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span><span id=__span-34-93><a id=__codelineno-34-93 name=__codelineno-34-93 href=#__codelineno-34-93></a>                <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span><span id=__span-34-94><a id=__codelineno-34-94 name=__codelineno-34-94 href=#__codelineno-34-94></a>                    <span class=p>{</span>
</span><span id=__span-34-95><a id=__codelineno-34-95 name=__codelineno-34-95 href=#__codelineno-34-95></a>                        <span class=s2>"role"</span><span class=p>:</span> <span class=s2>"user"</span><span class=p>,</span>
</span><span id=__span-34-96><a id=__codelineno-34-96 name=__codelineno-34-96 href=#__codelineno-34-96></a>                        <span class=s2>"content"</span><span class=p>:</span> <span class=p>[</span>
</span><span id=__span-34-97><a id=__codelineno-34-97 name=__codelineno-34-97 href=#__codelineno-34-97></a>                            <span class=p>{</span>
</span><span id=__span-34-98><a id=__codelineno-34-98 name=__codelineno-34-98 href=#__codelineno-34-98></a>                                <span class=s2>"type"</span><span class=p>:</span> <span class=s2>"image_url"</span><span class=p>,</span>
</span><span id=__span-34-99><a id=__codelineno-34-99 name=__codelineno-34-99 href=#__codelineno-34-99></a>                                <span class=s2>"image_url"</span><span class=p>:</span> <span class=p>{</span><span class=s2>"url"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"data:image/png;base64,</span><span class=si>{</span><span class=n>image_base64</span><span class=si>}</span><span class=s2>"</span><span class=p>}</span>
</span><span id=__span-34-100><a id=__codelineno-34-100 name=__codelineno-34-100 href=#__codelineno-34-100></a>                            <span class=p>},</span>
</span><span id=__span-34-101><a id=__codelineno-34-101 name=__codelineno-34-101 href=#__codelineno-34-101></a>                            <span class=p>{</span>
</span><span id=__span-34-102><a id=__codelineno-34-102 name=__codelineno-34-102 href=#__codelineno-34-102></a>                                <span class=s2>"type"</span><span class=p>:</span> <span class=s2>"text"</span><span class=p>,</span>
</span><span id=__span-34-103><a id=__codelineno-34-103 name=__codelineno-34-103 href=#__codelineno-34-103></a>                                <span class=s2>"text"</span><span class=p>:</span> <span class=s2>"Write the LaTeX representation for this image."</span>
</span><span id=__span-34-104><a id=__codelineno-34-104 name=__codelineno-34-104 href=#__codelineno-34-104></a>                            <span class=p>},</span>
</span><span id=__span-34-105><a id=__codelineno-34-105 name=__codelineno-34-105 href=#__codelineno-34-105></a>                        <span class=p>],</span>
</span><span id=__span-34-106><a id=__codelineno-34-106 name=__codelineno-34-106 href=#__codelineno-34-106></a>                    <span class=p>},</span>
</span><span id=__span-34-107><a id=__codelineno-34-107 name=__codelineno-34-107 href=#__codelineno-34-107></a>                <span class=p>],</span>
</span><span id=__span-34-108><a id=__codelineno-34-108 name=__codelineno-34-108 href=#__codelineno-34-108></a>                <span class=n>temperature</span><span class=o>=</span><span class=n>temperature</span><span class=p>,</span>
</span><span id=__span-34-109><a id=__codelineno-34-109 name=__codelineno-34-109 href=#__codelineno-34-109></a>                <span class=n>max_tokens</span><span class=o>=</span><span class=n>max_tokens</span><span class=p>,</span>
</span><span id=__span-34-110><a id=__codelineno-34-110 name=__codelineno-34-110 href=#__codelineno-34-110></a>            <span class=p>)</span>
</span><span id=__span-34-111><a id=__codelineno-34-111 name=__codelineno-34-111 href=#__codelineno-34-111></a>
</span><span id=__span-34-112><a id=__codelineno-34-112 name=__codelineno-34-112 href=#__codelineno-34-112></a>            <span class=c1># Extract prediction</span>
</span><span id=__span-34-113><a id=__codelineno-34-113 name=__codelineno-34-113 href=#__codelineno-34-113></a>            <span class=n>prediction</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span><span id=__span-34-114><a id=__codelineno-34-114 name=__codelineno-34-114 href=#__codelineno-34-114></a>            <span class=n>ground_truth</span> <span class=o>=</span> <span class=n>sample</span><span class=p>[</span><span class=s2>"text"</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span><span id=__span-34-115><a id=__codelineno-34-115 name=__codelineno-34-115 href=#__codelineno-34-115></a>
</span><span id=__span-34-116><a id=__codelineno-34-116 name=__codelineno-34-116 href=#__codelineno-34-116></a>            <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-34-117><a id=__codelineno-34-117 name=__codelineno-34-117 href=#__codelineno-34-117></a>                <span class=s2>"prediction"</span><span class=p>:</span> <span class=n>prediction</span><span class=p>,</span>
</span><span id=__span-34-118><a id=__codelineno-34-118 name=__codelineno-34-118 href=#__codelineno-34-118></a>                <span class=s2>"ground_truth"</span><span class=p>:</span> <span class=n>ground_truth</span><span class=p>,</span>
</span><span id=__span-34-119><a id=__codelineno-34-119 name=__codelineno-34-119 href=#__codelineno-34-119></a>            <span class=p>}</span>
</span><span id=__span-34-120><a id=__codelineno-34-120 name=__codelineno-34-120 href=#__codelineno-34-120></a>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span><span id=__span-34-121><a id=__codelineno-34-121 name=__codelineno-34-121 href=#__codelineno-34-121></a>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Error on sample </span><span class=si>{</span><span class=n>idx</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-122><a id=__codelineno-34-122 name=__codelineno-34-122 href=#__codelineno-34-122></a>            <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-34-123><a id=__codelineno-34-123 name=__codelineno-34-123 href=#__codelineno-34-123></a>                <span class=s2>"prediction"</span><span class=p>:</span> <span class=s2>""</span><span class=p>,</span>
</span><span id=__span-34-124><a id=__codelineno-34-124 name=__codelineno-34-124 href=#__codelineno-34-124></a>                <span class=s2>"ground_truth"</span><span class=p>:</span> <span class=n>sample</span><span class=p>[</span><span class=s2>"text"</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>(),</span>
</span><span id=__span-34-125><a id=__codelineno-34-125 name=__codelineno-34-125 href=#__codelineno-34-125></a>            <span class=p>}</span>
</span><span id=__span-34-126><a id=__codelineno-34-126 name=__codelineno-34-126 href=#__codelineno-34-126></a>
</span><span id=__span-34-127><a id=__codelineno-34-127 name=__codelineno-34-127 href=#__codelineno-34-127></a>    <span class=c1># Run evaluation with parallel requests</span>
</span><span id=__span-34-128><a id=__codelineno-34-128 name=__codelineno-34-128 href=#__codelineno-34-128></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running inference on </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2> samples..."</span><span class=p>)</span>
</span><span id=__span-34-129><a id=__codelineno-34-129 name=__codelineno-34-129 href=#__codelineno-34-129></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Parallelism: </span><span class=si>{</span><span class=n>max_parallel_requests</span><span class=si>}</span><span class=s2> concurrent requests"</span><span class=p>)</span>
</span><span id=__span-34-130><a id=__codelineno-34-130 name=__codelineno-34-130 href=#__codelineno-34-130></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-131><a id=__codelineno-34-131 name=__codelineno-34-131 href=#__codelineno-34-131></a>
</span><span id=__span-34-132><a id=__codelineno-34-132 name=__codelineno-34-132 href=#__codelineno-34-132></a>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-34-133><a id=__codelineno-34-133 name=__codelineno-34-133 href=#__codelineno-34-133></a>    <span class=k>with</span> <span class=n>ThreadPoolExecutor</span><span class=p>(</span><span class=n>max_workers</span><span class=o>=</span><span class=n>max_parallel_requests</span><span class=p>)</span> <span class=k>as</span> <span class=n>executor</span><span class=p>:</span>
</span><span id=__span-34-134><a id=__codelineno-34-134 name=__codelineno-34-134 href=#__codelineno-34-134></a>        <span class=c1># Submit all tasks</span>
</span><span id=__span-34-135><a id=__codelineno-34-135 name=__codelineno-34-135 href=#__codelineno-34-135></a>        <span class=n>futures</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-34-136><a id=__codelineno-34-136 name=__codelineno-34-136 href=#__codelineno-34-136></a>            <span class=n>executor</span><span class=o>.</span><span class=n>submit</span><span class=p>(</span><span class=n>run_inference</span><span class=p>,</span> <span class=n>dataset</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>i</span><span class=p>)</span>
</span><span id=__span-34-137><a id=__codelineno-34-137 name=__codelineno-34-137 href=#__codelineno-34-137></a>            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>))</span>
</span><span id=__span-34-138><a id=__codelineno-34-138 name=__codelineno-34-138 href=#__codelineno-34-138></a>        <span class=p>]</span>
</span><span id=__span-34-139><a id=__codelineno-34-139 name=__codelineno-34-139 href=#__codelineno-34-139></a>
</span><span id=__span-34-140><a id=__codelineno-34-140 name=__codelineno-34-140 href=#__codelineno-34-140></a>        <span class=c1># Collect results with progress bar</span>
</span><span id=__span-34-141><a id=__codelineno-34-141 name=__codelineno-34-141 href=#__codelineno-34-141></a>        <span class=k>for</span> <span class=n>future</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>as_completed</span><span class=p>(</span><span class=n>futures</span><span class=p>),</span> <span class=n>total</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>),</span> <span class=n>desc</span><span class=o>=</span><span class=s2>"Evaluating"</span><span class=p>):</span>
</span><span id=__span-34-142><a id=__codelineno-34-142 name=__codelineno-34-142 href=#__codelineno-34-142></a>            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>future</span><span class=o>.</span><span class=n>result</span><span class=p>())</span>
</span><span id=__span-34-143><a id=__codelineno-34-143 name=__codelineno-34-143 href=#__codelineno-34-143></a>
</span><span id=__span-34-144><a id=__codelineno-34-144 name=__codelineno-34-144 href=#__codelineno-34-144></a>    <span class=c1># === Calculate metrics ===</span>
</span><span id=__span-34-145><a id=__codelineno-34-145 name=__codelineno-34-145 href=#__codelineno-34-145></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-146><a id=__codelineno-34-146 name=__codelineno-34-146 href=#__codelineno-34-146></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-147><a id=__codelineno-34-147 name=__codelineno-34-147 href=#__codelineno-34-147></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"CALCULATING METRICS"</span><span class=p>)</span>
</span><span id=__span-34-148><a id=__codelineno-34-148 name=__codelineno-34-148 href=#__codelineno-34-148></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-149><a id=__codelineno-34-149 name=__codelineno-34-149 href=#__codelineno-34-149></a>
</span><span id=__span-34-150><a id=__codelineno-34-150 name=__codelineno-34-150 href=#__codelineno-34-150></a>    <span class=n>predictions</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=p>[</span><span class=s2>"prediction"</span><span class=p>]</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>results</span><span class=p>]</span>
</span><span id=__span-34-151><a id=__codelineno-34-151 name=__codelineno-34-151 href=#__codelineno-34-151></a>    <span class=n>ground_truths</span> <span class=o>=</span> <span class=p>[</span><span class=n>r</span><span class=p>[</span><span class=s2>"ground_truth"</span><span class=p>]</span> <span class=k>for</span> <span class=n>r</span> <span class=ow>in</span> <span class=n>results</span><span class=p>]</span>
</span><span id=__span-34-152><a id=__codelineno-34-152 name=__codelineno-34-152 href=#__codelineno-34-152></a>
</span><span id=__span-34-153><a id=__codelineno-34-153 name=__codelineno-34-153 href=#__codelineno-34-153></a>    <span class=c1># Exact match accuracy</span>
</span><span id=__span-34-154><a id=__codelineno-34-154 name=__codelineno-34-154 href=#__codelineno-34-154></a>    <span class=n>exact_matches</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span> <span class=o>==</span> <span class=n>g</span> <span class=k>for</span> <span class=n>p</span><span class=p>,</span> <span class=n>g</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>ground_truths</span><span class=p>))</span>
</span><span id=__span-34-155><a id=__codelineno-34-155 name=__codelineno-34-155 href=#__codelineno-34-155></a>    <span class=n>exact_match_accuracy</span> <span class=o>=</span> <span class=n>exact_matches</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span><span id=__span-34-156><a id=__codelineno-34-156 name=__codelineno-34-156 href=#__codelineno-34-156></a>
</span><span id=__span-34-157><a id=__codelineno-34-157 name=__codelineno-34-157 href=#__codelineno-34-157></a>    <span class=c1># Character Error Rate (CER)</span>
</span><span id=__span-34-158><a id=__codelineno-34-158 name=__codelineno-34-158 href=#__codelineno-34-158></a>    <span class=c1># Lower is better, 0 = perfect</span>
</span><span id=__span-34-159><a id=__codelineno-34-159 name=__codelineno-34-159 href=#__codelineno-34-159></a>    <span class=n>character_error_rate</span> <span class=o>=</span> <span class=n>cer</span><span class=p>(</span><span class=n>ground_truths</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)</span>
</span><span id=__span-34-160><a id=__codelineno-34-160 name=__codelineno-34-160 href=#__codelineno-34-160></a>
</span><span id=__span-34-161><a id=__codelineno-34-161 name=__codelineno-34-161 href=#__codelineno-34-161></a>    <span class=c1># Word Error Rate (WER)</span>
</span><span id=__span-34-162><a id=__codelineno-34-162 name=__codelineno-34-162 href=#__codelineno-34-162></a>    <span class=c1># Lower is better, 0 = perfect</span>
</span><span id=__span-34-163><a id=__codelineno-34-163 name=__codelineno-34-163 href=#__codelineno-34-163></a>    <span class=n>word_error_rate</span> <span class=o>=</span> <span class=n>wer</span><span class=p>(</span><span class=n>ground_truths</span><span class=p>,</span> <span class=n>predictions</span><span class=p>)</span>
</span><span id=__span-34-164><a id=__codelineno-34-164 name=__codelineno-34-164 href=#__codelineno-34-164></a>
</span><span id=__span-34-165><a id=__codelineno-34-165 name=__codelineno-34-165 href=#__codelineno-34-165></a>    <span class=c1># === Print results ===</span>
</span><span id=__span-34-166><a id=__codelineno-34-166 name=__codelineno-34-166 href=#__codelineno-34-166></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-167><a id=__codelineno-34-167 name=__codelineno-34-167 href=#__codelineno-34-167></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"📊 EVALUATION RESULTS"</span><span class=p>)</span>
</span><span id=__span-34-168><a id=__codelineno-34-168 name=__codelineno-34-168 href=#__codelineno-34-168></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-169><a id=__codelineno-34-169 name=__codelineno-34-169 href=#__codelineno-34-169></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Samples evaluated: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-170><a id=__codelineno-34-170 name=__codelineno-34-170 href=#__codelineno-34-170></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-171><a id=__codelineno-34-171 name=__codelineno-34-171 href=#__codelineno-34-171></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Exact Match Accuracy:  </span><span class=si>{</span><span class=n>exact_match_accuracy</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>  (</span><span class=si>{</span><span class=n>exact_matches</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>)</span><span class=si>}</span><span class=s2>)"</span><span class=p>)</span>
</span><span id=__span-34-172><a id=__codelineno-34-172 name=__codelineno-34-172 href=#__codelineno-34-172></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Character Error Rate:  </span><span class=si>{</span><span class=n>character_error_rate</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>  (lower is better)"</span><span class=p>)</span>
</span><span id=__span-34-173><a id=__codelineno-34-173 name=__codelineno-34-173 href=#__codelineno-34-173></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Word Error Rate:       </span><span class=si>{</span><span class=n>word_error_rate</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>  (lower is better)"</span><span class=p>)</span>
</span><span id=__span-34-174><a id=__codelineno-34-174 name=__codelineno-34-174 href=#__codelineno-34-174></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-175><a id=__codelineno-34-175 name=__codelineno-34-175 href=#__codelineno-34-175></a>
</span><span id=__span-34-176><a id=__codelineno-34-176 name=__codelineno-34-176 href=#__codelineno-34-176></a>    <span class=c1># === Print example predictions ===</span>
</span><span id=__span-34-177><a id=__codelineno-34-177 name=__codelineno-34-177 href=#__codelineno-34-177></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>""</span><span class=p>)</span>
</span><span id=__span-34-178><a id=__codelineno-34-178 name=__codelineno-34-178 href=#__codelineno-34-178></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"📝 EXAMPLE PREDICTIONS (first 5)"</span><span class=p>)</span>
</span><span id=__span-34-179><a id=__codelineno-34-179 name=__codelineno-34-179 href=#__codelineno-34-179></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-180><a id=__codelineno-34-180 name=__codelineno-34-180 href=#__codelineno-34-180></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>min</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>))):</span>
</span><span id=__span-34-181><a id=__codelineno-34-181 name=__codelineno-34-181 href=#__codelineno-34-181></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Sample </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>:"</span><span class=p>)</span>
</span><span id=__span-34-182><a id=__codelineno-34-182 name=__codelineno-34-182 href=#__codelineno-34-182></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Ground Truth: </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>'ground_truth'</span><span class=p>]</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-183><a id=__codelineno-34-183 name=__codelineno-34-183 href=#__codelineno-34-183></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Prediction:   </span><span class=si>{</span><span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>'prediction'</span><span class=p>]</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-184><a id=__codelineno-34-184 name=__codelineno-34-184 href=#__codelineno-34-184></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Match: </span><span class=si>{</span><span class=s1>'✓'</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>'prediction'</span><span class=p>]</span><span class=w> </span><span class=o>==</span><span class=w> </span><span class=n>results</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=s1>'ground_truth'</span><span class=p>]</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>'✗'</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-185><a id=__codelineno-34-185 name=__codelineno-34-185 href=#__codelineno-34-185></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-186><a id=__codelineno-34-186 name=__codelineno-34-186 href=#__codelineno-34-186></a>
</span><span id=__span-34-187><a id=__codelineno-34-187 name=__codelineno-34-187 href=#__codelineno-34-187></a>    <span class=c1># Save full results to volume</span>
</span><span id=__span-34-188><a id=__codelineno-34-188 name=__codelineno-34-188 href=#__codelineno-34-188></a>    <span class=n>results_file</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"/data/Finetuned_Gemma_3_4b_it/eval_results_</span><span class=si>{</span><span class=n>dataset_split</span><span class=si>}</span><span class=s2>.json"</span>
</span><span id=__span-34-189><a id=__codelineno-34-189 name=__codelineno-34-189 href=#__codelineno-34-189></a>    <span class=kn>import</span><span class=w> </span><span class=nn>json</span>
</span><span id=__span-34-190><a id=__codelineno-34-190 name=__codelineno-34-190 href=#__codelineno-34-190></a>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>results_file</span><span class=p>,</span> <span class=s2>"w"</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span><span id=__span-34-191><a id=__codelineno-34-191 name=__codelineno-34-191 href=#__codelineno-34-191></a>        <span class=n>json</span><span class=o>.</span><span class=n>dump</span><span class=p>({</span>
</span><span id=__span-34-192><a id=__codelineno-34-192 name=__codelineno-34-192 href=#__codelineno-34-192></a>            <span class=s2>"metrics"</span><span class=p>:</span> <span class=p>{</span>
</span><span id=__span-34-193><a id=__codelineno-34-193 name=__codelineno-34-193 href=#__codelineno-34-193></a>                <span class=s2>"exact_match_accuracy"</span><span class=p>:</span> <span class=n>exact_match_accuracy</span><span class=p>,</span>
</span><span id=__span-34-194><a id=__codelineno-34-194 name=__codelineno-34-194 href=#__codelineno-34-194></a>                <span class=s2>"character_error_rate"</span><span class=p>:</span> <span class=n>character_error_rate</span><span class=p>,</span>
</span><span id=__span-34-195><a id=__codelineno-34-195 name=__codelineno-34-195 href=#__codelineno-34-195></a>                <span class=s2>"word_error_rate"</span><span class=p>:</span> <span class=n>word_error_rate</span><span class=p>,</span>
</span><span id=__span-34-196><a id=__codelineno-34-196 name=__codelineno-34-196 href=#__codelineno-34-196></a>            <span class=p>},</span>
</span><span id=__span-34-197><a id=__codelineno-34-197 name=__codelineno-34-197 href=#__codelineno-34-197></a>            <span class=s2>"num_samples"</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>),</span>
</span><span id=__span-34-198><a id=__codelineno-34-198 name=__codelineno-34-198 href=#__codelineno-34-198></a>            <span class=s2>"examples"</span><span class=p>:</span> <span class=n>results</span><span class=p>[:</span><span class=mi>20</span><span class=p>],</span>  <span class=c1># Save first 20 examples</span>
</span><span id=__span-34-199><a id=__codelineno-34-199 name=__codelineno-34-199 href=#__codelineno-34-199></a>        <span class=p>},</span> <span class=n>f</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-34-200><a id=__codelineno-34-200 name=__codelineno-34-200 href=#__codelineno-34-200></a>
</span><span id=__span-34-201><a id=__codelineno-34-201 name=__codelineno-34-201 href=#__codelineno-34-201></a>    <span class=n>exp_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-34-202><a id=__codelineno-34-202 name=__codelineno-34-202 href=#__codelineno-34-202></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=se>\n</span><span class=s2>✓ Full results saved to </span><span class=si>{</span><span class=n>results_file</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-203><a id=__codelineno-34-203 name=__codelineno-34-203 href=#__codelineno-34-203></a>
</span><span id=__span-34-204><a id=__codelineno-34-204 name=__codelineno-34-204 href=#__codelineno-34-204></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-34-205><a id=__codelineno-34-205 name=__codelineno-34-205 href=#__codelineno-34-205></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-34-206><a id=__codelineno-34-206 name=__codelineno-34-206 href=#__codelineno-34-206></a>        <span class=s2>"metrics"</span><span class=p>:</span> <span class=p>{</span>
</span><span id=__span-34-207><a id=__codelineno-34-207 name=__codelineno-34-207 href=#__codelineno-34-207></a>            <span class=s2>"exact_match_accuracy"</span><span class=p>:</span> <span class=n>exact_match_accuracy</span><span class=p>,</span>
</span><span id=__span-34-208><a id=__codelineno-34-208 name=__codelineno-34-208 href=#__codelineno-34-208></a>            <span class=s2>"character_error_rate"</span><span class=p>:</span> <span class=n>character_error_rate</span><span class=p>,</span>
</span><span id=__span-34-209><a id=__codelineno-34-209 name=__codelineno-34-209 href=#__codelineno-34-209></a>            <span class=s2>"word_error_rate"</span><span class=p>:</span> <span class=n>word_error_rate</span><span class=p>,</span>
</span><span id=__span-34-210><a id=__codelineno-34-210 name=__codelineno-34-210 href=#__codelineno-34-210></a>        <span class=p>},</span>
</span><span id=__span-34-211><a id=__codelineno-34-211 name=__codelineno-34-211 href=#__codelineno-34-211></a>        <span class=s2>"num_samples"</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>results</span><span class=p>),</span>
</span><span id=__span-34-212><a id=__codelineno-34-212 name=__codelineno-34-212 href=#__codelineno-34-212></a>        <span class=s2>"examples"</span><span class=p>:</span> <span class=n>results</span><span class=p>[:</span><span class=mi>10</span><span class=p>],</span>  <span class=c1># Return first 10 examples</span>
</span><span id=__span-34-213><a id=__codelineno-34-213 name=__codelineno-34-213 href=#__codelineno-34-213></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>What the metrics mean:</strong></p> <ol> <li> <p><strong>Exact Match Accuracy</strong>: The gold standard. Did we get it 100% right? For LaTeX, even a missing space matters.</p> </li> <li> <p><strong>Character Error Rate (CER)</strong>: How many character edits (insert/delete/replace) to go from prediction to ground truth? Lower is better. 0% = perfect, 100% = complete garbage.</p> </li> <li> <p><strong>Word Error Rate (WER)</strong>: Same as CER but at word level. More forgiving for LaTeX because <code>\frac{a}{b}</code> has multiple "words".</p> </li> </ol> <h3 id=running-evaluation>Running Evaluation<a class=headerlink href=#running-evaluation title="Permanent link">¶</a></h3> <p><strong>Basic run:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::evaluate_model
</span></code></pre></div> <p>This auto-detects your deployed vLLM endpoint and evaluates on 100 samples.</p> <p><strong>Evaluate more samples:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::evaluate_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>500</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a><span class=w>  </span>--max-parallel-requests<span class=o>=</span><span class=m>16</span>
</span></code></pre></div> <p><strong>Custom endpoint:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::evaluate_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a><span class=w>  </span>--endpoint-url<span class=o>=</span><span class=s2>"https://your-custom-endpoint.modal.run/v1"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>1000</span>
</span></code></pre></div> <p><strong>Example output:</strong></p> <div class="language-text highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a>📊 EVALUATION RESULTS
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>================================================================================
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a>Samples evaluated: 100
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a>
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a>Exact Match Accuracy:  78.00%  (78/100)
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a>Character Error Rate:  5.23%  (lower is better)
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a>Word Error Rate:       8.45%  (lower is better)
</span><span id=__span-38-8><a id=__codelineno-38-8 name=__codelineno-38-8 href=#__codelineno-38-8></a>================================================================================
</span><span id=__span-38-9><a id=__codelineno-38-9 name=__codelineno-38-9 href=#__codelineno-38-9></a>
</span><span id=__span-38-10><a id=__codelineno-38-10 name=__codelineno-38-10 href=#__codelineno-38-10></a>📝 EXAMPLE PREDICTIONS (first 5)
</span><span id=__span-38-11><a id=__codelineno-38-11 name=__codelineno-38-11 href=#__codelineno-38-11></a>================================================================================
</span><span id=__span-38-12><a id=__codelineno-38-12 name=__codelineno-38-12 href=#__codelineno-38-12></a>
</span><span id=__span-38-13><a id=__codelineno-38-13 name=__codelineno-38-13 href=#__codelineno-38-13></a>Sample 1:
</span><span id=__span-38-14><a id=__codelineno-38-14 name=__codelineno-38-14 href=#__codelineno-38-14></a>  Ground Truth: \frac{d}{dx} \left( x^2 + 2x + 1 \right) = 2x + 2
</span><span id=__span-38-15><a id=__codelineno-38-15 name=__codelineno-38-15 href=#__codelineno-38-15></a>  Prediction:   \frac{d}{dx} \left( x^2 + 2x + 1 \right) = 2x + 2
</span><span id=__span-38-16><a id=__codelineno-38-16 name=__codelineno-38-16 href=#__codelineno-38-16></a>  Match: ✓
</span><span id=__span-38-17><a id=__codelineno-38-17 name=__codelineno-38-17 href=#__codelineno-38-17></a>
</span><span id=__span-38-18><a id=__codelineno-38-18 name=__codelineno-38-18 href=#__codelineno-38-18></a>Sample 2:
</span><span id=__span-38-19><a id=__codelineno-38-19 name=__codelineno-38-19 href=#__codelineno-38-19></a>  Ground Truth: \int_{0}^{1} x^2 dx = \frac{1}{3}
</span><span id=__span-38-20><a id=__codelineno-38-20 name=__codelineno-38-20 href=#__codelineno-38-20></a>  Prediction:   \int_{0}^{1} x^2 dx = \frac{1}{3}
</span><span id=__span-38-21><a id=__codelineno-38-21 name=__codelineno-38-21 href=#__codelineno-38-21></a>  Match: ✓
</span><span id=__span-38-22><a id=__codelineno-38-22 name=__codelineno-38-22 href=#__codelineno-38-22></a>
</span><span id=__span-38-23><a id=__codelineno-38-23 name=__codelineno-38-23 href=#__codelineno-38-23></a>...
</span></code></pre></div> <h2 id=complete-workflow-example>Complete Workflow Example<a class=headerlink href=#complete-workflow-example title="Permanent link">¶</a></h2> <p>Let me show you how I'd actually use this end-to-end:</p> <h3 id=1-download-everything-one-time>1. Download Everything (One Time)<a class=headerlink href=#1-download-everything-one-time title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a><span class=c1># Download dataset (CPU, cheap)</span>
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::download_datasets
</span><span id=__span-39-3><a id=__codelineno-39-3 name=__codelineno-39-3 href=#__codelineno-39-3></a>
</span><span id=__span-39-4><a id=__codelineno-39-4 name=__codelineno-39-4 href=#__codelineno-39-4></a><span class=c1># Download model (L40S, ~$1 for 10 minutes)</span>
</span><span id=__span-39-5><a id=__codelineno-39-5 name=__codelineno-39-5 href=#__codelineno-39-5></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::download_models
</span></code></pre></div> <p><strong>Cost so far:</strong> ~$1 <strong>Time:</strong> ~15 minutes</p> <h3 id=2-quick-test-run-make-sure-it-works>2. Quick Test Run (Make Sure It Works)<a class=headerlink href=#2-quick-test-run-make-sure-it-works title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a><span class=c1># Train on 100 samples for 1 epoch</span>
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-40-3><a id=__codelineno-40-3 name=__codelineno-40-3 href=#__codelineno-40-3></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>100</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-40-4><a id=__codelineno-40-4 name=__codelineno-40-4 href=#__codelineno-40-4></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>1</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-40-5><a id=__codelineno-40-5 name=__codelineno-40-5 href=#__codelineno-40-5></a><span class=w>  </span>--save-steps<span class=o>=</span><span class=m>50</span>
</span></code></pre></div> <p><strong>Cost:</strong> ~$3-5 (A100-80GB for 30-60 minutes) <strong>Time:</strong> 30-60 minutes</p> <p>If this works, you know your pipeline is solid.</p> <h3 id=3-full-training-run>3. Full Training Run<a class=headerlink href=#3-full-training-run title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a><span class=c1># Production training with HF Hub push</span>
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a><span class=w>  </span>--hub-id<span class=o>=</span><span class=s2>"your-username/gemma-latex-ocr"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>3</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a><span class=w>  </span>--learning-rate<span class=o>=</span><span class=m>0</span>.0003<span class=w> </span><span class=se>\</span>
</span><span id=__span-41-6><a id=__codelineno-41-6 name=__codelineno-41-6 href=#__codelineno-41-6></a><span class=w>  </span>--per-device-train-batch-size<span class=o>=</span><span class=m>4</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-7><a id=__codelineno-41-7 name=__codelineno-41-7 href=#__codelineno-41-7></a><span class=w>  </span>--gradient-accumulation-steps<span class=o>=</span><span class=m>4</span>
</span></code></pre></div> <p><strong>Cost:</strong> ~$20-40 (A100-80GB for 4-8 hours depending on dataset size) <strong>Time:</strong> 4-8 hours</p> <p>While this runs, go touch grass. Check W&amp;B dashboard occasionally to make sure loss is going down.</p> <h3 id=4-deploy-for-serving>4. Deploy for Serving<a class=headerlink href=#4-deploy-for-serving title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a>modal<span class=w> </span>deploy<span class=w> </span>FinetuneGemmaUnslothModal.py
</span></code></pre></div> <p><strong>Cost:</strong> <span class=arithmatex>\(0 when idle, ~\)</span>1/hr when active (L40S)</p> <p>Modal gives you a URL. Save it.</p> <h3 id=5-evaluate>5. Evaluate<a class=headerlink href=#5-evaluate title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-43-1><a id=__codelineno-43-1 name=__codelineno-43-1 href=#__codelineno-43-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::evaluate_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-43-2><a id=__codelineno-43-2 name=__codelineno-43-2 href=#__codelineno-43-2></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>500</span>
</span></code></pre></div> <p><strong>Cost:</strong> ~$0.10 (CPU for 10-20 minutes) <strong>Time:</strong> 10-20 minutes</p> <p>Check your metrics. If accuracy is good (&gt;75%), you're golden. If not, tweak hyperparameters and go back to step 3.</p> <h3 id=6-use-in-production>6. Use in Production<a class=headerlink href=#6-use-in-production title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-44-1><a id=__codelineno-44-1 name=__codelineno-44-1 href=#__codelineno-44-1></a><span class=c1># In your application</span>
</span><span id=__span-44-2><a id=__codelineno-44-2 name=__codelineno-44-2 href=#__codelineno-44-2></a><span class=kn>from</span><span class=w> </span><span class=nn>openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-44-3><a id=__codelineno-44-3 name=__codelineno-44-3 href=#__codelineno-44-3></a>
</span><span id=__span-44-4><a id=__codelineno-44-4 name=__codelineno-44-4 href=#__codelineno-44-4></a><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span><span id=__span-44-5><a id=__codelineno-44-5 name=__codelineno-44-5 href=#__codelineno-44-5></a>    <span class=n>base_url</span><span class=o>=</span><span class=s2>"https://your-endpoint.modal.run/v1"</span><span class=p>,</span>
</span><span id=__span-44-6><a id=__codelineno-44-6 name=__codelineno-44-6 href=#__codelineno-44-6></a>    <span class=n>api_key</span><span class=o>=</span><span class=s2>"EMPTY"</span>
</span><span id=__span-44-7><a id=__codelineno-44-7 name=__codelineno-44-7 href=#__codelineno-44-7></a><span class=p>)</span>
</span><span id=__span-44-8><a id=__codelineno-44-8 name=__codelineno-44-8 href=#__codelineno-44-8></a>
</span><span id=__span-44-9><a id=__codelineno-44-9 name=__codelineno-44-9 href=#__codelineno-44-9></a><span class=c1># Your app can now read LaTeX from images!</span>
</span></code></pre></div> <p><strong>Total cost for full pipeline:</strong> ~$25-50 <strong>Time:</strong> 1 day (mostly waiting for training)</p> <p>Compare this to managing your own GPU infrastructure... yeah, Modal wins.</p> <h2 id=hyperparameter-tuning-tips>Hyperparameter Tuning Tips<a class=headerlink href=#hyperparameter-tuning-tips title="Permanent link">¶</a></h2> <h3 id=for-better-accuracy>For Better Accuracy<a class=headerlink href=#for-better-accuracy title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-45-1><a id=__codelineno-45-1 name=__codelineno-45-1 href=#__codelineno-45-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-45-2><a id=__codelineno-45-2 name=__codelineno-45-2 href=#__codelineno-45-2></a><span class=w>  </span>--lora-r<span class=o>=</span><span class=m>64</span><span class=w> </span><span class=se>\ </span><span class=w>             </span><span class=c1># Higher rank = more capacity</span>
</span><span id=__span-45-3><a id=__codelineno-45-3 name=__codelineno-45-3 href=#__codelineno-45-3></a><span class=w>  </span>--lora-alpha<span class=o>=</span><span class=m>128</span><span class=w> </span><span class=se>\ </span><span class=w>        </span><span class=c1># Scale accordingly</span>
</span><span id=__span-45-4><a id=__codelineno-45-4 name=__codelineno-45-4 href=#__codelineno-45-4></a><span class=w>  </span>--learning-rate<span class=o>=</span><span class=m>0</span>.0001<span class=w> </span><span class=se>\ </span><span class=w>  </span><span class=c1># Lower LR = more stable</span>
</span><span id=__span-45-5><a id=__codelineno-45-5 name=__codelineno-45-5 href=#__codelineno-45-5></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>5</span><span class=w>       </span><span class=c1># More epochs</span>
</span></code></pre></div> <p><strong>Trade-off:</strong> Slower training, higher cost, but better results.</p> <h3 id=for-faster-iteration>For Faster Iteration<a class=headerlink href=#for-faster-iteration title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-46-1><a id=__codelineno-46-1 name=__codelineno-46-1 href=#__codelineno-46-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-46-2><a id=__codelineno-46-2 name=__codelineno-46-2 href=#__codelineno-46-2></a><span class=w>  </span>--lora-r<span class=o>=</span><span class=m>16</span><span class=w> </span><span class=se>\ </span><span class=w>             </span><span class=c1># Lower rank = faster</span>
</span><span id=__span-46-3><a id=__codelineno-46-3 name=__codelineno-46-3 href=#__codelineno-46-3></a><span class=w>  </span>--lora-alpha<span class=o>=</span><span class=m>32</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-46-4><a id=__codelineno-46-4 name=__codelineno-46-4 href=#__codelineno-46-4></a><span class=w>  </span>--learning-rate<span class=o>=</span><span class=m>0</span>.0005<span class=w> </span><span class=se>\ </span><span class=w>  </span><span class=c1># Higher LR = faster convergence</span>
</span><span id=__span-46-5><a id=__codelineno-46-5 name=__codelineno-46-5 href=#__codelineno-46-5></a><span class=w>  </span>--num-train-epochs<span class=o>=</span><span class=m>2</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-46-6><a id=__codelineno-46-6 name=__codelineno-46-6 href=#__codelineno-46-6></a><span class=w>  </span>--max-samples<span class=o>=</span><span class=m>5000</span><span class=w>         </span><span class=c1># Smaller dataset</span>
</span></code></pre></div> <p><strong>Trade-off:</strong> Lower accuracy, but 2-3x faster training.</p> <h3 id=for-memory-issues>For Memory Issues<a class=headerlink href=#for-memory-issues title="Permanent link">¶</a></h3> <p>If you get OOM errors:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-47-1><a id=__codelineno-47-1 name=__codelineno-47-1 href=#__codelineno-47-1></a>modal<span class=w> </span>run<span class=w> </span>FinetuneGemmaUnslothModal.py::fine_tune_unsloth<span class=w> </span><span class=se>\</span>
</span><span id=__span-47-2><a id=__codelineno-47-2 name=__codelineno-47-2 href=#__codelineno-47-2></a><span class=w>  </span>--per-device-train-batch-size<span class=o>=</span><span class=m>2</span><span class=w> </span><span class=se>\ </span><span class=w>    </span><span class=c1># Smaller batches</span>
</span><span id=__span-47-3><a id=__codelineno-47-3 name=__codelineno-47-3 href=#__codelineno-47-3></a><span class=w>  </span>--gradient-accumulation-steps<span class=o>=</span><span class=m>8</span><span class=w> </span><span class=se>\ </span><span class=w>    </span><span class=c1># Maintain effective batch size</span>
</span><span id=__span-47-4><a id=__codelineno-47-4 name=__codelineno-47-4 href=#__codelineno-47-4></a><span class=w>  </span>--max-seq-length<span class=o>=</span><span class=m>4096</span><span class=w>                  </span><span class=c1># Shorter sequences</span>
</span></code></pre></div> <p>Or switch to A100-80GB if you're on A100-40GB.</p> <h2 id=common-issues-and-solutions>Common Issues and Solutions<a class=headerlink href=#common-issues-and-solutions title="Permanent link">¶</a></h2> <h3 id=secret-not-found>"Secret not found"<a class=headerlink href=#secret-not-found title="Permanent link">¶</a></h3> <p><strong>Error:</strong> <code>Modal Secret "secrets-hf-wandb" not found</code></p> <p><strong>Fix:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-48-1><a id=__codelineno-48-1 name=__codelineno-48-1 href=#__codelineno-48-1></a>modal<span class=w> </span>secret<span class=w> </span>create<span class=w> </span>secrets-hf-wandb<span class=w> </span><span class=se>\</span>
</span><span id=__span-48-2><a id=__codelineno-48-2 name=__codelineno-48-2 href=#__codelineno-48-2></a><span class=w>  </span><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_xxx<span class=w> </span><span class=se>\</span>
</span><span id=__span-48-3><a id=__codelineno-48-3 name=__codelineno-48-3 href=#__codelineno-48-3></a><span class=w>  </span><span class=nv>WANDB_API_KEY</span><span class=o>=</span>xxx
</span></code></pre></div> <h3 id=cuda-out-of-memory>CUDA Out of Memory<a class=headerlink href=#cuda-out-of-memory title="Permanent link">¶</a></h3> <p><strong>Error:</strong> <code>CUDA out of memory</code></p> <p><strong>Fixes:</strong> 1. Reduce batch size: <code>--per-device-train-batch-size=2</code> 2. Reduce sequence length: <code>--max-seq-length=4096</code> 3. Use smaller LoRA rank: <code>--lora-r=16 --lora-alpha=32</code> 4. Switch to A100-80GB</p> <h3 id=image-build-timeout>Image Build Timeout<a class=headerlink href=#image-build-timeout title="Permanent link">¶</a></h3> <p><strong>Error:</strong> Image build exceeds timeout</p> <p><strong>Fix:</strong> First build takes 15-20 minutes. This is normal. Modal caches it. Grab a coffee.</p> <h3 id=vllm-server-not-responding>vLLM Server Not Responding<a class=headerlink href=#vllm-server-not-responding title="Permanent link">¶</a></h3> <p><strong>Error:</strong> <code>Could not connect to endpoint</code></p> <p><strong>Fix:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-49-1><a id=__codelineno-49-1 name=__codelineno-49-1 href=#__codelineno-49-1></a><span class=c1># Make sure it's deployed</span>
</span><span id=__span-49-2><a id=__codelineno-49-2 name=__codelineno-49-2 href=#__codelineno-49-2></a>modal<span class=w> </span>app<span class=w> </span>list
</span><span id=__span-49-3><a id=__codelineno-49-3 name=__codelineno-49-3 href=#__codelineno-49-3></a>
</span><span id=__span-49-4><a id=__codelineno-49-4 name=__codelineno-49-4 href=#__codelineno-49-4></a><span class=c1># If not running, deploy it</span>
</span><span id=__span-49-5><a id=__codelineno-49-5 name=__codelineno-49-5 href=#__codelineno-49-5></a>modal<span class=w> </span>deploy<span class=w> </span>FinetuneGemmaUnslothModal.py
</span></code></pre></div> <p>The first request after deploy takes 30-60 seconds (cold start). Be patient.</p> <h3 id=evaluation-fails>Evaluation Fails<a class=headerlink href=#evaluation-fails title="Permanent link">¶</a></h3> <p><strong>Error:</strong> Various errors during eval</p> <p><strong>Checks:</strong> 1. Is vLLM running? <code>modal app list</code> 2. Is the endpoint URL correct? 3. Is the model path correct in the eval function?</p> <h2 id=cost-breakdown>Cost Breakdown<a class=headerlink href=#cost-breakdown title="Permanent link">¶</a></h2> <p>Based on Modal pricing (approximate):</p> <h3 id=training>Training<a class=headerlink href=#training title="Permanent link">¶</a></h3> <ul> <li><strong>Download dataset:</strong> $0.001 (CPU, 5 min)</li> <li><strong>Download model:</strong> $1 (L40S, 10 min)</li> <li><strong>Test training:</strong> $5 (A100-80GB, 1 hour)</li> <li><strong>Full training:</strong> $25-40 (A100-80GB, 6-10 hours)</li> </ul> <h3 id=serving-pay-per-use>Serving (pay per use)<a class=headerlink href=#serving-pay-per-use title="Permanent link">¶</a></h3> <ul> <li><strong>Idle:</strong> $0/month (auto-scales to 0)</li> <li><strong>Active:</strong> ~$1/hour (L40S)</li> <li><strong>Typical monthly cost:</strong> $5-20 (depends on usage)</li> </ul> <h3 id=evaluation>Evaluation<a class=headerlink href=#evaluation title="Permanent link">¶</a></h3> <ul> <li><strong>CPU cost:</strong> ~$0.10 per eval run</li> </ul> <h3 id=storage>Storage<a class=headerlink href=#storage title="Permanent link">¶</a></h3> <ul> <li><strong>Volumes:</strong> Free up to 50GB</li> <li><strong>This project:</strong> ~15GB = $0/month</li> </ul> <p><strong>Total for complete pipeline:</strong> $30-50 one-time + $5-20/month for serving</p> <h2 id=whats-next>What's Next?<a class=headerlink href=#whats-next title="Permanent link">¶</a></h2> <p>You've built a complete production ML pipeline. Here's what you can do next:</p> <ol> <li> <p><strong>Try different models:</strong> Replace Gemma with Llama, Qwen, or any other vision-language model. Just change <code>BASE_MODEL_NAME</code>.</p> </li> <li> <p><strong>Use your own dataset:</strong> Got images + text pairs? Upload to HuggingFace, point the script at it.</p> </li> <li> <p><strong>Optimize serving:</strong> Experiment with different GPUs, batch sizes, quantization.</p> </li> <li> <p><strong>Add more metrics:</strong> BLEU score, semantic similarity, whatever matters for your use case.</p> </li> <li> <p><strong>Build an app:</strong> You have an API. Now build a web app that uses it!</p> </li> </ol> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">¶</a></h2> <ul> <li><strong><a href=https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3_(4B)-Vision.ipynb>Original Unsloth Colab</a></strong> - Where this all started</li> <li><strong><a href=https://docs.unsloth.ai/ >Unsloth Documentation</a></strong> - Deep dive into Unsloth</li> <li><strong><a href=https://modal.com/docs>Modal Documentation</a></strong> - Everything about Modal</li> <li><strong><a href=https://docs.vllm.ai/ >vLLM Documentation</a></strong> - Serving optimization</li> <li><strong><a href=https://huggingface.co/google/gemma-3-4b-it>Gemma Model Card</a></strong> - About the base model</li> <li><strong><a href=https://arxiv.org/abs/2106.09685>LoRA Paper</a></strong> - The theory behind it</li> </ul> <hr> <h2 id=wrapping-up>Wrapping Up<a class=headerlink href=#wrapping-up title="Permanent link">¶</a></h2> <p>You just built what most companies would consider their "production ML infrastructure": - Dataset management - Distributed training - Model versioning - API deployment - Evaluation pipelines</p> <p>All in one Python file, running on Modal. No Kubernetes, no Docker nightmares, no infrastructure headaches.</p> <p>The Unsloth Colab notebook showed you how to train on a single GPU. This tutorial showed you how to take that exact workflow and productionize it - separate stages, proper caching, auto-scaling deployment, real evaluation metrics.</p> <p>This is how I actually do ML work nowadays. Write code locally, run on Modal's GPUs, deploy with one command.</p> <p>Got questions? Hit me up on Twitter <a href=https://x.com/adithya_s_k>@adithya_s_k</a>!</p> <p>Now go build something cool with this. 🚀</p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 13, 2025 19:27:59 UTC">October 13, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 13, 2025 19:27:59 UTC">October 13, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../TrainNanochatModalTutorial/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Training Nanochat on Modal"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Training Nanochat on Modal </div> </div> </a> <a href=../FinetuneLlamaAxolotlGPUModalTutorial/ class="md-footer__link md-footer__link--next" aria-label="Next: Multi-GPU Training with Axolotl"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Multi-GPU Training with Axolotl </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>