<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/AIBreakDown/BACKUP/ rel=canonical><link rel=icon href=../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>Tiny Recursive Models (TRM): When 7M Parameters Beat 671B - AI Engineering Academy</title><link rel=stylesheet href=../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script><meta property=og:type content=website><meta property=og:title content="Tiny Recursive Models (TRM): When 7M Parameters Beat 671B - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/AIBreakDown/BACKUP.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/AIBreakDown/BACKUP/ property=og:url><meta property=twitter:card content=summary_large_image><meta property=twitter:title content="Tiny Recursive Models (TRM): When 7M Parameters Beat 671B - AI Engineering Academy"><meta property=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta property=twitter:image content=https://aiengineering.academy/assets/images/social/AIBreakDown/BACKUP.png></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#tiny-recursive-models-trm-when-7m-parameters-beat-671b class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Tiny Recursive Models (TRM): When 7M Parameters Beat 671B </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class=md-tabs__item> <a href=../../RAG/ class=md-tabs__link> RAG </a> </li> <li class=md-tabs__item> <a href=../../LLM/ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../TRM/ class=md-tabs__link> AI BreakDown </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../RAG/ class=md-nav__link> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../LLM/ class=md-nav__link> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../TRM/ class=md-nav__link> <span class=md-ellipsis> AI BreakDown </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#1-introduction-the-paradigm-shift class=md-nav__link> <span class=md-ellipsis> 1. Introduction: The Paradigm Shift </span> </a> <nav class=md-nav aria-label="1. Introduction: The Paradigm Shift"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#why-this-matters-for-you class=md-nav__link> <span class=md-ellipsis> Why This Matters for You </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-the-problem-why-llms-fail-at-systematic-reasoning class=md-nav__link> <span class=md-ellipsis> 2. The Problem: Why LLMs Fail at Systematic Reasoning </span> </a> <nav class=md-nav aria-label="2. The Problem: Why LLMs Fail at Systematic Reasoning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_1 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-from-hrm-to-trm-the-evolution class=md-nav__link> <span class=md-ellipsis> 3. From HRM to TRM: The Evolution </span> </a> <nav class=md-nav aria-label="3. From HRM to TRM: The Evolution"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-trm-insight class=md-nav__link> <span class=md-ellipsis> The TRM Insight </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-data-flow-how-information-moves-through-trm class=md-nav__link> <span class=md-ellipsis> 4. Data Flow: How Information Moves Through TRM </span> </a> <nav class=md-nav aria-label="4. Data Flow: How Information Moves Through TRM"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_2 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_1 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#5-recurrence-vs-transformers-understanding-the-difference class=md-nav__link> <span class=md-ellipsis> 5. Recurrence vs Transformers: Understanding the Difference </span> </a> <nav class=md-nav aria-label="5. Recurrence vs Transformers: Understanding the Difference"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_3 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_2 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#6-the-three-streams-trms-core-architecture class=md-nav__link> <span class=md-ellipsis> 6. The Three Streams: TRM's Core Architecture </span> </a> <nav class=md-nav aria-label="6. The Three Streams: TRM's Core Architecture"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_4 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_3 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#7-recursive-improvement-the-24-pass-process class=md-nav__link> <span class=md-ellipsis> 7. Recursive Improvement: The 24-Pass Process </span> </a> <nav class=md-nav aria-label="7. Recursive Improvement: The 24-Pass Process"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_5 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_4 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#8-transformer-architecture-the-building-blocks class=md-nav__link> <span class=md-ellipsis> 8. Transformer Architecture: The Building Blocks </span> </a> <nav class=md-nav aria-label="8. Transformer Architecture: The Building Blocks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_6 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_5 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#9-deep-supervision-training-at-multiple-scales class=md-nav__link> <span class=md-ellipsis> 9. Deep Supervision: Training at Multiple Scales </span> </a> <nav class=md-nav aria-label="9. Deep Supervision: Training at Multiple Scales"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_7 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_6 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#10-adaptive-computation-time-act-computing-smarter-not-harder class=md-nav__link> <span class=md-ellipsis> 10. Adaptive Computation Time (ACT): Computing Smarter, Not Harder </span> </a> <nav class=md-nav aria-label="10. Adaptive Computation Time (ACT): Computing Smarter, Not Harder"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_8 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_7 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#11-the-complete-solving-process-end-to-end class=md-nav__link> <span class=md-ellipsis> 11. The Complete Solving Process: End-to-End </span> </a> <nav class=md-nav aria-label="11. The Complete Solving Process: End-to-End"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#what-youre-seeing_9 class=md-nav__link> <span class=md-ellipsis> What You're Seeing </span> </a> </li> <li class=md-nav__item> <a href=#technical-deep-dive_8 class=md-nav__link> <span class=md-ellipsis> Technical Deep Dive </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#12-hrm-vs-trm-a-comprehensive-comparison class=md-nav__link> <span class=md-ellipsis> 12. HRM vs TRM: A Comprehensive Comparison </span> </a> <nav class=md-nav aria-label="12. HRM vs TRM: A Comprehensive Comparison"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#architecture-comparison class=md-nav__link> <span class=md-ellipsis> Architecture Comparison </span> </a> </li> <li class=md-nav__item> <a href=#performance-comparison class=md-nav__link> <span class=md-ellipsis> Performance Comparison </span> </a> </li> <li class=md-nav__item> <a href=#key-innovations-in-trm class=md-nav__link> <span class=md-ellipsis> Key Innovations in TRM </span> </a> </li> <li class=md-nav__item> <a href=#training-time-comparison class=md-nav__link> <span class=md-ellipsis> Training Time Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#13-complete-pytorch-implementation class=md-nav__link> <span class=md-ellipsis> 13. Complete PyTorch Implementation </span> </a> <nav class=md-nav aria-label="13. Complete PyTorch Implementation"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#multi-head-attention class=md-nav__link> <span class=md-ellipsis> Multi-Head Attention </span> </a> </li> <li class=md-nav__item> <a href=#feed-forward-network class=md-nav__link> <span class=md-ellipsis> Feed-Forward Network </span> </a> </li> <li class=md-nav__item> <a href=#transformer-block class=md-nav__link> <span class=md-ellipsis> Transformer Block </span> </a> </li> <li class=md-nav__item> <a href=#complete-trm-model class=md-nav__link> <span class=md-ellipsis> Complete TRM Model </span> </a> </li> <li class=md-nav__item> <a href=#model-variants class=md-nav__link> <span class=md-ellipsis> Model Variants </span> </a> </li> <li class=md-nav__item> <a href=#training-utilities class=md-nav__link> <span class=md-ellipsis> Training Utilities </span> </a> </li> <li class=md-nav__item> <a href=#training-loop-with-deep-supervision class=md-nav__link> <span class=md-ellipsis> Training Loop with Deep Supervision </span> </a> </li> <li class=md-nav__item> <a href=#complete-training-script class=md-nav__link> <span class=md-ellipsis> Complete Training Script </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#14-getting-started-practical-setup-guide class=md-nav__link> <span class=md-ellipsis> 14. Getting Started: Practical Setup Guide </span> </a> <nav class=md-nav aria-label="14. Getting Started: Practical Setup Guide"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#installation class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=#dataset-preparation class=md-nav__link> <span class=md-ellipsis> Dataset Preparation </span> </a> </li> <li class=md-nav__item> <a href=#grid-representation class=md-nav__link> <span class=md-ellipsis> Grid Representation </span> </a> </li> <li class=md-nav__item> <a href=#training-your-first-trm class=md-nav__link> <span class=md-ellipsis> Training Your First TRM </span> </a> </li> <li class=md-nav__item> <a href=#inference-and-evaluation class=md-nav__link> <span class=md-ellipsis> Inference and Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#evaluation-on-test-set class=md-nav__link> <span class=md-ellipsis> Evaluation on Test Set </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#15-results-across-all-benchmarks class=md-nav__link> <span class=md-ellipsis> 15. Results Across All Benchmarks </span> </a> <nav class=md-nav aria-label="15. Results Across All Benchmarks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sudoku-extreme class=md-nav__link> <span class=md-ellipsis> Sudoku-Extreme </span> </a> </li> <li class=md-nav__item> <a href=#maze-hard class=md-nav__link> <span class=md-ellipsis> Maze-Hard </span> </a> </li> <li class=md-nav__item> <a href=#arc-agi-1-original-benchmark class=md-nav__link> <span class=md-ellipsis> ARC-AGI-1 (Original Benchmark) </span> </a> </li> <li class=md-nav__item> <a href=#arc-agi-2-2024-competition class=md-nav__link> <span class=md-ellipsis> ARC-AGI-2 (2024 Competition) </span> </a> </li> <li class=md-nav__item> <a href=#parameter-efficiency class=md-nav__link> <span class=md-ellipsis> Parameter Efficiency </span> </a> </li> <li class=md-nav__item> <a href=#inference-speed class=md-nav__link> <span class=md-ellipsis> Inference Speed </span> </a> </li> <li class=md-nav__item> <a href=#scaling-analysis class=md-nav__link> <span class=md-ellipsis> Scaling Analysis </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#16-why-this-works-theoretical-insights class=md-nav__link> <span class=md-ellipsis> 16. Why This Works: Theoretical Insights </span> </a> <nav class=md-nav aria-label="16. Why This Works: Theoretical Insights"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#compression-and-regularization class=md-nav__link> <span class=md-ellipsis> Compression and Regularization </span> </a> </li> <li class=md-nav__item> <a href=#iterative-refinement-vs-single-pass class=md-nav__link> <span class=md-ellipsis> Iterative Refinement vs Single-Pass </span> </a> </li> <li class=md-nav__item> <a href=#error-correction class=md-nav__link> <span class=md-ellipsis> Error Correction </span> </a> </li> <li class=md-nav__item> <a href=#deep-supervision-as-curriculum-learning class=md-nav__link> <span class=md-ellipsis> Deep Supervision as Curriculum Learning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#17-applications-and-extensions class=md-nav__link> <span class=md-ellipsis> 17. Applications and Extensions </span> </a> <nav class=md-nav aria-label="17. Applications and Extensions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#beyond-puzzles class=md-nav__link> <span class=md-ellipsis> Beyond Puzzles </span> </a> </li> <li class=md-nav__item> <a href=#modifications-for-other-domains class=md-nav__link> <span class=md-ellipsis> Modifications for Other Domains </span> </a> </li> <li class=md-nav__item> <a href=#competition-considerations class=md-nav__link> <span class=md-ellipsis> Competition Considerations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#18-conclusion-and-future-directions class=md-nav__link> <span class=md-ellipsis> 18. Conclusion and Future Directions </span> </a> <nav class=md-nav aria-label="18. Conclusion and Future Directions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-paradigm-shift class=md-nav__link> <span class=md-ellipsis> The Paradigm Shift </span> </a> </li> <li class=md-nav__item> <a href=#open-questions class=md-nav__link> <span class=md-ellipsis> Open Questions </span> </a> </li> <li class=md-nav__item> <a href=#what-this-means-for-the-field class=md-nav__link> <span class=md-ellipsis> What This Means for the Field </span> </a> </li> <li class=md-nav__item> <a href=#final-thoughts class=md-nav__link> <span class=md-ellipsis> Final Thoughts </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#further-resources class=md-nav__link> <span class=md-ellipsis> Further Resources </span> </a> <nav class=md-nav aria-label="Further Resources"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#paper-and-code class=md-nav__link> <span class=md-ellipsis> Paper and Code </span> </a> </li> <li class=md-nav__item> <a href=#datasets class=md-nav__link> <span class=md-ellipsis> Datasets </span> </a> </li> <li class=md-nav__item> <a href=#related-research class=md-nav__link> <span class=md-ellipsis> Related Research </span> </a> </li> <li class=md-nav__item> <a href=#community class=md-nav__link> <span class=md-ellipsis> Community </span> </a> </li> <li class=md-nav__item> <a href=#video-explanations class=md-nav__link> <span class=md-ellipsis> Video Explanations </span> </a> </li> <li class=md-nav__item> <a href=#try-it-yourself class=md-nav__link> <span class=md-ellipsis> Try It Yourself </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/AIBreakDown/BACKUP.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/AIBreakDown/BACKUP.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=tiny-recursive-models-trm-when-7m-parameters-beat-671b>Tiny Recursive Models (TRM): When 7M Parameters Beat 671B<a class=headerlink href=#tiny-recursive-models-trm-when-7m-parameters-beat-671b title="Permanent link">¶</a></h1> <p>When a tiny 7 million parameter model decisively beats massive 671 billion parameter models at reasoning tasks, it's time to rethink everything we thought we knew about AI scaling. Welcome to the world of Tiny Recursive Models (TRM), where less truly is more.</p> <p>The results speak for themselves: On Sudoku-Extreme, TRM achieves 87.4% accuracy while GPT-4, Claude 3.7, and DeepSeek R1 all score 0%. That's not a typo. Zero percent. On ARC-AGI-2, the newest and hardest abstract reasoning benchmark, TRM's 7.8% accuracy beats Gemini 2.5 Pro's 4.9% and O3-mini's 3.0%, while using less than 0.01% of the parameters.</p> <p>This isn't just an incremental improvement. It's a paradigm shift in how we think about building AI systems for reasoning tasks.</p> <hr> <h2 id=1-introduction-the-paradigm-shift>1. Introduction: The Paradigm Shift<a class=headerlink href=#1-introduction-the-paradigm-shift title="Permanent link">¶</a></h2> <p>For years, we've been in an arms race for bigger models: - 2018: BERT (110M parameters) - 2019: GPT-2 (1.5B parameters) - 2020: GPT-3 (175B parameters) - 2023: GPT-4 (rumored 1.7T parameters)</p> <p>The assumption was simple: more parameters equals better reasoning. Throw enough compute at a problem, and you'll solve it.</p> <p>TRM challenges this assumption fundamentally. With just 7 million parameters, a model smaller than most image classifiers from 2015, it outperforms frontier language models on systematic reasoning tasks. The secret? <strong>Iteration, not just scale.</strong></p> <p><div class=video-container><iframe src=assets/videos/Scene1_Title.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing>What You're Seeing<a class=headerlink href=#what-youre-seeing title="Permanent link">¶</a></h3> <p>The opening visualization introduces our journey through TRM's architecture using Sudoku as a teaching framework. Sudoku is perfect for understanding TRM because: - It requires both local constraints (cell-level rules) and global reasoning (grid-level consistency) - Solutions emerge through iterative refinement, not single-pass generation - Success is binary and verifiable (no ambiguity in correctness)</p> <p>These same properties appear in many reasoning tasks: mathematical problem-solving, logical deduction, constraint satisfaction, and even code generation.</p> <h3 id=why-this-matters-for-you>Why This Matters for You<a class=headerlink href=#why-this-matters-for-you title="Permanent link">¶</a></h3> <p><strong>For Practitioners:</strong> You can now deploy powerful reasoning models on edge devices, mobile phones, and constrained environments. A 7M parameter model fits comfortably in less than 30MB of memory.</p> <p><strong>For Researchers:</strong> TRM demonstrates that architectural innovation can be more important than raw scale. The techniques here generalize to other domains where data is scarce but reasoning is crucial.</p> <p><strong>For the Field:</strong> This challenges the "bigger is better" narrative and suggests we've been leaving significant efficiency gains on the table by focusing primarily on scaling.</p> <hr> <h2 id=2-the-problem-why-llms-fail-at-systematic-reasoning>2. The Problem: Why LLMs Fail at Systematic Reasoning<a class=headerlink href=#2-the-problem-why-llms-fail-at-systematic-reasoning title="Permanent link">¶</a></h2> <p>Let's start with a concrete example. Here's a hard Sudoku puzzle:</p> <p><div class=video-container><iframe src=assets/videos/Scene2_SudokuSetup.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_1>What You're Seeing<a class=headerlink href=#what-youre-seeing_1 title="Permanent link">¶</a></h3> <p>This scene shows how a Sudoku puzzle maps to a machine learning problem. You're seeing: - A 9x9 grid with initial clues (given numbers) - Empty cells that must be filled (the reasoning challenge) - Constraints that must be satisfied simultaneously (row, column, box uniqueness) - The grid representation that neural networks process</p> <p>The visualization demonstrates tokenization, where each cell becomes a token (like words in language), and positional encoding, where grid location matters (like word order in sentences).</p> <h3 id=technical-deep-dive>Technical Deep Dive<a class=headerlink href=#technical-deep-dive title="Permanent link">¶</a></h3> <p><strong>Why Traditional LLMs Struggle:</strong></p> <p>Large language models like GPT-4 or Claude generate answers autoregressively, token by token, in a single forward pass. For a Sudoku puzzle, this means:</p> <ol> <li><strong>No Error Correction:</strong> Once a token is generated, it's used for all subsequent predictions. A single error cascades through the entire solution.</li> <li><strong>No Iterative Refinement:</strong> Humans solve Sudoku by making tentative guesses, checking constraints, and revising. LLMs don't naturally do this.</li> <li><strong>Working Memory Limitations:</strong> Even with chain-of-thought prompting, LLMs must hold all intermediate reasoning in the context window, competing with the input puzzle for limited space.</li> </ol> <p>Here's the empirical evidence from hard Sudoku puzzles:</p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>DeepSeek R1</td> <td>671B</td> <td>0.0%</td> </tr> <tr> <td>Claude 3.7 8K</td> <td>Unknown</td> <td>0.0%</td> </tr> <tr> <td>O3-mini-high</td> <td>Unknown</td> <td>0.0%</td> </tr> <tr> <td>TRM-MLP</td> <td>5M</td> <td><strong>87.4%</strong></td> </tr> </tbody> </table> <p><strong>Input Representation:</strong></p> <p>When we feed a Sudoku puzzle to a neural network, we need to represent it numerically:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=c1># Each cell is represented as an integer (0-9, plus special tokens)</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a><span class=c1># For a 9x9 Sudoku:</span>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=n>grid</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>  <span class=c1># Row 1: 0 means empty</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>  <span class=c1># Row 2</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>    <span class=c1># ... more rows</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=p>]</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a><span class=c1># Flattened to sequence: [5, 3, 0, 0, 7, 0, ...]</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a><span class=c1># Length: 81 tokens for full 9x9 grid</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=c1># Vocabulary size: 12 (0=pad, 1=EOS, 2-11=digits 0-9)</span>
</span></code></pre></div> <p>The grid is flattened into a sequence and each position becomes a token. For variable-sized grids (up to 30x30 for ARC-AGI), we use padding and special end-of-sequence tokens.</p> <p><strong>Problem Complexity:</strong></p> <p>Sudoku is NP-complete. The model must learn: - <strong>Row constraints:</strong> Each of 9 rows must contain digits 1-9 exactly once - <strong>Column constraints:</strong> Each of 9 columns must contain digits 1-9 exactly once - <strong>Box constraints:</strong> Each of 9 3x3 sub-grids must contain digits 1-9 exactly once - <strong>Logical deduction:</strong> Advanced techniques like naked pairs, hidden triples, X-wings</p> <p>This requires global reasoning. Changing one cell can invalidate choices made 20 steps earlier. Single-pass autoregressive generation simply cannot handle this effectively.</p> <details class=note> <summary>Key Concepts</summary> <ul> <li><strong>Tokenization</strong>: Each cell is a discrete token (like words in NLP)</li> <li><strong>Positional Information</strong>: Grid location is critical (encoded like position in a sentence)</li> <li><strong>Hard Constraints</strong>: Rules that MUST be satisfied (unlike soft preferences in language)</li> <li><strong>NP-Complete</strong>: No known polynomial-time algorithm; requires search/reasoning</li> </ul> </details> <hr> <h2 id=3-from-hrm-to-trm-the-evolution>3. From HRM to TRM: The Evolution<a class=headerlink href=#3-from-hrm-to-trm-the-evolution title="Permanent link">¶</a></h2> <p>Before diving into TRM's architecture, we need to understand its predecessor: Hierarchical Reasoning Models (HRM).</p> <p>HRM was itself a breakthrough. Published earlier in 2024, it introduced two key ideas: 1. <strong>Recursive Reasoning:</strong> Process information through the same network multiple times, rather than a single forward pass 2. <strong>Deep Supervision:</strong> Provide training signal at multiple intermediate steps, not just the final output</p> <p>HRM achieved impressive results: 55% on Sudoku-Extreme (vs 0% for LLMs), 40.3% on ARC-AGI-1. But the architecture was complex: - Two separate networks (f_L and f_H) operating at different "hierarchical frequencies" - Theoretical justification based on neuroscience (brain oscillations, hierarchical processing) - Complex training with Q-learning for adaptive computation - Heavy mathematical dependencies (Implicit Function Theorem, fixed-point iterations)</p> <h3 id=the-trm-insight>The TRM Insight<a class=headerlink href=#the-trm-insight title="Permanent link">¶</a></h3> <p>The TRM paper asked a simple question: <strong>What if most of HRM's complexity is unnecessary?</strong></p> <p>The analysis revealed that HRM's gains came primarily from <strong>deep supervision</strong> (iterating on predictions), not from the hierarchical dual-network design. This led to radical simplification:</p> <p><strong>HRM:</strong> Two networks (27M params) → <strong>TRM:</strong> One network (7M params) <strong>HRM:</strong> Complex fixed-point theory → <strong>TRM:</strong> Straightforward backpropagation <strong>HRM:</strong> 4-layer networks → <strong>TRM:</strong> 2-layer networks (surprisingly better!) <strong>HRM:</strong> Dual latent states → <strong>TRM:</strong> Clear separation (answer + reasoning)</p> <p>The result? Better performance with 75% fewer parameters and conceptually simpler architecture.</p> <hr> <h2 id=4-data-flow-how-information-moves-through-trm>4. Data Flow: How Information Moves Through TRM<a class=headerlink href=#4-data-flow-how-information-moves-through-trm title="Permanent link">¶</a></h2> <p>Before diving into the three-stream architecture, let's understand the overall data flow.</p> <p><div class=video-container><iframe src=assets/videos/Scene3_DataFlow.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_2>What You're Seeing<a class=headerlink href=#what-youre-seeing_2 title="Permanent link">¶</a></h3> <p>This visualization shows how information flows through TRM: - <strong>Input encoding:</strong> Sudoku grid → embedded vectors (dimension 256) - <strong>Transformer processing:</strong> Recursive passes through the same small network - <strong>Output decoding:</strong> Embedded vectors → predicted solution grid</p> <p>Notice how the same network (same weights) is applied multiple times. This is weight sharing, the key to TRM's parameter efficiency.</p> <h3 id=technical-deep-dive_1>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_1 title="Permanent link">¶</a></h3> <p><strong>The Complete Pipeline:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Simplified TRM forward pass</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=k>def</span><span class=w> </span><span class=nf>trm_forward</span><span class=p>(</span><span class=n>question_grid</span><span class=p>,</span> <span class=n>answer_grid</span><span class=p>,</span> <span class=n>latent_reasoning</span><span class=p>):</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    <span class=c1># Phase 1: Embed inputs into vector space</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>embed_question</span><span class=p>(</span><span class=n>question_grid</span><span class=p>)</span>        <span class=c1># [batch, 81, 256]</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>embed_answer</span><span class=p>(</span><span class=n>answer_grid</span><span class=p>)</span>            <span class=c1># [batch, 81, 256]</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>    <span class=n>z</span> <span class=o>=</span> <span class=n>initialize_latent</span><span class=p>(</span><span class=n>latent_reasoning</span><span class=p>)</span>  <span class=c1># [batch, 32, 256]</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>    <span class=c1># Phase 2: Recursive reasoning (8 steps)</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>    <span class=c1># Only update z (reasoning), keep x (question) and y (answer) fixed</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>8</span><span class=p>):</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>        <span class=n>combined</span> <span class=o>=</span> <span class=n>concatenate</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>])</span>    <span class=c1># [batch, 194, 256]</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>        <span class=n>output</span> <span class=o>=</span> <span class=n>transformer_block</span><span class=p>(</span><span class=n>combined</span><span class=p>)</span>  <span class=c1># Same weights every time!</span>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a>        <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>split</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=p>[</span><span class=mi>81</span><span class=p>,</span> <span class=mi>81</span><span class=p>,</span> <span class=mi>32</span><span class=p>])</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>    <span class=c1># Phase 3: Refinement (16 steps)</span>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a>    <span class=c1># Now update y (answer) using the refined z (reasoning)</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a>    <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a>        <span class=n>combined</span> <span class=o>=</span> <span class=n>concatenate</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>])</span>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a>        <span class=n>output</span> <span class=o>=</span> <span class=n>transformer_block</span><span class=p>(</span><span class=n>combined</span><span class=p>)</span>  <span class=c1># Still same weights!</span>
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a>        <span class=n>_</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>split</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=p>[</span><span class=mi>81</span><span class=p>,</span> <span class=mi>81</span><span class=p>,</span> <span class=mi>32</span><span class=p>])</span>
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a>
</span><span id=__span-1-22><a id=__codelineno-1-22 name=__codelineno-1-22 href=#__codelineno-1-22></a>    <span class=c1># Phase 4: Decode to predictions</span>
</span><span id=__span-1-23><a id=__codelineno-1-23 name=__codelineno-1-23 href=#__codelineno-1-23></a>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>reverse_embed</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>  <span class=c1># [batch, 81, 12] logits</span>
</span><span id=__span-1-24><a id=__codelineno-1-24 name=__codelineno-1-24 href=#__codelineno-1-24></a>    <span class=k>return</span> <span class=n>predictions</span>
</span></code></pre></div> <p><strong>Key Innovation: Weight Sharing</strong></p> <p>Unlike a traditional transformer with different weights for each layer, TRM uses the <strong>same weights</strong> repeatedly. This: - Dramatically reduces parameters (2-layer network used 24 times = 48 effective layers) - Forces information compression (all reasoning must fit in the shared representation) - Acts as strong regularization (prevents overfitting on small datasets)</p> <p><strong>The Three Phases:</strong></p> <ol> <li><strong>Embedding:</strong> Transform discrete tokens (0-11) into continuous vectors (256-dim)</li> <li><strong>Recursive Processing:</strong> Apply the same transformer 24 times with different update patterns</li> <li><strong>Decoding:</strong> Transform vectors back to discrete predictions</li> </ol> <p>This is fundamentally different from standard transformers, which have unique weights for each layer.</p> <details class=example> <summary>Architecture Details</summary> <ul> <li><strong>Embedding dimension:</strong> 256 (vs 512-2048 in large LLMs)</li> <li><strong>Transformer layers:</strong> 2 (vs 96 in GPT-4)</li> <li><strong>Recursions:</strong> 8 + 16 = 24 effective passes</li> <li><strong>Total effective depth:</strong> 2 layers × 24 recursions = 48 layers</li> <li><strong>Parameters:</strong> ~7M total (vs 175B in GPT-3)</li> </ul> </details> <hr> <h2 id=5-recurrence-vs-transformers-understanding-the-difference>5. Recurrence vs Transformers: Understanding the Difference<a class=headerlink href=#5-recurrence-vs-transformers-understanding-the-difference title="Permanent link">¶</a></h2> <p>To appreciate TRM's design, we need to understand what came before it.</p> <p><div class=video-container><iframe src=assets/videos/Scene4_RecursionComparison.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_3>What You're Seeing<a class=headerlink href=#what-youre-seeing_3 title="Permanent link">¶</a></h3> <p>Side-by-side comparison: - <strong>Left:</strong> Recurrent processing (RNN/LSTM) - sequential, cell by cell - <strong>Right:</strong> Transformer processing - parallel across all cells</p> <p>Traditional recurrent networks process information sequentially, maintaining a hidden state. Transformers process everything in parallel using attention.</p> <p><div class=video-container><iframe src=assets/videos/Scene4b_ArchitectureComparison.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=technical-deep-dive_2>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_2 title="Permanent link">¶</a></h3> <p><strong>Recurrent Neural Networks (RNNs):</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># RNN processes sequentially</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>hidden</span> <span class=o>=</span> <span class=n>initial_state</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=k>for</span> <span class=n>cell</span> <span class=ow>in</span> <span class=n>grid</span><span class=p>:</span>  <span class=c1># Must go one by one</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    <span class=n>hidden</span> <span class=o>=</span> <span class=n>rnn_cell</span><span class=p>(</span><span class=n>cell</span><span class=p>,</span> <span class=n>hidden</span><span class=p>)</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>    <span class=n>predictions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>decode</span><span class=p>(</span><span class=n>hidden</span><span class=p>))</span>
</span></code></pre></div> <p><strong>Problems with RNNs:</strong> - <strong>Sequential bottleneck:</strong> Can't parallelize across the grid - <strong>Vanishing gradients:</strong> Information from early cells gets diluted - <strong>Limited context:</strong> Hidden state size is fixed, limiting working memory - <strong>Training time:</strong> O(n) sequential steps, very slow on modern hardware</p> <p><strong>Transformers:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Transformer processes in parallel</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>embedded_grid</span> <span class=o>=</span> <span class=n>embed</span><span class=p>(</span><span class=n>grid</span><span class=p>)</span>  <span class=c1># All cells at once</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=n>attended</span> <span class=o>=</span> <span class=n>self_attention</span><span class=p>(</span><span class=n>embedded_grid</span><span class=p>)</span>  <span class=c1># All-to-all connections</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>predictions</span> <span class=o>=</span> <span class=n>decode</span><span class=p>(</span><span class=n>attended</span><span class=p>)</span>  <span class=c1># Parallel predictions</span>
</span></code></pre></div> <p><strong>Advantages of Transformers:</strong> - <strong>Parallelization:</strong> Process all 81 Sudoku cells simultaneously on GPU - <strong>Direct connections:</strong> Every cell can attend to every other cell (no gradient vanishing) - <strong>Flexible context:</strong> Attention weights dynamically determine what's relevant - <strong>Training speed:</strong> O(1) sequential operations (10-100x faster than RNNs)</p> <p><strong>Performance Comparison:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>RNN/LSTM</th> <th>Transformer</th> <th>TRM</th> </tr> </thead> <tbody> <tr> <td><strong>Parallelization</strong></td> <td>Sequential only</td> <td>Fully parallel</td> <td>Fully parallel</td> </tr> <tr> <td><strong>Context Window</strong></td> <td>Fixed hidden size</td> <td>Full grid access</td> <td>Full grid + latent</td> </tr> <tr> <td><strong>Training Speed</strong></td> <td>Slow</td> <td>Fast</td> <td>Fast</td> </tr> <tr> <td><strong>Memory</strong></td> <td>O(n)</td> <td>O(n²)</td> <td>O(n²) but n is small</td> </tr> <tr> <td><strong>Parameters</strong></td> <td>Few</td> <td>Many</td> <td>Very few (reused)</td> </tr> <tr> <td><strong>Gradient Flow</strong></td> <td>Vanishing</td> <td>Direct paths</td> <td>Direct paths</td> </tr> </tbody> </table> <p><strong>Why TRM Uses Transformers:</strong></p> <p>For reasoning tasks with rich interactions (like Sudoku constraints), transformers excel because: 1. Every cell needs information from many other cells simultaneously 2. The importance of different cells changes dynamically as the puzzle is solved 3. Parallel processing allows efficient training even with recursive application</p> <details class=note> <summary>Why This Matters</summary> <ul> <li><strong>RNNs</strong> were the standard for sequences before 2017 but couldn't handle long-range dependencies</li> <li><strong>Transformers</strong> revolutionized NLP by enabling parallel processing and better scaling</li> <li><strong>TRM</strong> shows transformers work even better when recursively applied on small networks</li> </ul> </details> <hr> <h2 id=6-the-three-streams-trms-core-architecture>6. The Three Streams: TRM's Core Architecture<a class=headerlink href=#6-the-three-streams-trms-core-architecture title="Permanent link">¶</a></h2> <p>Here's where TRM gets really interesting. Instead of just processing input → output, TRM maintains three separate information streams.</p> <p><div class=video-container><iframe src=assets/videos/Scene5_TwoLatentStates.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_4>What You're Seeing<a class=headerlink href=#what-youre-seeing_4 title="Permanent link">¶</a></h3> <p>This visualization shows TRM's internal representations: - <strong>Question stream (x):</strong> The input puzzle, fixed throughout processing - <strong>Answer stream (y):</strong> The working solution, progressively refined - <strong>Reasoning stream (z):</strong> Intermediate thoughts and constraints, helps improve y</p> <p>Think of it like working on a puzzle at your desk with three Post-it notes:</p> <ol> <li><strong>Note 1 (x-stream):</strong> "Original puzzle clues" - you keep referring back to it but never change it</li> <li><strong>Note 2 (y-stream):</strong> "Current solution attempt" - starts rough, gets better with each revision</li> <li><strong>Note 3 (z-stream):</strong> "Scratch work and logic" - temporary deductions that help you improve the solution</li> </ol> <h3 id=technical-deep-dive_3>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_3 title="Permanent link">¶</a></h3> <p><strong>Why Three Streams?</strong></p> <p>HRM called these "hierarchical latent states" with complex biological justification. TRM has a simpler explanation:</p> <p><strong>x-stream (Question):</strong> This is your problem statement. It never changes during solving. The model can always look back at the original clues.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Question stream - fixed throughout</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>x</span> <span class=o>=</span> <span class=n>embed_question</span><span class=p>([</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=o>...</span><span class=p>])</span>  <span class=c1># Original puzzle</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=c1># Shape: [batch_size, 81, 256]</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=c1># Never updated during recursive processing</span>
</span></code></pre></div> <p><strong>y-stream (Answer):</strong> This is your working solution. It starts as a guess (often initialized randomly or as a copy of input) and gets iteratively refined.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Answer stream - refined in Phase 2</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>y</span> <span class=o>=</span> <span class=n>embed_initial_answer</span><span class=p>([</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=o>...</span><span class=p>])</span>  <span class=c1># Start empty or random</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Shape: [batch_size, 81, 256]</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=c1># Updated during refinement phase to improve predictions</span>
</span></code></pre></div> <p><strong>z-stream (Reasoning):</strong> This is your scratch space for intermediate logic. It doesn't directly correspond to a solution but helps compute one.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Reasoning stream - refined in Phase 1</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>  <span class=c1># Start random</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># Shape: [batch_size, 32, 256]</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># 32 is arbitrary "working memory" size</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=c1># Updated during reasoning phase to build understanding</span>
</span></code></pre></div> <p><strong>The Interaction:</strong></p> <p>All three streams are concatenated and processed together:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=k>def</span><span class=w> </span><span class=nf>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>):</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=c1># Concatenate the three streams</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>    <span class=n>combined</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [batch, 194, 256]</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=c1>#                     81 + 81 + 32 = 194 tokens</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=c1># Process through transformer</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=c1># Every token can attend to every other token across all streams!</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=n>attended</span> <span class=o>=</span> <span class=n>multi_head_attention</span><span class=p>(</span><span class=n>combined</span><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=n>processed</span> <span class=o>=</span> <span class=n>feed_forward</span><span class=p>(</span><span class=n>attended</span><span class=p>)</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>    <span class=c1># Split back into three streams</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>    <span class=n>x_new</span> <span class=o>=</span> <span class=n>processed</span><span class=p>[:,</span> <span class=p>:</span><span class=mi>81</span><span class=p>,</span> <span class=p>:]</span>      <span class=c1># Question (won't use update)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=n>y_new</span> <span class=o>=</span> <span class=n>processed</span><span class=p>[:,</span> <span class=mi>81</span><span class=p>:</span><span class=mi>162</span><span class=p>,</span> <span class=p>:]</span>   <span class=c1># Answer (may use update)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=n>z_new</span> <span class=o>=</span> <span class=n>processed</span><span class=p>[:,</span> <span class=mi>162</span><span class=p>:,</span> <span class=p>:]</span>     <span class=c1># Reasoning (may use update)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>    <span class=k>return</span> <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span>
</span></code></pre></div> <p><strong>Why This Works:</strong></p> <ol> <li><strong>Cross-stream attention:</strong> The answer stream can look at both the question and the reasoning</li> <li><strong>Separation of concerns:</strong> Reasoning logic (z) is separated from actual predictions (y)</li> <li><strong>Memory efficiency:</strong> Only 32 reasoning tokens vs 81 answer tokens (less to store in working memory)</li> <li><strong>Iterative refinement:</strong> Improve reasoning first, then use it to improve the answer</li> </ol> <p><strong>The Update Schedule:</strong></p> <table> <thead> <tr> <th>Phase</th> <th>Steps</th> <th>Updates</th> <th>Purpose</th> </tr> </thead> <tbody> <tr> <td>Reasoning</td> <td>8</td> <td>z only</td> <td>Build understanding of the problem</td> </tr> <tr> <td>Refinement</td> <td>16</td> <td>y only</td> <td>Improve answer using understanding</td> </tr> </tbody> </table> <p>This separation is crucial. You don't try to improve your answer until you've thought about the problem. Just like a human would:</p> <ol> <li>Read the puzzle (x)</li> <li>Think about constraints and deductions (update z 8 times)</li> <li>Fill in answers based on your reasoning (update y 16 times)</li> </ol> <details class=note> <summary>Why Not More Streams?</summary> <p>The paper tested this: - <strong>1 stream:</strong> 71.9% accuracy - forces model to mix answer and reasoning - <strong>2 streams (y + z):</strong> 87.4% accuracy - optimal separation - <strong>7 streams (multi-scale z):</strong> 77.6% accuracy - unnecessary complexity</p> <p>Two streams (answer + reasoning) is the sweet spot.</p> </details> <hr> <h2 id=7-recursive-improvement-the-24-pass-process>7. Recursive Improvement: The 24-Pass Process<a class=headerlink href=#7-recursive-improvement-the-24-pass-process title="Permanent link">¶</a></h2> <p>Now we get to the heart of TRM: how it uses recursive processing to progressively improve predictions.</p> <p><div class=video-container><iframe src=assets/videos/Scene6_TwentyOnePasses.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_5>What You're Seeing<a class=headerlink href=#what-youre-seeing_5 title="Permanent link">¶</a></h3> <p>This visualization shows TRM making multiple passes through the puzzle: - <strong>Passes 1-8:</strong> Building reasoning in the z-stream (understanding constraints) - <strong>Passes 9-24:</strong> Refining the answer in the y-stream (improving predictions) - Notice how difficult cells require more iterations, while easy cells stabilize quickly</p> <p>Each pass uses the same transformer weights, but the information in the streams evolves.</p> <h3 id=technical-deep-dive_4>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_4 title="Permanent link">¶</a></h3> <p><strong>Phase 1: Reasoning (8 iterations)</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Phase 1: Build understanding</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=c1># Update z-stream only, keep x and y fixed</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>8</span><span class=p>):</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>    <span class=c1># Only keep updated z (reasoning)</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>    <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=c1># Discard x_new and y_new (don't update question or answer yet)</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=c1># What's happening in z:</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=c1># - Identifying constraint relationships</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>    <span class=c1># - Building logical deduction chains</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>    <span class=c1># - Preparing to update the answer</span>
</span></code></pre></div> <p>After 8 steps, z contains rich information about the problem structure, but y (the answer) hasn't changed yet.</p> <p><strong>Phase 2: Refinement (16 iterations)</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># Phase 2: Improve answer</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=c1># Update y-stream only, keep x and z fixed</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>    <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>    <span class=c1># Only keep updated y (answer)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=c1># Discard x_new and z_new (question and reasoning are done)</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=c1># What's happening in y:</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>    <span class=c1># - Filling in cells based on reasoning in z</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>    <span class=c1># - Correcting mistakes from previous iterations</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>    <span class=c1># - Increasing confidence in predictions</span>
</span></code></pre></div> <p>After 16 steps, y should contain a high-quality solution, informed by the reasoning in z.</p> <p><strong>Why This Schedule?</strong></p> <p>You might ask: why 8 reasoning steps and 16 refinement steps? The paper tested various combinations:</p> <table> <thead> <tr> <th>Configuration</th> <th>Reasoning Steps</th> <th>Refinement Steps</th> <th>Effective Depth</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Small</td> <td>2</td> <td>4</td> <td>12</td> <td>73.7%</td> </tr> <tr> <td>Medium</td> <td>6</td> <td>10</td> <td>32</td> <td>84.2%</td> </tr> <tr> <td>Optimal</td> <td>8</td> <td>16</td> <td>48</td> <td>87.4%</td> </tr> <tr> <td>Large</td> <td>12</td> <td>24</td> <td>72</td> <td>85.8%</td> </tr> </tbody> </table> <p>The optimal point balances: - <strong>Enough reasoning</strong> to build good understanding (8 steps) - <strong>Enough refinement</strong> to improve answers fully (16 steps) - <strong>Not too much</strong> that you overfit or waste compute (diminishing returns after 24 total)</p> <p><strong>Complete Training Loop with Deep Supervision:</strong></p> <p>Here's where it gets really interesting. TRM doesn't just apply these 24 passes once. It applies them up to 16 times during training, with supervision at each round:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=k>def</span><span class=w> </span><span class=nf>train_step</span><span class=p>(</span><span class=n>question_grid</span><span class=p>,</span> <span class=n>true_answer_grid</span><span class=p>):</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>embed_question</span><span class=p>(</span><span class=n>question_grid</span><span class=p>)</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>embed_answer</span><span class=p>(</span><span class=n>question_grid</span><span class=p>)</span>  <span class=c1># Start with question as initial guess</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=c1># Deep supervision: train on multiple improvement cycles</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=k>for</span> <span class=n>supervision_step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>  <span class=c1># Up to 16 supervision steps</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>        <span class=c1># Phase 1: Reasoning (8 steps)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>8</span><span class=p>):</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>            <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>            <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>        <span class=c1># Phase 2: Refinement (16 steps)</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>            <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>            <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>        <span class=c1># Compute loss after this improvement cycle</span>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>        <span class=n>predictions</span> <span class=o>=</span> <span class=n>reverse_embed</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>cross_entropy</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>true_answer_grid</span><span class=p>)</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span>
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>
</span><span id=__span-10-25><a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>        <span class=c1># Detach to prevent backprop through all previous cycles</span>
</span><span id=__span-10-26><a id=__codelineno-10-26 name=__codelineno-10-26 href=#__codelineno-10-26></a>        <span class=c1># Only backprop through the last cycle</span>
</span><span id=__span-10-27><a id=__codelineno-10-27 name=__codelineno-10-27 href=#__codelineno-10-27></a>        <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-10-28><a id=__codelineno-10-28 name=__codelineno-10-28 href=#__codelineno-10-28></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-10-29><a id=__codelineno-10-29 name=__codelineno-10-29 href=#__codelineno-10-29></a>
</span><span id=__span-10-30><a id=__codelineno-10-30 name=__codelineno-10-30 href=#__codelineno-10-30></a>    <span class=c1># Backpropagate</span>
</span><span id=__span-10-31><a id=__codelineno-10-31 name=__codelineno-10-31 href=#__codelineno-10-31></a>    <span class=n>total_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-10-32><a id=__codelineno-10-32 name=__codelineno-10-32 href=#__codelineno-10-32></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></code></pre></div> <p>This gives TRM: - <strong>Effective depth:</strong> 2 layers × 24 recursions × 16 supervision = 768 effective layers! - <strong>Multiple chances:</strong> If the model doesn't get it right in one cycle, it has 15 more tries - <strong>Progressive improvement:</strong> Each supervision step sees the model's own previous attempt</p> <p><strong>Convergence Patterns:</strong></p> <p>From experiments: - <strong>Easy cells:</strong> Converge in ~2-4 passes (single digit possibility) - <strong>Medium cells:</strong> Converge in ~8-12 passes (simple logical deduction) - <strong>Hard cells:</strong> Need all 24 passes (complex constraint propagation)</p> <details class=note> <summary>Comparison to Human Solving</summary> <p>Humans solve Sudoku similarly: 1. <strong>Scan phase:</strong> Look for obvious cells (like z-stream reasoning) 2. <strong>Fill phase:</strong> Write in answers based on deductions (like y-stream refinement) 3. <strong>Iterate:</strong> If stuck, re-examine and refine (like multiple supervision cycles)</p> <p>TRM learns to mimic this without being explicitly programmed to do so!</p> </details> <hr> <h2 id=8-transformer-architecture-the-building-blocks>8. Transformer Architecture: The Building Blocks<a class=headerlink href=#8-transformer-architecture-the-building-blocks title="Permanent link">¶</a></h2> <p>Now let's look at what's inside those transformer blocks that get applied recursively.</p> <p><div class=video-container><iframe src=assets/videos/Scene7_TransformerDetails.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_6>What You're Seeing<a class=headerlink href=#what-youre-seeing_6 title="Permanent link">¶</a></h3> <p>Detailed visualization of: - <strong>Attention weights</strong> between cells (which cells influence which) - <strong>Multi-head attention</strong> (different heads specialize in different constraint types) - <strong>Information flow</strong> through layers</p> <p>Notice how attention patterns change across passes as the model refines its understanding.</p> <h3 id=technical-deep-dive_5>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_5 title="Permanent link">¶</a></h3> <p><strong>Multi-Head Self-Attention:</strong></p> <p>This is the core of how transformers work. For each token, we compute:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=kn>import</span><span class=w> </span><span class=nn>math</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a><span class=k>class</span><span class=w> </span><span class=nc>MultiHeadAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a><span class=sd>    Multi-head attention allows the model to attend to different aspects</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=sd>    of the input simultaneously.</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a><span class=sd>    For Sudoku:</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a><span class=sd>    - Head 1 might focus on row constraints</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a><span class=sd>    - Head 2 might focus on column constraints</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a><span class=sd>    - Head 3 might focus on box constraints</span>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=sd>    - Head 4 might focus on more complex patterns</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a><span class=sd>    """</span>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>):</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a>        <span class=k>assert</span> <span class=n>d_model</span> <span class=o>%</span> <span class=n>n_heads</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=s2>"d_model must be divisible by n_heads"</span>
</span><span id=__span-11-20><a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a>
</span><span id=__span-11-21><a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>      <span class=c1># 256</span>
</span><span id=__span-11-22><a id=__codelineno-11-22 name=__codelineno-11-22 href=#__codelineno-11-22></a>        <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>=</span> <span class=n>n_heads</span>      <span class=c1># 4</span>
</span><span id=__span-11-23><a id=__codelineno-11-23 name=__codelineno-11-23 href=#__codelineno-11-23></a>        <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span> <span class=o>=</span> <span class=n>d_model</span> <span class=o>//</span> <span class=n>n_heads</span>  <span class=c1># 64 per head</span>
</span><span id=__span-11-24><a id=__codelineno-11-24 name=__codelineno-11-24 href=#__codelineno-11-24></a>
</span><span id=__span-11-25><a id=__codelineno-11-25 name=__codelineno-11-25 href=#__codelineno-11-25></a>        <span class=c1># Linear projections for Q, K, V</span>
</span><span id=__span-11-26><a id=__codelineno-11-26 name=__codelineno-11-26 href=#__codelineno-11-26></a>        <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-11-27><a id=__codelineno-11-27 name=__codelineno-11-27 href=#__codelineno-11-27></a>        <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-11-28><a id=__codelineno-11-28 name=__codelineno-11-28 href=#__codelineno-11-28></a>        <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-11-29><a id=__codelineno-11-29 name=__codelineno-11-29 href=#__codelineno-11-29></a>
</span><span id=__span-11-30><a id=__codelineno-11-30 name=__codelineno-11-30 href=#__codelineno-11-30></a>        <span class=c1># Output projection</span>
</span><span id=__span-11-31><a id=__codelineno-11-31 name=__codelineno-11-31 href=#__codelineno-11-31></a>        <span class=bp>self</span><span class=o>.</span><span class=n>out_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-11-32><a id=__codelineno-11-32 name=__codelineno-11-32 href=#__codelineno-11-32></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-11-33><a id=__codelineno-11-33 name=__codelineno-11-33 href=#__codelineno-11-33></a>
</span><span id=__span-11-34><a id=__codelineno-11-34 name=__codelineno-11-34 href=#__codelineno-11-34></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-11-35><a id=__codelineno-11-35 name=__codelineno-11-35 href=#__codelineno-11-35></a>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>d_model</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-11-36><a id=__codelineno-11-36 name=__codelineno-11-36 href=#__codelineno-11-36></a>
</span><span id=__span-11-37><a id=__codelineno-11-37 name=__codelineno-11-37 href=#__codelineno-11-37></a>        <span class=c1># Step 1: Project to Q, K, V</span>
</span><span id=__span-11-38><a id=__codelineno-11-38 name=__codelineno-11-38 href=#__codelineno-11-38></a>        <span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># [batch, seq_len, 256]</span>
</span><span id=__span-11-39><a id=__codelineno-11-39 name=__codelineno-11-39 href=#__codelineno-11-39></a>        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-11-40><a id=__codelineno-11-40 name=__codelineno-11-40 href=#__codelineno-11-40></a>        <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-11-41><a id=__codelineno-11-41 name=__codelineno-11-41 href=#__codelineno-11-41></a>
</span><span id=__span-11-42><a id=__codelineno-11-42 name=__codelineno-11-42 href=#__codelineno-11-42></a>        <span class=c1># Step 2: Split into multiple heads</span>
</span><span id=__span-11-43><a id=__codelineno-11-43 name=__codelineno-11-43 href=#__codelineno-11-43></a>        <span class=c1># Reshape to [batch, n_heads, seq_len, d_k]</span>
</span><span id=__span-11-44><a id=__codelineno-11-44 name=__codelineno-11-44 href=#__codelineno-11-44></a>        <span class=n>q</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-11-45><a id=__codelineno-11-45 name=__codelineno-11-45 href=#__codelineno-11-45></a>        <span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-11-46><a id=__codelineno-11-46 name=__codelineno-11-46 href=#__codelineno-11-46></a>        <span class=n>v</span> <span class=o>=</span> <span class=n>v</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-11-47><a id=__codelineno-11-47 name=__codelineno-11-47 href=#__codelineno-11-47></a>
</span><span id=__span-11-48><a id=__codelineno-11-48 name=__codelineno-11-48 href=#__codelineno-11-48></a>        <span class=c1># Step 3: Compute attention scores</span>
</span><span id=__span-11-49><a id=__codelineno-11-49 name=__codelineno-11-49 href=#__codelineno-11-49></a>        <span class=c1># scores[i,j] = how much should token i attend to token j?</span>
</span><span id=__span-11-50><a id=__codelineno-11-50 name=__codelineno-11-50 href=#__codelineno-11-50></a>        <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span>
</span><span id=__span-11-51><a id=__codelineno-11-51 name=__codelineno-11-51 href=#__codelineno-11-51></a>        <span class=c1># Shape: [batch, n_heads, seq_len, seq_len]</span>
</span><span id=__span-11-52><a id=__codelineno-11-52 name=__codelineno-11-52 href=#__codelineno-11-52></a>
</span><span id=__span-11-53><a id=__codelineno-11-53 name=__codelineno-11-53 href=#__codelineno-11-53></a>        <span class=c1># Why divide by sqrt(d_k)?</span>
</span><span id=__span-11-54><a id=__codelineno-11-54 name=__codelineno-11-54 href=#__codelineno-11-54></a>        <span class=c1># Without scaling, dot products can get very large</span>
</span><span id=__span-11-55><a id=__codelineno-11-55 name=__codelineno-11-55 href=#__codelineno-11-55></a>        <span class=c1># → softmax becomes peaked → gradients vanish</span>
</span><span id=__span-11-56><a id=__codelineno-11-56 name=__codelineno-11-56 href=#__codelineno-11-56></a>        <span class=c1># Scaling keeps values in a nice range for softmax</span>
</span><span id=__span-11-57><a id=__codelineno-11-57 name=__codelineno-11-57 href=#__codelineno-11-57></a>
</span><span id=__span-11-58><a id=__codelineno-11-58 name=__codelineno-11-58 href=#__codelineno-11-58></a>        <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-11-59><a id=__codelineno-11-59 name=__codelineno-11-59 href=#__codelineno-11-59></a>            <span class=n>scores</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>mask</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mf>1e9</span><span class=p>)</span>
</span><span id=__span-11-60><a id=__codelineno-11-60 name=__codelineno-11-60 href=#__codelineno-11-60></a>
</span><span id=__span-11-61><a id=__codelineno-11-61 name=__codelineno-11-61 href=#__codelineno-11-61></a>        <span class=c1># Step 4: Apply softmax to get attention weights</span>
</span><span id=__span-11-62><a id=__codelineno-11-62 name=__codelineno-11-62 href=#__codelineno-11-62></a>        <span class=n>attn_weights</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-11-63><a id=__codelineno-11-63 name=__codelineno-11-63 href=#__codelineno-11-63></a>        <span class=n>attn_weights</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>attn_weights</span><span class=p>)</span>
</span><span id=__span-11-64><a id=__codelineno-11-64 name=__codelineno-11-64 href=#__codelineno-11-64></a>
</span><span id=__span-11-65><a id=__codelineno-11-65 name=__codelineno-11-65 href=#__codelineno-11-65></a>        <span class=c1># Step 5: Apply attention to values</span>
</span><span id=__span-11-66><a id=__codelineno-11-66 name=__codelineno-11-66 href=#__codelineno-11-66></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>attn_weights</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span><span id=__span-11-67><a id=__codelineno-11-67 name=__codelineno-11-67 href=#__codelineno-11-67></a>        <span class=c1># Shape: [batch, n_heads, seq_len, d_k]</span>
</span><span id=__span-11-68><a id=__codelineno-11-68 name=__codelineno-11-68 href=#__codelineno-11-68></a>
</span><span id=__span-11-69><a id=__codelineno-11-69 name=__codelineno-11-69 href=#__codelineno-11-69></a>        <span class=c1># Step 6: Concatenate heads and project</span>
</span><span id=__span-11-70><a id=__codelineno-11-70 name=__codelineno-11-70 href=#__codelineno-11-70></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-11-71><a id=__codelineno-11-71 name=__codelineno-11-71 href=#__codelineno-11-71></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-11-72><a id=__codelineno-11-72 name=__codelineno-11-72 href=#__codelineno-11-72></a>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_proj</span><span class=p>(</span><span class=n>attn_output</span><span class=p>)</span>
</span><span id=__span-11-73><a id=__codelineno-11-73 name=__codelineno-11-73 href=#__codelineno-11-73></a>
</span><span id=__span-11-74><a id=__codelineno-11-74 name=__codelineno-11-74 href=#__codelineno-11-74></a>        <span class=k>return</span> <span class=n>output</span>
</span></code></pre></div> <p><strong>Feed-Forward Network:</strong></p> <p>After attention, each token is processed independently through a feed-forward network:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>class</span><span class=w> </span><span class=nc>FeedForward</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=sd>    Two-layer MLP with GELU activation.</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=sd>    Typical expansion factor is 4x:</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=sd>    256 → 1024 → 256</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a><span class=sd>    This adds non-linearity and allows the model to process</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a><span class=sd>    the attended information.</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a><span class=sd>    """</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>):</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-12-14><a id=__codelineno-12-14 name=__codelineno-12-14 href=#__codelineno-12-14></a>        <span class=bp>self</span><span class=o>.</span><span class=n>linear1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ff</span><span class=p>)</span>
</span><span id=__span-12-15><a id=__codelineno-12-15 name=__codelineno-12-15 href=#__codelineno-12-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_ff</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-12-16><a id=__codelineno-12-16 name=__codelineno-12-16 href=#__codelineno-12-16></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-12-17><a id=__codelineno-12-17 name=__codelineno-12-17 href=#__codelineno-12-17></a>
</span><span id=__span-12-18><a id=__codelineno-12-18 name=__codelineno-12-18 href=#__codelineno-12-18></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-12-19><a id=__codelineno-12-19 name=__codelineno-12-19 href=#__codelineno-12-19></a>        <span class=c1># Expand → Activate → Compress</span>
</span><span id=__span-12-20><a id=__codelineno-12-20 name=__codelineno-12-20 href=#__codelineno-12-20></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>gelu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear1</span><span class=p>(</span><span class=n>x</span><span class=p>))))</span>
</span></code></pre></div> <p><strong>Complete Transformer Block:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=k>class</span><span class=w> </span><span class=nc>TransformerBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=sd>    A single transformer block combining:</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a><span class=sd>    1. Multi-head attention (tokens talk to each other)</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=sd>    2. Add &amp; Normalize (residual connection)</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a><span class=sd>    3. Feed-forward (process information)</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=sd>    4. Add &amp; Normalize (another residual)</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a><span class=sd>    TRM uses 2 of these blocks sequentially, then recurses.</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a><span class=sd>    """</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>use_attention</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>        <span class=bp>self</span><span class=o>.</span><span class=n>use_attention</span> <span class=o>=</span> <span class=n>use_attention</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>        <span class=k>if</span> <span class=n>use_attention</span><span class=p>:</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a>            <span class=bp>self</span><span class=o>.</span><span class=n>attention</span> <span class=o>=</span> <span class=n>MultiHeadAttention</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>            <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ffn</span> <span class=o>=</span> <span class=n>FeedForward</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ff</span><span class=p>,</span> <span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a>        <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a>        <span class=c1># Block 1: Self-attention with residual</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_attention</span><span class=p>:</span>
</span><span id=__span-13-27><a id=__codelineno-13-27 name=__codelineno-13-27 href=#__codelineno-13-27></a>            <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span><span id=__span-13-28><a id=__codelineno-13-28 name=__codelineno-13-28 href=#__codelineno-13-28></a>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-13-29><a id=__codelineno-13-29 name=__codelineno-13-29 href=#__codelineno-13-29></a>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>residual</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-13-30><a id=__codelineno-13-30 name=__codelineno-13-30 href=#__codelineno-13-30></a>
</span><span id=__span-13-31><a id=__codelineno-13-31 name=__codelineno-13-31 href=#__codelineno-13-31></a>        <span class=c1># Block 2: Feed-forward with residual</span>
</span><span id=__span-13-32><a id=__codelineno-13-32 name=__codelineno-13-32 href=#__codelineno-13-32></a>        <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span><span id=__span-13-33><a id=__codelineno-13-33 name=__codelineno-13-33 href=#__codelineno-13-33></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffn</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-13-34><a id=__codelineno-13-34 name=__codelineno-13-34 href=#__codelineno-13-34></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>residual</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-13-35><a id=__codelineno-13-35 name=__codelineno-13-35 href=#__codelineno-13-35></a>
</span><span id=__span-13-36><a id=__codelineno-13-36 name=__codelineno-13-36 href=#__codelineno-13-36></a>        <span class=k>return</span> <span class=n>x</span>
</span></code></pre></div> <p><strong>Attention Patterns for Sudoku:</strong></p> <p>Different attention heads learn different constraint types:</p> <table> <thead> <tr> <th>Head</th> <th>Focus</th> <th>Example Pattern</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Row constraints</td> <td>Cell (4,5) attends strongly to all cells in row 4</td> </tr> <tr> <td>2</td> <td>Column constraints</td> <td>Cell (4,5) attends strongly to all cells in column 5</td> </tr> <tr> <td>3</td> <td>Box constraints</td> <td>Cell (4,5) attends strongly to cells in its 3x3 box</td> </tr> <tr> <td>4</td> <td>Complex logic</td> <td>Pairs, triples, and other Sudoku techniques</td> </tr> </tbody> </table> <p>This emerges from training without explicit programming!</p> <details class=example> <summary>MLP-Only Variant (TRM-MLP)</summary> <p>Interestingly, for Sudoku, you can replace attention with a simple MLP:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=k>class</span><span class=w> </span><span class=nc>MLPMixer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=sd>    For fixed, small sequence lengths, an MLP can work better than attention.</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=sd>    TRM-MLP achieves 87.4% on Sudoku vs 74.7% for TRM-Att.</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=sd>    """</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>seq_len</span><span class=o>=</span><span class=mi>194</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>):</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>        <span class=c1># Mix across sequence dimension</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>mix</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>seq_len</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>)</span>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a>        <span class=c1># x: [batch, seq_len, d_model]</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>        <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-14-17><a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>  <span class=c1># [batch, d_model, seq_len]</span>
</span><span id=__span-14-18><a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>mix</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-14-19><a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>  <span class=c1># [batch, seq_len, d_model]</span>
</span><span id=__span-14-20><a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a>        <span class=k>return</span> <span class=n>residual</span> <span class=o>+</span> <span class=n>x</span>
</span></code></pre></div> <p>For larger, variable-length tasks like ARC-AGI, attention works better.</p> </details> <hr> <h2 id=9-deep-supervision-training-at-multiple-scales>9. Deep Supervision: Training at Multiple Scales<a class=headerlink href=#9-deep-supervision-training-at-multiple-scales title="Permanent link">¶</a></h2> <p>One of TRM's key innovations is deep supervision, which provides training signal at multiple points during the recursive process.</p> <p><div class=video-container><iframe src=assets/videos/Scene8_DeepSupervision.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_7>What You're Seeing<a class=headerlink href=#what-youre-seeing_7 title="Permanent link">¶</a></h3> <p>Visualization of training signals at different depths: - Loss is computed after each supervision cycle (not just at the end) - Earlier cycles receive weaker signal (still learning basics) - Later cycles receive stronger signal (refining final answer) - Gradients flow through the network at multiple points</p> <h3 id=technical-deep-dive_6>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_6 title="Permanent link">¶</a></h3> <p><strong>Traditional Training:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Standard approach: loss only at the end</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>embed_inputs</span><span class=p>(</span><span class=n>question</span><span class=p>,</span> <span class=n>initial_answer</span><span class=p>)</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>24</span><span class=p>):</span>  <span class=c1># All 24 recursive passes</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>transformer_block</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a><span class=n>predictions</span> <span class=o>=</span> <span class=n>decode</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a><span class=n>loss</span> <span class=o>=</span> <span class=n>cross_entropy</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>)</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>  <span class=c1># Backprop through all 24 passes</span>
</span></code></pre></div> <p><strong>Problem:</strong> Gradients must flow through 24 applications of the same network. Even with good architecture, this can lead to vanishing gradients.</p> <p><strong>Deep Supervision Approach:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># TRM approach: supervision at multiple points</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=k>def</span><span class=w> </span><span class=nf>train_with_deep_supervision</span><span class=p>(</span><span class=n>question</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>,</span> <span class=n>n_sup</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>embed_question</span><span class=p>(</span><span class=n>question</span><span class=p>)</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>embed_answer</span><span class=p>(</span><span class=n>question</span><span class=p>)</span>  <span class=c1># Start with input as initial guess</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn_like</span><span class=p>(</span><span class=n>latent_size</span><span class=p>)</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>    <span class=k>for</span> <span class=n>sup_step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_sup</span><span class=p>):</span>  <span class=c1># 16 supervision cycles</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>        <span class=c1># Do one complete reasoning + refinement cycle</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>        <span class=c1># Phase 1: Reasoning (8 steps)</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>8</span><span class=p>):</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>            <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span> <span class=k>if</span> <span class=n>sup_step</span> <span class=o>&lt;</span> <span class=n>n_sup</span> <span class=o>-</span> <span class=mi>1</span> <span class=k>else</span> <span class=n>nullcontext</span><span class=p>():</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a>                <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-16-15><a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a>                <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>
</span><span id=__span-16-16><a id=__codelineno-16-16 name=__codelineno-16-16 href=#__codelineno-16-16></a>
</span><span id=__span-16-17><a id=__codelineno-16-17 name=__codelineno-16-17 href=#__codelineno-16-17></a>        <span class=c1># Phase 2: Refinement (16 steps)</span>
</span><span id=__span-16-18><a id=__codelineno-16-18 name=__codelineno-16-18 href=#__codelineno-16-18></a>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-16-19><a id=__codelineno-16-19 name=__codelineno-16-19 href=#__codelineno-16-19></a>            <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>()</span> <span class=k>if</span> <span class=n>sup_step</span> <span class=o>&lt;</span> <span class=n>n_sup</span> <span class=o>-</span> <span class=mi>1</span> <span class=k>else</span> <span class=n>nullcontext</span><span class=p>():</span>
</span><span id=__span-16-20><a id=__codelineno-16-20 name=__codelineno-16-20 href=#__codelineno-16-20></a>                <span class=n>x</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-16-21><a id=__codelineno-16-21 name=__codelineno-16-21 href=#__codelineno-16-21></a>                <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>
</span><span id=__span-16-22><a id=__codelineno-16-22 name=__codelineno-16-22 href=#__codelineno-16-22></a>
</span><span id=__span-16-23><a id=__codelineno-16-23 name=__codelineno-16-23 href=#__codelineno-16-23></a>        <span class=c1># Compute loss at this supervision step</span>
</span><span id=__span-16-24><a id=__codelineno-16-24 name=__codelineno-16-24 href=#__codelineno-16-24></a>        <span class=n>predictions</span> <span class=o>=</span> <span class=n>decode</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-16-25><a id=__codelineno-16-25 name=__codelineno-16-25 href=#__codelineno-16-25></a>        <span class=n>loss</span> <span class=o>=</span> <span class=n>cross_entropy</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>)</span>
</span><span id=__span-16-26><a id=__codelineno-16-26 name=__codelineno-16-26 href=#__codelineno-16-26></a>
</span><span id=__span-16-27><a id=__codelineno-16-27 name=__codelineno-16-27 href=#__codelineno-16-27></a>        <span class=c1># Weight early supervision less than later supervision</span>
</span><span id=__span-16-28><a id=__codelineno-16-28 name=__codelineno-16-28 href=#__codelineno-16-28></a>        <span class=n>weight</span> <span class=o>=</span> <span class=p>(</span><span class=n>sup_step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_sup</span>  <span class=c1># 0.0625, 0.125, ..., 1.0</span>
</span><span id=__span-16-29><a id=__codelineno-16-29 name=__codelineno-16-29 href=#__codelineno-16-29></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>weight</span> <span class=o>*</span> <span class=n>loss</span>
</span><span id=__span-16-30><a id=__codelineno-16-30 name=__codelineno-16-30 href=#__codelineno-16-30></a>
</span><span id=__span-16-31><a id=__codelineno-16-31 name=__codelineno-16-31 href=#__codelineno-16-31></a>        <span class=c1># Detach for next cycle (prevent backprop through all history)</span>
</span><span id=__span-16-32><a id=__codelineno-16-32 name=__codelineno-16-32 href=#__codelineno-16-32></a>        <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-16-33><a id=__codelineno-16-33 name=__codelineno-16-33 href=#__codelineno-16-33></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-16-34><a id=__codelineno-16-34 name=__codelineno-16-34 href=#__codelineno-16-34></a>
</span><span id=__span-16-35><a id=__codelineno-16-35 name=__codelineno-16-35 href=#__codelineno-16-35></a>    <span class=c1># Backpropagate total weighted loss</span>
</span><span id=__span-16-36><a id=__codelineno-16-36 name=__codelineno-16-36 href=#__codelineno-16-36></a>    <span class=n>total_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-16-37><a id=__codelineno-16-37 name=__codelineno-16-37 href=#__codelineno-16-37></a>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></code></pre></div> <p><strong>Benefits of Deep Supervision:</strong></p> <ol> <li><strong>Better Gradient Flow:</strong> Each supervision cycle provides direct signal, preventing vanishing gradients</li> <li><strong>Curriculum Learning:</strong> Early cycles learn basic patterns, later cycles learn refinement</li> <li><strong>Regularization:</strong> Training on intermediate predictions prevents overfitting to final answers</li> <li><strong>Interpretability:</strong> Can inspect what the model predicts at each stage</li> </ol> <p><strong>Effective Depth:</strong></p> <p>With deep supervision, TRM achieves: - 2 layers per block × 24 recursive applications × 16 supervision cycles = <strong>768 effective layers</strong></p> <p>This is deeper than GPT-4 (estimated ~96-128 layers) while using 0.001% of the parameters!</p> <p><strong>Weighting Strategy:</strong></p> <p>The paper uses increasing weights for later supervision steps:</p> <table> <thead> <tr> <th>Supervision Step</th> <th>Weight</th> <th>Rationale</th> </tr> </thead> <tbody> <tr> <td>1-4</td> <td>0.0625-0.25</td> <td>Still learning basic reasoning</td> </tr> <tr> <td>5-8</td> <td>0.3125-0.5</td> <td>Starting to make good predictions</td> </tr> <tr> <td>9-12</td> <td>0.5625-0.75</td> <td>Refinement phase</td> </tr> <tr> <td>13-16</td> <td>0.8125-1.0</td> <td>Final answer quality</td> </tr> </tbody> </table> <p>This ensures the model focuses most on getting the final answer right, while still learning from intermediate attempts.</p> <details class=note> <summary>Deep Supervision in Practice</summary> <ul> <li>Used in: ResNet, DenseNet, Vision Transformers, many modern architectures</li> <li>Particularly effective for: Very deep networks, small datasets, complex reasoning</li> <li>Can be removed at inference: Only need final prediction, not intermediate ones</li> <li>Alternative names: Intermediate supervision, auxiliary losses, multi-scale training</li> </ul> </details> <hr> <h2 id=10-adaptive-computation-time-act-computing-smarter-not-harder>10. Adaptive Computation Time (ACT): Computing Smarter, Not Harder<a class=headerlink href=#10-adaptive-computation-time-act-computing-smarter-not-harder title="Permanent link">¶</a></h2> <p>Not all problems require the same amount of thinking. TRM uses Adaptive Computation Time to dynamically adjust processing.</p> <p><div class=video-container><iframe src=assets/videos/Scene9_AdaptiveComputation.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_8>What You're Seeing<a class=headerlink href=#what-youre-seeing_8 title="Permanent link">¶</a></h3> <p>The model adapting its computation: - <strong>Easy cells</strong> (only one valid option): Halt after 2-3 supervision cycles - <strong>Medium cells</strong> (simple deduction): Use 8-12 cycles - <strong>Hard cells</strong> (complex constraints): Use all 16 cycles</p> <p>Color intensity shows which cells required more computation.</p> <h3 id=technical-deep-dive_7>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_7 title="Permanent link">¶</a></h3> <p><strong>The Problem:</strong></p> <p>Training with 16 supervision cycles on every example is expensive. Many examples are easy and don't need all 16 cycles. Can we train on easy examples faster without losing quality on hard ones?</p> <p><strong>HRM's Solution (Complex):</strong></p> <p>HRM used Q-learning with two losses: 1. <strong>Halting loss:</strong> Learn when to stop 2. <strong>Continue loss:</strong> Learn benefit of continuing</p> <p>This required <strong>two forward passes</strong> per training step (one for each loss), doubling compute.</p> <p><strong>TRM's Solution (Simpler):</strong></p> <p>Just predict whether the current answer is correct:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=k>class</span><span class=w> </span><span class=nc>TRMWithACT</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>):</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>trm</span> <span class=o>=</span> <span class=n>TinyRecursiveModel</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>        <span class=c1># Single halting predictor</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>        <span class=bp>self</span><span class=o>.</span><span class=n>halt_head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>ground_truth</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>        <span class=c1># Normal TRM forward pass</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>        <span class=n>predictions</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trm</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>        <span class=c1># Predict: "Is this answer correct?"</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>        <span class=c1># Average pool the answer stream</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>        <span class=n>y_pooled</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [batch, d_model]</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>        <span class=n>halt_logit</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>halt_head</span><span class=p>(</span><span class=n>y_pooled</span><span class=p>)</span>  <span class=c1># [batch, 1]</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>        <span class=k>if</span> <span class=n>ground_truth</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>            <span class=c1># Training: learn to predict correctness</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>            <span class=n>is_correct</span> <span class=o>=</span> <span class=p>(</span><span class=n>predictions</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=o>==</span> <span class=n>ground_truth</span><span class=p>)</span><span class=o>.</span><span class=n>float</span><span class=p>()</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a>            <span class=n>halt_loss</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>functional</span><span class=o>.</span><span class=n>binary_cross_entropy_with_logits</span><span class=p>(</span>
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a>                <span class=n>halt_logit</span><span class=p>,</span> <span class=n>is_correct</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-17-22><a id=__codelineno-17-22 name=__codelineno-17-22 href=#__codelineno-17-22></a>            <span class=p>)</span>
</span><span id=__span-17-23><a id=__codelineno-17-23 name=__codelineno-17-23 href=#__codelineno-17-23></a>            <span class=k>return</span> <span class=n>predictions</span><span class=p>,</span> <span class=n>halt_loss</span>
</span><span id=__span-17-24><a id=__codelineno-17-24 name=__codelineno-17-24 href=#__codelineno-17-24></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-17-25><a id=__codelineno-17-25 name=__codelineno-17-25 href=#__codelineno-17-25></a>            <span class=c1># Inference: use prediction to decide whether to halt</span>
</span><span id=__span-17-26><a id=__codelineno-17-26 name=__codelineno-17-26 href=#__codelineno-17-26></a>            <span class=n>should_halt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>halt_logit</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mf>0.5</span>
</span><span id=__span-17-27><a id=__codelineno-17-27 name=__codelineno-17-27 href=#__codelineno-17-27></a>            <span class=k>return</span> <span class=n>predictions</span><span class=p>,</span> <span class=n>should_halt</span>
</span></code></pre></div> <p><strong>Training with ACT:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=k>def</span><span class=w> </span><span class=nf>train_with_act</span><span class=p>(</span><span class=n>question</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>,</span> <span class=n>max_sup</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>    <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>initialize_streams</span><span class=p>(</span><span class=n>question</span><span class=p>)</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a>    <span class=k>for</span> <span class=n>sup_step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_sup</span><span class=p>):</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>        <span class=c1># Do one reasoning + refinement cycle</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>        <span class=n>y</span><span class=p>,</span> <span class=n>z</span> <span class=o>=</span> <span class=n>trm_cycle</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a>
</span><span id=__span-18-9><a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a>        <span class=c1># Compute loss and halting prediction</span>
</span><span id=__span-18-10><a id=__codelineno-18-10 name=__codelineno-18-10 href=#__codelineno-18-10></a>        <span class=n>predictions</span><span class=p>,</span> <span class=n>halt_loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>)</span>
</span><span id=__span-18-11><a id=__codelineno-18-11 name=__codelineno-18-11 href=#__codelineno-18-11></a>        <span class=n>prediction_loss</span> <span class=o>=</span> <span class=n>cross_entropy</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>ground_truth</span><span class=p>)</span>
</span><span id=__span-18-12><a id=__codelineno-18-12 name=__codelineno-18-12 href=#__codelineno-18-12></a>
</span><span id=__span-18-13><a id=__codelineno-18-13 name=__codelineno-18-13 href=#__codelineno-18-13></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>prediction_loss</span> <span class=o>+</span> <span class=n>halt_loss</span>
</span><span id=__span-18-14><a id=__codelineno-18-14 name=__codelineno-18-14 href=#__codelineno-18-14></a>
</span><span id=__span-18-15><a id=__codelineno-18-15 name=__codelineno-18-15 href=#__codelineno-18-15></a>        <span class=c1># Check if we should halt (during training, to compute statistics)</span>
</span><span id=__span-18-16><a id=__codelineno-18-16 name=__codelineno-18-16 href=#__codelineno-18-16></a>        <span class=n>should_halt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>halt_head</span><span class=p>(</span><span class=n>y</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)))</span> <span class=o>&gt;</span> <span class=mf>0.5</span>
</span><span id=__span-18-17><a id=__codelineno-18-17 name=__codelineno-18-17 href=#__codelineno-18-17></a>
</span><span id=__span-18-18><a id=__codelineno-18-18 name=__codelineno-18-18 href=#__codelineno-18-18></a>        <span class=k>if</span> <span class=n>should_halt</span> <span class=ow>and</span> <span class=n>sup_step</span> <span class=o>&gt;=</span> <span class=mi>2</span><span class=p>:</span>  <span class=c1># Minimum 2 cycles</span>
</span><span id=__span-18-19><a id=__codelineno-18-19 name=__codelineno-18-19 href=#__codelineno-18-19></a>            <span class=k>break</span>
</span><span id=__span-18-20><a id=__codelineno-18-20 name=__codelineno-18-20 href=#__codelineno-18-20></a>
</span><span id=__span-18-21><a id=__codelineno-18-21 name=__codelineno-18-21 href=#__codelineno-18-21></a>        <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-18-22><a id=__codelineno-18-22 name=__codelineno-18-22 href=#__codelineno-18-22></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-18-23><a id=__codelineno-18-23 name=__codelineno-18-23 href=#__codelineno-18-23></a>
</span><span id=__span-18-24><a id=__codelineno-18-24 name=__codelineno-18-24 href=#__codelineno-18-24></a>    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=p>(</span><span class=n>sup_step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># Average loss per cycle used</span>
</span></code></pre></div> <p><strong>Benefits:</strong></p> <ol> <li><strong>Single Forward Pass:</strong> Unlike HRM's Q-learning (2 passes), TRM uses 1</li> <li><strong>Simpler:</strong> Just binary classification (correct vs incorrect)</li> <li><strong>Effective:</strong> On average, training uses ~6 supervision cycles instead of 16</li> <li><strong>No Performance Loss:</strong> Test accuracy is the same (we still use all 16 at inference)</li> </ol> <p><strong>Halting Statistics (Sudoku-Extreme):</strong></p> <table> <thead> <tr> <th>Puzzle Difficulty</th> <th>Average Cycles Used</th> <th>Time Saved</th> </tr> </thead> <tbody> <tr> <td>Easy</td> <td>2.3</td> <td>85%</td> </tr> <tr> <td>Medium</td> <td>5.8</td> <td>64%</td> </tr> <tr> <td>Hard</td> <td>11.2</td> <td>30%</td> </tr> <tr> <td>Extreme</td> <td>15.1</td> <td>6%</td> </tr> </tbody> </table> <p><strong>Comparison to HRM:</strong></p> <table> <thead> <tr> <th>Aspect</th> <th>HRM ACT</th> <th>TRM ACT</th> <th>Improvement</th> </tr> </thead> <tbody> <tr> <td>Forward passes</td> <td>2 per step</td> <td>1 per step</td> <td>2x faster</td> </tr> <tr> <td>Loss functions</td> <td>2 (halt + continue)</td> <td>1 (halt only)</td> <td>Simpler</td> </tr> <tr> <td>Training time</td> <td>100%</td> <td>50%</td> <td>2x faster</td> </tr> <tr> <td>Test accuracy</td> <td>55%</td> <td>87.4%</td> <td>59% better</td> </tr> </tbody> </table> <details class=note> <summary>When to Use ACT</summary> <p><strong>Use ACT when:</strong> - Training data has mixed difficulty - Want faster training - Have compute budget constraints</p> <p><strong>Don't use ACT when:</strong> - All examples are similar difficulty - Training time is not a concern - Want simplest possible implementation</p> </details> <hr> <h2 id=11-the-complete-solving-process-end-to-end>11. The Complete Solving Process: End-to-End<a class=headerlink href=#11-the-complete-solving-process-end-to-end title="Permanent link">¶</a></h2> <p>Let's see how all the pieces come together to solve a Sudoku puzzle.</p> <p><div class=video-container><iframe src=assets/videos/Scene10_SolvingProcess.mp4 style=position:relative;width:100%;height:22.172vw frameborder=0 allowfullscreen alt=type:video></iframe></div></p> <h3 id=what-youre-seeing_9>What You're Seeing<a class=headerlink href=#what-youre-seeing_9 title="Permanent link">¶</a></h3> <p>Complete end-to-end visualization: - <strong>Input:</strong> Partial Sudoku grid with clues - <strong>Processing:</strong> 24 recursive passes (8 reasoning + 16 refinement) - <strong>Attention:</strong> Patterns evolving as understanding builds - <strong>Predictions:</strong> Confidence increasing, errors being corrected - <strong>Output:</strong> Complete solved grid</p> <h3 id=technical-deep-dive_8>Technical Deep Dive<a class=headerlink href=#technical-deep-dive_8 title="Permanent link">¶</a></h3> <p><strong>Step-by-Step Execution:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=k>def</span><span class=w> </span><span class=nf>solve_sudoku</span><span class=p>(</span><span class=n>puzzle_grid</span><span class=p>):</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=sd>    Complete inference pipeline for solving a Sudoku puzzle.</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=sd>    Args:</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a><span class=sd>        puzzle_grid: [9, 9] numpy array with 0 for empty cells</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=sd>    Returns:</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a><span class=sd>        solution_grid: [9, 9] numpy array with completed solution</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a><span class=sd>    """</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>    <span class=c1># Step 1: Preprocess</span>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a>    <span class=c1># Flatten to sequence and add special tokens</span>
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a>    <span class=n>puzzle_flat</span> <span class=o>=</span> <span class=n>puzzle_grid</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>  <span class=c1># [81]</span>
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a>    <span class=n>puzzle_tokens</span> <span class=o>=</span> <span class=n>puzzle_flat</span> <span class=o>+</span> <span class=mi>2</span>  <span class=c1># Shift by 2 (0=pad, 1=EOS, 2+=digits)</span>
</span><span id=__span-19-15><a id=__codelineno-19-15 name=__codelineno-19-15 href=#__codelineno-19-15></a>    <span class=n>puzzle_tensor</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>puzzle_tokens</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [1, 81]</span>
</span><span id=__span-19-16><a id=__codelineno-19-16 name=__codelineno-19-16 href=#__codelineno-19-16></a>
</span><span id=__span-19-17><a id=__codelineno-19-17 name=__codelineno-19-17 href=#__codelineno-19-17></a>    <span class=c1># Step 2: Embed</span>
</span><span id=__span-19-18><a id=__codelineno-19-18 name=__codelineno-19-18 href=#__codelineno-19-18></a>    <span class=n>x</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>puzzle_tensor</span><span class=p>)</span>  <span class=c1># [1, 81, 256]</span>
</span><span id=__span-19-19><a id=__codelineno-19-19 name=__codelineno-19-19 href=#__codelineno-19-19></a>    <span class=n>y</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>puzzle_tensor</span><span class=p>)</span>  <span class=c1># Start with input as guess</span>
</span><span id=__span-19-20><a id=__codelineno-19-20 name=__codelineno-19-20 href=#__codelineno-19-20></a>    <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>  <span class=c1># Random reasoning state</span>
</span><span id=__span-19-21><a id=__codelineno-19-21 name=__codelineno-19-21 href=#__codelineno-19-21></a>
</span><span id=__span-19-22><a id=__codelineno-19-22 name=__codelineno-19-22 href=#__codelineno-19-22></a>    <span class=c1># Step 3: Reasoning Phase (8 passes)</span>
</span><span id=__span-19-23><a id=__codelineno-19-23 name=__codelineno-19-23 href=#__codelineno-19-23></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>8</span><span class=p>):</span>
</span><span id=__span-19-24><a id=__codelineno-19-24 name=__codelineno-19-24 href=#__codelineno-19-24></a>        <span class=c1># Concatenate three streams</span>
</span><span id=__span-19-25><a id=__codelineno-19-25 name=__codelineno-19-25 href=#__codelineno-19-25></a>        <span class=n>combined</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [1, 194, 256]</span>
</span><span id=__span-19-26><a id=__codelineno-19-26 name=__codelineno-19-26 href=#__codelineno-19-26></a>
</span><span id=__span-19-27><a id=__codelineno-19-27 name=__codelineno-19-27 href=#__codelineno-19-27></a>        <span class=c1># Pass through 2-layer transformer</span>
</span><span id=__span-19-28><a id=__codelineno-19-28 name=__codelineno-19-28 href=#__codelineno-19-28></a>        <span class=k>for</span> <span class=n>transformer_block</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>transformer_blocks</span><span class=p>:</span>
</span><span id=__span-19-29><a id=__codelineno-19-29 name=__codelineno-19-29 href=#__codelineno-19-29></a>            <span class=n>combined</span> <span class=o>=</span> <span class=n>transformer_block</span><span class=p>(</span><span class=n>combined</span><span class=p>)</span>
</span><span id=__span-19-30><a id=__codelineno-19-30 name=__codelineno-19-30 href=#__codelineno-19-30></a>
</span><span id=__span-19-31><a id=__codelineno-19-31 name=__codelineno-19-31 href=#__codelineno-19-31></a>        <span class=c1># Split and update only z</span>
</span><span id=__span-19-32><a id=__codelineno-19-32 name=__codelineno-19-32 href=#__codelineno-19-32></a>        <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>combined</span><span class=p>,</span> <span class=p>[</span><span class=mi>81</span><span class=p>,</span> <span class=mi>81</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-19-33><a id=__codelineno-19-33 name=__codelineno-19-33 href=#__codelineno-19-33></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>
</span><span id=__span-19-34><a id=__codelineno-19-34 name=__codelineno-19-34 href=#__codelineno-19-34></a>
</span><span id=__span-19-35><a id=__codelineno-19-35 name=__codelineno-19-35 href=#__codelineno-19-35></a>    <span class=c1># Step 4: Refinement Phase (16 passes)</span>
</span><span id=__span-19-36><a id=__codelineno-19-36 name=__codelineno-19-36 href=#__codelineno-19-36></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>16</span><span class=p>):</span>
</span><span id=__span-19-37><a id=__codelineno-19-37 name=__codelineno-19-37 href=#__codelineno-19-37></a>        <span class=n>combined</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-19-38><a id=__codelineno-19-38 name=__codelineno-19-38 href=#__codelineno-19-38></a>
</span><span id=__span-19-39><a id=__codelineno-19-39 name=__codelineno-19-39 href=#__codelineno-19-39></a>        <span class=k>for</span> <span class=n>transformer_block</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>transformer_blocks</span><span class=p>:</span>
</span><span id=__span-19-40><a id=__codelineno-19-40 name=__codelineno-19-40 href=#__codelineno-19-40></a>            <span class=n>combined</span> <span class=o>=</span> <span class=n>transformer_block</span><span class=p>(</span><span class=n>combined</span><span class=p>)</span>
</span><span id=__span-19-41><a id=__codelineno-19-41 name=__codelineno-19-41 href=#__codelineno-19-41></a>
</span><span id=__span-19-42><a id=__codelineno-19-42 name=__codelineno-19-42 href=#__codelineno-19-42></a>        <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>combined</span><span class=p>,</span> <span class=p>[</span><span class=mi>81</span><span class=p>,</span> <span class=mi>81</span><span class=p>,</span> <span class=mi>32</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-19-43><a id=__codelineno-19-43 name=__codelineno-19-43 href=#__codelineno-19-43></a>        <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>
</span><span id=__span-19-44><a id=__codelineno-19-44 name=__codelineno-19-44 href=#__codelineno-19-44></a>
</span><span id=__span-19-45><a id=__codelineno-19-45 name=__codelineno-19-45 href=#__codelineno-19-45></a>    <span class=c1># Step 5: Decode to predictions</span>
</span><span id=__span-19-46><a id=__codelineno-19-46 name=__codelineno-19-46 href=#__codelineno-19-46></a>    <span class=n>logits</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>reverse_embedding</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>  <span class=c1># [1, 81, 12]</span>
</span><span id=__span-19-47><a id=__codelineno-19-47 name=__codelineno-19-47 href=#__codelineno-19-47></a>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [1, 81]</span>
</span><span id=__span-19-48><a id=__codelineno-19-48 name=__codelineno-19-48 href=#__codelineno-19-48></a>
</span><span id=__span-19-49><a id=__codelineno-19-49 name=__codelineno-19-49 href=#__codelineno-19-49></a>    <span class=c1># Step 6: Post-process</span>
</span><span id=__span-19-50><a id=__codelineno-19-50 name=__codelineno-19-50 href=#__codelineno-19-50></a>    <span class=n>solution_tokens</span> <span class=o>=</span> <span class=n>predictions</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span> <span class=o>-</span> <span class=mi>2</span>  <span class=c1># Shift back</span>
</span><span id=__span-19-51><a id=__codelineno-19-51 name=__codelineno-19-51 href=#__codelineno-19-51></a>    <span class=n>solution_grid</span> <span class=o>=</span> <span class=n>solution_tokens</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>9</span><span class=p>,</span> <span class=mi>9</span><span class=p>)</span>
</span><span id=__span-19-52><a id=__codelineno-19-52 name=__codelineno-19-52 href=#__codelineno-19-52></a>
</span><span id=__span-19-53><a id=__codelineno-19-53 name=__codelineno-19-53 href=#__codelineno-19-53></a>    <span class=k>return</span> <span class=n>solution_grid</span>
</span><span id=__span-19-54><a id=__codelineno-19-54 name=__codelineno-19-54 href=#__codelineno-19-54></a>
</span><span id=__span-19-55><a id=__codelineno-19-55 name=__codelineno-19-55 href=#__codelineno-19-55></a><span class=c1># Example usage</span>
</span><span id=__span-19-56><a id=__codelineno-19-56 name=__codelineno-19-56 href=#__codelineno-19-56></a><span class=n>puzzle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span><span id=__span-19-57><a id=__codelineno-19-57 name=__codelineno-19-57 href=#__codelineno-19-57></a>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-19-58><a id=__codelineno-19-58 name=__codelineno-19-58 href=#__codelineno-19-58></a>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-19-59><a id=__codelineno-19-59 name=__codelineno-19-59 href=#__codelineno-19-59></a>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-19-60><a id=__codelineno-19-60 name=__codelineno-19-60 href=#__codelineno-19-60></a>    <span class=c1># ... rest of puzzle</span>
</span><span id=__span-19-61><a id=__codelineno-19-61 name=__codelineno-19-61 href=#__codelineno-19-61></a><span class=p>])</span>
</span><span id=__span-19-62><a id=__codelineno-19-62 name=__codelineno-19-62 href=#__codelineno-19-62></a>
</span><span id=__span-19-63><a id=__codelineno-19-63 name=__codelineno-19-63 href=#__codelineno-19-63></a><span class=n>solution</span> <span class=o>=</span> <span class=n>solve_sudoku</span><span class=p>(</span><span class=n>puzzle</span><span class=p>)</span>
</span><span id=__span-19-64><a id=__codelineno-19-64 name=__codelineno-19-64 href=#__codelineno-19-64></a><span class=nb>print</span><span class=p>(</span><span class=n>solution</span><span class=p>)</span>
</span></code></pre></div> <p><strong>What Happens Inside:</strong></p> <p><strong>Passes 1-8 (Reasoning):</strong> - z learns constraint relationships - Identifies which cells constrain which - Builds logical deduction chains - Prepares information for filling cells</p> <p><strong>Passes 9-24 (Refinement):</strong> - y gets updated with actual cell values - Early passes fill obvious cells - Middle passes apply logical deduction - Late passes correct errors and verify</p> <p><strong>Success Metrics:</strong></p> <p>On Sudoku-Extreme test set (423K puzzles): - <strong>Accuracy:</strong> 87.4% (TRM-MLP) or 74.7% (TRM-Att) - <strong>Inference time:</strong> ~15ms per puzzle on GPU - <strong>Invalid solutions:</strong> &lt;0.5% (most errors are unsolved, not rule-breaking)</p> <p><strong>Why It Works:</strong></p> <ol> <li><strong>Iterative Refinement:</strong> Can fix errors from earlier passes</li> <li><strong>Global Context:</strong> Attention allows every cell to influence every other</li> <li><strong>Learned Strategies:</strong> Discovers Sudoku solving techniques from data</li> <li><strong>Deep Supervision:</strong> Trained to improve answers progressively</li> </ol> <details class=example> <summary>Extending to ARC-AGI</summary> <p>The same architecture works on ARC-AGI with minimal changes:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=c1># Changes for ARC-AGI:</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=c1># 1. Larger grids (up to 30x30 instead of 9x9)</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=c1># 2. Multi-example tasks (2-3 examples shown before test)</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a><span class=c1># 3. Task ID embedding (link examples from same task)</span>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a><span class=c1># 4. More colors (10 instead of 9)</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=c1># Everything else stays the same:</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a><span class=c1># - Three streams (question, answer, reasoning)</span>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a><span class=c1># - Recursive processing (8 + 16 passes)</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a><span class=c1># - Deep supervision (16 cycles)</span>
</span><span id=__span-20-11><a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a><span class=c1># - Same 2-layer transformer</span>
</span></code></pre></div> <p>Results on ARC-AGI-1: 44.6% (vs 40.3% for HRM, 21% for direct prediction)</p> </details> <hr> <h2 id=12-hrm-vs-trm-a-comprehensive-comparison>12. HRM vs TRM: A Comprehensive Comparison<a class=headerlink href=#12-hrm-vs-trm-a-comprehensive-comparison title="Permanent link">¶</a></h2> <p>Let's directly compare TRM to its predecessor HRM across all dimensions.</p> <h3 id=architecture-comparison>Architecture Comparison<a class=headerlink href=#architecture-comparison title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>Aspect</th> <th>HRM</th> <th>TRM</th> <th>Impact</th> </tr> </thead> <tbody> <tr> <td><strong>Networks</strong></td> <td>2 separate (f_L, f_H)</td> <td>1 unified</td> <td>50% fewer weights</td> </tr> <tr> <td><strong>Layers</strong></td> <td>4 per network</td> <td>2 total</td> <td>75% fewer layers</td> </tr> <tr> <td><strong>Parameters</strong></td> <td>27M</td> <td>5-7M</td> <td>74-81% reduction</td> </tr> <tr> <td><strong>Latent States</strong></td> <td>z_L and z_H (hierarchical)</td> <td>y and z (answer + reasoning)</td> <td>Simpler interpretation</td> </tr> <tr> <td><strong>Biological Justification</strong></td> <td>Complex (brain oscillations)</td> <td>None needed</td> <td>Easier to understand</td> </tr> <tr> <td><strong>Fixed-Point Theory</strong></td> <td>Required (IFT)</td> <td>Not required</td> <td>Simpler training</td> </tr> <tr> <td><strong>Gradient Computation</strong></td> <td>1-step approximation</td> <td>Full backprop</td> <td>More accurate</td> </tr> <tr> <td><strong>ACT Mechanism</strong></td> <td>Q-learning (2 passes)</td> <td>Binary BCE (1 pass)</td> <td>2x faster</td> </tr> </tbody> </table> <h3 id=performance-comparison>Performance Comparison<a class=headerlink href=#performance-comparison title="Permanent link">¶</a></h3> <p><strong>Sudoku-Extreme:</strong></p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>0.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>55.0%</td> </tr> <tr> <td>TRM (n=2, T=2)</td> <td>5M</td> <td>73.7%</td> </tr> <tr> <td><strong>TRM (n=3, T=3)</strong></td> <td><strong>5M</strong></td> <td><strong>87.4%</strong></td> </tr> </tbody> </table> <p><strong>Maze-Hard:</strong></p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>0.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>74.5%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>85.3%</strong></td> </tr> </tbody> </table> <p><strong>ARC-AGI-1:</strong></p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>21.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>40.3%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>44.6%</strong></td> </tr> </tbody> </table> <p><strong>ARC-AGI-2:</strong></p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Gemini 2.5 Pro</td> <td>Unknown</td> <td>4.9%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>5.0%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>7.8%</strong></td> </tr> </tbody> </table> <h3 id=key-innovations-in-trm>Key Innovations in TRM<a class=headerlink href=#key-innovations-in-trm title="Permanent link">¶</a></h3> <p><strong>1. No Fixed-Point Theorem Required</strong></p> <p>HRM relied on the Implicit Function Theorem (IFT), assuming recursions converge to a fixed point z* where:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>z_L* ≈ f_L(z_L* + z_H + x)
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>z_H* ≈ f_H(z_L + z_H*)
</span></code></pre></div> <p>TRM eliminates this by: - Defining a "full recursion cycle" (n steps of reasoning, then refinement) - Back-propagating through the complete cycle - No assumptions about convergence needed</p> <p><strong>2. Simpler Latent State Interpretation</strong></p> <p>HRM: "z_L is low-level hierarchical reasoning, z_H is high-level hierarchical reasoning based on brain oscillations"</p> <p>TRM: "y is your current answer, z is your scratch work to improve it"</p> <p>The TRM interpretation is: - Easier to understand - Doesn't require neuroscience background - Actually explains why 2 streams is optimal (not 1, not 3+)</p> <p><strong>3. Single Network with Weight Sharing</strong></p> <p>HRM used f_L and f_H with different weights. TRM showed you can use the same weights for both, determined by what inputs you provide:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># HRM: Two networks</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a><span class=n>z_L</span> <span class=o>=</span> <span class=n>f_L</span><span class=p>(</span><span class=n>z_L</span> <span class=o>+</span> <span class=n>z_H</span> <span class=o>+</span> <span class=n>x</span><span class=p>)</span>  <span class=c1># Has x</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a><span class=n>z_H</span> <span class=o>=</span> <span class=n>f_H</span><span class=p>(</span><span class=n>z_L</span> <span class=o>+</span> <span class=n>z_H</span><span class=p>)</span>      <span class=c1># No x</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a><span class=c1># TRM: One network, different inputs</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a><span class=n>z</span> <span class=o>=</span> <span class=n>net</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>  <span class=c1># Has x → updates reasoning</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=n>y</span> <span class=o>=</span> <span class=n>net</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>     <span class=c1># No x → updates answer</span>
</span></code></pre></div> <p>The network learns to behave differently based on input composition.</p> <p><strong>4. Two Layers Beat Four Layers</strong></p> <p>Surprisingly, TRM found that <strong>smaller networks generalize better</strong> on limited data:</p> <table> <thead> <tr> <th>Layers</th> <th>Parameters</th> <th>Sudoku Accuracy</th> </tr> </thead> <tbody> <tr> <td>4</td> <td>10M</td> <td>79.5%</td> </tr> <tr> <td>3</td> <td>7.5M</td> <td>83.2%</td> </tr> <tr> <td><strong>2</strong></td> <td><strong>5M</strong></td> <td><strong>87.4%</strong></td> </tr> <tr> <td>1</td> <td>2.5M</td> <td>68.3%</td> </tr> </tbody> </table> <p>Hypothesis: With small datasets, overfitting is the main enemy. Smaller networks with more recursions provide better regularization than large networks with fewer recursions.</p> <h3 id=training-time-comparison>Training Time Comparison<a class=headerlink href=#training-time-comparison title="Permanent link">¶</a></h3> <p><strong>TRM Training:</strong> - <strong>Time:</strong> 48 hours on 4× H100 GPUs - <strong>Dataset:</strong> ~100K examples (with augmentation) - <strong>Iterations:</strong> ~1M optimization steps - <strong>Cost:</strong> ~$500-1000 in compute</p> <p><strong>HRM Training:</strong> - <strong>Time:</strong> ~36 hours on 4× H100 GPUs - <strong>Dataset:</strong> Same - <strong>Iterations:</strong> ~750K optimization steps - <strong>Cost:</strong> ~$400-800 in compute</p> <p>TRM trains slightly longer but achieves much better results. The parameter efficiency means inference is much cheaper.</p> <details class=note> <summary>Why Not Use HRM Anymore?</summary> <p>TRM is strictly better: - <strong>Simpler:</strong> Easier to understand and implement - <strong>Better:</strong> Higher accuracy across all benchmarks - <strong>Smaller:</strong> Fewer parameters means faster inference - <strong>Cleaner:</strong> No complex mathematical requirements - <strong>Same cost:</strong> Training time is similar</p> <p>Unless you specifically need the hierarchical interpretation for some reason, use TRM.</p> </details> <hr> <h2 id=13-complete-pytorch-implementation>13. Complete PyTorch Implementation<a class=headerlink href=#13-complete-pytorch-implementation title="Permanent link">¶</a></h2> <p>Now let's build TRM from scratch with complete, runnable PyTorch code.</p> <h3 id=multi-head-attention>Multi-Head Attention<a class=headerlink href=#multi-head-attention title="Permanent link">¶</a></h3> <p>We already saw this earlier, but here's the complete implementation:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>nn</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=kn>import</span><span class=w> </span><span class=nn>torch.nn.functional</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>F</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a><span class=kn>import</span><span class=w> </span><span class=nn>math</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a><span class=k>class</span><span class=w> </span><span class=nc>MultiHeadAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a><span class=sd>    Multi-head attention mechanism.</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a><span class=sd>    Key insight: Different heads learn different relationships.</span>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a><span class=sd>    For Sudoku: row constraints, column constraints, box constraints, etc.</span>
</span><span id=__span-23-12><a id=__codelineno-23-12 name=__codelineno-23-12 href=#__codelineno-23-12></a><span class=sd>    """</span>
</span><span id=__span-23-13><a id=__codelineno-23-13 name=__codelineno-23-13 href=#__codelineno-23-13></a>
</span><span id=__span-23-14><a id=__codelineno-23-14 name=__codelineno-23-14 href=#__codelineno-23-14></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>):</span>
</span><span id=__span-23-15><a id=__codelineno-23-15 name=__codelineno-23-15 href=#__codelineno-23-15></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-23-16><a id=__codelineno-23-16 name=__codelineno-23-16 href=#__codelineno-23-16></a>        <span class=k>assert</span> <span class=n>d_model</span> <span class=o>%</span> <span class=n>n_heads</span> <span class=o>==</span> <span class=mi>0</span>
</span><span id=__span-23-17><a id=__codelineno-23-17 name=__codelineno-23-17 href=#__codelineno-23-17></a>
</span><span id=__span-23-18><a id=__codelineno-23-18 name=__codelineno-23-18 href=#__codelineno-23-18></a>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span><span id=__span-23-19><a id=__codelineno-23-19 name=__codelineno-23-19 href=#__codelineno-23-19></a>        <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>=</span> <span class=n>n_heads</span>
</span><span id=__span-23-20><a id=__codelineno-23-20 name=__codelineno-23-20 href=#__codelineno-23-20></a>        <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span> <span class=o>=</span> <span class=n>d_model</span> <span class=o>//</span> <span class=n>n_heads</span>
</span><span id=__span-23-21><a id=__codelineno-23-21 name=__codelineno-23-21 href=#__codelineno-23-21></a>
</span><span id=__span-23-22><a id=__codelineno-23-22 name=__codelineno-23-22 href=#__codelineno-23-22></a>        <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-23-23><a id=__codelineno-23-23 name=__codelineno-23-23 href=#__codelineno-23-23></a>        <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-23-24><a id=__codelineno-23-24 name=__codelineno-23-24 href=#__codelineno-23-24></a>        <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-23-25><a id=__codelineno-23-25 name=__codelineno-23-25 href=#__codelineno-23-25></a>        <span class=bp>self</span><span class=o>.</span><span class=n>out_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-23-26><a id=__codelineno-23-26 name=__codelineno-23-26 href=#__codelineno-23-26></a>
</span><span id=__span-23-27><a id=__codelineno-23-27 name=__codelineno-23-27 href=#__codelineno-23-27></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-23-28><a id=__codelineno-23-28 name=__codelineno-23-28 href=#__codelineno-23-28></a>
</span><span id=__span-23-29><a id=__codelineno-23-29 name=__codelineno-23-29 href=#__codelineno-23-29></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-23-30><a id=__codelineno-23-30 name=__codelineno-23-30 href=#__codelineno-23-30></a>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>d_model</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-23-31><a id=__codelineno-23-31 name=__codelineno-23-31 href=#__codelineno-23-31></a>
</span><span id=__span-23-32><a id=__codelineno-23-32 name=__codelineno-23-32 href=#__codelineno-23-32></a>        <span class=c1># Project and split into heads</span>
</span><span id=__span-23-33><a id=__codelineno-23-33 name=__codelineno-23-33 href=#__codelineno-23-33></a>        <span class=n>q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-23-34><a id=__codelineno-23-34 name=__codelineno-23-34 href=#__codelineno-23-34></a>        <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-23-35><a id=__codelineno-23-35 name=__codelineno-23-35 href=#__codelineno-23-35></a>        <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span><span id=__span-23-36><a id=__codelineno-23-36 name=__codelineno-23-36 href=#__codelineno-23-36></a>
</span><span id=__span-23-37><a id=__codelineno-23-37 name=__codelineno-23-37 href=#__codelineno-23-37></a>        <span class=c1># Attention scores</span>
</span><span id=__span-23-38><a id=__codelineno-23-38 name=__codelineno-23-38 href=#__codelineno-23-38></a>        <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>d_k</span><span class=p>)</span>
</span><span id=__span-23-39><a id=__codelineno-23-39 name=__codelineno-23-39 href=#__codelineno-23-39></a>        <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-23-40><a id=__codelineno-23-40 name=__codelineno-23-40 href=#__codelineno-23-40></a>            <span class=n>scores</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>mask</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=mf>1e9</span><span class=p>)</span>
</span><span id=__span-23-41><a id=__codelineno-23-41 name=__codelineno-23-41 href=#__codelineno-23-41></a>
</span><span id=__span-23-42><a id=__codelineno-23-42 name=__codelineno-23-42 href=#__codelineno-23-42></a>        <span class=n>attn_weights</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-23-43><a id=__codelineno-23-43 name=__codelineno-23-43 href=#__codelineno-23-43></a>        <span class=n>attn_weights</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>attn_weights</span><span class=p>)</span>
</span><span id=__span-23-44><a id=__codelineno-23-44 name=__codelineno-23-44 href=#__codelineno-23-44></a>
</span><span id=__span-23-45><a id=__codelineno-23-45 name=__codelineno-23-45 href=#__codelineno-23-45></a>        <span class=c1># Apply attention</span>
</span><span id=__span-23-46><a id=__codelineno-23-46 name=__codelineno-23-46 href=#__codelineno-23-46></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>attn_weights</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span><span id=__span-23-47><a id=__codelineno-23-47 name=__codelineno-23-47 href=#__codelineno-23-47></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span><span id=__span-23-48><a id=__codelineno-23-48 name=__codelineno-23-48 href=#__codelineno-23-48></a>        <span class=n>attn_output</span> <span class=o>=</span> <span class=n>attn_output</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-23-49><a id=__codelineno-23-49 name=__codelineno-23-49 href=#__codelineno-23-49></a>
</span><span id=__span-23-50><a id=__codelineno-23-50 name=__codelineno-23-50 href=#__codelineno-23-50></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>out_proj</span><span class=p>(</span><span class=n>attn_output</span><span class=p>)</span>
</span></code></pre></div> <h3 id=feed-forward-network>Feed-Forward Network<a class=headerlink href=#feed-forward-network title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=k>class</span><span class=w> </span><span class=nc>FeedForward</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a><span class=sd>    Position-wise feed-forward network.</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a><span class=sd>    Applies the same transformation to each position independently.</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a><span class=sd>    """</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>):</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>linear1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ff</span><span class=p>)</span>
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10 href=#__codelineno-24-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_ff</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-24-11><a id=__codelineno-24-11 name=__codelineno-24-11 href=#__codelineno-24-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-24-12><a id=__codelineno-24-12 name=__codelineno-24-12 href=#__codelineno-24-12></a>
</span><span id=__span-24-13><a id=__codelineno-24-13 name=__codelineno-24-13 href=#__codelineno-24-13></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span><span id=__span-24-14><a id=__codelineno-24-14 name=__codelineno-24-14 href=#__codelineno-24-14></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>F</span><span class=o>.</span><span class=n>gelu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear1</span><span class=p>(</span><span class=n>x</span><span class=p>))))</span>
</span></code></pre></div> <h3 id=transformer-block>Transformer Block<a class=headerlink href=#transformer-block title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=k>class</span><span class=w> </span><span class=nc>TransformerBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a><span class=sd>    Complete transformer block with attention and feed-forward.</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a><span class=sd>    Includes residual connections and layer normalization.</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a><span class=sd>    """</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>use_attention</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a>        <span class=bp>self</span><span class=o>.</span><span class=n>use_attention</span> <span class=o>=</span> <span class=n>use_attention</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a>        <span class=k>if</span> <span class=n>use_attention</span><span class=p>:</span>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12 href=#__codelineno-25-12></a>            <span class=bp>self</span><span class=o>.</span><span class=n>attention</span> <span class=o>=</span> <span class=n>MultiHeadAttention</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13 href=#__codelineno-25-13></a>            <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-25-14><a id=__codelineno-25-14 name=__codelineno-25-14 href=#__codelineno-25-14></a>
</span><span id=__span-25-15><a id=__codelineno-25-15 name=__codelineno-25-15 href=#__codelineno-25-15></a>        <span class=bp>self</span><span class=o>.</span><span class=n>ffn</span> <span class=o>=</span> <span class=n>FeedForward</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ff</span><span class=p>,</span> <span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-25-16><a id=__codelineno-25-16 name=__codelineno-25-16 href=#__codelineno-25-16></a>        <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-25-17><a id=__codelineno-25-17 name=__codelineno-25-17 href=#__codelineno-25-17></a>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-25-18><a id=__codelineno-25-18 name=__codelineno-25-18 href=#__codelineno-25-18></a>
</span><span id=__span-25-19><a id=__codelineno-25-19 name=__codelineno-25-19 href=#__codelineno-25-19></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-25-20><a id=__codelineno-25-20 name=__codelineno-25-20 href=#__codelineno-25-20></a>        <span class=c1># Self-attention block</span>
</span><span id=__span-25-21><a id=__codelineno-25-21 name=__codelineno-25-21 href=#__codelineno-25-21></a>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>use_attention</span><span class=p>:</span>
</span><span id=__span-25-22><a id=__codelineno-25-22 name=__codelineno-25-22 href=#__codelineno-25-22></a>            <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span><span id=__span-25-23><a id=__codelineno-25-23 name=__codelineno-25-23 href=#__codelineno-25-23></a>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-25-24><a id=__codelineno-25-24 name=__codelineno-25-24 href=#__codelineno-25-24></a>            <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>residual</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-25-25><a id=__codelineno-25-25 name=__codelineno-25-25 href=#__codelineno-25-25></a>
</span><span id=__span-25-26><a id=__codelineno-25-26 name=__codelineno-25-26 href=#__codelineno-25-26></a>        <span class=c1># Feed-forward block</span>
</span><span id=__span-25-27><a id=__codelineno-25-27 name=__codelineno-25-27 href=#__codelineno-25-27></a>        <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span><span id=__span-25-28><a id=__codelineno-25-28 name=__codelineno-25-28 href=#__codelineno-25-28></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ffn</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span><span id=__span-25-29><a id=__codelineno-25-29 name=__codelineno-25-29 href=#__codelineno-25-29></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>residual</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span><span id=__span-25-30><a id=__codelineno-25-30 name=__codelineno-25-30 href=#__codelineno-25-30></a>
</span><span id=__span-25-31><a id=__codelineno-25-31 name=__codelineno-25-31 href=#__codelineno-25-31></a>        <span class=k>return</span> <span class=n>x</span>
</span></code></pre></div> <h3 id=complete-trm-model>Complete TRM Model<a class=headerlink href=#complete-trm-model title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=k>class</span><span class=w> </span><span class=nc>TRM</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a><span class=sd>    Tiny Recursive Model - Complete Implementation</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a><span class=sd>    Key components:</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a><span class=sd>    - Three streams: question (x), answer (y), reasoning (z)</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=sd>    - Recursive processing: same weights applied multiple times</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a><span class=sd>    - Two-phase updates: reasoning then refinement</span>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a><span class=sd>    """</span>
</span><span id=__span-26-10><a id=__codelineno-26-10 name=__codelineno-26-10 href=#__codelineno-26-10></a>
</span><span id=__span-26-11><a id=__codelineno-26-11 name=__codelineno-26-11 href=#__codelineno-26-11></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span>
</span><span id=__span-26-12><a id=__codelineno-26-12 name=__codelineno-26-12 href=#__codelineno-26-12></a>        <span class=bp>self</span><span class=p>,</span>
</span><span id=__span-26-13><a id=__codelineno-26-13 name=__codelineno-26-13 href=#__codelineno-26-13></a>        <span class=n>vocab_size</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span>           <span class=c1># 0=pad, 1=EOS, 2-11=digits 0-9</span>
</span><span id=__span-26-14><a id=__codelineno-26-14 name=__codelineno-26-14 href=#__codelineno-26-14></a>        <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>             <span class=c1># Embedding dimension</span>
</span><span id=__span-26-15><a id=__codelineno-26-15 name=__codelineno-26-15 href=#__codelineno-26-15></a>        <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>               <span class=c1># Attention heads</span>
</span><span id=__span-26-16><a id=__codelineno-26-16 name=__codelineno-26-16 href=#__codelineno-26-16></a>        <span class=n>d_ff</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>               <span class=c1># Feed-forward dimension</span>
</span><span id=__span-26-17><a id=__codelineno-26-17 name=__codelineno-26-17 href=#__codelineno-26-17></a>        <span class=n>n_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>              <span class=c1># Transformer layers (2 is optimal!)</span>
</span><span id=__span-26-18><a id=__codelineno-26-18 name=__codelineno-26-18 href=#__codelineno-26-18></a>        <span class=n>max_seq_len</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>         <span class=c1># Maximum sequence length</span>
</span><span id=__span-26-19><a id=__codelineno-26-19 name=__codelineno-26-19 href=#__codelineno-26-19></a>        <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span><span id=__span-26-20><a id=__codelineno-26-20 name=__codelineno-26-20 href=#__codelineno-26-20></a>        <span class=n>n_reasoning_steps</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>     <span class=c1># Phase 1: update z</span>
</span><span id=__span-26-21><a id=__codelineno-26-21 name=__codelineno-26-21 href=#__codelineno-26-21></a>        <span class=n>n_refinement_steps</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>   <span class=c1># Phase 2: update y</span>
</span><span id=__span-26-22><a id=__codelineno-26-22 name=__codelineno-26-22 href=#__codelineno-26-22></a>        <span class=n>use_attention</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>      <span class=c1># False for MLP-only variant</span>
</span><span id=__span-26-23><a id=__codelineno-26-23 name=__codelineno-26-23 href=#__codelineno-26-23></a>        <span class=n>tie_embeddings</span><span class=o>=</span><span class=kc>True</span>      <span class=c1># Share input/output embeddings</span>
</span><span id=__span-26-24><a id=__codelineno-26-24 name=__codelineno-26-24 href=#__codelineno-26-24></a>    <span class=p>):</span>
</span><span id=__span-26-25><a id=__codelineno-26-25 name=__codelineno-26-25 href=#__codelineno-26-25></a>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span><span id=__span-26-26><a id=__codelineno-26-26 name=__codelineno-26-26 href=#__codelineno-26-26></a>
</span><span id=__span-26-27><a id=__codelineno-26-27 name=__codelineno-26-27 href=#__codelineno-26-27></a>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span><span id=__span-26-28><a id=__codelineno-26-28 name=__codelineno-26-28 href=#__codelineno-26-28></a>        <span class=bp>self</span><span class=o>.</span><span class=n>n_reasoning_steps</span> <span class=o>=</span> <span class=n>n_reasoning_steps</span>
</span><span id=__span-26-29><a id=__codelineno-26-29 name=__codelineno-26-29 href=#__codelineno-26-29></a>        <span class=bp>self</span><span class=o>.</span><span class=n>n_refinement_steps</span> <span class=o>=</span> <span class=n>n_refinement_steps</span>
</span><span id=__span-26-30><a id=__codelineno-26-30 name=__codelineno-26-30 href=#__codelineno-26-30></a>        <span class=bp>self</span><span class=o>.</span><span class=n>use_attention</span> <span class=o>=</span> <span class=n>use_attention</span>
</span><span id=__span-26-31><a id=__codelineno-26-31 name=__codelineno-26-31 href=#__codelineno-26-31></a>
</span><span id=__span-26-32><a id=__codelineno-26-32 name=__codelineno-26-32 href=#__codelineno-26-32></a>        <span class=c1># Embeddings</span>
</span><span id=__span-26-33><a id=__codelineno-26-33 name=__codelineno-26-33 href=#__codelineno-26-33></a>        <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-26-34><a id=__codelineno-26-34 name=__codelineno-26-34 href=#__codelineno-26-34></a>        <span class=bp>self</span><span class=o>.</span><span class=n>position_embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>max_seq_len</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span><span id=__span-26-35><a id=__codelineno-26-35 name=__codelineno-26-35 href=#__codelineno-26-35></a>        <span class=bp>self</span><span class=o>.</span><span class=n>embedding_dropout</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span><span id=__span-26-36><a id=__codelineno-26-36 name=__codelineno-26-36 href=#__codelineno-26-36></a>
</span><span id=__span-26-37><a id=__codelineno-26-37 name=__codelineno-26-37 href=#__codelineno-26-37></a>        <span class=c1># Transformer blocks (reused recursively)</span>
</span><span id=__span-26-38><a id=__codelineno-26-38 name=__codelineno-26-38 href=#__codelineno-26-38></a>        <span class=bp>self</span><span class=o>.</span><span class=n>transformer_blocks</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span>
</span><span id=__span-26-39><a id=__codelineno-26-39 name=__codelineno-26-39 href=#__codelineno-26-39></a>            <span class=n>TransformerBlock</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>d_ff</span><span class=p>,</span> <span class=n>dropout</span><span class=p>,</span> <span class=n>use_attention</span><span class=p>)</span>
</span><span id=__span-26-40><a id=__codelineno-26-40 name=__codelineno-26-40 href=#__codelineno-26-40></a>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_layers</span><span class=p>)</span>
</span><span id=__span-26-41><a id=__codelineno-26-41 name=__codelineno-26-41 href=#__codelineno-26-41></a>        <span class=p>])</span>
</span><span id=__span-26-42><a id=__codelineno-26-42 name=__codelineno-26-42 href=#__codelineno-26-42></a>
</span><span id=__span-26-43><a id=__codelineno-26-43 name=__codelineno-26-43 href=#__codelineno-26-43></a>        <span class=c1># Output projection</span>
</span><span id=__span-26-44><a id=__codelineno-26-44 name=__codelineno-26-44 href=#__codelineno-26-44></a>        <span class=bp>self</span><span class=o>.</span><span class=n>reverse_embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span><span id=__span-26-45><a id=__codelineno-26-45 name=__codelineno-26-45 href=#__codelineno-26-45></a>
</span><span id=__span-26-46><a id=__codelineno-26-46 name=__codelineno-26-46 href=#__codelineno-26-46></a>        <span class=c1># Weight tying: use same weights for input and output embeddings</span>
</span><span id=__span-26-47><a id=__codelineno-26-47 name=__codelineno-26-47 href=#__codelineno-26-47></a>        <span class=k>if</span> <span class=n>tie_embeddings</span><span class=p>:</span>
</span><span id=__span-26-48><a id=__codelineno-26-48 name=__codelineno-26-48 href=#__codelineno-26-48></a>            <span class=bp>self</span><span class=o>.</span><span class=n>reverse_embedding</span><span class=o>.</span><span class=n>weight</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding</span><span class=o>.</span><span class=n>weight</span>
</span><span id=__span-26-49><a id=__codelineno-26-49 name=__codelineno-26-49 href=#__codelineno-26-49></a>
</span><span id=__span-26-50><a id=__codelineno-26-50 name=__codelineno-26-50 href=#__codelineno-26-50></a>        <span class=bp>self</span><span class=o>.</span><span class=n>_init_weights</span><span class=p>()</span>
</span><span id=__span-26-51><a id=__codelineno-26-51 name=__codelineno-26-51 href=#__codelineno-26-51></a>
</span><span id=__span-26-52><a id=__codelineno-26-52 name=__codelineno-26-52 href=#__codelineno-26-52></a>    <span class=k>def</span><span class=w> </span><span class=nf>_init_weights</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-26-53><a id=__codelineno-26-53 name=__codelineno-26-53 href=#__codelineno-26-53></a><span class=w>        </span><span class=sd>"""Initialize weights with small random values."""</span>
</span><span id=__span-26-54><a id=__codelineno-26-54 name=__codelineno-26-54 href=#__codelineno-26-54></a>        <span class=k>for</span> <span class=n>module</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span><span id=__span-26-55><a id=__codelineno-26-55 name=__codelineno-26-55 href=#__codelineno-26-55></a>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>):</span>
</span><span id=__span-26-56><a id=__codelineno-26-56 name=__codelineno-26-56 href=#__codelineno-26-56></a>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-26-57><a id=__codelineno-26-57 name=__codelineno-26-57 href=#__codelineno-26-57></a>                <span class=k>if</span> <span class=n>module</span><span class=o>.</span><span class=n>bias</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-26-58><a id=__codelineno-26-58 name=__codelineno-26-58 href=#__codelineno-26-58></a>                    <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-26-59><a id=__codelineno-26-59 name=__codelineno-26-59 href=#__codelineno-26-59></a>            <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>):</span>
</span><span id=__span-26-60><a id=__codelineno-26-60 name=__codelineno-26-60 href=#__codelineno-26-60></a>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>normal_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>,</span> <span class=n>mean</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span> <span class=n>std</span><span class=o>=</span><span class=mf>0.02</span><span class=p>)</span>
</span><span id=__span-26-61><a id=__codelineno-26-61 name=__codelineno-26-61 href=#__codelineno-26-61></a>            <span class=k>elif</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>):</span>
</span><span id=__span-26-62><a id=__codelineno-26-62 name=__codelineno-26-62 href=#__codelineno-26-62></a>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>ones_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>weight</span><span class=p>)</span>
</span><span id=__span-26-63><a id=__codelineno-26-63 name=__codelineno-26-63 href=#__codelineno-26-63></a>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>zeros_</span><span class=p>(</span><span class=n>module</span><span class=o>.</span><span class=n>bias</span><span class=p>)</span>
</span><span id=__span-26-64><a id=__codelineno-26-64 name=__codelineno-26-64 href=#__codelineno-26-64></a>
</span><span id=__span-26-65><a id=__codelineno-26-65 name=__codelineno-26-65 href=#__codelineno-26-65></a>    <span class=k>def</span><span class=w> </span><span class=nf>embed_tokens</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>token_ids</span><span class=p>):</span>
</span><span id=__span-26-66><a id=__codelineno-26-66 name=__codelineno-26-66 href=#__codelineno-26-66></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-26-67><a id=__codelineno-26-67 name=__codelineno-26-67 href=#__codelineno-26-67></a><span class=sd>        Convert token IDs to embeddings with positional encoding.</span>
</span><span id=__span-26-68><a id=__codelineno-26-68 name=__codelineno-26-68 href=#__codelineno-26-68></a>
</span><span id=__span-26-69><a id=__codelineno-26-69 name=__codelineno-26-69 href=#__codelineno-26-69></a><span class=sd>        Args:</span>
</span><span id=__span-26-70><a id=__codelineno-26-70 name=__codelineno-26-70 href=#__codelineno-26-70></a><span class=sd>            token_ids: [batch, seq_len] integer tensor</span>
</span><span id=__span-26-71><a id=__codelineno-26-71 name=__codelineno-26-71 href=#__codelineno-26-71></a>
</span><span id=__span-26-72><a id=__codelineno-26-72 name=__codelineno-26-72 href=#__codelineno-26-72></a><span class=sd>        Returns:</span>
</span><span id=__span-26-73><a id=__codelineno-26-73 name=__codelineno-26-73 href=#__codelineno-26-73></a><span class=sd>            embeddings: [batch, seq_len, d_model] float tensor</span>
</span><span id=__span-26-74><a id=__codelineno-26-74 name=__codelineno-26-74 href=#__codelineno-26-74></a><span class=sd>        """</span>
</span><span id=__span-26-75><a id=__codelineno-26-75 name=__codelineno-26-75 href=#__codelineno-26-75></a>        <span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span> <span class=o>=</span> <span class=n>token_ids</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-26-76><a id=__codelineno-26-76 name=__codelineno-26-76 href=#__codelineno-26-76></a>
</span><span id=__span-26-77><a id=__codelineno-26-77 name=__codelineno-26-77 href=#__codelineno-26-77></a>        <span class=c1># Token embeddings</span>
</span><span id=__span-26-78><a id=__codelineno-26-78 name=__codelineno-26-78 href=#__codelineno-26-78></a>        <span class=n>token_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>token_embedding</span><span class=p>(</span><span class=n>token_ids</span><span class=p>)</span>
</span><span id=__span-26-79><a id=__codelineno-26-79 name=__codelineno-26-79 href=#__codelineno-26-79></a>
</span><span id=__span-26-80><a id=__codelineno-26-80 name=__codelineno-26-80 href=#__codelineno-26-80></a>        <span class=c1># Positional embeddings</span>
</span><span id=__span-26-81><a id=__codelineno-26-81 name=__codelineno-26-81 href=#__codelineno-26-81></a>        <span class=n>positions</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>seq_len</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>token_ids</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-26-82><a id=__codelineno-26-82 name=__codelineno-26-82 href=#__codelineno-26-82></a>        <span class=n>positions</span> <span class=o>=</span> <span class=n>positions</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-26-83><a id=__codelineno-26-83 name=__codelineno-26-83 href=#__codelineno-26-83></a>        <span class=n>pos_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>position_embedding</span><span class=p>(</span><span class=n>positions</span><span class=p>)</span>
</span><span id=__span-26-84><a id=__codelineno-26-84 name=__codelineno-26-84 href=#__codelineno-26-84></a>
</span><span id=__span-26-85><a id=__codelineno-26-85 name=__codelineno-26-85 href=#__codelineno-26-85></a>        <span class=c1># Combine</span>
</span><span id=__span-26-86><a id=__codelineno-26-86 name=__codelineno-26-86 href=#__codelineno-26-86></a>        <span class=n>embeddings</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding_dropout</span><span class=p>(</span><span class=n>token_emb</span> <span class=o>+</span> <span class=n>pos_emb</span><span class=p>)</span>
</span><span id=__span-26-87><a id=__codelineno-26-87 name=__codelineno-26-87 href=#__codelineno-26-87></a>
</span><span id=__span-26-88><a id=__codelineno-26-88 name=__codelineno-26-88 href=#__codelineno-26-88></a>        <span class=k>return</span> <span class=n>embeddings</span>
</span><span id=__span-26-89><a id=__codelineno-26-89 name=__codelineno-26-89 href=#__codelineno-26-89></a>
</span><span id=__span-26-90><a id=__codelineno-26-90 name=__codelineno-26-90 href=#__codelineno-26-90></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_transformer_blocks</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-26-91><a id=__codelineno-26-91 name=__codelineno-26-91 href=#__codelineno-26-91></a><span class=w>        </span><span class=sd>"""Apply all transformer blocks sequentially."""</span>
</span><span id=__span-26-92><a id=__codelineno-26-92 name=__codelineno-26-92 href=#__codelineno-26-92></a>        <span class=k>for</span> <span class=n>block</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>transformer_blocks</span><span class=p>:</span>
</span><span id=__span-26-93><a id=__codelineno-26-93 name=__codelineno-26-93 href=#__codelineno-26-93></a>            <span class=n>x</span> <span class=o>=</span> <span class=n>block</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-26-94><a id=__codelineno-26-94 name=__codelineno-26-94 href=#__codelineno-26-94></a>        <span class=k>return</span> <span class=n>x</span>
</span><span id=__span-26-95><a id=__codelineno-26-95 name=__codelineno-26-95 href=#__codelineno-26-95></a>
</span><span id=__span-26-96><a id=__codelineno-26-96 name=__codelineno-26-96 href=#__codelineno-26-96></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward_pass</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-26-97><a id=__codelineno-26-97 name=__codelineno-26-97 href=#__codelineno-26-97></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-26-98><a id=__codelineno-26-98 name=__codelineno-26-98 href=#__codelineno-26-98></a><span class=sd>        Single forward pass through the transformer.</span>
</span><span id=__span-26-99><a id=__codelineno-26-99 name=__codelineno-26-99 href=#__codelineno-26-99></a>
</span><span id=__span-26-100><a id=__codelineno-26-100 name=__codelineno-26-100 href=#__codelineno-26-100></a><span class=sd>        This is the key: all three streams are concatenated,</span>
</span><span id=__span-26-101><a id=__codelineno-26-101 name=__codelineno-26-101 href=#__codelineno-26-101></a><span class=sd>        processed together, then split back apart.</span>
</span><span id=__span-26-102><a id=__codelineno-26-102 name=__codelineno-26-102 href=#__codelineno-26-102></a>
</span><span id=__span-26-103><a id=__codelineno-26-103 name=__codelineno-26-103 href=#__codelineno-26-103></a><span class=sd>        Args:</span>
</span><span id=__span-26-104><a id=__codelineno-26-104 name=__codelineno-26-104 href=#__codelineno-26-104></a><span class=sd>            x: [batch, len_x, d_model] - question stream</span>
</span><span id=__span-26-105><a id=__codelineno-26-105 name=__codelineno-26-105 href=#__codelineno-26-105></a><span class=sd>            y: [batch, len_y, d_model] - answer stream</span>
</span><span id=__span-26-106><a id=__codelineno-26-106 name=__codelineno-26-106 href=#__codelineno-26-106></a><span class=sd>            z: [batch, len_z, d_model] - reasoning stream</span>
</span><span id=__span-26-107><a id=__codelineno-26-107 name=__codelineno-26-107 href=#__codelineno-26-107></a>
</span><span id=__span-26-108><a id=__codelineno-26-108 name=__codelineno-26-108 href=#__codelineno-26-108></a><span class=sd>        Returns:</span>
</span><span id=__span-26-109><a id=__codelineno-26-109 name=__codelineno-26-109 href=#__codelineno-26-109></a><span class=sd>            x_new, y_new, z_new: Updated streams</span>
</span><span id=__span-26-110><a id=__codelineno-26-110 name=__codelineno-26-110 href=#__codelineno-26-110></a><span class=sd>        """</span>
</span><span id=__span-26-111><a id=__codelineno-26-111 name=__codelineno-26-111 href=#__codelineno-26-111></a>        <span class=n>len_x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-26-112><a id=__codelineno-26-112 name=__codelineno-26-112 href=#__codelineno-26-112></a>        <span class=n>len_y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-26-113><a id=__codelineno-26-113 name=__codelineno-26-113 href=#__codelineno-26-113></a>        <span class=n>len_z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-26-114><a id=__codelineno-26-114 name=__codelineno-26-114 href=#__codelineno-26-114></a>
</span><span id=__span-26-115><a id=__codelineno-26-115 name=__codelineno-26-115 href=#__codelineno-26-115></a>        <span class=c1># Concatenate three streams</span>
</span><span id=__span-26-116><a id=__codelineno-26-116 name=__codelineno-26-116 href=#__codelineno-26-116></a>        <span class=n>combined</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [batch, len_x+len_y+len_z, d_model]</span>
</span><span id=__span-26-117><a id=__codelineno-26-117 name=__codelineno-26-117 href=#__codelineno-26-117></a>
</span><span id=__span-26-118><a id=__codelineno-26-118 name=__codelineno-26-118 href=#__codelineno-26-118></a>        <span class=c1># Process through transformer</span>
</span><span id=__span-26-119><a id=__codelineno-26-119 name=__codelineno-26-119 href=#__codelineno-26-119></a>        <span class=n>combined</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>apply_transformer_blocks</span><span class=p>(</span><span class=n>combined</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-26-120><a id=__codelineno-26-120 name=__codelineno-26-120 href=#__codelineno-26-120></a>
</span><span id=__span-26-121><a id=__codelineno-26-121 name=__codelineno-26-121 href=#__codelineno-26-121></a>        <span class=c1># Split back</span>
</span><span id=__span-26-122><a id=__codelineno-26-122 name=__codelineno-26-122 href=#__codelineno-26-122></a>        <span class=n>x_new</span> <span class=o>=</span> <span class=n>combined</span><span class=p>[:,</span> <span class=p>:</span><span class=n>len_x</span><span class=p>,</span> <span class=p>:]</span>
</span><span id=__span-26-123><a id=__codelineno-26-123 name=__codelineno-26-123 href=#__codelineno-26-123></a>        <span class=n>y_new</span> <span class=o>=</span> <span class=n>combined</span><span class=p>[:,</span> <span class=n>len_x</span><span class=p>:</span><span class=n>len_x</span><span class=o>+</span><span class=n>len_y</span><span class=p>,</span> <span class=p>:]</span>
</span><span id=__span-26-124><a id=__codelineno-26-124 name=__codelineno-26-124 href=#__codelineno-26-124></a>        <span class=n>z_new</span> <span class=o>=</span> <span class=n>combined</span><span class=p>[:,</span> <span class=n>len_x</span><span class=o>+</span><span class=n>len_y</span><span class=p>:,</span> <span class=p>:]</span>
</span><span id=__span-26-125><a id=__codelineno-26-125 name=__codelineno-26-125 href=#__codelineno-26-125></a>
</span><span id=__span-26-126><a id=__codelineno-26-126 name=__codelineno-26-126 href=#__codelineno-26-126></a>        <span class=k>return</span> <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span>
</span><span id=__span-26-127><a id=__codelineno-26-127 name=__codelineno-26-127 href=#__codelineno-26-127></a>
</span><span id=__span-26-128><a id=__codelineno-26-128 name=__codelineno-26-128 href=#__codelineno-26-128></a>    <span class=k>def</span><span class=w> </span><span class=nf>recursive_reasoning</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>return_trajectory</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span><span id=__span-26-129><a id=__codelineno-26-129 name=__codelineno-26-129 href=#__codelineno-26-129></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-26-130><a id=__codelineno-26-130 name=__codelineno-26-130 href=#__codelineno-26-130></a><span class=sd>        The heart of TRM: recursive reasoning.</span>
</span><span id=__span-26-131><a id=__codelineno-26-131 name=__codelineno-26-131 href=#__codelineno-26-131></a>
</span><span id=__span-26-132><a id=__codelineno-26-132 name=__codelineno-26-132 href=#__codelineno-26-132></a><span class=sd>        Phase 1 (n_reasoning_steps): Update z (build understanding)</span>
</span><span id=__span-26-133><a id=__codelineno-26-133 name=__codelineno-26-133 href=#__codelineno-26-133></a><span class=sd>        Phase 2 (n_refinement_steps): Update y (improve answer)</span>
</span><span id=__span-26-134><a id=__codelineno-26-134 name=__codelineno-26-134 href=#__codelineno-26-134></a>
</span><span id=__span-26-135><a id=__codelineno-26-135 name=__codelineno-26-135 href=#__codelineno-26-135></a><span class=sd>        Args:</span>
</span><span id=__span-26-136><a id=__codelineno-26-136 name=__codelineno-26-136 href=#__codelineno-26-136></a><span class=sd>            x: Question stream (fixed)</span>
</span><span id=__span-26-137><a id=__codelineno-26-137 name=__codelineno-26-137 href=#__codelineno-26-137></a><span class=sd>            y: Answer stream (refined in phase 2)</span>
</span><span id=__span-26-138><a id=__codelineno-26-138 name=__codelineno-26-138 href=#__codelineno-26-138></a><span class=sd>            z: Reasoning stream (refined in phase 1)</span>
</span><span id=__span-26-139><a id=__codelineno-26-139 name=__codelineno-26-139 href=#__codelineno-26-139></a>
</span><span id=__span-26-140><a id=__codelineno-26-140 name=__codelineno-26-140 href=#__codelineno-26-140></a><span class=sd>        Returns:</span>
</span><span id=__span-26-141><a id=__codelineno-26-141 name=__codelineno-26-141 href=#__codelineno-26-141></a><span class=sd>            y_final: Final answer predictions</span>
</span><span id=__span-26-142><a id=__codelineno-26-142 name=__codelineno-26-142 href=#__codelineno-26-142></a><span class=sd>            trajectory: (optional) History of states</span>
</span><span id=__span-26-143><a id=__codelineno-26-143 name=__codelineno-26-143 href=#__codelineno-26-143></a><span class=sd>        """</span>
</span><span id=__span-26-144><a id=__codelineno-26-144 name=__codelineno-26-144 href=#__codelineno-26-144></a>        <span class=n>trajectory</span> <span class=o>=</span> <span class=p>{</span><span class=s1>'z_states'</span><span class=p>:</span> <span class=p>[],</span> <span class=s1>'y_states'</span><span class=p>:</span> <span class=p>[]}</span> <span class=k>if</span> <span class=n>return_trajectory</span> <span class=k>else</span> <span class=kc>None</span>
</span><span id=__span-26-145><a id=__codelineno-26-145 name=__codelineno-26-145 href=#__codelineno-26-145></a>
</span><span id=__span-26-146><a id=__codelineno-26-146 name=__codelineno-26-146 href=#__codelineno-26-146></a>        <span class=c1># Phase 1: Build reasoning (update z only)</span>
</span><span id=__span-26-147><a id=__codelineno-26-147 name=__codelineno-26-147 href=#__codelineno-26-147></a>        <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_reasoning_steps</span><span class=p>):</span>
</span><span id=__span-26-148><a id=__codelineno-26-148 name=__codelineno-26-148 href=#__codelineno-26-148></a>            <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-26-149><a id=__codelineno-26-149 name=__codelineno-26-149 href=#__codelineno-26-149></a>            <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>  <span class=c1># Only update z</span>
</span><span id=__span-26-150><a id=__codelineno-26-150 name=__codelineno-26-150 href=#__codelineno-26-150></a>
</span><span id=__span-26-151><a id=__codelineno-26-151 name=__codelineno-26-151 href=#__codelineno-26-151></a>            <span class=k>if</span> <span class=n>return_trajectory</span><span class=p>:</span>
</span><span id=__span-26-152><a id=__codelineno-26-152 name=__codelineno-26-152 href=#__codelineno-26-152></a>                <span class=n>trajectory</span><span class=p>[</span><span class=s1>'z_states'</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>z</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>clone</span><span class=p>())</span>
</span><span id=__span-26-153><a id=__codelineno-26-153 name=__codelineno-26-153 href=#__codelineno-26-153></a>
</span><span id=__span-26-154><a id=__codelineno-26-154 name=__codelineno-26-154 href=#__codelineno-26-154></a>        <span class=c1># Phase 2: Refine answer (update y only)</span>
</span><span id=__span-26-155><a id=__codelineno-26-155 name=__codelineno-26-155 href=#__codelineno-26-155></a>        <span class=k>for</span> <span class=n>step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_refinement_steps</span><span class=p>):</span>
</span><span id=__span-26-156><a id=__codelineno-26-156 name=__codelineno-26-156 href=#__codelineno-26-156></a>            <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-26-157><a id=__codelineno-26-157 name=__codelineno-26-157 href=#__codelineno-26-157></a>            <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>  <span class=c1># Only update y</span>
</span><span id=__span-26-158><a id=__codelineno-26-158 name=__codelineno-26-158 href=#__codelineno-26-158></a>
</span><span id=__span-26-159><a id=__codelineno-26-159 name=__codelineno-26-159 href=#__codelineno-26-159></a>            <span class=k>if</span> <span class=n>return_trajectory</span><span class=p>:</span>
</span><span id=__span-26-160><a id=__codelineno-26-160 name=__codelineno-26-160 href=#__codelineno-26-160></a>                <span class=n>trajectory</span><span class=p>[</span><span class=s1>'y_states'</span><span class=p>]</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>y</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>clone</span><span class=p>())</span>
</span><span id=__span-26-161><a id=__codelineno-26-161 name=__codelineno-26-161 href=#__codelineno-26-161></a>
</span><span id=__span-26-162><a id=__codelineno-26-162 name=__codelineno-26-162 href=#__codelineno-26-162></a>        <span class=k>return</span> <span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>trajectory</span><span class=p>)</span> <span class=k>if</span> <span class=n>return_trajectory</span> <span class=k>else</span> <span class=n>y</span>
</span><span id=__span-26-163><a id=__codelineno-26-163 name=__codelineno-26-163 href=#__codelineno-26-163></a>
</span><span id=__span-26-164><a id=__codelineno-26-164 name=__codelineno-26-164 href=#__codelineno-26-164></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>question_ids</span><span class=p>,</span> <span class=n>answer_ids</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>latent_len</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span><span id=__span-26-165><a id=__codelineno-26-165 name=__codelineno-26-165 href=#__codelineno-26-165></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-26-166><a id=__codelineno-26-166 name=__codelineno-26-166 href=#__codelineno-26-166></a><span class=sd>        Complete forward pass.</span>
</span><span id=__span-26-167><a id=__codelineno-26-167 name=__codelineno-26-167 href=#__codelineno-26-167></a>
</span><span id=__span-26-168><a id=__codelineno-26-168 name=__codelineno-26-168 href=#__codelineno-26-168></a><span class=sd>        Args:</span>
</span><span id=__span-26-169><a id=__codelineno-26-169 name=__codelineno-26-169 href=#__codelineno-26-169></a><span class=sd>            question_ids: [batch, len_q] - input question as tokens</span>
</span><span id=__span-26-170><a id=__codelineno-26-170 name=__codelineno-26-170 href=#__codelineno-26-170></a><span class=sd>            answer_ids: [batch, len_a] - target answer (for training)</span>
</span><span id=__span-26-171><a id=__codelineno-26-171 name=__codelineno-26-171 href=#__codelineno-26-171></a><span class=sd>            latent_len: int - length of reasoning stream</span>
</span><span id=__span-26-172><a id=__codelineno-26-172 name=__codelineno-26-172 href=#__codelineno-26-172></a>
</span><span id=__span-26-173><a id=__codelineno-26-173 name=__codelineno-26-173 href=#__codelineno-26-173></a><span class=sd>        Returns:</span>
</span><span id=__span-26-174><a id=__codelineno-26-174 name=__codelineno-26-174 href=#__codelineno-26-174></a><span class=sd>            logits: [batch, len_a, vocab_size] - predicted answer</span>
</span><span id=__span-26-175><a id=__codelineno-26-175 name=__codelineno-26-175 href=#__codelineno-26-175></a><span class=sd>        """</span>
</span><span id=__span-26-176><a id=__codelineno-26-176 name=__codelineno-26-176 href=#__codelineno-26-176></a>        <span class=n>batch_size</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-26-177><a id=__codelineno-26-177 name=__codelineno-26-177 href=#__codelineno-26-177></a>        <span class=n>device</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>device</span>
</span><span id=__span-26-178><a id=__codelineno-26-178 name=__codelineno-26-178 href=#__codelineno-26-178></a>
</span><span id=__span-26-179><a id=__codelineno-26-179 name=__codelineno-26-179 href=#__codelineno-26-179></a>        <span class=c1># Embed question (x stream - fixed)</span>
</span><span id=__span-26-180><a id=__codelineno-26-180 name=__codelineno-26-180 href=#__codelineno-26-180></a>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>question_ids</span><span class=p>)</span>
</span><span id=__span-26-181><a id=__codelineno-26-181 name=__codelineno-26-181 href=#__codelineno-26-181></a>
</span><span id=__span-26-182><a id=__codelineno-26-182 name=__codelineno-26-182 href=#__codelineno-26-182></a>        <span class=c1># Embed or initialize answer (y stream - will be refined)</span>
</span><span id=__span-26-183><a id=__codelineno-26-183 name=__codelineno-26-183 href=#__codelineno-26-183></a>        <span class=k>if</span> <span class=n>answer_ids</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-26-184><a id=__codelineno-26-184 name=__codelineno-26-184 href=#__codelineno-26-184></a>            <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>answer_ids</span><span class=p>)</span>  <span class=c1># Training: start from target</span>
</span><span id=__span-26-185><a id=__codelineno-26-185 name=__codelineno-26-185 href=#__codelineno-26-185></a>        <span class=k>else</span><span class=p>:</span>
</span><span id=__span-26-186><a id=__codelineno-26-186 name=__codelineno-26-186 href=#__codelineno-26-186></a>            <span class=n>len_a</span> <span class=o>=</span> <span class=mi>81</span>  <span class=c1># Default for Sudoku</span>
</span><span id=__span-26-187><a id=__codelineno-26-187 name=__codelineno-26-187 href=#__codelineno-26-187></a>            <span class=n>y</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>len_a</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>
</span><span id=__span-26-188><a id=__codelineno-26-188 name=__codelineno-26-188 href=#__codelineno-26-188></a>
</span><span id=__span-26-189><a id=__codelineno-26-189 name=__codelineno-26-189 href=#__codelineno-26-189></a>        <span class=c1># Initialize reasoning (z stream - will be refined)</span>
</span><span id=__span-26-190><a id=__codelineno-26-190 name=__codelineno-26-190 href=#__codelineno-26-190></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>latent_len</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>
</span><span id=__span-26-191><a id=__codelineno-26-191 name=__codelineno-26-191 href=#__codelineno-26-191></a>
</span><span id=__span-26-192><a id=__codelineno-26-192 name=__codelineno-26-192 href=#__codelineno-26-192></a>        <span class=c1># Recursive reasoning</span>
</span><span id=__span-26-193><a id=__codelineno-26-193 name=__codelineno-26-193 href=#__codelineno-26-193></a>        <span class=n>y_final</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>recursive_reasoning</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>,</span> <span class=n>mask</span><span class=p>)</span>
</span><span id=__span-26-194><a id=__codelineno-26-194 name=__codelineno-26-194 href=#__codelineno-26-194></a>
</span><span id=__span-26-195><a id=__codelineno-26-195 name=__codelineno-26-195 href=#__codelineno-26-195></a>        <span class=c1># Decode to token predictions</span>
</span><span id=__span-26-196><a id=__codelineno-26-196 name=__codelineno-26-196 href=#__codelineno-26-196></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reverse_embedding</span><span class=p>(</span><span class=n>y_final</span><span class=p>)</span>
</span><span id=__span-26-197><a id=__codelineno-26-197 name=__codelineno-26-197 href=#__codelineno-26-197></a>
</span><span id=__span-26-198><a id=__codelineno-26-198 name=__codelineno-26-198 href=#__codelineno-26-198></a>        <span class=k>return</span> <span class=n>logits</span>
</span><span id=__span-26-199><a id=__codelineno-26-199 name=__codelineno-26-199 href=#__codelineno-26-199></a>
</span><span id=__span-26-200><a id=__codelineno-26-200 name=__codelineno-26-200 href=#__codelineno-26-200></a>    <span class=k>def</span><span class=w> </span><span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>question_ids</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=mi>81</span><span class=p>,</span> <span class=n>latent_len</span><span class=o>=</span><span class=mi>32</span><span class=p>):</span>
</span><span id=__span-26-201><a id=__codelineno-26-201 name=__codelineno-26-201 href=#__codelineno-26-201></a><span class=w>        </span><span class=sd>"""</span>
</span><span id=__span-26-202><a id=__codelineno-26-202 name=__codelineno-26-202 href=#__codelineno-26-202></a><span class=sd>        Generate answer for a given question.</span>
</span><span id=__span-26-203><a id=__codelineno-26-203 name=__codelineno-26-203 href=#__codelineno-26-203></a>
</span><span id=__span-26-204><a id=__codelineno-26-204 name=__codelineno-26-204 href=#__codelineno-26-204></a><span class=sd>        Args:</span>
</span><span id=__span-26-205><a id=__codelineno-26-205 name=__codelineno-26-205 href=#__codelineno-26-205></a><span class=sd>            question_ids: [batch, len_q] - input question</span>
</span><span id=__span-26-206><a id=__codelineno-26-206 name=__codelineno-26-206 href=#__codelineno-26-206></a><span class=sd>            max_length: int - maximum answer length</span>
</span><span id=__span-26-207><a id=__codelineno-26-207 name=__codelineno-26-207 href=#__codelineno-26-207></a><span class=sd>            latent_len: int - reasoning stream length</span>
</span><span id=__span-26-208><a id=__codelineno-26-208 name=__codelineno-26-208 href=#__codelineno-26-208></a>
</span><span id=__span-26-209><a id=__codelineno-26-209 name=__codelineno-26-209 href=#__codelineno-26-209></a><span class=sd>        Returns:</span>
</span><span id=__span-26-210><a id=__codelineno-26-210 name=__codelineno-26-210 href=#__codelineno-26-210></a><span class=sd>            generated: [batch, max_length] - predicted tokens</span>
</span><span id=__span-26-211><a id=__codelineno-26-211 name=__codelineno-26-211 href=#__codelineno-26-211></a><span class=sd>        """</span>
</span><span id=__span-26-212><a id=__codelineno-26-212 name=__codelineno-26-212 href=#__codelineno-26-212></a>        <span class=n>batch_size</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-26-213><a id=__codelineno-26-213 name=__codelineno-26-213 href=#__codelineno-26-213></a>        <span class=n>device</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>device</span>
</span><span id=__span-26-214><a id=__codelineno-26-214 name=__codelineno-26-214 href=#__codelineno-26-214></a>
</span><span id=__span-26-215><a id=__codelineno-26-215 name=__codelineno-26-215 href=#__codelineno-26-215></a>        <span class=c1># Initialize empty answer</span>
</span><span id=__span-26-216><a id=__codelineno-26-216 name=__codelineno-26-216 href=#__codelineno-26-216></a>        <span class=n>y_init</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>max_length</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-26-217><a id=__codelineno-26-217 name=__codelineno-26-217 href=#__codelineno-26-217></a>
</span><span id=__span-26-218><a id=__codelineno-26-218 name=__codelineno-26-218 href=#__codelineno-26-218></a>        <span class=c1># Get predictions</span>
</span><span id=__span-26-219><a id=__codelineno-26-219 name=__codelineno-26-219 href=#__codelineno-26-219></a>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>question_ids</span><span class=p>,</span> <span class=n>y_init</span><span class=p>,</span> <span class=n>latent_len</span><span class=p>)</span>
</span><span id=__span-26-220><a id=__codelineno-26-220 name=__codelineno-26-220 href=#__codelineno-26-220></a>
</span><span id=__span-26-221><a id=__codelineno-26-221 name=__codelineno-26-221 href=#__codelineno-26-221></a>        <span class=c1># Take argmax</span>
</span><span id=__span-26-222><a id=__codelineno-26-222 name=__codelineno-26-222 href=#__codelineno-26-222></a>        <span class=n>generated</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-26-223><a id=__codelineno-26-223 name=__codelineno-26-223 href=#__codelineno-26-223></a>
</span><span id=__span-26-224><a id=__codelineno-26-224 name=__codelineno-26-224 href=#__codelineno-26-224></a>        <span class=k>return</span> <span class=n>generated</span>
</span><span id=__span-26-225><a id=__codelineno-26-225 name=__codelineno-26-225 href=#__codelineno-26-225></a>
</span><span id=__span-26-226><a id=__codelineno-26-226 name=__codelineno-26-226 href=#__codelineno-26-226></a>    <span class=k>def</span><span class=w> </span><span class=nf>count_parameters</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-26-227><a id=__codelineno-26-227 name=__codelineno-26-227 href=#__codelineno-26-227></a><span class=w>        </span><span class=sd>"""Count total trainable parameters."""</span>
</span><span id=__span-26-228><a id=__codelineno-26-228 name=__codelineno-26-228 href=#__codelineno-26-228></a>        <span class=k>return</span> <span class=nb>sum</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>parameters</span><span class=p>()</span> <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>)</span>
</span></code></pre></div> <h3 id=model-variants>Model Variants<a class=headerlink href=#model-variants title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=k>def</span><span class=w> </span><span class=nf>create_trm_att</span><span class=p>(</span><span class=n>vocab_size</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a><span class=sd>    Create TRM with attention (TRM-Att variant).</span>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a><span class=sd>    Best for: Maze, ARC-AGI (large, variable-length problems)</span>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a><span class=sd>    Parameters: ~7M</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a><span class=sd>    """</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>    <span class=k>return</span> <span class=n>TRM</span><span class=p>(</span>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a>        <span class=n>vocab_size</span><span class=o>=</span><span class=n>vocab_size</span><span class=p>,</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a>        <span class=n>d_model</span><span class=o>=</span><span class=n>d_model</span><span class=p>,</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a>        <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a>        <span class=n>d_ff</span><span class=o>=</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>4</span><span class=p>,</span>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a>        <span class=n>n_layers</span><span class=o>=</span><span class=n>n_layers</span><span class=p>,</span>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a>        <span class=n>n_reasoning_steps</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a>        <span class=n>n_refinement_steps</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16 href=#__codelineno-27-16></a>        <span class=n>use_attention</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17 href=#__codelineno-27-17></a>    <span class=p>)</span>
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18 href=#__codelineno-27-18></a>
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19 href=#__codelineno-27-19></a><span class=k>def</span><span class=w> </span><span class=nf>create_trm_mlp</span><span class=p>(</span><span class=n>vocab_size</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_layers</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span><span id=__span-27-20><a id=__codelineno-27-20 name=__codelineno-27-20 href=#__codelineno-27-20></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-27-21><a id=__codelineno-27-21 name=__codelineno-27-21 href=#__codelineno-27-21></a><span class=sd>    Create TRM without attention (TRM-MLP variant).</span>
</span><span id=__span-27-22><a id=__codelineno-27-22 name=__codelineno-27-22 href=#__codelineno-27-22></a>
</span><span id=__span-27-23><a id=__codelineno-27-23 name=__codelineno-27-23 href=#__codelineno-27-23></a><span class=sd>    Best for: Sudoku (fixed-length, highly structured problems)</span>
</span><span id=__span-27-24><a id=__codelineno-27-24 name=__codelineno-27-24 href=#__codelineno-27-24></a><span class=sd>    Parameters: ~5M</span>
</span><span id=__span-27-25><a id=__codelineno-27-25 name=__codelineno-27-25 href=#__codelineno-27-25></a><span class=sd>    Achieves 87.4% on Sudoku-Extreme!</span>
</span><span id=__span-27-26><a id=__codelineno-27-26 name=__codelineno-27-26 href=#__codelineno-27-26></a><span class=sd>    """</span>
</span><span id=__span-27-27><a id=__codelineno-27-27 name=__codelineno-27-27 href=#__codelineno-27-27></a>    <span class=k>return</span> <span class=n>TRM</span><span class=p>(</span>
</span><span id=__span-27-28><a id=__codelineno-27-28 name=__codelineno-27-28 href=#__codelineno-27-28></a>        <span class=n>vocab_size</span><span class=o>=</span><span class=n>vocab_size</span><span class=p>,</span>
</span><span id=__span-27-29><a id=__codelineno-27-29 name=__codelineno-27-29 href=#__codelineno-27-29></a>        <span class=n>d_model</span><span class=o>=</span><span class=n>d_model</span><span class=p>,</span>
</span><span id=__span-27-30><a id=__codelineno-27-30 name=__codelineno-27-30 href=#__codelineno-27-30></a>        <span class=n>n_heads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=c1># Not used, but kept for compatibility</span>
</span><span id=__span-27-31><a id=__codelineno-27-31 name=__codelineno-27-31 href=#__codelineno-27-31></a>        <span class=n>d_ff</span><span class=o>=</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>4</span><span class=p>,</span>
</span><span id=__span-27-32><a id=__codelineno-27-32 name=__codelineno-27-32 href=#__codelineno-27-32></a>        <span class=n>n_layers</span><span class=o>=</span><span class=n>n_layers</span><span class=p>,</span>
</span><span id=__span-27-33><a id=__codelineno-27-33 name=__codelineno-27-33 href=#__codelineno-27-33></a>        <span class=n>n_reasoning_steps</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-27-34><a id=__codelineno-27-34 name=__codelineno-27-34 href=#__codelineno-27-34></a>        <span class=n>n_refinement_steps</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span><span id=__span-27-35><a id=__codelineno-27-35 name=__codelineno-27-35 href=#__codelineno-27-35></a>        <span class=n>use_attention</span><span class=o>=</span><span class=kc>False</span>  <span class=c1># Key difference!</span>
</span><span id=__span-27-36><a id=__codelineno-27-36 name=__codelineno-27-36 href=#__codelineno-27-36></a>    <span class=p>)</span>
</span><span id=__span-27-37><a id=__codelineno-27-37 name=__codelineno-27-37 href=#__codelineno-27-37></a>
</span><span id=__span-27-38><a id=__codelineno-27-38 name=__codelineno-27-38 href=#__codelineno-27-38></a><span class=c1># Example: Create models</span>
</span><span id=__span-27-39><a id=__codelineno-27-39 name=__codelineno-27-39 href=#__codelineno-27-39></a><span class=n>model_att</span> <span class=o>=</span> <span class=n>create_trm_att</span><span class=p>()</span>
</span><span id=__span-27-40><a id=__codelineno-27-40 name=__codelineno-27-40 href=#__codelineno-27-40></a><span class=n>model_mlp</span> <span class=o>=</span> <span class=n>create_trm_mlp</span><span class=p>()</span>
</span><span id=__span-27-41><a id=__codelineno-27-41 name=__codelineno-27-41 href=#__codelineno-27-41></a>
</span><span id=__span-27-42><a id=__codelineno-27-42 name=__codelineno-27-42 href=#__codelineno-27-42></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"TRM-Att parameters: </span><span class=si>{</span><span class=n>model_att</span><span class=o>.</span><span class=n>count_parameters</span><span class=p>()</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>M"</span><span class=p>)</span>
</span><span id=__span-27-43><a id=__codelineno-27-43 name=__codelineno-27-43 href=#__codelineno-27-43></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"TRM-MLP parameters: </span><span class=si>{</span><span class=n>model_mlp</span><span class=o>.</span><span class=n>count_parameters</span><span class=p>()</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>M"</span><span class=p>)</span>
</span></code></pre></div> <h3 id=training-utilities>Training Utilities<a class=headerlink href=#training-utilities title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=k>class</span><span class=w> </span><span class=nc>ExponentialMovingAverage</span><span class=p>:</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a><span class=sd>    EMA for model weights - improves stability on small datasets.</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a><span class=sd>    Instead of using current weights directly, maintain a moving average.</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a><span class=sd>    This prevents sharp updates that might break good solutions.</span>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a><span class=sd>    """</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a>
</span><span id=__span-28-9><a id=__codelineno-28-9 name=__codelineno-28-9 href=#__codelineno-28-9></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=mf>0.999</span><span class=p>):</span>
</span><span id=__span-28-10><a id=__codelineno-28-10 name=__codelineno-28-10 href=#__codelineno-28-10></a>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>model</span>
</span><span id=__span-28-11><a id=__codelineno-28-11 name=__codelineno-28-11 href=#__codelineno-28-11></a>        <span class=bp>self</span><span class=o>.</span><span class=n>decay</span> <span class=o>=</span> <span class=n>decay</span>
</span><span id=__span-28-12><a id=__codelineno-28-12 name=__codelineno-28-12 href=#__codelineno-28-12></a>        <span class=bp>self</span><span class=o>.</span><span class=n>shadow</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-28-13><a id=__codelineno-28-13 name=__codelineno-28-13 href=#__codelineno-28-13></a>        <span class=bp>self</span><span class=o>.</span><span class=n>backup</span> <span class=o>=</span> <span class=p>{}</span>
</span><span id=__span-28-14><a id=__codelineno-28-14 name=__codelineno-28-14 href=#__codelineno-28-14></a>
</span><span id=__span-28-15><a id=__codelineno-28-15 name=__codelineno-28-15 href=#__codelineno-28-15></a>        <span class=c1># Initialize shadow weights</span>
</span><span id=__span-28-16><a id=__codelineno-28-16 name=__codelineno-28-16 href=#__codelineno-28-16></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-28-17><a id=__codelineno-28-17 name=__codelineno-28-17 href=#__codelineno-28-17></a>            <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span><span id=__span-28-18><a id=__codelineno-28-18 name=__codelineno-28-18 href=#__codelineno-28-18></a>                <span class=bp>self</span><span class=o>.</span><span class=n>shadow</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=n>param</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span><span id=__span-28-19><a id=__codelineno-28-19 name=__codelineno-28-19 href=#__codelineno-28-19></a>
</span><span id=__span-28-20><a id=__codelineno-28-20 name=__codelineno-28-20 href=#__codelineno-28-20></a>    <span class=k>def</span><span class=w> </span><span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-28-21><a id=__codelineno-28-21 name=__codelineno-28-21 href=#__codelineno-28-21></a><span class=w>        </span><span class=sd>"""Update shadow weights after each optimization step."""</span>
</span><span id=__span-28-22><a id=__codelineno-28-22 name=__codelineno-28-22 href=#__codelineno-28-22></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-28-23><a id=__codelineno-28-23 name=__codelineno-28-23 href=#__codelineno-28-23></a>            <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span><span id=__span-28-24><a id=__codelineno-28-24 name=__codelineno-28-24 href=#__codelineno-28-24></a>                <span class=bp>self</span><span class=o>.</span><span class=n>shadow</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decay</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>shadow</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>decay</span><span class=p>)</span> <span class=o>*</span> <span class=n>param</span><span class=o>.</span><span class=n>data</span>
</span><span id=__span-28-25><a id=__codelineno-28-25 name=__codelineno-28-25 href=#__codelineno-28-25></a>
</span><span id=__span-28-26><a id=__codelineno-28-26 name=__codelineno-28-26 href=#__codelineno-28-26></a>    <span class=k>def</span><span class=w> </span><span class=nf>apply_shadow</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-28-27><a id=__codelineno-28-27 name=__codelineno-28-27 href=#__codelineno-28-27></a><span class=w>        </span><span class=sd>"""Replace model weights with shadow weights (for inference)."""</span>
</span><span id=__span-28-28><a id=__codelineno-28-28 name=__codelineno-28-28 href=#__codelineno-28-28></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-28-29><a id=__codelineno-28-29 name=__codelineno-28-29 href=#__codelineno-28-29></a>            <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span><span id=__span-28-30><a id=__codelineno-28-30 name=__codelineno-28-30 href=#__codelineno-28-30></a>                <span class=bp>self</span><span class=o>.</span><span class=n>backup</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=n>param</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span><span id=__span-28-31><a id=__codelineno-28-31 name=__codelineno-28-31 href=#__codelineno-28-31></a>                <span class=n>param</span><span class=o>.</span><span class=n>data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>shadow</span><span class=p>[</span><span class=n>name</span><span class=p>]</span>
</span><span id=__span-28-32><a id=__codelineno-28-32 name=__codelineno-28-32 href=#__codelineno-28-32></a>
</span><span id=__span-28-33><a id=__codelineno-28-33 name=__codelineno-28-33 href=#__codelineno-28-33></a>    <span class=k>def</span><span class=w> </span><span class=nf>restore</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-28-34><a id=__codelineno-28-34 name=__codelineno-28-34 href=#__codelineno-28-34></a><span class=w>        </span><span class=sd>"""Restore original weights (after inference)."""</span>
</span><span id=__span-28-35><a id=__codelineno-28-35 name=__codelineno-28-35 href=#__codelineno-28-35></a>        <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span><span id=__span-28-36><a id=__codelineno-28-36 name=__codelineno-28-36 href=#__codelineno-28-36></a>            <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span><span id=__span-28-37><a id=__codelineno-28-37 name=__codelineno-28-37 href=#__codelineno-28-37></a>                <span class=n>param</span><span class=o>.</span><span class=n>data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>backup</span><span class=p>[</span><span class=n>name</span><span class=p>]</span>
</span><span id=__span-28-38><a id=__codelineno-28-38 name=__codelineno-28-38 href=#__codelineno-28-38></a>
</span><span id=__span-28-39><a id=__codelineno-28-39 name=__codelineno-28-39 href=#__codelineno-28-39></a><span class=k>def</span><span class=w> </span><span class=nf>get_lr_scheduler</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>warmup_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>total_steps</span><span class=o>=</span><span class=mi>100000</span><span class=p>):</span>
</span><span id=__span-28-40><a id=__codelineno-28-40 name=__codelineno-28-40 href=#__codelineno-28-40></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-28-41><a id=__codelineno-28-41 name=__codelineno-28-41 href=#__codelineno-28-41></a><span class=sd>    Learning rate scheduler with warmup and cosine decay.</span>
</span><span id=__span-28-42><a id=__codelineno-28-42 name=__codelineno-28-42 href=#__codelineno-28-42></a>
</span><span id=__span-28-43><a id=__codelineno-28-43 name=__codelineno-28-43 href=#__codelineno-28-43></a><span class=sd>    Warmup: Gradually increase from 0 to target LR</span>
</span><span id=__span-28-44><a id=__codelineno-28-44 name=__codelineno-28-44 href=#__codelineno-28-44></a><span class=sd>    Cosine: Smoothly decrease to near 0</span>
</span><span id=__span-28-45><a id=__codelineno-28-45 name=__codelineno-28-45 href=#__codelineno-28-45></a><span class=sd>    """</span>
</span><span id=__span-28-46><a id=__codelineno-28-46 name=__codelineno-28-46 href=#__codelineno-28-46></a>    <span class=k>def</span><span class=w> </span><span class=nf>lr_lambda</span><span class=p>(</span><span class=n>current_step</span><span class=p>):</span>
</span><span id=__span-28-47><a id=__codelineno-28-47 name=__codelineno-28-47 href=#__codelineno-28-47></a>        <span class=k>if</span> <span class=n>current_step</span> <span class=o>&lt;</span> <span class=n>warmup_steps</span><span class=p>:</span>
</span><span id=__span-28-48><a id=__codelineno-28-48 name=__codelineno-28-48 href=#__codelineno-28-48></a>            <span class=c1># Linear warmup</span>
</span><span id=__span-28-49><a id=__codelineno-28-49 name=__codelineno-28-49 href=#__codelineno-28-49></a>            <span class=k>return</span> <span class=nb>float</span><span class=p>(</span><span class=n>current_step</span><span class=p>)</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>warmup_steps</span><span class=p>))</span>
</span><span id=__span-28-50><a id=__codelineno-28-50 name=__codelineno-28-50 href=#__codelineno-28-50></a>        <span class=c1># Cosine decay</span>
</span><span id=__span-28-51><a id=__codelineno-28-51 name=__codelineno-28-51 href=#__codelineno-28-51></a>        <span class=n>progress</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>current_step</span> <span class=o>-</span> <span class=n>warmup_steps</span><span class=p>)</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=nb>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>total_steps</span> <span class=o>-</span> <span class=n>warmup_steps</span><span class=p>))</span>
</span><span id=__span-28-52><a id=__codelineno-28-52 name=__codelineno-28-52 href=#__codelineno-28-52></a>        <span class=k>return</span> <span class=nb>max</span><span class=p>(</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>+</span> <span class=n>math</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>math</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=n>progress</span><span class=p>)))</span>
</span><span id=__span-28-53><a id=__codelineno-28-53 name=__codelineno-28-53 href=#__codelineno-28-53></a>
</span><span id=__span-28-54><a id=__codelineno-28-54 name=__codelineno-28-54 href=#__codelineno-28-54></a>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>LambdaLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>lr_lambda</span><span class=p>)</span>
</span></code></pre></div> <h3 id=training-loop-with-deep-supervision>Training Loop with Deep Supervision<a class=headerlink href=#training-loop-with-deep-supervision title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a><span class=k>def</span><span class=w> </span><span class=nf>train_with_deep_supervision</span><span class=p>(</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a>    <span class=n>model</span><span class=p>,</span>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a>    <span class=n>train_loader</span><span class=p>,</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a>    <span class=n>optimizer</span><span class=p>,</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a>    <span class=n>scheduler</span><span class=p>,</span>
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a>    <span class=n>ema</span><span class=p>,</span>
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7 href=#__codelineno-29-7></a>    <span class=n>device</span><span class=p>,</span>
</span><span id=__span-29-8><a id=__codelineno-29-8 name=__codelineno-29-8 href=#__codelineno-29-8></a>    <span class=n>n_supervision</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span><span id=__span-29-9><a id=__codelineno-29-9 name=__codelineno-29-9 href=#__codelineno-29-9></a>    <span class=n>max_grad_norm</span><span class=o>=</span><span class=mf>1.0</span>
</span><span id=__span-29-10><a id=__codelineno-29-10 name=__codelineno-29-10 href=#__codelineno-29-10></a><span class=p>):</span>
</span><span id=__span-29-11><a id=__codelineno-29-11 name=__codelineno-29-11 href=#__codelineno-29-11></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-29-12><a id=__codelineno-29-12 name=__codelineno-29-12 href=#__codelineno-29-12></a><span class=sd>    Training loop with deep supervision and all the tricks.</span>
</span><span id=__span-29-13><a id=__codelineno-29-13 name=__codelineno-29-13 href=#__codelineno-29-13></a>
</span><span id=__span-29-14><a id=__codelineno-29-14 name=__codelineno-29-14 href=#__codelineno-29-14></a><span class=sd>    Args:</span>
</span><span id=__span-29-15><a id=__codelineno-29-15 name=__codelineno-29-15 href=#__codelineno-29-15></a><span class=sd>        model: TRM model</span>
</span><span id=__span-29-16><a id=__codelineno-29-16 name=__codelineno-29-16 href=#__codelineno-29-16></a><span class=sd>        train_loader: DataLoader for training data</span>
</span><span id=__span-29-17><a id=__codelineno-29-17 name=__codelineno-29-17 href=#__codelineno-29-17></a><span class=sd>        optimizer: Optimizer (e.g., AdamW)</span>
</span><span id=__span-29-18><a id=__codelineno-29-18 name=__codelineno-29-18 href=#__codelineno-29-18></a><span class=sd>        scheduler: Learning rate scheduler</span>
</span><span id=__span-29-19><a id=__codelineno-29-19 name=__codelineno-29-19 href=#__codelineno-29-19></a><span class=sd>        ema: Exponential moving average</span>
</span><span id=__span-29-20><a id=__codelineno-29-20 name=__codelineno-29-20 href=#__codelineno-29-20></a><span class=sd>        device: torch.device</span>
</span><span id=__span-29-21><a id=__codelineno-29-21 name=__codelineno-29-21 href=#__codelineno-29-21></a><span class=sd>        n_supervision: Number of supervision cycles (16 in paper)</span>
</span><span id=__span-29-22><a id=__codelineno-29-22 name=__codelineno-29-22 href=#__codelineno-29-22></a><span class=sd>        max_grad_norm: Gradient clipping threshold</span>
</span><span id=__span-29-23><a id=__codelineno-29-23 name=__codelineno-29-23 href=#__codelineno-29-23></a>
</span><span id=__span-29-24><a id=__codelineno-29-24 name=__codelineno-29-24 href=#__codelineno-29-24></a><span class=sd>    Returns:</span>
</span><span id=__span-29-25><a id=__codelineno-29-25 name=__codelineno-29-25 href=#__codelineno-29-25></a><span class=sd>        average_loss: Loss for this epoch</span>
</span><span id=__span-29-26><a id=__codelineno-29-26 name=__codelineno-29-26 href=#__codelineno-29-26></a><span class=sd>    """</span>
</span><span id=__span-29-27><a id=__codelineno-29-27 name=__codelineno-29-27 href=#__codelineno-29-27></a>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span><span id=__span-29-28><a id=__codelineno-29-28 name=__codelineno-29-28 href=#__codelineno-29-28></a>    <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-29-29><a id=__codelineno-29-29 name=__codelineno-29-29 href=#__codelineno-29-29></a>    <span class=n>num_batches</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-29-30><a id=__codelineno-29-30 name=__codelineno-29-30 href=#__codelineno-29-30></a>
</span><span id=__span-29-31><a id=__codelineno-29-31 name=__codelineno-29-31 href=#__codelineno-29-31></a>    <span class=k>for</span> <span class=n>question_ids</span><span class=p>,</span> <span class=n>answer_ids</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
</span><span id=__span-29-32><a id=__codelineno-29-32 name=__codelineno-29-32 href=#__codelineno-29-32></a>        <span class=n>question_ids</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-29-33><a id=__codelineno-29-33 name=__codelineno-29-33 href=#__codelineno-29-33></a>        <span class=n>answer_ids</span> <span class=o>=</span> <span class=n>answer_ids</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-29-34><a id=__codelineno-29-34 name=__codelineno-29-34 href=#__codelineno-29-34></a>
</span><span id=__span-29-35><a id=__codelineno-29-35 name=__codelineno-29-35 href=#__codelineno-29-35></a>        <span class=n>batch_size</span> <span class=o>=</span> <span class=n>question_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-29-36><a id=__codelineno-29-36 name=__codelineno-29-36 href=#__codelineno-29-36></a>
</span><span id=__span-29-37><a id=__codelineno-29-37 name=__codelineno-29-37 href=#__codelineno-29-37></a>        <span class=c1># Initialize streams</span>
</span><span id=__span-29-38><a id=__codelineno-29-38 name=__codelineno-29-38 href=#__codelineno-29-38></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>question_ids</span><span class=p>)</span>
</span><span id=__span-29-39><a id=__codelineno-29-39 name=__codelineno-29-39 href=#__codelineno-29-39></a>        <span class=n>y</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>question_ids</span><span class=p>)</span>  <span class=c1># Start with input</span>
</span><span id=__span-29-40><a id=__codelineno-29-40 name=__codelineno-29-40 href=#__codelineno-29-40></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>d_model</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.02</span>
</span><span id=__span-29-41><a id=__codelineno-29-41 name=__codelineno-29-41 href=#__codelineno-29-41></a>
</span><span id=__span-29-42><a id=__codelineno-29-42 name=__codelineno-29-42 href=#__codelineno-29-42></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span><span id=__span-29-43><a id=__codelineno-29-43 name=__codelineno-29-43 href=#__codelineno-29-43></a>        <span class=n>cycle_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span><span id=__span-29-44><a id=__codelineno-29-44 name=__codelineno-29-44 href=#__codelineno-29-44></a>
</span><span id=__span-29-45><a id=__codelineno-29-45 name=__codelineno-29-45 href=#__codelineno-29-45></a>        <span class=c1># Deep supervision: multiple improvement cycles</span>
</span><span id=__span-29-46><a id=__codelineno-29-46 name=__codelineno-29-46 href=#__codelineno-29-46></a>        <span class=k>for</span> <span class=n>sup_step</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_supervision</span><span class=p>):</span>
</span><span id=__span-29-47><a id=__codelineno-29-47 name=__codelineno-29-47 href=#__codelineno-29-47></a>            <span class=c1># Phase 1: Reasoning</span>
</span><span id=__span-29-48><a id=__codelineno-29-48 name=__codelineno-29-48 href=#__codelineno-29-48></a>            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>n_reasoning_steps</span><span class=p>):</span>
</span><span id=__span-29-49><a id=__codelineno-29-49 name=__codelineno-29-49 href=#__codelineno-29-49></a>                <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-29-50><a id=__codelineno-29-50 name=__codelineno-29-50 href=#__codelineno-29-50></a>                <span class=n>z</span> <span class=o>=</span> <span class=n>z_new</span>
</span><span id=__span-29-51><a id=__codelineno-29-51 name=__codelineno-29-51 href=#__codelineno-29-51></a>
</span><span id=__span-29-52><a id=__codelineno-29-52 name=__codelineno-29-52 href=#__codelineno-29-52></a>            <span class=c1># Phase 2: Refinement</span>
</span><span id=__span-29-53><a id=__codelineno-29-53 name=__codelineno-29-53 href=#__codelineno-29-53></a>            <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>n_refinement_steps</span><span class=p>):</span>
</span><span id=__span-29-54><a id=__codelineno-29-54 name=__codelineno-29-54 href=#__codelineno-29-54></a>                <span class=n>x_new</span><span class=p>,</span> <span class=n>y_new</span><span class=p>,</span> <span class=n>z_new</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>forward_pass</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-29-55><a id=__codelineno-29-55 name=__codelineno-29-55 href=#__codelineno-29-55></a>                <span class=n>y</span> <span class=o>=</span> <span class=n>y_new</span>
</span><span id=__span-29-56><a id=__codelineno-29-56 name=__codelineno-29-56 href=#__codelineno-29-56></a>
</span><span id=__span-29-57><a id=__codelineno-29-57 name=__codelineno-29-57 href=#__codelineno-29-57></a>            <span class=c1># Compute loss for this cycle</span>
</span><span id=__span-29-58><a id=__codelineno-29-58 name=__codelineno-29-58 href=#__codelineno-29-58></a>            <span class=n>logits</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>reverse_embedding</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span><span id=__span-29-59><a id=__codelineno-29-59 name=__codelineno-29-59 href=#__codelineno-29-59></a>            <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span>
</span><span id=__span-29-60><a id=__codelineno-29-60 name=__codelineno-29-60 href=#__codelineno-29-60></a>                <span class=n>logits</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>logits</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)),</span>
</span><span id=__span-29-61><a id=__codelineno-29-61 name=__codelineno-29-61 href=#__codelineno-29-61></a>                <span class=n>answer_ids</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span>
</span><span id=__span-29-62><a id=__codelineno-29-62 name=__codelineno-29-62 href=#__codelineno-29-62></a>                <span class=n>ignore_index</span><span class=o>=</span><span class=mi>0</span>  <span class=c1># Ignore padding</span>
</span><span id=__span-29-63><a id=__codelineno-29-63 name=__codelineno-29-63 href=#__codelineno-29-63></a>            <span class=p>)</span>
</span><span id=__span-29-64><a id=__codelineno-29-64 name=__codelineno-29-64 href=#__codelineno-29-64></a>
</span><span id=__span-29-65><a id=__codelineno-29-65 name=__codelineno-29-65 href=#__codelineno-29-65></a>            <span class=c1># Weight: increase for later supervision steps</span>
</span><span id=__span-29-66><a id=__codelineno-29-66 name=__codelineno-29-66 href=#__codelineno-29-66></a>            <span class=n>weight</span> <span class=o>=</span> <span class=p>(</span><span class=n>sup_step</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=n>n_supervision</span>
</span><span id=__span-29-67><a id=__codelineno-29-67 name=__codelineno-29-67 href=#__codelineno-29-67></a>            <span class=n>cycle_loss</span> <span class=o>+=</span> <span class=n>weight</span> <span class=o>*</span> <span class=n>loss</span>
</span><span id=__span-29-68><a id=__codelineno-29-68 name=__codelineno-29-68 href=#__codelineno-29-68></a>
</span><span id=__span-29-69><a id=__codelineno-29-69 name=__codelineno-29-69 href=#__codelineno-29-69></a>            <span class=c1># Detach to prevent backprop through all history</span>
</span><span id=__span-29-70><a id=__codelineno-29-70 name=__codelineno-29-70 href=#__codelineno-29-70></a>            <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-29-71><a id=__codelineno-29-71 name=__codelineno-29-71 href=#__codelineno-29-71></a>            <span class=n>z</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span><span id=__span-29-72><a id=__codelineno-29-72 name=__codelineno-29-72 href=#__codelineno-29-72></a>
</span><span id=__span-29-73><a id=__codelineno-29-73 name=__codelineno-29-73 href=#__codelineno-29-73></a>        <span class=c1># Backpropagate</span>
</span><span id=__span-29-74><a id=__codelineno-29-74 name=__codelineno-29-74 href=#__codelineno-29-74></a>        <span class=n>cycle_loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span><span id=__span-29-75><a id=__codelineno-29-75 name=__codelineno-29-75 href=#__codelineno-29-75></a>
</span><span id=__span-29-76><a id=__codelineno-29-76 name=__codelineno-29-76 href=#__codelineno-29-76></a>        <span class=c1># Gradient clipping (crucial for stability!)</span>
</span><span id=__span-29-77><a id=__codelineno-29-77 name=__codelineno-29-77 href=#__codelineno-29-77></a>        <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_grad_norm</span><span class=p>)</span>
</span><span id=__span-29-78><a id=__codelineno-29-78 name=__codelineno-29-78 href=#__codelineno-29-78></a>
</span><span id=__span-29-79><a id=__codelineno-29-79 name=__codelineno-29-79 href=#__codelineno-29-79></a>        <span class=c1># Update weights</span>
</span><span id=__span-29-80><a id=__codelineno-29-80 name=__codelineno-29-80 href=#__codelineno-29-80></a>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-29-81><a id=__codelineno-29-81 name=__codelineno-29-81 href=#__codelineno-29-81></a>        <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span><span id=__span-29-82><a id=__codelineno-29-82 name=__codelineno-29-82 href=#__codelineno-29-82></a>
</span><span id=__span-29-83><a id=__codelineno-29-83 name=__codelineno-29-83 href=#__codelineno-29-83></a>        <span class=c1># Update EMA</span>
</span><span id=__span-29-84><a id=__codelineno-29-84 name=__codelineno-29-84 href=#__codelineno-29-84></a>        <span class=n>ema</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>
</span><span id=__span-29-85><a id=__codelineno-29-85 name=__codelineno-29-85 href=#__codelineno-29-85></a>
</span><span id=__span-29-86><a id=__codelineno-29-86 name=__codelineno-29-86 href=#__codelineno-29-86></a>        <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>cycle_loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-29-87><a id=__codelineno-29-87 name=__codelineno-29-87 href=#__codelineno-29-87></a>        <span class=n>num_batches</span> <span class=o>+=</span> <span class=mi>1</span>
</span><span id=__span-29-88><a id=__codelineno-29-88 name=__codelineno-29-88 href=#__codelineno-29-88></a>
</span><span id=__span-29-89><a id=__codelineno-29-89 name=__codelineno-29-89 href=#__codelineno-29-89></a>    <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=n>num_batches</span>
</span></code></pre></div> <h3 id=complete-training-script>Complete Training Script<a class=headerlink href=#complete-training-script title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a><span class=sd>    Complete training script for TRM.</span>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a><span class=sd>    """</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a>    <span class=c1># Setup</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a>    <span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>'cuda'</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>'cpu'</span><span class=p>)</span>
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Using device: </span><span class=si>{</span><span class=n>device</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-8><a id=__codelineno-30-8 name=__codelineno-30-8 href=#__codelineno-30-8></a>
</span><span id=__span-30-9><a id=__codelineno-30-9 name=__codelineno-30-9 href=#__codelineno-30-9></a>    <span class=c1># Hyperparameters</span>
</span><span id=__span-30-10><a id=__codelineno-30-10 name=__codelineno-30-10 href=#__codelineno-30-10></a>    <span class=n>vocab_size</span> <span class=o>=</span> <span class=mi>12</span>
</span><span id=__span-30-11><a id=__codelineno-30-11 name=__codelineno-30-11 href=#__codelineno-30-11></a>    <span class=n>d_model</span> <span class=o>=</span> <span class=mi>256</span>
</span><span id=__span-30-12><a id=__codelineno-30-12 name=__codelineno-30-12 href=#__codelineno-30-12></a>    <span class=n>n_layers</span> <span class=o>=</span> <span class=mi>2</span>
</span><span id=__span-30-13><a id=__codelineno-30-13 name=__codelineno-30-13 href=#__codelineno-30-13></a>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>32</span>
</span><span id=__span-30-14><a id=__codelineno-30-14 name=__codelineno-30-14 href=#__codelineno-30-14></a>    <span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>1e-4</span>
</span><span id=__span-30-15><a id=__codelineno-30-15 name=__codelineno-30-15 href=#__codelineno-30-15></a>    <span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>100</span>
</span><span id=__span-30-16><a id=__codelineno-30-16 name=__codelineno-30-16 href=#__codelineno-30-16></a>
</span><span id=__span-30-17><a id=__codelineno-30-17 name=__codelineno-30-17 href=#__codelineno-30-17></a>    <span class=c1># Create model</span>
</span><span id=__span-30-18><a id=__codelineno-30-18 name=__codelineno-30-18 href=#__codelineno-30-18></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>create_trm_mlp</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>d_model</span><span class=p>,</span> <span class=n>n_layers</span><span class=p>)</span>
</span><span id=__span-30-19><a id=__codelineno-30-19 name=__codelineno-30-19 href=#__codelineno-30-19></a>    <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-30-20><a id=__codelineno-30-20 name=__codelineno-30-20 href=#__codelineno-30-20></a>
</span><span id=__span-30-21><a id=__codelineno-30-21 name=__codelineno-30-21 href=#__codelineno-30-21></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Parameters: </span><span class=si>{</span><span class=n>model</span><span class=o>.</span><span class=n>count_parameters</span><span class=p>()</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mf>1e6</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>M"</span><span class=p>)</span>
</span><span id=__span-30-22><a id=__codelineno-30-22 name=__codelineno-30-22 href=#__codelineno-30-22></a>
</span><span id=__span-30-23><a id=__codelineno-30-23 name=__codelineno-30-23 href=#__codelineno-30-23></a>    <span class=c1># Optimizer and scheduler</span>
</span><span id=__span-30-24><a id=__codelineno-30-24 name=__codelineno-30-24 href=#__codelineno-30-24></a>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>)</span>
</span><span id=__span-30-25><a id=__codelineno-30-25 name=__codelineno-30-25 href=#__codelineno-30-25></a>    <span class=n>scheduler</span> <span class=o>=</span> <span class=n>get_lr_scheduler</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>warmup_steps</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>
</span><span id=__span-30-26><a id=__codelineno-30-26 name=__codelineno-30-26 href=#__codelineno-30-26></a>
</span><span id=__span-30-27><a id=__codelineno-30-27 name=__codelineno-30-27 href=#__codelineno-30-27></a>    <span class=c1># EMA for stability</span>
</span><span id=__span-30-28><a id=__codelineno-30-28 name=__codelineno-30-28 href=#__codelineno-30-28></a>    <span class=n>ema</span> <span class=o>=</span> <span class=n>ExponentialMovingAverage</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>decay</span><span class=o>=</span><span class=mf>0.999</span><span class=p>)</span>
</span><span id=__span-30-29><a id=__codelineno-30-29 name=__codelineno-30-29 href=#__codelineno-30-29></a>
</span><span id=__span-30-30><a id=__codelineno-30-30 name=__codelineno-30-30 href=#__codelineno-30-30></a>    <span class=c1># Loss function</span>
</span><span id=__span-30-31><a id=__codelineno-30-31 name=__codelineno-30-31 href=#__codelineno-30-31></a>    <span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span><span class=n>ignore_index</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-30-32><a id=__codelineno-30-32 name=__codelineno-30-32 href=#__codelineno-30-32></a>
</span><span id=__span-30-33><a id=__codelineno-30-33 name=__codelineno-30-33 href=#__codelineno-30-33></a>    <span class=c1># Training loop</span>
</span><span id=__span-30-34><a id=__codelineno-30-34 name=__codelineno-30-34 href=#__codelineno-30-34></a>    <span class=n>best_val_loss</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=s1>'inf'</span><span class=p>)</span>
</span><span id=__span-30-35><a id=__codelineno-30-35 name=__codelineno-30-35 href=#__codelineno-30-35></a>
</span><span id=__span-30-36><a id=__codelineno-30-36 name=__codelineno-30-36 href=#__codelineno-30-36></a>    <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span><span id=__span-30-37><a id=__codelineno-30-37 name=__codelineno-30-37 href=#__codelineno-30-37></a>        <span class=c1># Train</span>
</span><span id=__span-30-38><a id=__codelineno-30-38 name=__codelineno-30-38 href=#__codelineno-30-38></a>        <span class=n>train_loss</span> <span class=o>=</span> <span class=n>train_with_deep_supervision</span><span class=p>(</span>
</span><span id=__span-30-39><a id=__codelineno-30-39 name=__codelineno-30-39 href=#__codelineno-30-39></a>            <span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>scheduler</span><span class=p>,</span> <span class=n>ema</span><span class=p>,</span> <span class=n>device</span>
</span><span id=__span-30-40><a id=__codelineno-30-40 name=__codelineno-30-40 href=#__codelineno-30-40></a>        <span class=p>)</span>
</span><span id=__span-30-41><a id=__codelineno-30-41 name=__codelineno-30-41 href=#__codelineno-30-41></a>
</span><span id=__span-30-42><a id=__codelineno-30-42 name=__codelineno-30-42 href=#__codelineno-30-42></a>        <span class=c1># Validate with EMA weights</span>
</span><span id=__span-30-43><a id=__codelineno-30-43 name=__codelineno-30-43 href=#__codelineno-30-43></a>        <span class=n>ema</span><span class=o>.</span><span class=n>apply_shadow</span><span class=p>()</span>
</span><span id=__span-30-44><a id=__codelineno-30-44 name=__codelineno-30-44 href=#__codelineno-30-44></a>        <span class=n>val_loss</span> <span class=o>=</span> <span class=n>evaluate</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>val_loader</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>device</span><span class=p>)</span>
</span><span id=__span-30-45><a id=__codelineno-30-45 name=__codelineno-30-45 href=#__codelineno-30-45></a>        <span class=n>ema</span><span class=o>.</span><span class=n>restore</span><span class=p>()</span>
</span><span id=__span-30-46><a id=__codelineno-30-46 name=__codelineno-30-46 href=#__codelineno-30-46></a>
</span><span id=__span-30-47><a id=__codelineno-30-47 name=__codelineno-30-47 href=#__codelineno-30-47></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-48><a id=__codelineno-30-48 name=__codelineno-30-48 href=#__codelineno-30-48></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Train Loss: </span><span class=si>{</span><span class=n>train_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-49><a id=__codelineno-30-49 name=__codelineno-30-49 href=#__codelineno-30-49></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  Val Loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-50><a id=__codelineno-30-50 name=__codelineno-30-50 href=#__codelineno-30-50></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"  LR: </span><span class=si>{</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>'lr'</span><span class=p>]</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-51><a id=__codelineno-30-51 name=__codelineno-30-51 href=#__codelineno-30-51></a>
</span><span id=__span-30-52><a id=__codelineno-30-52 name=__codelineno-30-52 href=#__codelineno-30-52></a>        <span class=c1># Save best model</span>
</span><span id=__span-30-53><a id=__codelineno-30-53 name=__codelineno-30-53 href=#__codelineno-30-53></a>        <span class=k>if</span> <span class=n>val_loss</span> <span class=o>&lt;</span> <span class=n>best_val_loss</span><span class=p>:</span>
</span><span id=__span-30-54><a id=__codelineno-30-54 name=__codelineno-30-54 href=#__codelineno-30-54></a>            <span class=n>best_val_loss</span> <span class=o>=</span> <span class=n>val_loss</span>
</span><span id=__span-30-55><a id=__codelineno-30-55 name=__codelineno-30-55 href=#__codelineno-30-55></a>            <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
</span><span id=__span-30-56><a id=__codelineno-30-56 name=__codelineno-30-56 href=#__codelineno-30-56></a>                <span class=s1>'epoch'</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span><span id=__span-30-57><a id=__codelineno-30-57 name=__codelineno-30-57 href=#__codelineno-30-57></a>                <span class=s1>'model_state_dict'</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span><span id=__span-30-58><a id=__codelineno-30-58 name=__codelineno-30-58 href=#__codelineno-30-58></a>                <span class=s1>'ema_shadow'</span><span class=p>:</span> <span class=n>ema</span><span class=o>.</span><span class=n>shadow</span><span class=p>,</span>
</span><span id=__span-30-59><a id=__codelineno-30-59 name=__codelineno-30-59 href=#__codelineno-30-59></a>                <span class=s1>'optimizer_state_dict'</span><span class=p>:</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span><span id=__span-30-60><a id=__codelineno-30-60 name=__codelineno-30-60 href=#__codelineno-30-60></a>                <span class=s1>'scheduler_state_dict'</span><span class=p>:</span> <span class=n>scheduler</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span><span id=__span-30-61><a id=__codelineno-30-61 name=__codelineno-30-61 href=#__codelineno-30-61></a>                <span class=s1>'val_loss'</span><span class=p>:</span> <span class=n>val_loss</span><span class=p>,</span>
</span><span id=__span-30-62><a id=__codelineno-30-62 name=__codelineno-30-62 href=#__codelineno-30-62></a>            <span class=p>},</span> <span class=s1>'best_trm_model.pt'</span><span class=p>)</span>
</span><span id=__span-30-63><a id=__codelineno-30-63 name=__codelineno-30-63 href=#__codelineno-30-63></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"  Saved new best model!"</span><span class=p>)</span>
</span><span id=__span-30-64><a id=__codelineno-30-64 name=__codelineno-30-64 href=#__codelineno-30-64></a>
</span><span id=__span-30-65><a id=__codelineno-30-65 name=__codelineno-30-65 href=#__codelineno-30-65></a><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>"__main__"</span><span class=p>:</span>
</span><span id=__span-30-66><a id=__codelineno-30-66 name=__codelineno-30-66 href=#__codelineno-30-66></a>    <span class=n>main</span><span class=p>()</span>
</span></code></pre></div> <p>This is a complete, working implementation of TRM. You can run this code to train your own model!</p> <hr> <h2 id=14-getting-started-practical-setup-guide>14. Getting Started: Practical Setup Guide<a class=headerlink href=#14-getting-started-practical-setup-guide title="Permanent link">¶</a></h2> <p>Let's get you set up to actually train and use TRM.</p> <h3 id=installation>Installation<a class=headerlink href=#installation title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a><span class=c1># Clone the TinyRecursiveModels repository</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2 href=#__codelineno-31-2></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/alexjmartineau/TinyRecursiveModels.git
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3 href=#__codelineno-31-3></a><span class=nb>cd</span><span class=w> </span>TinyRecursiveModels
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4 href=#__codelineno-31-4></a>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5 href=#__codelineno-31-5></a><span class=c1># Create virtual environment</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6 href=#__codelineno-31-6></a>python<span class=w> </span>-m<span class=w> </span>venv<span class=w> </span>trm_env
</span><span id=__span-31-7><a id=__codelineno-31-7 name=__codelineno-31-7 href=#__codelineno-31-7></a><span class=nb>source</span><span class=w> </span>trm_env/bin/activate<span class=w>  </span><span class=c1># On Windows: trm_env\Scripts\activate</span>
</span><span id=__span-31-8><a id=__codelineno-31-8 name=__codelineno-31-8 href=#__codelineno-31-8></a>
</span><span id=__span-31-9><a id=__codelineno-31-9 name=__codelineno-31-9 href=#__codelineno-31-9></a><span class=c1># Install dependencies</span>
</span><span id=__span-31-10><a id=__codelineno-31-10 name=__codelineno-31-10 href=#__codelineno-31-10></a>pip<span class=w> </span>install<span class=w> </span>-r<span class=w> </span>requirements.txt
</span><span id=__span-31-11><a id=__codelineno-31-11 name=__codelineno-31-11 href=#__codelineno-31-11></a>
</span><span id=__span-31-12><a id=__codelineno-31-12 name=__codelineno-31-12 href=#__codelineno-31-12></a><span class=c1># Core dependencies:</span>
</span><span id=__span-31-13><a id=__codelineno-31-13 name=__codelineno-31-13 href=#__codelineno-31-13></a><span class=c1># - torch &gt;= 2.0.0</span>
</span><span id=__span-31-14><a id=__codelineno-31-14 name=__codelineno-31-14 href=#__codelineno-31-14></a><span class=c1># - numpy &gt;= 1.24.0</span>
</span><span id=__span-31-15><a id=__codelineno-31-15 name=__codelineno-31-15 href=#__codelineno-31-15></a><span class=c1># - tqdm (for progress bars)</span>
</span><span id=__span-31-16><a id=__codelineno-31-16 name=__codelineno-31-16 href=#__codelineno-31-16></a><span class=c1># - wandb (optional, for logging)</span>
</span></code></pre></div> <h3 id=dataset-preparation>Dataset Preparation<a class=headerlink href=#dataset-preparation title="Permanent link">¶</a></h3> <p><strong>For Sudoku:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a><span class=kn>from</span><span class=w> </span><span class=nn>puzzle_dataset</span><span class=w> </span><span class=kn>import</span> <span class=n>SudokuDataset</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a><span class=c1># The repository includes Sudoku puzzle generators</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a><span class=c1># Download pre-generated puzzles or generate your own</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a><span class=c1># Training set: 1000 extreme Sudoku puzzles</span>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a><span class=c1># Test set: 423,000 puzzles for evaluation</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a><span class=n>dataset</span> <span class=o>=</span> <span class=n>SudokuDataset</span><span class=p>(</span>
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11 href=#__codelineno-32-11></a>    <span class=n>data_dir</span><span class=o>=</span><span class=s1>'data/sudoku'</span><span class=p>,</span>
</span><span id=__span-32-12><a id=__codelineno-32-12 name=__codelineno-32-12 href=#__codelineno-32-12></a>    <span class=n>split</span><span class=o>=</span><span class=s1>'train'</span><span class=p>,</span>
</span><span id=__span-32-13><a id=__codelineno-32-13 name=__codelineno-32-13 href=#__codelineno-32-13></a>    <span class=n>augmentations</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># Apply dihedral transformations and recoloring</span>
</span><span id=__span-32-14><a id=__codelineno-32-14 name=__codelineno-32-14 href=#__codelineno-32-14></a><span class=p>)</span>
</span><span id=__span-32-15><a id=__codelineno-32-15 name=__codelineno-32-15 href=#__codelineno-32-15></a>
</span><span id=__span-32-16><a id=__codelineno-32-16 name=__codelineno-32-16 href=#__codelineno-32-16></a><span class=c1># Data augmentation for Sudoku:</span>
</span><span id=__span-32-17><a id=__codelineno-32-17 name=__codelineno-32-17 href=#__codelineno-32-17></a><span class=c1># - 72 dihedral transformations (rotations + flips + reflections)</span>
</span><span id=__span-32-18><a id=__codelineno-32-18 name=__codelineno-32-18 href=#__codelineno-32-18></a><span class=c1># - 9 color permutations</span>
</span><span id=__span-32-19><a id=__codelineno-32-19 name=__codelineno-32-19 href=#__codelineno-32-19></a><span class=c1># Total: 72 variants per puzzle</span>
</span><span id=__span-32-20><a id=__codelineno-32-20 name=__codelineno-32-20 href=#__codelineno-32-20></a>
</span><span id=__span-32-21><a id=__codelineno-32-21 name=__codelineno-32-21 href=#__codelineno-32-21></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Dataset size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-32-22><a id=__codelineno-32-22 name=__codelineno-32-22 href=#__codelineno-32-22></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"With augmentation: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>dataset</span><span class=p>)</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>72</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span></code></pre></div> <p><strong>For ARC-AGI:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=c1># Download ARC-AGI datasets</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a>wget<span class=w> </span>https://github.com/fchollet/ARC-AGI/archive/refs/heads/master.zip
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3 href=#__codelineno-33-3></a>unzip<span class=w> </span>master.zip
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4 href=#__codelineno-33-4></a>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5 href=#__codelineno-33-5></a><span class=c1># The repository includes data loaders for ARC</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6 href=#__codelineno-33-6></a><span class=c1># Each task has:</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7 href=#__codelineno-33-7></a><span class=c1># - 2-3 training examples (input-output pairs)</span>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8 href=#__codelineno-33-8></a><span class=c1># - 1-2 test inputs (predict outputs)</span>
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=kn>from</span><span class=w> </span><span class=nn>dataset.arc_dataset</span><span class=w> </span><span class=kn>import</span> <span class=n>ARCDataset</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a><span class=n>arc_dataset</span> <span class=o>=</span> <span class=n>ARCDataset</span><span class=p>(</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a>    <span class=n>data_dir</span><span class=o>=</span><span class=s1>'ARC-AGI-master/data'</span><span class=p>,</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>    <span class=n>split</span><span class=o>=</span><span class=s1>'training'</span><span class=p>,</span>  <span class=c1># or 'evaluation'</span>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a>    <span class=n>augmentations</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a>    <span class=n>max_augmentations</span><span class=o>=</span><span class=mi>1000</span>  <span class=c1># Up to 1000 augmented versions per task</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a><span class=p>)</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a><span class=c1># ARC augmentation:</span>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11 href=#__codelineno-34-11></a><span class=c1># - Color permutations (swap color mappings)</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12 href=#__codelineno-34-12></a><span class=c1># - Dihedral transformations (rotations and flips)</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13 href=#__codelineno-34-13></a><span class=c1># - Spatial translations (move grids within 30x30 space)</span>
</span></code></pre></div> <h3 id=grid-representation>Grid Representation<a class=headerlink href=#grid-representation title="Permanent link">¶</a></h3> <p>Understanding how grids are tokenized:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=k>def</span><span class=w> </span><span class=nf>tokenize_grid</span><span class=p>(</span><span class=n>grid</span><span class=p>,</span> <span class=n>max_size</span><span class=o>=</span><span class=mi>30</span><span class=p>):</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3 href=#__codelineno-35-3></a><span class=sd>    Convert a grid to token sequence.</span>
</span><span id=__span-35-4><a id=__codelineno-35-4 name=__codelineno-35-4 href=#__codelineno-35-4></a>
</span><span id=__span-35-5><a id=__codelineno-35-5 name=__codelineno-35-5 href=#__codelineno-35-5></a><span class=sd>    Args:</span>
</span><span id=__span-35-6><a id=__codelineno-35-6 name=__codelineno-35-6 href=#__codelineno-35-6></a><span class=sd>        grid: [H, W] numpy array with values 0-9</span>
</span><span id=__span-35-7><a id=__codelineno-35-7 name=__codelineno-35-7 href=#__codelineno-35-7></a><span class=sd>        max_size: Maximum grid dimension (30 for ARC-AGI)</span>
</span><span id=__span-35-8><a id=__codelineno-35-8 name=__codelineno-35-8 href=#__codelineno-35-8></a>
</span><span id=__span-35-9><a id=__codelineno-35-9 name=__codelineno-35-9 href=#__codelineno-35-9></a><span class=sd>    Returns:</span>
</span><span id=__span-35-10><a id=__codelineno-35-10 name=__codelineno-35-10 href=#__codelineno-35-10></a><span class=sd>        tokens: [max_size * max_size] with padding</span>
</span><span id=__span-35-11><a id=__codelineno-35-11 name=__codelineno-35-11 href=#__codelineno-35-11></a><span class=sd>    """</span>
</span><span id=__span-35-12><a id=__codelineno-35-12 name=__codelineno-35-12 href=#__codelineno-35-12></a>    <span class=n>H</span><span class=p>,</span> <span class=n>W</span> <span class=o>=</span> <span class=n>grid</span><span class=o>.</span><span class=n>shape</span>
</span><span id=__span-35-13><a id=__codelineno-35-13 name=__codelineno-35-13 href=#__codelineno-35-13></a>
</span><span id=__span-35-14><a id=__codelineno-35-14 name=__codelineno-35-14 href=#__codelineno-35-14></a>    <span class=c1># Flatten grid</span>
</span><span id=__span-35-15><a id=__codelineno-35-15 name=__codelineno-35-15 href=#__codelineno-35-15></a>    <span class=n>flat</span> <span class=o>=</span> <span class=n>grid</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>  <span class=c1># [H*W]</span>
</span><span id=__span-35-16><a id=__codelineno-35-16 name=__codelineno-35-16 href=#__codelineno-35-16></a>
</span><span id=__span-35-17><a id=__codelineno-35-17 name=__codelineno-35-17 href=#__codelineno-35-17></a>    <span class=c1># Add 2 to shift (0=pad, 1=EOS, 2-11=colors 0-9)</span>
</span><span id=__span-35-18><a id=__codelineno-35-18 name=__codelineno-35-18 href=#__codelineno-35-18></a>    <span class=n>tokens</span> <span class=o>=</span> <span class=n>flat</span> <span class=o>+</span> <span class=mi>2</span>
</span><span id=__span-35-19><a id=__codelineno-35-19 name=__codelineno-35-19 href=#__codelineno-35-19></a>
</span><span id=__span-35-20><a id=__codelineno-35-20 name=__codelineno-35-20 href=#__codelineno-35-20></a>    <span class=c1># Add EOS markers to delineate grid boundary</span>
</span><span id=__span-35-21><a id=__codelineno-35-21 name=__codelineno-35-21 href=#__codelineno-35-21></a>    <span class=c1># Create padded grid with EOS on right and bottom</span>
</span><span id=__span-35-22><a id=__codelineno-35-22 name=__codelineno-35-22 href=#__codelineno-35-22></a>    <span class=n>padded</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=n>max_size</span><span class=p>,</span> <span class=n>max_size</span><span class=p>),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int64</span><span class=p>)</span>
</span><span id=__span-35-23><a id=__codelineno-35-23 name=__codelineno-35-23 href=#__codelineno-35-23></a>    <span class=n>padded</span><span class=p>[:</span><span class=n>H</span><span class=p>,</span> <span class=p>:</span><span class=n>W</span><span class=p>]</span> <span class=o>=</span> <span class=n>tokens</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span><span id=__span-35-24><a id=__codelineno-35-24 name=__codelineno-35-24 href=#__codelineno-35-24></a>    <span class=n>padded</span><span class=p>[</span><span class=n>H</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=mi>1</span>  <span class=c1># EOS marker on bottom</span>
</span><span id=__span-35-25><a id=__codelineno-35-25 name=__codelineno-35-25 href=#__codelineno-35-25></a>    <span class=n>padded</span><span class=p>[:,</span> <span class=n>W</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>  <span class=c1># EOS marker on right</span>
</span><span id=__span-35-26><a id=__codelineno-35-26 name=__codelineno-35-26 href=#__codelineno-35-26></a>
</span><span id=__span-35-27><a id=__codelineno-35-27 name=__codelineno-35-27 href=#__codelineno-35-27></a>    <span class=k>return</span> <span class=n>padded</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span><span id=__span-35-28><a id=__codelineno-35-28 name=__codelineno-35-28 href=#__codelineno-35-28></a>
</span><span id=__span-35-29><a id=__codelineno-35-29 name=__codelineno-35-29 href=#__codelineno-35-29></a><span class=c1># Example: 2x2 grid</span>
</span><span id=__span-35-30><a id=__codelineno-35-30 name=__codelineno-35-30 href=#__codelineno-35-30></a><span class=n>grid</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>]])</span>
</span><span id=__span-35-31><a id=__codelineno-35-31 name=__codelineno-35-31 href=#__codelineno-35-31></a><span class=n>tokens</span> <span class=o>=</span> <span class=n>tokenize_grid</span><span class=p>(</span><span class=n>grid</span><span class=p>,</span> <span class=n>max_size</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>
</span><span id=__span-35-32><a id=__codelineno-35-32 name=__codelineno-35-32 href=#__codelineno-35-32></a><span class=nb>print</span><span class=p>(</span><span class=n>tokens</span><span class=p>)</span>
</span><span id=__span-35-33><a id=__codelineno-35-33 name=__codelineno-35-33 href=#__codelineno-35-33></a><span class=c1># Output: [7, 5, 1, 0, 8, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]</span>
</span><span id=__span-35-34><a id=__codelineno-35-34 name=__codelineno-35-34 href=#__codelineno-35-34></a><span class=c1>#         [5+2, 3+2, EOS, pad, 6+2, 0+2, EOS, pad, ...]</span>
</span></code></pre></div> <h3 id=training-your-first-trm>Training Your First TRM<a class=headerlink href=#training-your-first-trm title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a><span class=c1># Train on Sudoku (fastest, good for testing)</span>
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>python<span class=w> </span>pretrain.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a><span class=w>    </span>--dataset<span class=w> </span>sudoku<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a><span class=w>    </span>--model_type<span class=w> </span>mlp<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-5><a id=__codelineno-36-5 name=__codelineno-36-5 href=#__codelineno-36-5></a><span class=w>    </span>--d_model<span class=w> </span><span class=m>256</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-6><a id=__codelineno-36-6 name=__codelineno-36-6 href=#__codelineno-36-6></a><span class=w>    </span>--n_layers<span class=w> </span><span class=m>2</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-7><a id=__codelineno-36-7 name=__codelineno-36-7 href=#__codelineno-36-7></a><span class=w>    </span>--n_reasoning_steps<span class=w> </span><span class=m>8</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-8><a id=__codelineno-36-8 name=__codelineno-36-8 href=#__codelineno-36-8></a><span class=w>    </span>--n_refinement_steps<span class=w> </span><span class=m>16</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-9><a id=__codelineno-36-9 name=__codelineno-36-9 href=#__codelineno-36-9></a><span class=w>    </span>--n_supervision<span class=w> </span><span class=m>16</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-10><a id=__codelineno-36-10 name=__codelineno-36-10 href=#__codelineno-36-10></a><span class=w>    </span>--batch_size<span class=w> </span><span class=m>32</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-11><a id=__codelineno-36-11 name=__codelineno-36-11 href=#__codelineno-36-11></a><span class=w>    </span>--learning_rate<span class=w> </span>1e-4<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-12><a id=__codelineno-36-12 name=__codelineno-36-12 href=#__codelineno-36-12></a><span class=w>    </span>--num_epochs<span class=w> </span><span class=m>100</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-13><a id=__codelineno-36-13 name=__codelineno-36-13 href=#__codelineno-36-13></a><span class=w>    </span>--save_dir<span class=w> </span>checkpoints/sudoku_trm
</span><span id=__span-36-14><a id=__codelineno-36-14 name=__codelineno-36-14 href=#__codelineno-36-14></a>
</span><span id=__span-36-15><a id=__codelineno-36-15 name=__codelineno-36-15 href=#__codelineno-36-15></a><span class=c1># Train on ARC-AGI (slower, more challenging)</span>
</span><span id=__span-36-16><a id=__codelineno-36-16 name=__codelineno-36-16 href=#__codelineno-36-16></a>python<span class=w> </span>pretrain.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-17><a id=__codelineno-36-17 name=__codelineno-36-17 href=#__codelineno-36-17></a><span class=w>    </span>--dataset<span class=w> </span>arc<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-18><a id=__codelineno-36-18 name=__codelineno-36-18 href=#__codelineno-36-18></a><span class=w>    </span>--model_type<span class=w> </span>att<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-19><a id=__codelineno-36-19 name=__codelineno-36-19 href=#__codelineno-36-19></a><span class=w>    </span>--d_model<span class=w> </span><span class=m>256</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-20><a id=__codelineno-36-20 name=__codelineno-36-20 href=#__codelineno-36-20></a><span class=w>    </span>--n_layers<span class=w> </span><span class=m>2</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-21><a id=__codelineno-36-21 name=__codelineno-36-21 href=#__codelineno-36-21></a><span class=w>    </span>--batch_size<span class=w> </span><span class=m>16</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-22><a id=__codelineno-36-22 name=__codelineno-36-22 href=#__codelineno-36-22></a><span class=w>    </span>--learning_rate<span class=w> </span>5e-5<span class=w> </span><span class=se>\</span>
</span><span id=__span-36-23><a id=__codelineno-36-23 name=__codelineno-36-23 href=#__codelineno-36-23></a><span class=w>    </span>--num_epochs<span class=w> </span><span class=m>200</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-36-24><a id=__codelineno-36-24 name=__codelineno-36-24 href=#__codelineno-36-24></a><span class=w>    </span>--save_dir<span class=w> </span>checkpoints/arc_trm
</span></code></pre></div> <h3 id=inference-and-evaluation>Inference and Evaluation<a class=headerlink href=#inference-and-evaluation title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a><span class=c1># Load trained model</span>
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2 href=#__codelineno-37-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>TRM</span><span class=o>.</span><span class=n>load_from_checkpoint</span><span class=p>(</span><span class=s1>'checkpoints/sudoku_trm/best_model.pt'</span><span class=p>)</span>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3 href=#__codelineno-37-3></a><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span><span id=__span-37-4><a id=__codelineno-37-4 name=__codelineno-37-4 href=#__codelineno-37-4></a><span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-37-5><a id=__codelineno-37-5 name=__codelineno-37-5 href=#__codelineno-37-5></a>
</span><span id=__span-37-6><a id=__codelineno-37-6 name=__codelineno-37-6 href=#__codelineno-37-6></a><span class=c1># Solve a Sudoku puzzle</span>
</span><span id=__span-37-7><a id=__codelineno-37-7 name=__codelineno-37-7 href=#__codelineno-37-7></a><span class=n>puzzle</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span>
</span><span id=__span-37-8><a id=__codelineno-37-8 name=__codelineno-37-8 href=#__codelineno-37-8></a>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-37-9><a id=__codelineno-37-9 name=__codelineno-37-9 href=#__codelineno-37-9></a>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-37-10><a id=__codelineno-37-10 name=__codelineno-37-10 href=#__codelineno-37-10></a>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-37-11><a id=__codelineno-37-11 name=__codelineno-37-11 href=#__codelineno-37-11></a>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span>
</span><span id=__span-37-12><a id=__codelineno-37-12 name=__codelineno-37-12 href=#__codelineno-37-12></a>    <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span>
</span><span id=__span-37-13><a id=__codelineno-37-13 name=__codelineno-37-13 href=#__codelineno-37-13></a>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span>
</span><span id=__span-37-14><a id=__codelineno-37-14 name=__codelineno-37-14 href=#__codelineno-37-14></a>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>6</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span>
</span><span id=__span-37-15><a id=__codelineno-37-15 name=__codelineno-37-15 href=#__codelineno-37-15></a>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span>
</span><span id=__span-37-16><a id=__codelineno-37-16 name=__codelineno-37-16 href=#__codelineno-37-16></a>    <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>9</span><span class=p>]</span>
</span><span id=__span-37-17><a id=__codelineno-37-17 name=__codelineno-37-17 href=#__codelineno-37-17></a><span class=p>])</span>
</span><span id=__span-37-18><a id=__codelineno-37-18 name=__codelineno-37-18 href=#__codelineno-37-18></a>
</span><span id=__span-37-19><a id=__codelineno-37-19 name=__codelineno-37-19 href=#__codelineno-37-19></a><span class=c1># Tokenize</span>
</span><span id=__span-37-20><a id=__codelineno-37-20 name=__codelineno-37-20 href=#__codelineno-37-20></a><span class=n>puzzle_tokens</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>puzzle</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span> <span class=o>+</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span><span id=__span-37-21><a id=__codelineno-37-21 name=__codelineno-37-21 href=#__codelineno-37-21></a>
</span><span id=__span-37-22><a id=__codelineno-37-22 name=__codelineno-37-22 href=#__codelineno-37-22></a><span class=c1># Generate solution</span>
</span><span id=__span-37-23><a id=__codelineno-37-23 name=__codelineno-37-23 href=#__codelineno-37-23></a><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-37-24><a id=__codelineno-37-24 name=__codelineno-37-24 href=#__codelineno-37-24></a>    <span class=n>solution_tokens</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>puzzle_tokens</span><span class=p>)</span>
</span><span id=__span-37-25><a id=__codelineno-37-25 name=__codelineno-37-25 href=#__codelineno-37-25></a>
</span><span id=__span-37-26><a id=__codelineno-37-26 name=__codelineno-37-26 href=#__codelineno-37-26></a><span class=c1># Decode</span>
</span><span id=__span-37-27><a id=__codelineno-37-27 name=__codelineno-37-27 href=#__codelineno-37-27></a><span class=n>solution</span> <span class=o>=</span> <span class=p>(</span><span class=n>solution_tokens</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span> <span class=o>-</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>9</span><span class=p>,</span> <span class=mi>9</span><span class=p>)</span>
</span><span id=__span-37-28><a id=__codelineno-37-28 name=__codelineno-37-28 href=#__codelineno-37-28></a>
</span><span id=__span-37-29><a id=__codelineno-37-29 name=__codelineno-37-29 href=#__codelineno-37-29></a><span class=nb>print</span><span class=p>(</span><span class=s2>"Solution:"</span><span class=p>)</span>
</span><span id=__span-37-30><a id=__codelineno-37-30 name=__codelineno-37-30 href=#__codelineno-37-30></a><span class=nb>print</span><span class=p>(</span><span class=n>solution</span><span class=p>)</span>
</span><span id=__span-37-31><a id=__codelineno-37-31 name=__codelineno-37-31 href=#__codelineno-37-31></a>
</span><span id=__span-37-32><a id=__codelineno-37-32 name=__codelineno-37-32 href=#__codelineno-37-32></a><span class=c1># Verify (check all constraints)</span>
</span><span id=__span-37-33><a id=__codelineno-37-33 name=__codelineno-37-33 href=#__codelineno-37-33></a><span class=k>def</span><span class=w> </span><span class=nf>is_valid_sudoku</span><span class=p>(</span><span class=n>grid</span><span class=p>):</span>
</span><span id=__span-37-34><a id=__codelineno-37-34 name=__codelineno-37-34 href=#__codelineno-37-34></a>    <span class=c1># Check rows</span>
</span><span id=__span-37-35><a id=__codelineno-37-35 name=__codelineno-37-35 href=#__codelineno-37-35></a>    <span class=k>for</span> <span class=n>row</span> <span class=ow>in</span> <span class=n>grid</span><span class=p>:</span>
</span><span id=__span-37-36><a id=__codelineno-37-36 name=__codelineno-37-36 href=#__codelineno-37-36></a>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>))</span> <span class=o>!=</span> <span class=mi>9</span> <span class=ow>or</span> <span class=ow>not</span> <span class=nb>set</span><span class=p>(</span><span class=n>row</span><span class=p>)</span> <span class=o>==</span> <span class=nb>set</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>10</span><span class=p>)):</span>
</span><span id=__span-37-37><a id=__codelineno-37-37 name=__codelineno-37-37 href=#__codelineno-37-37></a>            <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-37-38><a id=__codelineno-37-38 name=__codelineno-37-38 href=#__codelineno-37-38></a>    <span class=c1># Check columns</span>
</span><span id=__span-37-39><a id=__codelineno-37-39 name=__codelineno-37-39 href=#__codelineno-37-39></a>    <span class=k>for</span> <span class=n>col</span> <span class=ow>in</span> <span class=n>grid</span><span class=o>.</span><span class=n>T</span><span class=p>:</span>
</span><span id=__span-37-40><a id=__codelineno-37-40 name=__codelineno-37-40 href=#__codelineno-37-40></a>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>col</span><span class=p>))</span> <span class=o>!=</span> <span class=mi>9</span><span class=p>:</span>
</span><span id=__span-37-41><a id=__codelineno-37-41 name=__codelineno-37-41 href=#__codelineno-37-41></a>            <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-37-42><a id=__codelineno-37-42 name=__codelineno-37-42 href=#__codelineno-37-42></a>    <span class=c1># Check boxes</span>
</span><span id=__span-37-43><a id=__codelineno-37-43 name=__codelineno-37-43 href=#__codelineno-37-43></a>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>3</span><span class=p>):</span>
</span><span id=__span-37-44><a id=__codelineno-37-44 name=__codelineno-37-44 href=#__codelineno-37-44></a>        <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>9</span><span class=p>,</span> <span class=mi>3</span><span class=p>):</span>
</span><span id=__span-37-45><a id=__codelineno-37-45 name=__codelineno-37-45 href=#__codelineno-37-45></a>            <span class=n>box</span> <span class=o>=</span> <span class=n>grid</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=mi>3</span><span class=p>,</span> <span class=n>j</span><span class=p>:</span><span class=n>j</span><span class=o>+</span><span class=mi>3</span><span class=p>]</span><span class=o>.</span><span class=n>flatten</span><span class=p>()</span>
</span><span id=__span-37-46><a id=__codelineno-37-46 name=__codelineno-37-46 href=#__codelineno-37-46></a>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>box</span><span class=p>))</span> <span class=o>!=</span> <span class=mi>9</span><span class=p>:</span>
</span><span id=__span-37-47><a id=__codelineno-37-47 name=__codelineno-37-47 href=#__codelineno-37-47></a>                <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-37-48><a id=__codelineno-37-48 name=__codelineno-37-48 href=#__codelineno-37-48></a>    <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-37-49><a id=__codelineno-37-49 name=__codelineno-37-49 href=#__codelineno-37-49></a>
</span><span id=__span-37-50><a id=__codelineno-37-50 name=__codelineno-37-50 href=#__codelineno-37-50></a><span class=k>if</span> <span class=n>is_valid_sudoku</span><span class=p>(</span><span class=n>solution</span><span class=p>):</span>
</span><span id=__span-37-51><a id=__codelineno-37-51 name=__codelineno-37-51 href=#__codelineno-37-51></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Valid solution!"</span><span class=p>)</span>
</span><span id=__span-37-52><a id=__codelineno-37-52 name=__codelineno-37-52 href=#__codelineno-37-52></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-37-53><a id=__codelineno-37-53 name=__codelineno-37-53 href=#__codelineno-37-53></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Invalid solution"</span><span class=p>)</span>
</span></code></pre></div> <h3 id=evaluation-on-test-set>Evaluation on Test Set<a class=headerlink href=#evaluation-on-test-set title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a><span class=c1># Evaluate on Sudoku test set (423K puzzles)</span>
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a>python<span class=w> </span>evaluators/eval_sudoku.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a><span class=w>    </span>--model_path<span class=w> </span>checkpoints/sudoku_trm/best_model.pt<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a><span class=w>    </span>--test_data<span class=w> </span>data/sudoku/test.pkl<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a><span class=w>    </span>--batch_size<span class=w> </span><span class=m>64</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a><span class=w>    </span>--output_file<span class=w> </span>results/sudoku_results.json
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a>
</span><span id=__span-38-8><a id=__codelineno-38-8 name=__codelineno-38-8 href=#__codelineno-38-8></a><span class=c1># Evaluate on ARC-AGI evaluation set</span>
</span><span id=__span-38-9><a id=__codelineno-38-9 name=__codelineno-38-9 href=#__codelineno-38-9></a>python<span class=w> </span>evaluators/eval_arc.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-10><a id=__codelineno-38-10 name=__codelineno-38-10 href=#__codelineno-38-10></a><span class=w>    </span>--model_path<span class=w> </span>checkpoints/arc_trm/best_model.pt<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-11><a id=__codelineno-38-11 name=__codelineno-38-11 href=#__codelineno-38-11></a><span class=w>    </span>--data_dir<span class=w> </span>ARC-AGI-master/data/evaluation<span class=w> </span><span class=se>\</span>
</span><span id=__span-38-12><a id=__codelineno-38-12 name=__codelineno-38-12 href=#__codelineno-38-12></a><span class=w>    </span>--output_file<span class=w> </span>results/arc_results.json
</span></code></pre></div> <p>Results will include: - <strong>Accuracy:</strong> % of puzzles solved correctly - <strong>Partial credit:</strong> % of cells filled correctly - <strong>Invalid rate:</strong> % of solutions that violate constraints - <strong>Inference time:</strong> Average time per puzzle</p> <hr> <h2 id=15-results-across-all-benchmarks>15. Results Across All Benchmarks<a class=headerlink href=#15-results-across-all-benchmarks title="Permanent link">¶</a></h2> <p>Let's look at comprehensive results across all tasks.</p> <h3 id=sudoku-extreme>Sudoku-Extreme<a class=headerlink href=#sudoku-extreme title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Train Time</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>24h</td> <td>0.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>36h</td> <td>55.0%</td> </tr> <tr> <td><strong>TRM-MLP</strong></td> <td><strong>5M</strong></td> <td><strong>48h</strong></td> <td><strong>87.4%</strong></td> </tr> <tr> <td>TRM-Att</td> <td>7M</td> <td>48h</td> <td>74.7%</td> </tr> </tbody> </table> <p><strong>Key findings:</strong> - MLP variant works better than attention for fixed-size structured tasks - 75% fewer parameters than HRM, 59% better accuracy - Still far from human performance (~99%) but unprecedented for neural networks</p> <h3 id=maze-hard>Maze-Hard<a class=headerlink href=#maze-hard title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>0.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>74.5%</td> </tr> <tr> <td>TRM-MLP</td> <td>19M</td> <td>0.0%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>85.3%</strong></td> </tr> </tbody> </table> <p><strong>Key findings:</strong> - Attention is crucial for path-finding (non-local dependencies) - 14% improvement over HRM with fewer parameters</p> <h3 id=arc-agi-1-original-benchmark>ARC-AGI-1 (Original Benchmark)<a class=headerlink href=#arc-agi-1-original-benchmark title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Direct prediction</td> <td>27M</td> <td>21.0%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>40.3%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>44.6%</strong></td> </tr> <tr> <td>TRM-MLP</td> <td>19M</td> <td>29.6%</td> </tr> </tbody> </table> <p><strong>Context - LLM baselines:</strong> - DeepSeek R1: 15.8% - Claude 3.7: 28.6% - O3-mini: 34.5% - Gemini 2.5 Pro: 37.0%</p> <p>TRM beats most LLMs with &lt;0.01% of parameters!</p> <h3 id=arc-agi-2-2024-competition>ARC-AGI-2 (2024 Competition)<a class=headerlink href=#arc-agi-2-2024-competition title="Permanent link">¶</a></h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>Claude 3.7 16K</td> <td>Unknown</td> <td>0.7%</td> </tr> <tr> <td>DeepSeek R1</td> <td>671B</td> <td>1.3%</td> </tr> <tr> <td>O3-mini</td> <td>Unknown</td> <td>3.0%</td> </tr> <tr> <td>Gemini 2.5 Pro 32K</td> <td>Unknown</td> <td>4.9%</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>5.0%</td> </tr> <tr> <td><strong>TRM-Att</strong></td> <td><strong>7M</strong></td> <td><strong>7.8%</strong></td> </tr> </tbody> </table> <p><strong>Key findings:</strong> - ARC-AGI-2 is extremely hard (designed to resist current methods) - TRM achieves highest score among non-ensemble models - Current top leaderboard score: ~30% (Grok-4 with extensive test-time compute and ensembling)</p> <h3 id=parameter-efficiency>Parameter Efficiency<a class=headerlink href=#parameter-efficiency title="Permanent link">¶</a></h3> <p>Let's visualize the efficiency:</p> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>ARC-AGI-1 Acc</th> <th>Params per 1% Acc</th> </tr> </thead> <tbody> <tr> <td>Gemini 2.5 Pro</td> <td>~1T (estimated)</td> <td>37.0%</td> <td>27B</td> </tr> <tr> <td>O3-mini</td> <td>Unknown</td> <td>34.5%</td> <td>?</td> </tr> <tr> <td>HRM</td> <td>27M</td> <td>40.3%</td> <td>670K</td> </tr> <tr> <td><strong>TRM</strong></td> <td><strong>7M</strong></td> <td><strong>44.6%</strong></td> <td><strong>157K</strong></td> </tr> </tbody> </table> <p>TRM achieves each percentage point of accuracy with <strong>4.3x fewer parameters</strong> than HRM!</p> <h3 id=inference-speed>Inference Speed<a class=headerlink href=#inference-speed title="Permanent link">¶</a></h3> <p>On a single NVIDIA A100 GPU:</p> <table> <thead> <tr> <th>Task</th> <th>Model</th> <th>Latency (ms)</th> <th>Throughput (puzzles/sec)</th> </tr> </thead> <tbody> <tr> <td>Sudoku 9x9</td> <td>TRM-MLP</td> <td>12ms</td> <td>83</td> </tr> <tr> <td>Sudoku 9x9</td> <td>HRM</td> <td>25ms</td> <td>40</td> </tr> <tr> <td>ARC-AGI 30x30</td> <td>TRM-Att</td> <td>45ms</td> <td>22</td> </tr> <tr> <td>ARC-AGI 30x30</td> <td>HRM</td> <td>89ms</td> <td>11</td> </tr> </tbody> </table> <p>TRM is <strong>2x faster</strong> than HRM due to fewer parameters and simpler architecture.</p> <h3 id=scaling-analysis>Scaling Analysis<a class=headerlink href=#scaling-analysis title="Permanent link">¶</a></h3> <p>How does performance scale with recursion depth?</p> <table> <thead> <tr> <th>Recursion Config</th> <th>Effective Depth</th> <th>Sudoku Acc</th> <th>Training Time</th> </tr> </thead> <tbody> <tr> <td>n=1, T=1</td> <td>6</td> <td>63.2%</td> <td>Fast (20h)</td> </tr> <tr> <td>n=2, T=2</td> <td>20</td> <td>81.9%</td> <td>Medium (35h)</td> </tr> <tr> <td><strong>n=3, T=3</strong></td> <td><strong>42</strong></td> <td><strong>87.4%</strong></td> <td><strong>Slow (48h)</strong></td> </tr> <tr> <td>n=4, T=4</td> <td>72</td> <td>84.2%</td> <td>Very slow (72h)</td> </tr> </tbody> </table> <p><strong>Takeaway:</strong> There's a sweet spot around 40-50 effective layers. More doesn't always help (overfitting).</p> <hr> <h2 id=16-why-this-works-theoretical-insights>16. Why This Works: Theoretical Insights<a class=headerlink href=#16-why-this-works-theoretical-insights title="Permanent link">¶</a></h2> <h3 id=compression-and-regularization>Compression and Regularization<a class=headerlink href=#compression-and-regularization title="Permanent link">¶</a></h3> <p><strong>The Chinchilla Argument:</strong></p> <p>The Chinchilla scaling laws (from large language model research) suggest that for a given compute budget, there's an optimal model size. Too small: underfitting. Too large: needs more data.</p> <p>From the YouTube transcript, we can think of this as:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a>For fixed compute budget:
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a>- Small data → Optimal model size is SMALL
</span><span id=__span-39-3><a id=__codelineno-39-3 name=__codelineno-39-3 href=#__codelineno-39-3></a>- Large data → Optimal model size is LARGE
</span><span id=__span-39-4><a id=__codelineno-39-4 name=__codelineno-39-4 href=#__codelineno-39-4></a>
</span><span id=__span-39-5><a id=__codelineno-39-5 name=__codelineno-39-5 href=#__codelineno-39-5></a>ARC-AGI has ~1000 training tasks
</span><span id=__span-39-6><a id=__codelineno-39-6 name=__codelineno-39-6 href=#__codelineno-39-6></a>→ Optimal size is ~5-10M parameters
</span><span id=__span-39-7><a id=__codelineno-39-7 name=__codelineno-39-7 href=#__codelineno-39-7></a>→ TRM (7M) is near optimal
</span><span id=__span-39-8><a id=__codelineno-39-8 name=__codelineno-39-8 href=#__codelineno-39-8></a>→ LLMs (100B+) are massively overparameterized
</span></code></pre></div> <p><strong>Compression Forces Learning:</strong></p> <p>When you force knowledge into fewer parameters: 1. Model must learn efficient representations (no room for memorization) 2. Recursive application means same weights handle multiple cases 3. This is strong regularization (like L2, dropout, but architectural)</p> <p><strong>Comparison to Knowledge Distillation:</strong></p> <table> <thead> <tr> <th>Technique</th> <th>Approach</th> <th>Result</th> </tr> </thead> <tbody> <tr> <td>Knowledge Distillation</td> <td>Large teacher → Small student</td> <td>Student learns teacher's outputs</td> </tr> <tr> <td>TRM</td> <td>Small model + recursion</td> <td>Model learns efficient reasoning</td> </tr> </tbody> </table> <p>TRM shows you might not need the large teacher at all for reasoning tasks!</p> <h3 id=iterative-refinement-vs-single-pass>Iterative Refinement vs Single-Pass<a class=headerlink href=#iterative-refinement-vs-single-pass title="Permanent link">¶</a></h3> <p><strong>How Humans Solve Sudoku:</strong></p> <ol> <li>Scan for obvious cells (naked singles)</li> <li>Look for hidden singles</li> <li>Apply pair/triple techniques</li> <li>Try and verify</li> <li>Backtrack if needed</li> </ol> <p>This is inherently iterative.</p> <p><strong>How LLMs Try to Solve Sudoku:</strong></p> <ol> <li>Read puzzle</li> <li>Generate token 1</li> <li>Generate token 2 (conditioned on token 1)</li> <li>...</li> <li>Generate token 81</li> </ol> <p>Once token 1 is generated, it can't be changed. If wrong, solution fails.</p> <p><strong>How TRM Solves Sudoku:</strong></p> <ol> <li>Read puzzle (x stream)</li> <li>Think about constraints (update z 8 times)</li> <li>Propose solution (update y 16 times)</li> <li>Can revise earlier predictions in later passes!</li> </ol> <p>This matches human solving much better.</p> <h3 id=error-correction>Error Correction<a class=headerlink href=#error-correction title="Permanent link">¶</a></h3> <p><strong>Key Insight:</strong> TRM can fix its own mistakes.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a><span class=c1># Pass 5: Model predicts cell (4,5) = 7</span>
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a><span class=n>y</span><span class=p>[</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>]</span> <span class=o>=</span> <span class=n>embed</span><span class=p>(</span><span class=mi>7</span><span class=p>)</span>
</span><span id=__span-40-3><a id=__codelineno-40-3 name=__codelineno-40-3 href=#__codelineno-40-3></a>
</span><span id=__span-40-4><a id=__codelineno-40-4 name=__codelineno-40-4 href=#__codelineno-40-4></a><span class=c1># Pass 10: Model realizes this violates a constraint</span>
</span><span id=__span-40-5><a id=__codelineno-40-5 name=__codelineno-40-5 href=#__codelineno-40-5></a><span class=c1># Can change prediction!</span>
</span><span id=__span-40-6><a id=__codelineno-40-6 name=__codelineno-40-6 href=#__codelineno-40-6></a><span class=n>y</span><span class=p>[</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>]</span> <span class=o>=</span> <span class=n>embed</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># Corrected</span>
</span><span id=__span-40-7><a id=__codelineno-40-7 name=__codelineno-40-7 href=#__codelineno-40-7></a>
</span><span id=__span-40-8><a id=__codelineno-40-8 name=__codelineno-40-8 href=#__codelineno-40-8></a><span class=c1># LLM: Once 7 is generated, it's permanent</span>
</span></code></pre></div> <p>This error correction capability is crucial for reasoning tasks where mistakes are easy to make but also easy to verify.</p> <h3 id=deep-supervision-as-curriculum-learning>Deep Supervision as Curriculum Learning<a class=headerlink href=#deep-supervision-as-curriculum-learning title="Permanent link">¶</a></h3> <p>Deep supervision creates an implicit curriculum:</p> <table> <thead> <tr> <th>Supervision Cycle</th> <th>What Model Learns</th> </tr> </thead> <tbody> <tr> <td>1-4</td> <td>Basic patterns (rows, columns, boxes)</td> </tr> <tr> <td>5-8</td> <td>Simple logical deductions</td> </tr> <tr> <td>9-12</td> <td>Complex constraint propagation</td> </tr> <tr> <td>13-16</td> <td>Verification and correction</td> </tr> </tbody> </table> <p>Early cycles see more examples (due to ACT halting), so model learns basics thoroughly before advancing.</p> <hr> <h2 id=17-applications-and-extensions>17. Applications and Extensions<a class=headerlink href=#17-applications-and-extensions title="Permanent link">¶</a></h2> <h3 id=beyond-puzzles>Beyond Puzzles<a class=headerlink href=#beyond-puzzles title="Permanent link">¶</a></h3> <p>TRM's architecture generalizes to many reasoning domains:</p> <p><strong>Constraint Satisfaction Problems (CSP):</strong> - Graph coloring - Scheduling - Resource allocation - Configuration problems</p> <p><strong>Mathematical Reasoning:</strong> - Equation solving - Proof verification - Symbolic integration - Geometric constructions</p> <p><strong>Code Generation:</strong> - Program synthesis from examples - Bug fixing - Code optimization - Test generation</p> <p><strong>Planning and Search:</strong> - Route planning - Game playing (Go, Chess with legal moves) - Robotic manipulation planning</p> <h3 id=modifications-for-other-domains>Modifications for Other Domains<a class=headerlink href=#modifications-for-other-domains title="Permanent link">¶</a></h3> <p><strong>For Longer Sequences:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a><span class=c1># Increase latent reasoning capacity</span>
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a><span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=mi>64</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>  <span class=c1># vs 32 for Sudoku</span>
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a>
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a><span class=c1># Use attention (not MLP)</span>
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a><span class=n>model</span> <span class=o>=</span> <span class=n>create_trm_att</span><span class=p>(</span><span class=n>use_attention</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-41-6><a id=__codelineno-41-6 name=__codelineno-41-6 href=#__codelineno-41-6></a>
</span><span id=__span-41-7><a id=__codelineno-41-7 name=__codelineno-41-7 href=#__codelineno-41-7></a><span class=c1># More recursions for complex problems</span>
</span><span id=__span-41-8><a id=__codelineno-41-8 name=__codelineno-41-8 href=#__codelineno-41-8></a><span class=n>model</span><span class=o>.</span><span class=n>n_reasoning_steps</span> <span class=o>=</span> <span class=mi>12</span>  <span class=c1># vs 8</span>
</span><span id=__span-41-9><a id=__codelineno-41-9 name=__codelineno-41-9 href=#__codelineno-41-9></a><span class=n>model</span><span class=o>.</span><span class=n>n_refinement_steps</span> <span class=o>=</span> <span class=mi>24</span>  <span class=c1># vs 16</span>
</span></code></pre></div> <p><strong>For Multi-Modal Tasks:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a><span class=c1># Add vision encoder</span>
</span><span id=__span-42-2><a id=__codelineno-42-2 name=__codelineno-42-2 href=#__codelineno-42-2></a><span class=k>class</span><span class=w> </span><span class=nc>MultiModalTRM</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span><span id=__span-42-3><a id=__codelineno-42-3 name=__codelineno-42-3 href=#__codelineno-42-3></a>    <span class=k>def</span><span class=w> </span><span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span><span id=__span-42-4><a id=__codelineno-42-4 name=__codelineno-42-4 href=#__codelineno-42-4></a>        <span class=bp>self</span><span class=o>.</span><span class=n>vision_encoder</span> <span class=o>=</span> <span class=n>VisionTransformer</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span><span id=__span-42-5><a id=__codelineno-42-5 name=__codelineno-42-5 href=#__codelineno-42-5></a>        <span class=bp>self</span><span class=o>.</span><span class=n>trm</span> <span class=o>=</span> <span class=n>TRM</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span><span id=__span-42-6><a id=__codelineno-42-6 name=__codelineno-42-6 href=#__codelineno-42-6></a>
</span><span id=__span-42-7><a id=__codelineno-42-7 name=__codelineno-42-7 href=#__codelineno-42-7></a>    <span class=k>def</span><span class=w> </span><span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image</span><span class=p>,</span> <span class=n>text_query</span><span class=p>):</span>
</span><span id=__span-42-8><a id=__codelineno-42-8 name=__codelineno-42-8 href=#__codelineno-42-8></a>        <span class=c1># Encode image</span>
</span><span id=__span-42-9><a id=__codelineno-42-9 name=__codelineno-42-9 href=#__codelineno-42-9></a>        <span class=n>image_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>vision_encoder</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span><span id=__span-42-10><a id=__codelineno-42-10 name=__codelineno-42-10 href=#__codelineno-42-10></a>
</span><span id=__span-42-11><a id=__codelineno-42-11 name=__codelineno-42-11 href=#__codelineno-42-11></a>        <span class=c1># Use as x-stream (question)</span>
</span><span id=__span-42-12><a id=__codelineno-42-12 name=__codelineno-42-12 href=#__codelineno-42-12></a>        <span class=n>x</span> <span class=o>=</span> <span class=n>image_features</span>
</span><span id=__span-42-13><a id=__codelineno-42-13 name=__codelineno-42-13 href=#__codelineno-42-13></a>
</span><span id=__span-42-14><a id=__codelineno-42-14 name=__codelineno-42-14 href=#__codelineno-42-14></a>        <span class=c1># Text query as initial y</span>
</span><span id=__span-42-15><a id=__codelineno-42-15 name=__codelineno-42-15 href=#__codelineno-42-15></a>        <span class=n>y</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trm</span><span class=o>.</span><span class=n>embed_tokens</span><span class=p>(</span><span class=n>text_query</span><span class=p>)</span>
</span><span id=__span-42-16><a id=__codelineno-42-16 name=__codelineno-42-16 href=#__codelineno-42-16></a>
</span><span id=__span-42-17><a id=__codelineno-42-17 name=__codelineno-42-17 href=#__codelineno-42-17></a>        <span class=c1># Reasoning</span>
</span><span id=__span-42-18><a id=__codelineno-42-18 name=__codelineno-42-18 href=#__codelineno-42-18></a>        <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span><span id=__span-42-19><a id=__codelineno-42-19 name=__codelineno-42-19 href=#__codelineno-42-19></a>
</span><span id=__span-42-20><a id=__codelineno-42-20 name=__codelineno-42-20 href=#__codelineno-42-20></a>        <span class=c1># Run TRM</span>
</span><span id=__span-42-21><a id=__codelineno-42-21 name=__codelineno-42-21 href=#__codelineno-42-21></a>        <span class=n>y_final</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>trm</span><span class=o>.</span><span class=n>recursive_reasoning</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>z</span><span class=p>)</span>
</span><span id=__span-42-22><a id=__codelineno-42-22 name=__codelineno-42-22 href=#__codelineno-42-22></a>
</span><span id=__span-42-23><a id=__codelineno-42-23 name=__codelineno-42-23 href=#__codelineno-42-23></a>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>trm</span><span class=o>.</span><span class=n>reverse_embedding</span><span class=p>(</span><span class=n>y_final</span><span class=p>)</span>
</span></code></pre></div> <h3 id=competition-considerations>Competition Considerations<a class=headerlink href=#competition-considerations title="Permanent link">¶</a></h3> <p><strong>ARC-AGI Private Leaderboard Constraints:</strong></p> <ul> <li><strong>Time limit:</strong> 12 hours</li> <li><strong>Hardware:</strong> 4× NVIDIA L4 GPUs</li> <li><strong>Compute:</strong> ~48 L4-hours total</li> </ul> <p><strong>Current TRM:</strong> - <strong>Training:</strong> 48 hours on 4× H100 GPUs - <strong>H100 vs L4:</strong> ~3x more powerful - <strong>Total compute:</strong> 48h × 4 H100s = 192 H100-hours = <strong>576 L4-hours</strong></p> <p>This is <strong>12x more than allowed!</strong></p> <p><strong>Path to Competition Compliance:</strong></p> <ol> <li><strong>Better data efficiency:</strong> Train on fewer augmentations</li> <li><strong>Knowledge distillation:</strong> Use larger model to teach smaller one</li> <li><strong>Transfer learning:</strong> Pre-train on Concept ARC, fine-tune on competition tasks</li> <li><strong>Efficient search:</strong> Test-time compute for multiple tries</li> <li><strong>Architecture search:</strong> Find even smaller networks that work</li> </ol> <p>Current TRM is a research result demonstrating what's possible, not (yet) optimized for the competition constraints.</p> <hr> <h2 id=18-conclusion-and-future-directions>18. Conclusion and Future Directions<a class=headerlink href=#18-conclusion-and-future-directions title="Permanent link">¶</a></h2> <h3 id=the-paradigm-shift>The Paradigm Shift<a class=headerlink href=#the-paradigm-shift title="Permanent link">¶</a></h3> <p>TRM represents a fundamental shift in how we think about AI for reasoning:</p> <p><strong>Old paradigm:</strong> - Bigger models are better - Scale to hundreds of billions of parameters - Single-pass inference is sufficient - Pre-train on internet-scale data</p> <p><strong>New paradigm (TRM):</strong> - Smaller models with recursion are better - 5-10 million parameters is enough - Iterative refinement beats single-pass - Train on small, high-quality datasets</p> <p><strong>The Result:</strong> - 7M parameters outperform 671B parameters - Deployable on edge devices - Train in 2 days, not 2 months - Accessible to researchers without massive compute</p> <h3 id=open-questions>Open Questions<a class=headerlink href=#open-questions title="Permanent link">¶</a></h3> <p><strong>1. Optimal Recursion Depth:</strong> - Current: 8 reasoning + 16 refinement steps - Is there a better schedule? Task-dependent? - Can we learn the schedule?</p> <p><strong>2. Generative Extension:</strong> - TRM is currently supervised (predict correct answer) - Can we extend to generation (sample from distribution)? - Would enable uncertainty quantification</p> <p><strong>3. Scaling to Larger Problems:</strong> - Current: Up to 30×30 grids - Can TRM handle 100×100? Variable-size with better efficiency?</p> <p><strong>4. Transfer Learning:</strong> - Can a model trained on Sudoku transfer to other logic puzzles? - What's the minimal fine-tuning needed?</p> <p><strong>5. Theoretical Understanding:</strong> - Why does recursion help so much? - Can we prove convergence properties? - Connection to iterative algorithms in algorithms literature?</p> <h3 id=what-this-means-for-the-field>What This Means for the Field<a class=headerlink href=#what-this-means-for-the-field title="Permanent link">¶</a></h3> <p><strong>For AI Research:</strong> - <strong>Rethink scaling laws:</strong> Parameter efficiency matters - <strong>Architectural innovation:</strong> Can beat pure scaling - <strong>Small data regimes:</strong> TRM shows path forward</p> <p><strong>For Applications:</strong> - <strong>Edge deployment:</strong> Powerful reasoning without cloud - <strong>Real-time systems:</strong> Fast inference on constrained hardware - <strong>Cost reduction:</strong> 100-1000x cheaper than LLM APIs</p> <p><strong>For the Future:</strong> - Democratization: Powerful AI without massive compute - Sustainability: Lower energy consumption - Accessibility: More researchers can contribute</p> <h3 id=final-thoughts>Final Thoughts<a class=headerlink href=#final-thoughts title="Permanent link">¶</a></h3> <p>When I first encountered the TRM paper, I was skeptical. How could a tiny 7M parameter model beat GPT-4 at anything?</p> <p>But the results are undeniable. On systematic reasoning tasks requiring iterative refinement and error correction, TRM's approach of small networks with recursive processing fundamentally outperforms the single-pass autoregressive approach of large language models.</p> <p>This doesn't mean LLMs are obsolete. They excel at language understanding, general knowledge, and open-ended generation. But for reasoning? TRM shows us a better path.</p> <p>The future of AI isn't just about building bigger models. It's about building smarter architectures that use computation more efficiently. TRM is a proof of concept that <strong>less can truly be more</strong>.</p> <hr> <h2 id=further-resources>Further Resources<a class=headerlink href=#further-resources title="Permanent link">¶</a></h2> <h3 id=paper-and-code>Paper and Code<a class=headerlink href=#paper-and-code title="Permanent link">¶</a></h3> <ul> <li><strong>Original TRM Paper:</strong> <a href=https://arxiv.org/abs/2510.04871>Less is More: Recursive Reasoning with Tiny Networks</a></li> <li><strong>TinyRecursiveModels GitHub:</strong> <a href=https://github.com/alexjmartineau/TinyRecursiveModels>Official Implementation</a></li> <li><strong>HRM Paper (Predecessor):</strong> <a href=https://arxiv.org/abs/2506.21734>Hierarchical Reasoning Models</a></li> </ul> <h3 id=datasets>Datasets<a class=headerlink href=#datasets title="Permanent link">¶</a></h3> <ul> <li><strong>ARC-AGI:</strong> <a href=https://github.com/fchollet/ARC-AGI>Abstraction and Reasoning Corpus</a></li> <li><strong>ARC-AGI Competition:</strong> <a href=https://arcprize.org/leaderboard>Official Leaderboard</a></li> <li><strong>Concept ARC:</strong> <a href=https://github.com/victorvikram/ConceptARC>Extended Task Set</a></li> </ul> <h3 id=related-research>Related Research<a class=headerlink href=#related-research title="Permanent link">¶</a></h3> <ul> <li><strong>Deep Equilibrium Models:</strong> <a href=https://arxiv.org/abs/1909.01377>Bai et al., 2019</a></li> <li><strong>Adaptive Computation Time:</strong> <a href=https://arxiv.org/abs/1603.08983>Graves, 2016</a></li> <li><strong>Deep Supervision:</strong> <a href=https://arxiv.org/abs/1409.5185>Lee et al., 2015</a></li> </ul> <h3 id=community>Community<a class=headerlink href=#community title="Permanent link">¶</a></h3> <ul> <li><strong>AI Engineering Academy:</strong> More tutorials on <a href=/LLM/ServerLessFinetuning/ >LLM fine-tuning</a>, <a href=/RAG/ >RAG systems</a>, and <a href=/PromptEngineering/ >prompt engineering</a></li> <li><strong>ARC-AGI Discord:</strong> Active community working on the challenge</li> <li><strong>Twitter/X:</strong> Follow <a href=https://twitter.com/alexjmartin>@alexjmartin</a> for updates</li> </ul> <h3 id=video-explanations>Video Explanations<a class=headerlink href=#video-explanations title="Permanent link">¶</a></h3> <ul> <li><strong>Detailed Walkthrough:</strong> <a href="https://www.youtube.com/watch?v=yJQQB6MIUd0">YouTube breakdown of TRM</a> by a community expert</li> <li><strong>Visual Guide:</strong> The Remotion animations on this page (all 11 scenes)</li> </ul> <h3 id=try-it-yourself>Try It Yourself<a class=headerlink href=#try-it-yourself title="Permanent link">¶</a></h3> <p>Want to experiment with transformers and reasoning? Check out: - Our <a href=/LLM/HandsOnWithFinetuning/SFT/SFT/ >LLM Fine-tuning Tutorials</a> - <a href=https://huggingface.co/docs/transformers/ >Hugging Face Transformers Library</a> - <a href=https://course.fast.ai/ >Fast.ai Practical Deep Learning</a></p> <hr> <p><em>This comprehensive guide was written to demystify TRM and make it accessible to anyone interested in efficient AI for reasoning. All visualizations were created using Remotion and React. Full source code available in the <a href=https://github.com/adithya-s-k/AI-Engineering.academy>AI Engineering Academy repository</a>.</em></p> <p><em>For questions, corrections, or discussions, please open an issue on GitHub or reach out on Twitter.</em></p> <hr> <p><strong>Last Updated:</strong> November 2024 <strong>Author:</strong> Adithya S Kolavi <strong>License:</strong> CC BY 4.0</p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>