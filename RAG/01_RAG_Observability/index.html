<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/RAG/01_RAG_Observability/ rel=canonical><link href=../01_RAG_Evaluation/notebook/ rel=prev><link href=notebook/ rel=next><link rel=icon href=../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.21"><title>Intro to Observability - AI Engineering Academy</title><link rel=stylesheet href=../../assets/stylesheets/main.2a3383ac.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta property=og:type content=website><meta property=og:title content="Intro to Observability - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/RAG/01_RAG_Observability/README.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/RAG/01_RAG_Observability/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:title content="Intro to Observability - AI Engineering Academy"><meta name=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta name=twitter:image content=https://aiengineering.academy/assets/images/social/RAG/01_RAG_Observability/README.png><link rel=stylesheet href=../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#rag-observability-arize-phoenix-setup class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Intro to Observability </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> RAG </a> </li> <li class=md-tabs__item> <a href=../../LLM/ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> RAG </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> RAG </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex> <span class=md-ellipsis> Embedding and Similarity </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Embedding and Similarity </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../00_RAG_Base/Understanding_embeddings_and_similarity/ class=md-nav__link> <span class=md-ellipsis> What are Embeddings </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3 checked> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex> <span class=md-ellipsis> RAG Techniques </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> RAG Techniques </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../00_RAG_Base/ class=md-nav__link> <span class=md-ellipsis> RAG from Scratch </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../01_Basic_RAG/ class=md-nav__link> <span class=md-ellipsis> Basic RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../01_BM25_RAG/ class=md-nav__link> <span class=md-ellipsis> BM25 RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../01_Data_Ingestion/data_chunking/ class=md-nav__link> <span class=md-ellipsis> Data Ingestion </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../01_RAG_Evaluation/ class=md-nav__link> <span class=md-ellipsis> RAG Evaluation </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3_6 checked> <div class="md-nav__link md-nav__container"> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> RAG Observability </span> </a> <label class="md-nav__link md-nav__link--active" for=__nav_3_3_6 id=__nav_3_3_6_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_3_3_6_label aria-expanded=true> <label class=md-nav__title for=__nav_3_3_6> <span class="md-nav__icon md-icon"></span> RAG Observability </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=notebook/ class=md-nav__link> <span class=md-ellipsis> Observability(Arize Phoenix) </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../02_ReRanker_RAG/notebook/ class=md-nav__link> <span class=md-ellipsis> ReRanker RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../03_Hybrid_RAG/_Qdrant_Hybrid_Search/ class=md-nav__link> <span class=md-ellipsis> Hybrid RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../04_Sentence_Window_RAG/Sentence_window_retrieval/ class=md-nav__link> <span class=md-ellipsis> Sentence Window RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../05_Auto_Merging_RAG/Auto-merging_Retrieval/ class=md-nav__link> <span class=md-ellipsis> Auto Merging RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../06_HyDE_RAG/HyDEQueryTransformDemo/ class=md-nav__link> <span class=md-ellipsis> HyDE RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../06_Query_Transformation_RAG/query_transform_cookbook/ class=md-nav__link> <span class=md-ellipsis> Query Transformation RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../07_Self_Query_RAG/Self_Query_RAG/ class=md-nav__link> <span class=md-ellipsis> Self Query RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../08_RAG_Fusion/ragfusion/ class=md-nav__link> <span class=md-ellipsis> RAG Fusion </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../09_RAPTOR/raptor/ class=md-nav__link> <span class=md-ellipsis> RAPTOR </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../10_ColBERT_RAG/ColBert_RAG/ class=md-nav__link> <span class=md-ellipsis> ColBERT RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../11_Graph_RAG/GraphRAG_v1/ class=md-nav__link> <span class=md-ellipsis> Graph RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../12_Agnetic_RAG/multi_document_agents/ class=md-nav__link> <span class=md-ellipsis> Agentic RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../13_Vision_RAG/gpt4v_multi_modal_retrieval/ class=md-nav__link> <span class=md-ellipsis> Vision RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../14_CAG/CAG/ class=md-nav__link> <span class=md-ellipsis> CAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../LLM/ class=md-nav__link> <span class=md-ellipsis> LLM </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#table-of-contents class=md-nav__link> <span class=md-ellipsis> Table of Contents </span> </a> </li> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#prerequisites class=md-nav__link> <span class=md-ellipsis> Prerequisites </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#usage class=md-nav__link> <span class=md-ellipsis> Usage </span> </a> </li> <li class=md-nav__item> <a href=#1-setup class=md-nav__link> <span class=md-ellipsis> 1. Setup </span> </a> <nav class=md-nav aria-label="1. Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#11-install-required-packages class=md-nav__link> <span class=md-ellipsis> 1.1 Install required packages </span> </a> </li> <li class=md-nav__item> <a href=#12-setting-up-arize-phoenix class=md-nav__link> <span class=md-ellipsis> 1.2 Setting up Arize Phoenix </span> </a> </li> <li class=md-nav__item> <a href=#13-import-required-libraries-and-configure-the-environment class=md-nav__link> <span class=md-ellipsis> 1.3 Import Required Libraries and Configure the Environment </span> </a> </li> <li class=md-nav__item> <a href=#14-launch-the-phoenix-app class=md-nav__link> <span class=md-ellipsis> 1.4 Launch the Phoenix App </span> </a> </li> <li class=md-nav__item> <a href=#15-view-the-phoenix-app-session class=md-nav__link> <span class=md-ellipsis> 1.5 View the Phoenix App Session </span> </a> </li> <li class=md-nav__item> <a href=#16-set-up-the-endpoint-for-traces class=md-nav__link> <span class=md-ellipsis> 1.6 Set Up the Endpoint for Traces </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#2-trace-open-ai class=md-nav__link> <span class=md-ellipsis> 2. Trace Open AI </span> </a> <nav class=md-nav aria-label="2. Trace Open AI"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#21-install-and-import-the-openai-package class=md-nav__link> <span class=md-ellipsis> 2.1 Install and Import the OpenAI Package </span> </a> </li> <li class=md-nav__item> <a href=#22-configure-the-openai-api-key class=md-nav__link> <span class=md-ellipsis> 2.2 Configure the OpenAI API Key </span> </a> </li> <li class=md-nav__item> <a href=#23-set-up-opentelemetry-for-tracing class=md-nav__link> <span class=md-ellipsis> 2.3 Set Up OpenTelemetry for Tracing </span> </a> </li> <li class=md-nav__item> <a href=#24-instrument-openai-with-openinference class=md-nav__link> <span class=md-ellipsis> 2.4 Instrument OpenAI with OpenInference </span> </a> </li> <li class=md-nav__item> <a href=#25-make-a-request-to-openai-api class=md-nav__link> <span class=md-ellipsis> 2.5 Make a Request to OpenAI API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#3-trace-llama-index class=md-nav__link> <span class=md-ellipsis> 3. Trace Llama index </span> </a> <nav class=md-nav aria-label="3. Trace Llama index"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#31-install-and-import-the-required-libraries class=md-nav__link> <span class=md-ellipsis> 3.1 Install and Import the Required Libraries </span> </a> </li> <li class=md-nav__item> <a href=#32-retrieve-the-url-of-the-active-phoenix-session class=md-nav__link> <span class=md-ellipsis> 3.2 Retrieve the URL of the Active Phoenix Session </span> </a> </li> <li class=md-nav__item> <a href=#33-set-up-tracing-for-llama-index class=md-nav__link> <span class=md-ellipsis> 3.3 Set Up Tracing for Llama Index </span> </a> </li> <li class=md-nav__item> <a href=#34-interact-with-llama-index-using-openai class=md-nav__link> <span class=md-ellipsis> 3.4 Interact with Llama Index Using OpenAI </span> </a> </li> <li class=md-nav__item> <a href=#35-perform-a-chat-interaction-with-llama-index-using-openai class=md-nav__link> <span class=md-ellipsis> 3.5 Perform a Chat Interaction with Llama Index Using OpenAI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#4-observe-rag-pipeline class=md-nav__link> <span class=md-ellipsis> 4. Observe RAG Pipeline </span> </a> <nav class=md-nav aria-label="4. Observe RAG Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#41-setup-an-environment-for-observing-a-rag-piepline class=md-nav__link> <span class=md-ellipsis> 4.1 Setup an environment for observing a RAG piepline </span> </a> </li> <li class=md-nav__item> <a href=#42-prepare-rag-pipeline-with-embeddings-and-document-indexing class=md-nav__link> <span class=md-ellipsis> 4.2 Prepare RAG Pipeline with Embeddings and Document Indexing </span> </a> </li> <li class=md-nav__item> <a href=#43-query-the-vector-store-index class=md-nav__link> <span class=md-ellipsis> 4.3 Query the Vector Store Index </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/RAG/01_RAG_Observability/README.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/RAG/01_RAG_Observability/README.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=rag-observability-arize-phoenix-setup>RAG Observability - Arize Phoenix Setup<a class=headerlink href=#rag-observability-arize-phoenix-setup title="Permanent link">¶</a></h1> <p>Welcome to this notebook, where we explore the setup and observation of a Retrieval-Augmented Generation (RAG) pipeline using Llama Index.</p> <h2 id=table-of-contents>Table of Contents<a class=headerlink href=#table-of-contents title="Permanent link">¶</a></h2> <ol> <li><a href=#introduction>Introduction</a></li> <li><a href=#getting-started>Getting Started</a></li> <li><a href=#usage>Usage</a></li> <li><a href=#conclusion>Conclusion</a></li> </ol> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">¶</a></h2> <p>This guide provides a comprehensive walkthrough for configuring the necessary tools and libraries, including embedding models and vector store indexing, to enable efficient document retrieval and query processing. We’ll cover everything from installation and setup to querying and retrieving relevant information, equipping you with the knowledge to harness the power of RAG pipelines for advanced search capabilities.</p> <h2 id=getting-started>Getting Started<a class=headerlink href=#getting-started title="Permanent link">¶</a></h2> <p>To get started with this notebook, you'll need to have a basic understanding of Python and some familiarity with machine learning concepts. Don't worry if you're new to some of these ideas – we'll guide you through each step!</p> <h3 id=prerequisites>Prerequisites<a class=headerlink href=#prerequisites title="Permanent link">¶</a></h3> <ul> <li>Python 3.7+</li> <li>Jupyter Notebook or JupyterLab</li> <li>Basic knowledge of Python and machine learning concepts</li> </ul> <h2 id=usage>Usage<a class=headerlink href=#usage title="Permanent link">¶</a></h2> <h2 id=1-setup>1. Setup<a class=headerlink href=#1-setup title="Permanent link">¶</a></h2> <h3 id=11-install-required-packages>1.1 Install required packages<a class=headerlink href=#11-install-required-packages title="Permanent link">¶</a></h3> <p>To get started with setting up Arize Phoenix, you'll need to install the required packages.</p> <p>Arize Phoenix is a comprehensive tool designed for observability and monitoring in machine learning and AI systems. It provides functionalities for tracking and analyzing various aspects of machine learning models and data pipelines.</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>!pip<span class=w> </span>install<span class=w> </span>arize-phoenix
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>!pip<span class=w> </span>install<span class=w> </span>openinference-instrumentation-openai
</span></code></pre></div> <p>These commands will install:</p> <ul> <li><code>arize-phoenix</code>: A tool for observability in machine learning workflows.</li> <li><code>openinference-instrumentation-openai</code>: A package to instrument OpenAI models with observability tools like Arize Phoenix.</li> </ul> <h3 id=12-setting-up-arize-phoenix>1.2 Setting up Arize Phoenix<a class=headerlink href=#12-setting-up-arize-phoenix title="Permanent link">¶</a></h3> <p>There are 3 ways to do this:</p> <p>Read more <a href=https://docs.arize.com/phoenix/quickstart>here.</a></p> <ul> <li>Command Line</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>python3<span class=w> </span>-m<span class=w> </span>phoenix.server.main<span class=w> </span>serve
</span></code></pre></div> <ul> <li>Docker</li> </ul> <p>Launch the phoenix docker image using:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>docker<span class=w> </span>run<span class=w> </span>-p<span class=w> </span><span class=m>6006</span>:6006<span class=w> </span>-p<span class=w> </span><span class=m>4317</span>:4317<span class=w> </span>arizephoenix/phoenix:latest
</span></code></pre></div> <p>This will expose the Phoenix UI and REST API on localhost:6006 and exposes the gRPC endpoint for spans on localhost:4317.</p> <ul> <li>Notebook</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>phoenix</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>px</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>px</span><span class=o>.</span><span class=n>launch_app</span><span class=p>()</span>
</span></code></pre></div> <h3 id=13-import-required-libraries-and-configure-the-environment>1.3 Import Required Libraries and Configure the Environment<a class=headerlink href=#13-import-required-libraries-and-configure-the-environment title="Permanent link">¶</a></h3> <p>Before proceeding with data processing and evaluation, import the necessary libraries and set up the environment:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>json</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=kn>from</span><span class=w> </span><span class=nn>getpass</span><span class=w> </span><span class=kn>import</span> <span class=n>getpass</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=kn>import</span><span class=w> </span><span class=nn>nest_asyncio</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=kn>from</span><span class=w> </span><span class=nn>tqdm</span><span class=w> </span><span class=kn>import</span> <span class=n>tqdm</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=kn>import</span><span class=w> </span><span class=nn>phoenix</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>px</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a>
</span><span id=__span-4-9><a id=__codelineno-4-9 name=__codelineno-4-9 href=#__codelineno-4-9></a><span class=c1># Allows concurrent evaluations in notebook environments</span>
</span><span id=__span-4-10><a id=__codelineno-4-10 name=__codelineno-4-10 href=#__codelineno-4-10></a><span class=n>nest_asyncio</span><span class=o>.</span><span class=n>apply</span><span class=p>()</span>
</span><span id=__span-4-11><a id=__codelineno-4-11 name=__codelineno-4-11 href=#__codelineno-4-11></a>
</span><span id=__span-4-12><a id=__codelineno-4-12 name=__codelineno-4-12 href=#__codelineno-4-12></a><span class=c1># Set display options for pandas DataFrames to show more content</span>
</span><span id=__span-4-13><a id=__codelineno-4-13 name=__codelineno-4-13 href=#__codelineno-4-13></a><span class=n>pd</span><span class=o>.</span><span class=n>set_option</span><span class=p>(</span><span class=s2>"display.max_colwidth"</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>json</code>, <code>os</code>: Standard Python libraries for handling JSON data and operating system interactions.</p> </li> <li> <p><code>getpass</code>: A utility for securely capturing password input. <code>nest_asyncio</code>: Allows the usage of asyncio within Jupyter notebooks.</p> </li> <li> <p><code>pandas</code> (<code>pd</code>): A powerful data manipulation library for Python.</p> </li> <li> <p><code>tqdm</code>: Provides progress bars for loops, useful for tracking the progress of data processing.</p> </li> <li> <p><code>phoenix</code> (<code>px</code>): The phoenix library is part of Arize's observability tools. It provides an interactive UI for exploring data and monitoring machine learning models.</p> </li> </ul> <p>Configure <code>nest_asyncio</code> to allow concurrent evaluations in notebook environments and set the maximum column width for pandas DataFrames to ensure better readability.</p> <h3 id=14-launch-the-phoenix-app>1.4 Launch the Phoenix App<a class=headerlink href=#14-launch-the-phoenix-app title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>px</span><span class=o>.</span><span class=n>launch_app</span><span class=p>()</span>
</span></code></pre></div> <p>This function initializes and launches the Phoenix app, which opens in a new tab in your default web browser. It provides an interactive interface for exploring datasets, visualizing model performance, and debugging.</p> <h3 id=15-view-the-phoenix-app-session>1.5 View the Phoenix App Session<a class=headerlink href=#15-view-the-phoenix-app-session title="Permanent link">¶</a></h3> <p>Once the Phoenix app is launched, you can use the session object to interact with the app directly in the notebook. Run the following code to launch the Phoenix app and view it in the current session:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Launch and view the Phoenix app session</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=p>(</span><span class=n>session</span> <span class=o>:=</span> <span class=n>px</span><span class=o>.</span><span class=n>launch_app</span><span class=p>())</span><span class=o>.</span><span class=n>view</span><span class=p>()</span>
</span></code></pre></div> <p>This line launches the Phoenix app and assigns the session to a variable named session, with the <code>view()</code> method allowing you to display the Phoenix app directly within the notebook interface, providing a more integrated experience without switching between the browser and the notebook.</p> <h3 id=16-set-up-the-endpoint-for-traces>1.6 Set Up the Endpoint for Traces<a class=headerlink href=#16-set-up-the-endpoint-for-traces title="Permanent link">¶</a></h3> <p>To send traces to the Phoenix app for analysis and observability, define the endpoint URL where the Phoenix app is listening for incoming data.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=n>endpoint</span> <span class=o>=</span> <span class=s2>"http://127.0.0.1:6006/v1/traces"</span>
</span></code></pre></div> <p>The <code>endpoint</code> variable stores the URL of the Phoenix app's endpoint that listens for incoming traces.</p> <h2 id=2-trace-open-ai>2. Trace Open AI<a class=headerlink href=#2-trace-open-ai title="Permanent link">¶</a></h2> <p>For more integration, <a href=https://docs.arize.com/phoenix/tracing/integrations-tracing>read.</a></p> <h3 id=21-install-and-import-the-openai-package>2.1 Install and Import the OpenAI Package<a class=headerlink href=#21-install-and-import-the-openai-package title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a>!pip<span class=w> </span>install<span class=w> </span>openai
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>import<span class=w> </span>openai
</span></code></pre></div> <p><code>openai</code>: The Python client library for OpenAI's API. It enables you to make requests to OpenAI's models, including GPT-3 and GPT-4, for various tasks.</p> <h3 id=22-configure-the-openai-api-key>2.2 Configure the OpenAI API Key<a class=headerlink href=#22-configure-the-openai-api-key title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>import</span><span class=w> </span><span class=nn>openai</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=kn>from</span><span class=w> </span><span class=nn>getpass</span><span class=w> </span><span class=kn>import</span> <span class=n>getpass</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=c1># Retrieve API key from environment variable or prompt user if not set</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=k>if</span> <span class=ow>not</span> <span class=p>(</span><span class=n>openai_api_key</span> <span class=o>:=</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>"OPENAI_API_KEY"</span><span class=p>)):</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>    <span class=n>openai_api_key</span> <span class=o>=</span> <span class=n>getpass</span><span class=p>(</span><span class=s2>"🔑 Enter your OpenAI API key: "</span><span class=p>)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=c1># Set the API key for the OpenAI client</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=n>openai</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=n>openai_api_key</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=c1># Store the API key in environment variables for future use</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"OPENAI_API_KEY"</span><span class=p>]</span> <span class=o>=</span> <span class=n>openai_api_key</span>
</span></code></pre></div> <ul> <li> <p>Retrieve API Key: The code first attempts to get the API key from an environment variable (OPENAI_API_KEY). If the key is not found, it prompts the user to enter it securely using getpass.</p> </li> <li> <p>Set API Key: The retrieved or provided API key is then set for the openai client library.</p> </li> <li> <p>Store API Key: Finally, the API key is stored in the environment variables to ensure it is available for future use within the session.</p> </li> </ul> <h3 id=23-set-up-opentelemetry-for-tracing>2.3 Set Up OpenTelemetry for Tracing<a class=headerlink href=#23-set-up-opentelemetry-for-tracing title="Permanent link">¶</a></h3> <p>To enable tracing for your OpenAI interactions, configure OpenTelemetry with the necessary components.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry</span><span class=w> </span><span class=kn>import</span> <span class=n>trace</span> <span class=k>as</span> <span class=n>trace_api</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.exporter.otlp.proto.http.trace_exporter</span><span class=w> </span><span class=kn>import</span> <span class=n>OTLPSpanExporter</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.sdk</span><span class=w> </span><span class=kn>import</span> <span class=n>trace</span> <span class=k>as</span> <span class=n>trace_sdk</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.sdk.trace.export</span><span class=w> </span><span class=kn>import</span> <span class=n>SimpleSpanProcessor</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=c1># Set up the Tracer Provider</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a><span class=n>tracer_provider</span> <span class=o>=</span> <span class=n>trace_sdk</span><span class=o>.</span><span class=n>TracerProvider</span><span class=p>()</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a><span class=c1># Define the OTLP Span Exporter with the endpoint</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a><span class=n>span_exporter</span> <span class=o>=</span> <span class=n>OTLPSpanExporter</span><span class=p>(</span><span class=n>endpoint</span><span class=p>)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a><span class=c1># Set up the Span Processor to process and export spans</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a><span class=n>span_processor</span> <span class=o>=</span> <span class=n>SimpleSpanProcessor</span><span class=p>(</span><span class=n>span_exporter</span><span class=p>)</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a><span class=c1># Add the Span Processor to the Tracer Provider</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a><span class=n>tracer_provider</span><span class=o>.</span><span class=n>add_span_processor</span><span class=p>(</span><span class=n>span_processor</span><span class=p>)</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a><span class=c1># Set the global Tracer Provider</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a><span class=n>trace_api</span><span class=o>.</span><span class=n>set_tracer_provider</span><span class=p>(</span><span class=n>tracer_provider</span><span class=p>)</span>
</span></code></pre></div> <p><strong>OpenTelemetry Libraries</strong></p> <p>In the provided code, several OpenTelemetry libraries are used to set up tracing. Here's an overview of each:</p> <ul> <li><code>opentelemetry</code>:</li> </ul> <p>*<strong>*Purpose**</strong>: The core library for OpenTelemetry, providing APIs for tracing and metrics.</p> <p><strong>Usage</strong>: It includes the trace module, which is used to create and manage traces.</p> <ul> <li><code>opentelemetry.exporter.otlp.proto.http.trace_exporter</code>:</li> </ul> <p><strong>Purpose</strong>: Provides the OTLP (OpenTelemetry Protocol) exporter for traces using HTTP.</p> <p><strong>Usage</strong>: The <code>OTLPSpanExporter</code> class in this module sends trace data to an OTLP-compatible backend. This exporter is configured with an endpoint where trace data will be sent.</p> <ul> <li><code>opentelemetry.sdk.trace</code>:</li> </ul> <p><strong>Purpose</strong>: Contains the SDK implementations for tracing, including the <code>TracerProvider</code>.</p> <p><strong>Usage</strong>:</p> <ul> <li> <p><code>TracerProvider</code>: Manages Tracer instances and is responsible for exporting spans (units of work) collected during tracing.</p> </li> <li> <p><code>SimpleSpanProcessor</code>: A span processor that exports spans synchronously, used to process and send trace data to the exporter.</p> </li> <li> <p><code>opentelemetry.sdk.trace.export</code>:</p> </li> </ul> <p><strong>Purpose</strong>: Provides classes for exporting trace data.</p> <p><strong>Usage</strong>:</p> <ul> <li><code>SimpleSpanProcessor</code>: Processes spans and exports them using the specified exporter. It ensures that spans are sent to the backend for analysis.</li> </ul> <h3 id=24-instrument-openai-with-openinference>2.4 Instrument OpenAI with OpenInference<a class=headerlink href=#24-instrument-openai-with-openinference title="Permanent link">¶</a></h3> <p>To integrate OpenTelemetry with OpenAI and enable tracing for OpenAI model interactions, use the <code>OpenAIInstrumentor</code> from the <code>openinference</code> library.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=kn>from</span><span class=w> </span><span class=nn>openinference.instrumentation.openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAIInstrumentor</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a><span class=c1># Instantiate and apply instrumentation for OpenAI</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a><span class=n>OpenAIInstrumentor</span><span class=p>()</span><span class=o>.</span><span class=n>instrument</span><span class=p>()</span>
</span></code></pre></div> <ul> <li> <p><code>OpenAIInstrumentor</code>: A class from the openinference library designed to instrument OpenAI's API calls, enabling tracing and observability.</p> </li> <li> <p><code>instrument()</code>: This method configures the OpenAI API client to automatically generate and send trace data to the OpenTelemetry backend. It integrates with the tracing setup you have configured, allowing you to monitor and analyze interactions with OpenAI's models.</p> </li> </ul> <p>By running this code, you ensure that all OpenAI API calls are traced, allowing you to capture detailed insights into model usage and performance.</p> <h3 id=25-make-a-request-to-openai-api>2.5 Make a Request to OpenAI API<a class=headerlink href=#25-make-a-request-to-openai-api title="Permanent link">¶</a></h3> <p>To interact with OpenAI’s API and obtain a response, use the following code. This example demonstrates how to create a chat completion using the OpenAI API and print the result:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=kn>import</span><span class=w> </span><span class=nn>openai</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=c1># Create an OpenAI client instance</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=n>client</span> <span class=o>=</span> <span class=n>openai</span><span class=o>.</span><span class=n>OpenAI</span><span class=p>()</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=c1># Make a request to the OpenAI API for a chat completion</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a><span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>    <span class=n>model</span><span class=o>=</span><span class=s2>"gpt-4o"</span><span class=p>,</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>    <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>"role"</span><span class=p>:</span> <span class=s2>"user"</span><span class=p>,</span> <span class=s2>"content"</span><span class=p>:</span> <span class=s2>"Write a haiku."</span><span class=p>}],</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a><span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a><span class=c1># Print the content of the response</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>openai.OpenAI()</code>: Initializes an OpenAI client instance that can be used to interact with the OpenAI API.</p> </li> <li> <p><code>client.chat.completions.create()</code>: Sends a request to the OpenAI API to create a chat completion using the specified model.</p> </li> <li> <p><code>model="gpt-4o"</code>: Specifies the model to use for generating completions. Ensure the model name is correct and available in your OpenAI API account.</p> </li> <li> <p><code>messages</code>: A list of message objects representing the conversation history. In this case, it includes a single message from the user asking to "Write a haiku."</p> </li> </ul> <p><code>response.choices[0].message.content</code>: Extracts and prints the content of the completion response generated by the model.</p> <h2 id=3-trace-llama-index>3. Trace Llama index<a class=headerlink href=#3-trace-llama-index title="Permanent link">¶</a></h2> <h3 id=31-install-and-import-the-required-libraries>3.1 Install and Import the Required Libraries<a class=headerlink href=#31-install-and-import-the-required-libraries title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a>!pip<span class=w> </span>install<span class=w> </span>llama-index
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-core
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-llms-openai
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>!pip<span class=w> </span>install<span class=w> </span>openinference-instrumentation-llama-index<span class=o>==</span><span class=m>2</span>.2.4
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>!pip<span class=w> </span>install<span class=w> </span>-U<span class=w> </span>llama-index-callbacks-arize-phoenix
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>!pip<span class=w> </span>install<span class=w> </span><span class=s2>"arize-phoenix[llama-index]"</span>
</span></code></pre></div> <ul> <li> <p><code>llama-index</code>: Core package for Llama Index functionality.</p> </li> <li> <p><code>llama-index-core</code>: Provides core features and utilities for Llama Index.</p> </li> <li> <p><code>llama-index-llms-openai</code>: Integration package for Llama Index and OpenAI models.</p> </li> <li> <p><code>openinference-instrumentation-llama-index==2.2.4</code>: Provides instrumentation for tracing Llama Index interactions.</p> </li> <li> <p><code>llama-index-callbacks-arize-phoenix</code>: Callback integration for Arize Phoenix with Llama Index.</p> </li> <li> <p><code>arize-phoenix[llama-index]</code>: Extends Arize Phoenix to support Llama Index tracing.</p> </li> </ul> <h3 id=32-retrieve-the-url-of-the-active-phoenix-session>3.2 Retrieve the URL of the Active Phoenix Session<a class=headerlink href=#32-retrieve-the-url-of-the-active-phoenix-session title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># Retrieve the URL of the active Phoenix session</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>px</span><span class=o>.</span><span class=n>active_session</span><span class=p>()</span><span class=o>.</span><span class=n>url</span>
</span></code></pre></div> <p>Accesses the current active session of the Phoenix app and retrieves its URL, allowing you to view or share the link to the Phoenix interface where you can monitor and analyze trace data.</p> <h3 id=33-set-up-tracing-for-llama-index>3.3 Set Up Tracing for Llama Index<a class=headerlink href=#33-set-up-tracing-for-llama-index title="Permanent link">¶</a></h3> <p>To instrument Llama Index for tracing with OpenTelemetry, configure the tracer provider and integrate the Llama Index instrumentor.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=kn>from</span><span class=w> </span><span class=nn>openinference.instrumentation.llama_index</span><span class=w> </span><span class=kn>import</span> <span class=n>LlamaIndexInstrumentor</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.exporter.otlp.proto.http.trace_exporter</span><span class=w> </span><span class=kn>import</span> <span class=n>OTLPSpanExporter</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.sdk</span><span class=w> </span><span class=kn>import</span> <span class=n>trace</span> <span class=k>as</span> <span class=n>trace_sdk</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=kn>from</span><span class=w> </span><span class=nn>opentelemetry.sdk.trace.export</span><span class=w> </span><span class=kn>import</span> <span class=n>SimpleSpanProcessor</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a><span class=c1># Set up the Tracer Provider</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=n>tracer_provider</span> <span class=o>=</span> <span class=n>trace_sdk</span><span class=o>.</span><span class=n>TracerProvider</span><span class=p>()</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a><span class=c1># Add Span Processor to the Tracer Provider</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a><span class=n>tracer_provider</span><span class=o>.</span><span class=n>add_span_processor</span><span class=p>(</span><span class=n>SimpleSpanProcessor</span><span class=p>(</span><span class=n>OTLPSpanExporter</span><span class=p>(</span><span class=n>endpoint</span><span class=p>)))</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a><span class=c1># Instrument Llama Index with the Tracer Provider</span>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a><span class=n>LlamaIndexInstrumentor</span><span class=p>()</span><span class=o>.</span><span class=n>instrument</span><span class=p>(</span><span class=n>tracer_provider</span><span class=o>=</span><span class=n>tracer_provider</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>LlamaIndexInstrumentor</code>: This class from openinference.instrumentation.llama_index instruments Llama Index to support tracing and observability.</p> </li> <li> <p><code>trace_sdk.TracerProvider()</code>: Initializes a new Tracer Provider responsible for creating and managing trace data. OTLPSpanExporter(endpoint): Configures the OTLP exporter to send trace data to the specified endpoint.</p> </li> <li> <p><code>SimpleSpanProcessor</code>: Processes and exports spans synchronously.</p> </li> <li> <p><code>tracer_provider.add_span_processor</code>: Adds the span processor to the Tracer Provider.</p> </li> <li> <p><code>LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)</code>: Applies the instrumentation to Llama Index, using the provided Tracer Provider for tracing.</p> </li> </ul> <h3 id=34-interact-with-llama-index-using-openai>3.4 Interact with Llama Index Using OpenAI<a class=headerlink href=#34-interact-with-llama-index-using-openai title="Permanent link">¶</a></h3> <p>To perform a completion request with Llama Index using an OpenAI model, use the following code:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.llms.openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a><span class=c1># Initialize the OpenAI model</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=n>llm</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>"gpt-4o-mini"</span><span class=p>)</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a><span class=c1># Make a completion request</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=n>resp</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>complete</span><span class=p>(</span><span class=s2>"Paul Graham is "</span><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=c1># Print the response</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=nb>print</span><span class=p>(</span><span class=n>resp</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>from llama_index.llms.openai import OpenAI</code>: Imports the OpenAI class from the llama_index package, allowing interaction with OpenAI models.</p> </li> <li> <p><code>OpenAI(model="gpt-4o-mini")</code>: Initializes an instance of the OpenAI class with the specified model (e.g., gpt-4).</p> </li> <li> <p><code>llm.complete(...)</code>: Sends a prompt to the model to generate a completion based on the input text.</p> </li> </ul> <h3 id=35-perform-a-chat-interaction-with-llama-index-using-openai>3.5 Perform a Chat Interaction with Llama Index Using OpenAI<a class=headerlink href=#35-perform-a-chat-interaction-with-llama-index-using-openai title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.llms.openai</span><span class=w> </span><span class=kn>import</span> <span class=n>OpenAI</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.core.llms</span><span class=w> </span><span class=kn>import</span> <span class=n>ChatMessage</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=c1># Initialize the OpenAI model</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=n>llm</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>()</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a><span class=c1># Define the chat messages</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>    <span class=n>ChatMessage</span><span class=p>(</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>        <span class=n>role</span><span class=o>=</span><span class=s2>"system"</span><span class=p>,</span> <span class=n>content</span><span class=o>=</span><span class=s2>"You are a pirate with a colorful personality"</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>    <span class=p>),</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>    <span class=n>ChatMessage</span><span class=p>(</span><span class=n>role</span><span class=o>=</span><span class=s2>"user"</span><span class=p>,</span> <span class=n>content</span><span class=o>=</span><span class=s2>"What is your name"</span><span class=p>),</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a><span class=p>]</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a><span class=c1># Get the response from the model</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a><span class=n>resp</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>OpenAI</code>: A class for interacting with OpenAI models.</p> </li> <li> <p><code>ChatMessage</code>: A class to format chat messages.</p> </li> <li> <p><code>OpenAI()</code>: Initializes an instance of the OpenAI class.</p> </li> <li> <p><code>ChatMessage</code>: Creates chat message objects with a specified role (e.g., "system", "user") and content.</p> </li> <li> <p><code>role="system"</code>: Defines the system message to set the context or personality of the model.</p> </li> <li> <p><code>role="user"</code>: Represents a user message in the chat.</p> </li> <li> <p><code>llm.chat(messages)</code>: Sends the defined messages to the model and retrieves the response.</p> </li> </ul> <p>This code sets up a chat with an OpenAI model, specifying system and user messages to guide the interaction.</p> <h2 id=4-observe-rag-pipeline>4. Observe RAG Pipeline<a class=headerlink href=#4-observe-rag-pipeline title="Permanent link">¶</a></h2> <h3 id=41-setup-an-environment-for-observing-a-rag-piepline>4.1 Setup an environment for observing a RAG piepline<a class=headerlink href=#41-setup-an-environment-for-observing-a-rag-piepline title="Permanent link">¶</a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>!pip<span class=w> </span>install<span class=w> </span>llama-index
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-vector-stores-qdrant
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-readers-file
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-embeddings-fastembed
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a>!pip<span class=w> </span>install<span class=w> </span>llama-index-llms-openai
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a>!pip<span class=w> </span>install<span class=w> </span>-U<span class=w> </span>qdrant_client<span class=w> </span>fastembed
</span></code></pre></div> <ul> <li> <p><code>llama-index</code>: Core package for Llama Index functionality.</p> </li> <li> <p><code>llama-index-vector-stores-qdrant</code>: Integration for using Qdrant as a vector store with Llama Index.</p> </li> <li> <p><code>llama-index-readers-file</code>: Provides file reading capabilities for Llama Index.</p> </li> <li> <p><code>llama-index-embeddings-fastembed</code>: Adds FastEmbed support for generating embeddings with Llama Index.</p> </li> <li> <p><code>llama-index-llms-openai</code>: Integration for using OpenAI models with Llama Index.</p> </li> <li> <p><code>qdrant_client</code>: Client library for interacting with Qdrant, a vector search engine.</p> </li> <li> <p><code>fastembed</code>: Library for generating embeddings quickly.</p> </li> </ul> <h3 id=42-prepare-rag-pipeline-with-embeddings-and-document-indexing>4.2 Prepare RAG Pipeline with Embeddings and Document Indexing<a class=headerlink href=#42-prepare-rag-pipeline-with-embeddings-and-document-indexing title="Permanent link">¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.core</span><span class=w> </span><span class=kn>import</span> <span class=n>VectorStoreIndex</span><span class=p>,</span> <span class=n>SimpleDirectoryReader</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.embeddings.fastembed</span><span class=w> </span><span class=kn>import</span> <span class=n>FastEmbedEmbedding</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=c1># from llama_index.embeddings.openai import OpenAIEmbedding</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=kn>from</span><span class=w> </span><span class=nn>llama_index.core.settings</span><span class=w> </span><span class=kn>import</span> <span class=n>Settings</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a><span class=n>Settings</span><span class=o>.</span><span class=n>embed_model</span> <span class=o>=</span> <span class=n>FastEmbedEmbedding</span><span class=p>(</span><span class=n>model_name</span><span class=o>=</span><span class=s2>"BAAI/bge-base-en-v1.5"</span><span class=p>)</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=c1># Settings.embed_model = OpenAIEmbedding(embed_batch_size=10)</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a><span class=n>documents</span> <span class=o>=</span> <span class=n>SimpleDirectoryReader</span><span class=p>(</span><span class=s2>"data"</span><span class=p>)</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a><span class=n>index</span> <span class=o>=</span> <span class=n>VectorStoreIndex</span><span class=o>.</span><span class=n>from_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>VectorStoreIndex</code>: A class used to create and manage a vector store index. This index allows for efficient similarity search and retrieval based on vector representations of documents.</p> </li> <li> <p><code>SimpleDirectoryReader</code>: A class for loading documents from a specified directory. It reads and preprocesses files from the directory "sample_data" to be used in the indexing process.</p> </li> <li> <p><code>FastEmbedEmbedding</code>: Provides an embedding model for generating vector representations of text using the FastEmbed library. The model specified ("BAAI/bge-base-en-v1.5") is used to convert documents into embeddings, which are then used for similarity search within the vector store index.</p> </li> <li> <p><code>from llama_index.embeddings.openai import OpenAIEmbedding</code>:</p> </li> </ul> <p><code>OpenAIEmbedding</code>: (Commented out) Provides an embedding model for generating vector representations using OpenAI’s embeddings. Uncomment this line if you wish to use OpenAI’s model instead of FastEmbed. This model can be configured with parameters like <code>embed_batch_size</code> for batch processing.</p> <ul> <li> <p><code>Settings</code>: A configuration class used to set global settings for embedding models. By assigning the embed_model attribute, you specify which embedding model to use for the RAG pipeline.</p> </li> <li> <p><code>Settings.embed_model = FastEmbedEmbedding(model_name="BAAI/bge-base-en-v1.5")</code> Configures the Settings class to use the FastEmbed model for generating embeddings. This step is crucial for defining how text data will be represented in the vector store.</p> </li> <li> <p><code>documents = SimpleDirectoryReader("data").load_data()</code> Loads and preprocesses documents (in this case) from the "data" directory. Please ensure to tweak the directory name according to your project. The <code>load_data()</code> method reads all files in the specified directory and prepares them for indexing.</p> </li> <li> <p><code>index = VectorStoreIndex.from_documents(documents)</code> Creates a VectorStoreIndex from the preprocessed documents. This index allows for efficient querying and retrieval based on the vector representations generated by the embedding model.</p> </li> </ul> <h3 id=43-query-the-vector-store-index>4.3 Query the Vector Store Index<a class=headerlink href=#43-query-the-vector-store-index title="Permanent link">¶</a></h3> <p>Once the vector store index is set up, you can use it to perform queries and retrieve relevant information.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=n>query_engine</span> <span class=o>=</span> <span class=n>index</span><span class=o>.</span><span class=n>as_query_engine</span><span class=p>()</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=n>response</span> <span class=o>=</span> <span class=n>query_engine</span><span class=o>.</span><span class=n>query</span><span class=p>(</span><span class=s2>"What did the author do growing up?"</span><span class=p>)</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></code></pre></div> <ul> <li> <p><code>as_query_engine()</code>: Converts the <code>VectorStoreIndex</code> into a query engine. This engine allows you to perform searches and retrieve information based on the vector representations of documents stored in the index.</p> </li> <li> <p><code>query()</code>: Executes a query against the vector store index. The query string "What did the author do growing up?" is used to search for relevant documents and retrieve information based on the context provided by the vector embeddings.</p> </li> </ul> <p>Finally, the <code>response</code> containing the information retrieved from the vector store index, which is based on the query and the indexed documents is output.</p> <h2 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">¶</a></h2> <p>In this guide, we have set up a Retrieval-Augmented Generation (RAG) pipeline using Llama Index and integrated it with various components to observe its functionality. We began by configuring and installing the necessary libraries, including Llama Index, OpenTelemetry, and various embedding models.</p> <p>We then proceeded to:</p> <ul> <li>Initialize and configure the embedding models, using FastEmbed or OpenAI models as needed.</li> <li>Load and index documents from a directory to prepare the data for querying.</li> <li>Set up a query engine to perform searches and retrieve relevant information based on the indexed documents.</li> </ul> <p>By following these steps, you have successfully prepared a RAG pipeline capable of efficient document retrieval and query processing. This setup enables advanced search and information retrieval capabilities, leveraging the power of vector-based embeddings and indexing.</p> <p>Feel free to experiment with different configurations and queries to further explore the capabilities of the RAG pipeline. For any questions or additional customization, consult the documentation of the libraries used or seek further guidance.</p> <p>If you find this guide helpful, please consider giving us a star on GitHub! ⭐</p> <p><a href=https://github.com/adithya-s-k/AI-Engineering.academy><img alt="GitHub stars" src="https://img.shields.io/github/stars/adithya-s-k/AI-Engineering.academy.svg?style=social&label=Star&maxAge=2482000"></a></p> <p>Thank you for following this guide, and happy querying!</p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 13, 2025 19:27:59 UTC">October 13, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 13, 2025 19:27:59 UTC">October 13, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../01_RAG_Evaluation/notebook/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Notebook"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Notebook </div> </div> </a> <a href=notebook/ class="md-footer__link md-footer__link--next" aria-label="Next: Observability(Arize Phoenix)"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Observability(Arize Phoenix) </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>