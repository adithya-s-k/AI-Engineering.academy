<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/LLM/ServerLessFinetuning/ rel=canonical><link href=../VLM/PaliGemma_finetuning_notebook/ rel=prev><link href=TrainNanoGPTModalTutorial/ rel=next><link rel=icon href=../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>Write Deep Learning Code Locally and Run on GPUs Instantly - AI Engineering Academy</title><link rel=stylesheet href=../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../assets/_mkdocstrings.css><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script><meta property=og:type content=website><meta property=og:title content="Write Deep Learning Code Locally and Run on GPUs Instantly - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/index.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/LLM/ServerLessFinetuning/ property=og:url><meta property=twitter:card content=summary_large_image><meta property=twitter:title content="Write Deep Learning Code Locally and Run on GPUs Instantly - AI Engineering Academy"><meta property=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta property=twitter:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/index.png></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#write-code-locally-and-run-it-on-gpus-in-seconds class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Write Deep Learning Code Locally and Run on GPUs Instantly </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class=md-tabs__item> <a href=../../RAG/ class=md-tabs__link> RAG </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../AIBreakDown/TRM/ class=md-tabs__link> AI BreakDown </a> </li> <li class=md-tabs__item> <a href=../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../RAG/ class=md-nav__link> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> LLM </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex> <span class=md-ellipsis> Finetuning Techniques </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Finetuning Techniques </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../TheoryBehindFinetuning/PreTrain/ class=md-nav__link> <span class=md-ellipsis> PreTraining LLMs </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../TheoryBehindFinetuning/SFT/ class=md-nav__link> <span class=md-ellipsis> SFT </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../TheoryBehindFinetuning/PPO/ class=md-nav__link> <span class=md-ellipsis> PPO(Proximal Policy Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../TheoryBehindFinetuning/DPO/ class=md-nav__link> <span class=md-ellipsis> DPO(Direct Preference Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../TheoryBehindFinetuning/ORPO/ class=md-nav__link> <span class=md-ellipsis> ORPO(Odds Ratio Preference Optimization) </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../TheoryBehindFinetuning/GRPO/ class=md-nav__link> <span class=md-ellipsis> GRPO(Group Relative Policy Optimization) </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex> <span class=md-ellipsis> LLM Finetuning Hands on </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> LLM Finetuning Hands on </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../Gemma/ class=md-nav__link> <span class=md-ellipsis> Gemma </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../LLama2/Llama2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Llama2 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../Llama3_finetuning_notebook.ipynb class=md-nav__link> <span class=md-ellipsis> Llama3 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../Mistral-7b/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex> <span class=md-ellipsis> VLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> VLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../VLM/Florence2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Florence2 </span> </a> </li> <li class=md-nav__item> <a href=../VLM/PaliGemma_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> PaliGemma </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_5 checked> <div class="md-nav__link md-nav__container"> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Serverless Finetuning with Modal </span> </a> <label class="md-nav__link md-nav__link--active" for=__nav_4_5 id=__nav_4_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_5_label aria-expanded=true> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Serverless Finetuning with Modal </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=TrainNanoGPTModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training NanoGPT on Modal </span> </a> </li> <li class=md-nav__item> <a href=TrainNanochatModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training Nanochat on Modal </span> </a> </li> <li class=md-nav__item> <a href=FinetuneGemmaUnslothModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> </a> </li> <li class=md-nav__item> <a href=FinetuneLlamaAxolotlGPUModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Multi-GPU Training with Axolotl </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_6> <div class="md-nav__link md-nav__container"> <a href=../LLMArchitecture/ParameterCount/ class="md-nav__link "> <span class=md-ellipsis> LLM Architecture </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> LLM Architecture </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../AIBreakDown/TRM/ class=md-nav__link> <span class=md-ellipsis> AI BreakDown </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#stop-paying-for-idle-gpus-serverless-training-with-modal class=md-nav__link> <span class=md-ellipsis> Stop Paying for Idle GPUs: Serverless Training with Modal </span> </a> </li> <li class=md-nav__item> <a href=#inspiration class=md-nav__link> <span class=md-ellipsis> Inspiration </span> </a> </li> <li class=md-nav__item> <a href=#ok-what-is-modal class=md-nav__link> <span class=md-ellipsis> Ok, what is Modal? </span> </a> <nav class=md-nav aria-label="Ok, what is Modal?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> </li> <li class=md-nav__item> <a href=#core-concepts class=md-nav__link> <span class=md-ellipsis> Core Concepts </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tutorials class=md-nav__link> <span class=md-ellipsis> Tutorials </span> </a> <nav class=md-nav aria-label=Tutorials> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-training-nanogpt-on-modal class=md-nav__link> <span class=md-ellipsis> 1. Training NanoGPT on Modal </span> </a> </li> <li class=md-nav__item> <a href=#2-training-nanochat-on-modal class=md-nav__link> <span class=md-ellipsis> 2. Training Nanochat on Modal </span> </a> </li> <li class=md-nav__item> <a href=#3-fine-tuning-gemma-3-4b-with-unsloth class=md-nav__link> <span class=md-ellipsis> 3. Fine-tuning Gemma 3-4B with Unsloth </span> </a> </li> <li class=md-nav__item> <a href=#4-multi-gpu-training-with-axolotl class=md-nav__link> <span class=md-ellipsis> 4. Multi-GPU Training with Axolotl </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#final-thoughts class=md-nav__link> <span class=md-ellipsis> Final thoughts </span> </a> <nav class=md-nav aria-label="Final thoughts"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#need-help class=md-nav__link> <span class=md-ellipsis> Need Help? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/LLM/ServerLessFinetuning/README.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/LLM/ServerLessFinetuning/README.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=write-code-locally-and-run-it-on-gpus-in-seconds>Write code locally and run it on GPUs in Seconds<a class=headerlink href=#write-code-locally-and-run-it-on-gpus-in-seconds title="Permanent link">Â¶</a></h1> <h2 id=stop-paying-for-idle-gpus-serverless-training-with-modal>Stop Paying for Idle GPUs: Serverless Training with Modal<a class=headerlink href=#stop-paying-for-idle-gpus-serverless-training-with-modal title="Permanent link">Â¶</a></h2> <p>So let's face it, if you are doing anything with deep learning, GPUs are a must.</p> <p>They are expensive, and infrastructure is hard to set up. Most of the time, you're coding when the GPUs are sitting idle, and it's a pain to pay for the uptime when no deep learning scripts work on the first go.</p> <p>This was a problem I faced as "GPU Poor". I didn't want to spend money on GPUs when I was coding or doing something that didn't leverage the GPU compute. Even for things like downloading data, models, and data transformation, you don't need a GPU but still have to do it on a GPU.</p> <p>And especially on cloud providers, where you will have to worry about infrastructure. You can set up a VM with a GPU attached, then choose an image which is not even well-documented. If not done properly, you will have to install CUDA and stuff from scratch. If that also doesn't work, most of the time you resort to using a Docker container with the right installations.</p> <p>And if you start doing multi-GPU training, that's one more burden. Some GPU images don't even support NCCL for communication between GPU nodes, so you will have to be careful about that as well.</p> <p>So if you just want to set up a GPU and run, it's a lot of effort. There are providers like Runpod, Vast AI, and others that make it easier.</p> <p>I run a research lab called CognitiveLab [cognitivelab.in], where we do a bunch of model training, synthetic data generation, RL runs, and more. We wanted something that was easy to use, train, and flexible enough so that we don't need to be constrained by it.</p> <p>But when I looked for a solution where I could <strong>write my code locally on my machine and run it on a GPU</strong>, I stumbled across this beautiful solution called <a href=https://modal.com>Modal</a>. It's been 1 year since I started using it, and it's been a blessing.</p> <p>I will be covering the following:</p> <ul> <li>How to handle datasets on Modal efficiently, including creating and managing volumes for seamless data access.</li> <li>Writing training scripts using libraries like Unsloth and Axolotl to fine-tune models with minimal effort.</li> <li>Evaluating trained models with automated metrics to ensure performance and reliability.</li> <li>Serving these models in a scalable and high-throughput manner using vLLM for real-world applications.</li> </ul> <p>By the end of this, you'll have a clear understanding of how to write and experiment with training scripts locally and run them on GPUs as quickly as possible using Modal.</p> <blockquote> <p>I will be mainly covering SFT examples, but if you guys are interested, I will write a blog on how to set it up for RL with RL training and reward environments happening on different GPUs.</p> </blockquote> <h2 id=inspiration>Inspiration<a class=headerlink href=#inspiration title="Permanent link">Â¶</a></h2> <p><a href=https://x.com/thinkymachines><strong>Thinking Machines</strong></a>, the startup founded by ex-OpenAI CTO Mira Murati, recently launched Tinker, which allows developers to write training loops in Python on their laptops and run them on distributed GPUs.</p> <p>Check out their announcement: <a href=https://x.com/thinkymachines/status/1973447428977336578>Thinking Machines on X</a>.</p> <p>This is every developer's dream! However, I have been using Modal to achieve something similar for quite some time now.</p> <blockquote> <p><strong>PS:</strong> From the looks of it, their API is much more sophisticated. They have implemented several optimizations under the hood, such as efficient batching. Here is a <a href=https://x.com/cHHillee/status/1973469947889422539>tweet</a> that dives deeper into the details.</p> </blockquote> <div style="text-align: center; margin: 2em 0;"> <blockquote class=twitter-tweet data-theme=light><p dir=ltr>This is really cool, but you can do the same thing using <a href="https://twitter.com/modal?ref_src=twsrc%5Etfw">@modal</a> with just a few more lines of code.<br><br>You write the training loops on your local machine and then run it in on any number of GPUs and its way more flexible:<br><br>- It works with existing repos<br>- You only pay for the timeâ€¦ <a href=https://t.co/IVOalMvFVC>https://t.co/IVOalMvFVC</a></p>â€” Adithya S K (@adithya_s_k) <a href="https://twitter.com/adithya_s_k/status/1973977595726450739?ref_src=twsrc%5Etfw">October 3, 2025</a></blockquote> <script async src=https://platform.twitter.com/widgets.js charset=utf-8></script> </div> <p>Lot of you were interested in how to do this, so here we go.</p> <h2 id=ok-what-is-modal>Ok, what is Modal?<a class=headerlink href=#ok-what-is-modal title="Permanent link">Â¶</a></h2> <p>You would have come across the term Serverless GPUs.</p> <p>Let's just say Modal is a GPU provider platform that does right by serverless GPUs, and they have one of the best developer experiences ever.</p> <p>If you are doing anything in Python, training models, deploying them, writing servers, building agentic systems, then Modal can be used.</p> <p>As per the official Modal website:</p> <blockquote> <p>AI infrastructure that developers love, and that's 100% factual.</p> <p>Run inference, train, batch process with sub-second cold start, instant auto-scaling, and a developer experience that feels local.</p> </blockquote> <p><strong>Fun fact:</strong> Even Lovable uses Modal for running their sandbox.</p> <h3 id=getting-started>Getting Started<a class=headerlink href=#getting-started title="Permanent link">Â¶</a></h3> <p>First, all you have to do is:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>pip<span class=w> </span>install<span class=w> </span>modal
</span></code></pre></div> <p>and do:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>modal<span class=w> </span>setup
</span></code></pre></div> <p>You can also authenticate through their API keys:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_ID</span><span class=o>=</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_SECRET</span><span class=o>=</span>
</span></code></pre></div> <p>This is all you need to set up Modal.</p> <h3 id=core-concepts>Core Concepts<a class=headerlink href=#core-concepts title="Permanent link">Â¶</a></h3> <p>With Modal, you always start by creating an App, an Image, and Volumes.</p> <p><strong>App</strong> - To create an App, it's pretty simple:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>modal</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=c1># Create the Modal app</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=n>app</span> <span class=o>=</span> <span class=n>modal</span><span class=o>.</span><span class=n>App</span><span class=p>(</span><span class=s2>"&lt;app_name&gt;"</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Volumes</strong> - Then we can create or use existing volumes.</p> <p>You can think of volumes as a storage file system where you can store anything like model weights, datasets, scores, and more.</p> <p>If you want something to persist, add it in the volume. The best part is, for a function, you can have multiple volumes with different routes; you can have a volume for model weights in the <code>/model</code> path and for the dataset in the <code>/dataset</code> path.</p> <p>Something like this:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=n>dataset_volume</span> <span class=o>=</span> <span class=n>modal</span><span class=o>.</span><span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"dataset-volume"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>model_volume</span> <span class=o>=</span> <span class=n>modal</span><span class=o>.</span><span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"model-volume"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <p>Then you write the mapping that will be passed into functions:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>volume_config</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=s2>"/dataset"</span><span class=p>:</span> <span class=n>dataset_volume</span><span class=p>,</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=s2>"/model"</span><span class=p>:</span> <span class=n>model_volume</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=p>}</span>
</span></code></pre></div> <p>This is just to illustrate how you can attach volumes to any function. This gives us awesome power.</p> <p>You can download datasets, process them all on CPU instances, and when it comes time to train, just attach the same volume and use it, which makes life much easier.</p> <blockquote> <p>I generally create a volume for a single experiment or training run so that I have everything consolidated that can be used across the project.</p> </blockquote> <p><strong>Images</strong> - Next thing will be the images.</p> <p>This is the most important part. Defining an image can be tricky at first, but once it's done, you don't have to worry about it. Initially, it can take up some time.</p> <p>But it's very important. Refer to <a href=https://modal.com/docs/reference/modal.Image>Modal Image docs</a> to see all the ways to create an image.</p> <p>Here is a sample example image:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=n>train_image</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=n>modal</span><span class=o>.</span><span class=n>Image</span><span class=o>.</span><span class=n>debian_slim</span><span class=p>(</span><span class=n>python_version</span><span class=o>=</span><span class=s2>"3.11"</span><span class=p>)</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=o>.</span><span class=n>uv_pip_install</span><span class=p>(</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>        <span class=s2>"accelerate==1.9.0"</span><span class=p>,</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>        <span class=s2>"datasets==3.6.0"</span><span class=p>,</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>        <span class=s2>"hf-transfer==0.1.9"</span><span class=p>,</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>        <span class=s2>"huggingface_hub==0.34.2"</span><span class=p>,</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>        <span class=s2>"peft==0.16.0"</span><span class=p>,</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>        <span class=s2>"transformers==4.54.0"</span><span class=p>,</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>        <span class=s2>"trl==0.19.1"</span><span class=p>,</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>        <span class=s2>"unsloth[cu128-torch270]==2025.7.8"</span><span class=p>,</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>        <span class=s2>"unsloth_zoo==2025.7.10"</span><span class=p>,</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=s2>"wandb==0.21.0"</span><span class=p>,</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>    <span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>    <span class=o>.</span><span class=n>env</span><span class=p>({</span><span class=s2>"HF_HOME"</span><span class=p>:</span> <span class=s2>"/model_cache"</span><span class=p>})</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a><span class=p>)</span>
</span></code></pre></div> <p>So the base image uses Debian with Python 3.11, and then you install all the packages using uv. Then you set the environment <code>HF_HOME</code> so that everything is cached, and you won't have to download again and again. This is a good starting image.</p> <blockquote> <p><strong>Pro tip:</strong> I have a set of images that you can use for anything training-related. I have images to serve LLMs using vLLM, SGLang, training using Unsloth, MS Swift, and more. I will share these and go deeper into how to create images in a better way later.</p> </blockquote> <p><strong>Functions</strong> - There is one more thing: Functions.</p> <p>You can basically have any Python function to make it run on GPU or CPU on Modal. All you have to do is add a decorator:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>image</span><span class=p>,</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>modal</span><span class=o>.</span><span class=n>Secret</span><span class=o>.</span><span class=n>from_dotenv</span><span class=p>()],</span>  <span class=c1># local .env variables</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=p>{</span><span class=s2>"/data"</span><span class=p>:</span> <span class=n>volume</span><span class=p>},</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>3600</span><span class=p>,</span>  <span class=c1># 1 hour timeout</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=p>)</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=k>def</span><span class=w> </span><span class=nf>any_python_function</span><span class=p>():</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>    <span class=c1># Your code here</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>    <span class=k>pass</span>
</span></code></pre></div> <p>This is where you define which image the function will use, what secrets you will be passing, which volumes will be attached, and what is the timeout (there is a general timeout of 24 hrs).</p> <p>To know all the properties of a function, refer to <a href=https://modal.com/docs/reference/modal.Function>Modal Function docs</a></p> <hr> <p>Now the basics are out of the way. Let's do some training, fine-tuning, evaluation, and serving.</p> <h2 id=tutorials>Tutorials<a class=headerlink href=#tutorials title="Permanent link">Â¶</a></h2> <p>I have created comprehensive tutorials for each training approach:</p> <h3 id=1-training-nanogpt-on-modal>1. <a href=TrainNanoGPTModalTutorial/ >Training NanoGPT on Modal</a><a class=headerlink href=#1-training-nanogpt-on-modal title="Permanent link">Â¶</a></h3> <p>ðŸ“„ <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/TrainNanoGPTModal.py>View Python Script</a></strong></p> <p>Learn how to take an existing codebase (Andrej Karpathy's nanoGPT) and run it on Modal's serverless GPUs with minimal modifications. Perfect for beginners to understand:</p> <ul> <li>How to copy local repositories into Modal containers</li> <li>Data preparation, training, and sampling pipelines</li> <li>Managing persistent storage with Modal volumes</li> <li>Running existing Python projects on remote GPUs</li> </ul> <table> <thead> <tr> <th><strong>Level</strong></th> <th><strong>GPU Required</strong></th> <th><strong>Time</strong></th> </tr> </thead> <tbody> <tr> <td>Beginner</td> <td>1Ã— A100-40GB (or T4/L40S for testing)</td> <td>30 mins - 2 hours</td> </tr> </tbody> </table> <hr> <h3 id=2-training-nanochat-on-modal>2. <a href=TrainNanochatModalTutorial/ >Training Nanochat on Modal</a><a class=headerlink href=#2-training-nanochat-on-modal title="Permanent link">Â¶</a></h3> <p><strong>Build Your Own ChatGPT from Scratch - The Complete Pipeline</strong></p> <p>ðŸ“„ <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/TrainNanochatModal.py>View Python Script</a></strong></p> <p>The ultimate educational LLM training pipeline covering every step from raw text to a functioning ChatGPT. You'll learn:</p> <ul> <li>Training a custom BPE tokenizer (like GPT-4)</li> <li>Base model pretraining from random initialization</li> <li>Midtraining for conversation format and tool use</li> <li>Supervised fine-tuning on multiple tasks</li> <li>Reinforcement learning for improved reasoning</li> <li>Comprehensive evaluation on real benchmarks</li> <li>Deployment with CLI and web UI</li> </ul> <table> <thead> <tr> <th><strong>Level</strong></th> <th><strong>GPU Required</strong></th> <th><strong>Time</strong></th> </tr> </thead> <tbody> <tr> <td>Advanced</td> <td>4-8Ã— A100-80GB</td> <td>4-8 hours (full speedrun)</td> </tr> </tbody> </table> <blockquote> <p>This is the most comprehensive tutorial - you'll understand exactly how ChatGPT works by building one yourself. Perfect for those who want to go deep.</p> </blockquote> <hr> <h3 id=3-fine-tuning-gemma-3-4b-with-unsloth>3. <a href=FinetuneGemmaUnslothModalTutorial/ >Fine-tuning Gemma 3-4B with Unsloth</a><a class=headerlink href=#3-fine-tuning-gemma-3-4b-with-unsloth title="Permanent link">Â¶</a></h3> <p><strong>End-to-end vision-language model training and deployment</strong></p> <p>ðŸ“„ <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/FinetuneGemmaUnslothModal.py>View Python Script</a></strong></p> <p>A production-grade pipeline covering the complete ML workflow from data to deployment. You'll learn:</p> <ul> <li>Fine-tuning vision-language models with LoRA</li> <li>Optimized single-GPU training with Unsloth</li> <li>Model evaluation with automated metrics</li> <li>Serving with vLLM for high-throughput inference</li> <li>Auto-scaling deployment strategies</li> </ul> <table> <thead> <tr> <th><strong>Level</strong></th> <th><strong>GPU Required</strong></th> <th><strong>Time</strong></th> </tr> </thead> <tbody> <tr> <td>Intermediate</td> <td>1Ã— A100-80GB (or L40S)</td> <td>3-6 hours (full pipeline)</td> </tr> </tbody> </table> <hr> <h3 id=4-multi-gpu-training-with-axolotl>4. <a href=FinetuneLlamaAxolotlGPUModalTutorial/ >Multi-GPU Training with Axolotl</a><a class=headerlink href=#4-multi-gpu-training-with-axolotl title="Permanent link">Â¶</a></h3> <p><strong>Distributed training for large models (Llama 8 - 70B+)</strong></p> <p>ðŸ“„ <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/FinetuneLlamaAxolotlGPUModal.py>View Python Script</a></strong></p> <p>Advanced distributed training techniques for massive models. You'll learn:</p> <ul> <li>Multi-GPU training with Accelerate and DeepSpeed</li> <li>YAML-based configuration for reproducibility</li> <li>Dataset preprocessing for large-scale training</li> <li>Scaling from 2 to 8 GPUs</li> <li>Cost optimization strategies for expensive training runs</li> </ul> <table> <thead> <tr> <th><strong>Level</strong></th> <th><strong>GPU Required</strong></th> <th><strong>Time</strong></th> </tr> </thead> <tbody> <tr> <td>Advanced</td> <td>2-8Ã— A100-80GB</td> <td>4-12 hours (depends on model size)</td> </tr> </tbody> </table> <blockquote> <p>This is multi-GPU training, and you can run all types of parallelism (data, tensor, pipeline, FSDP) using Modal as well. For the sake of simplicity, I have used Accelerate, but you can go all out with the setup up to 8 GPUs. I have mainly been using Modal for multi-GPU training with a maximum of 8 GPUs. I haven't done multi-node training yet (should be possible with sandboxes, but the setup process might be a bit complex).</p> </blockquote> <hr> <p>I think these 3 examples will give you a good picture to replicate the process across multiple things.</p> <h2 id=final-thoughts>Final thoughts<a class=headerlink href=#final-thoughts title="Permanent link">Â¶</a></h2> <p>As someone working with AI models, infrastructure is crucial to get right as it's expensive and takes a lot of time to set up, especially for individual researchers and small labs who will find it hard to set up and manage infrastructure.</p> <p>With Modal, infrastructure becomes as easy as writing a python script and running it on CPU/GPU, deploying it, scaling it.</p> <p>In this, I go over the details on how to use Modal mainly for running training, eval, and serving scripts for LLM models, but you can do a lot more with Modal.</p> <blockquote> <p><strong>Fun fact:</strong> <a href=https://gitvizz.com>Gitvizz</a> uses modal to run all their backend code and I have been running it for 4 months which cost me less than 4$ and it scales really well. After using modal I completely stopped using k8s and stuff for smaller projects.</p> </blockquote> <hr> <h3 id=need-help>Need Help?<a class=headerlink href=#need-help title="Permanent link">Â¶</a></h3> <p>If your organization needs help with optimally using Modal, we at <a href=https://cognitivelab.in>CognitiveLab</a> can help you set it up and manage it for you.</p> <p>Reach out to us through our website or DM me on twitter <a href=https://x.com/adithya_s_k>@adithya_s_k</a></p> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">Â¶</a></h2> <ul> <li><a href=https://modal.com/docs>Modal Docs</a></li> <li><a href=https://docs.unsloth.ai/ >Unsloth Docs</a></li> <li><a href=https://docs.axolotl.ai/ >Axolotl Docs</a></li> <li><a href=https://github.com/karpathy/nanoGPT>NanoGPT</a></li> </ul></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../VLM/PaliGemma_finetuning_notebook/ class="md-footer__link md-footer__link--prev" aria-label="Previous: PaliGemma"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> PaliGemma </div> </div> </a> <a href=TrainNanoGPTModalTutorial/ class="md-footer__link md-footer__link--next" aria-label="Next: Training NanoGPT on Modal"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Training NanoGPT on Modal </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>