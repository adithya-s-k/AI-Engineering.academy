<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/LLM/ServerLessFinetuning/TrainNanochatModalTutorial/ rel=canonical><link href=../TrainNanoGPTModalTutorial/ rel=prev><link href=../FinetuneGemmaUnslothModalTutorial/ rel=next><link rel=icon href=../../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>Training Nanochat on Modal - AI Engineering Academy</title><link rel=stylesheet href=../../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script><meta property=og:type content=website><meta property=og:title content="Training Nanochat on Modal - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/TrainNanochatModalTutorial.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/LLM/ServerLessFinetuning/TrainNanochatModalTutorial/ property=og:url><meta property=twitter:card content=summary_large_image><meta property=twitter:title content="Training Nanochat on Modal - AI Engineering Academy"><meta property=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta property=twitter:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/TrainNanochatModalTutorial.png></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#training-nanochat-on-modal-build-your-own-chatgpt-from-scratch class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Training Nanochat on Modal </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class=md-tabs__item> <a href=../../../RAG/ class=md-tabs__link> RAG </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../../AIBreakDown/TRM/ class=md-tabs__link> AI BreakDown </a> </li> <li class=md-tabs__item> <a href=../../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../RAG/ class=md-nav__link> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> LLM </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex> <span class=md-ellipsis> Finetuning Techniques </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Finetuning Techniques </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PreTrain/ class=md-nav__link> <span class=md-ellipsis> PreTraining LLMs </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/SFT/ class=md-nav__link> <span class=md-ellipsis> SFT </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PPO/ class=md-nav__link> <span class=md-ellipsis> PPO(Proximal Policy Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/DPO/ class=md-nav__link> <span class=md-ellipsis> DPO(Direct Preference Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/ORPO/ class=md-nav__link> <span class=md-ellipsis> ORPO(Odds Ratio Preference Optimization) </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/GRPO/ class=md-nav__link> <span class=md-ellipsis> GRPO(Group Relative Policy Optimization) </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex> <span class=md-ellipsis> LLM Finetuning Hands on </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> LLM Finetuning Hands on </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Gemma/ class=md-nav__link> <span class=md-ellipsis> Gemma </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../LLama2/Llama2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Llama2 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Llama3_finetuning_notebook.ipynb class=md-nav__link> <span class=md-ellipsis> Llama3 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Mistral-7b/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex> <span class=md-ellipsis> VLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> VLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../VLM/Florence2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Florence2 </span> </a> </li> <li class=md-nav__item> <a href=../../VLM/PaliGemma_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> PaliGemma </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Serverless Finetuning with Modal </span> </a> <label class="md-nav__link " for=__nav_4_5 id=__nav_4_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_5_label aria-expanded=true> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Serverless Finetuning with Modal </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../TrainNanoGPTModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training NanoGPT on Modal </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Training Nanochat on Modal </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Training Nanochat on Modal </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-nanochat class=md-nav__link> <span class=md-ellipsis> Why Nanochat? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#set-up-your-secrets class=md-nav__link> <span class=md-ellipsis> Set Up Your Secrets </span> </a> </li> <li class=md-nav__item> <a href=#clone-nanochat class=md-nav__link> <span class=md-ellipsis> Clone Nanochat </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-pipeline class=md-nav__link> <span class=md-ellipsis> Understanding the Pipeline </span> </a> <nav class=md-nav aria-label="Understanding the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-full-speedrun class=md-nav__link> <span class=md-ellipsis> The Full Speedrun </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#configuration-and-setup class=md-nav__link> <span class=md-ellipsis> Configuration and Setup </span> </a> <nav class=md-nav aria-label="Configuration and Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-and-volumes class=md-nav__link> <span class=md-ellipsis> App and Volumes </span> </a> </li> <li class=md-nav__item> <a href=#configuration-constants class=md-nav__link> <span class=md-ellipsis> Configuration Constants </span> </a> </li> <li class=md-nav__item> <a href=#secrets-setup class=md-nav__link> <span class=md-ellipsis> Secrets Setup </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-the-container-image class=md-nav__link> <span class=md-ellipsis> Building the Container Image </span> </a> <nav class=md-nav aria-label="Building the Container Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-this-image-is-different class=md-nav__link> <span class=md-ellipsis> Why This Image is Different </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#helper-functions class=md-nav__link> <span class=md-ellipsis> Helper Functions </span> </a> <nav class=md-nav aria-label="Helper Functions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup-functions class=md-nav__link> <span class=md-ellipsis> Setup Functions </span> </a> </li> <li class=md-nav__item> <a href=#torchrun-helper class=md-nav__link> <span class=md-ellipsis> Torchrun Helper </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-1-dataset-download class=md-nav__link> <span class=md-ellipsis> Stage 1: Dataset Download </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-tokenizer-training class=md-nav__link> <span class=md-ellipsis> Stage 2: Tokenizer Training </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-base-model-pretraining class=md-nav__link> <span class=md-ellipsis> Stage 3: Base Model Pretraining </span> </a> <nav class=md-nav aria-label="Stage 3: Base Model Pretraining"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-architecture class=md-nav__link> <span class=md-ellipsis> Model Architecture </span> </a> </li> <li class=md-nav__item> <a href=#the-training-function class=md-nav__link> <span class=md-ellipsis> The Training Function </span> </a> </li> <li class=md-nav__item> <a href=#training-duration-and-cost class=md-nav__link> <span class=md-ellipsis> Training Duration and Cost </span> </a> </li> <li class=md-nav__item> <a href=#evaluation class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-4-midtraining class=md-nav__link> <span class=md-ellipsis> Stage 4: Midtraining </span> </a> </li> <li class=md-nav__item> <a href=#stage-5-supervised-fine-tuning class=md-nav__link> <span class=md-ellipsis> Stage 5: Supervised Fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#stage-6-reinforcement-learning-optional class=md-nav__link> <span class=md-ellipsis> Stage 6: Reinforcement Learning (Optional) </span> </a> </li> <li class=md-nav__item> <a href=#stage-7-evaluation class=md-nav__link> <span class=md-ellipsis> Stage 7: Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#stage-8-inference class=md-nav__link> <span class=md-ellipsis> Stage 8: Inference </span> </a> <nav class=md-nav aria-label="Stage 8: Inference"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chat-cli class=md-nav__link> <span class=md-ellipsis> Chat CLI </span> </a> </li> <li class=md-nav__item> <a href=#chat-web-ui class=md-nav__link> <span class=md-ellipsis> Chat Web UI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-the-complete-pipeline class=md-nav__link> <span class=md-ellipsis> Running the Complete Pipeline </span> </a> <nav class=md-nav aria-label="Running the Complete Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-main-pipeline class=md-nav__link> <span class=md-ellipsis> The Main Pipeline </span> </a> </li> <li class=md-nav__item> <a href=#quick-test-run-1-hour-24 class=md-nav__link> <span class=md-ellipsis> Quick Test Run (1 hour, $24) </span> </a> </li> <li class=md-nav__item> <a href=#full-speedrun-4-hours-96 class=md-nav__link> <span class=md-ellipsis> Full Speedrun (4 hours, $96) </span> </a> </li> <li class=md-nav__item> <a href=#gpt-2-grade-model-12-hours-288 class=md-nav__link> <span class=md-ellipsis> GPT-2 Grade Model (12 hours, $288) </span> </a> </li> <li class=md-nav__item> <a href=#running-stages-individually class=md-nav__link> <span class=md-ellipsis> Running Stages Individually </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-size class=md-nav__link> <span class=md-ellipsis> Model Size </span> </a> </li> <li class=md-nav__item> <a href=#batch-size class=md-nav__link> <span class=md-ellipsis> Batch Size </span> </a> </li> <li class=md-nav__item> <a href=#learning-rate class=md-nav__link> <span class=md-ellipsis> Learning Rate </span> </a> </li> <li class=md-nav__item> <a href=#dataset-size class=md-nav__link> <span class=md-ellipsis> Dataset Size </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cost-breakdown class=md-nav__link> <span class=md-ellipsis> Cost Breakdown </span> </a> <nav class=md-nav aria-label="Cost Breakdown"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#full-speedrun-d20-240-shards-4-gpus class=md-nav__link> <span class=md-ellipsis> Full Speedrun (d20, 240 shards, 4 GPUs) </span> </a> </li> <li class=md-nav__item> <a href=#quick-test-d12-8-shards-4-gpus class=md-nav__link> <span class=md-ellipsis> Quick Test (d12, 8 shards, 4 GPUs) </span> </a> </li> <li class=md-nav__item> <a href=#storage-costs class=md-nav__link> <span class=md-ellipsis> Storage Costs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#monitoring-and-debugging class=md-nav__link> <span class=md-ellipsis> Monitoring and Debugging </span> </a> <nav class=md-nav aria-label="Monitoring and Debugging"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#real-time-monitoring class=md-nav__link> <span class=md-ellipsis> Real-time Monitoring </span> </a> </li> <li class=md-nav__item> <a href=#weights-biases class=md-nav__link> <span class=md-ellipsis> Weights &amp; Biases </span> </a> </li> <li class=md-nav__item> <a href=#checking-outputs class=md-nav__link> <span class=md-ellipsis> Checking Outputs </span> </a> </li> <li class=md-nav__item> <a href=#gpu-utilization class=md-nav__link> <span class=md-ellipsis> GPU Utilization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> Common Issues and Solutions </span> </a> <nav class=md-nav aria-label="Common Issues and Solutions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nanochat-directory-not-found class=md-nav__link> <span class=md-ellipsis> "nanochat directory not found" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> CUDA Out of Memory </span> </a> </li> <li class=md-nav__item> <a href=#rust-compilation-fails class=md-nav__link> <span class=md-ellipsis> Rust Compilation Fails </span> </a> </li> <li class=md-nav__item> <a href=#training-loss-not-decreasing class=md-nav__link> <span class=md-ellipsis> Training Loss Not Decreasing </span> </a> </li> <li class=md-nav__item> <a href=#secrets-not-found class=md-nav__link> <span class=md-ellipsis> Secrets Not Found </span> </a> </li> <li class=md-nav__item> <a href=#image-build-timeout class=md-nav__link> <span class=md-ellipsis> Image Build Timeout </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-tips-and-tricks class=md-nav__link> <span class=md-ellipsis> Advanced Tips and Tricks </span> </a> <nav class=md-nav aria-label="Advanced Tips and Tricks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#resume-from-checkpoint class=md-nav__link> <span class=md-ellipsis> Resume from Checkpoint </span> </a> </li> <li class=md-nav__item> <a href=#custom-datasets class=md-nav__link> <span class=md-ellipsis> Custom Datasets </span> </a> </li> <li class=md-nav__item> <a href=#experiment-with-optimizers class=md-nav__link> <span class=md-ellipsis> Experiment with Optimizers </span> </a> </li> <li class=md-nav__item> <a href=#multi-node-training class=md-nav__link> <span class=md-ellipsis> Multi-Node Training </span> </a> </li> <li class=md-nav__item> <a href=#quantization class=md-nav__link> <span class=md-ellipsis> Quantization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#expected-results class=md-nav__link> <span class=md-ellipsis> Expected Results </span> </a> <nav class=md-nav aria-label="Expected Results"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#base-model-after-pretraining class=md-nav__link> <span class=md-ellipsis> Base Model (after pretraining) </span> </a> </li> <li class=md-nav__item> <a href=#after-sft class=md-nav__link> <span class=md-ellipsis> After SFT </span> </a> </li> <li class=md-nav__item> <a href=#after-rl-optional class=md-nav__link> <span class=md-ellipsis> After RL (optional) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> <nav class=md-nav aria-label="What's Next?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-scale-up class=md-nav__link> <span class=md-ellipsis> 1. Scale Up </span> </a> </li> <li class=md-nav__item> <a href=#2-custom-data class=md-nav__link> <span class=md-ellipsis> 2. Custom Data </span> </a> </li> <li class=md-nav__item> <a href=#3-longer-training class=md-nav__link> <span class=md-ellipsis> 3. Longer Training </span> </a> </li> <li class=md-nav__item> <a href=#4-deploy-for-production class=md-nav__link> <span class=md-ellipsis> 4. Deploy for Production </span> </a> </li> <li class=md-nav__item> <a href=#5-experiment-with-architecture class=md-nav__link> <span class=md-ellipsis> 5. Experiment with Architecture </span> </a> </li> <li class=md-nav__item> <a href=#6-advanced-fine-tuning class=md-nav__link> <span class=md-ellipsis> 6. Advanced Fine-tuning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> <li class=md-nav__item> <a href=#wrapping-up class=md-nav__link> <span class=md-ellipsis> Wrapping Up </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../FinetuneGemmaUnslothModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> </a> </li> <li class=md-nav__item> <a href=../FinetuneLlamaAxolotlGPUModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Multi-GPU Training with Axolotl </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_6> <div class="md-nav__link md-nav__container"> <a href=../../LLMArchitecture/ParameterCount/ class="md-nav__link "> <span class=md-ellipsis> LLM Architecture </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> LLM Architecture </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../AIBreakDown/TRM/ class=md-nav__link> <span class=md-ellipsis> AI BreakDown </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-nanochat class=md-nav__link> <span class=md-ellipsis> Why Nanochat? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-started class=md-nav__link> <span class=md-ellipsis> Getting Started </span> </a> <nav class=md-nav aria-label="Getting Started"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#set-up-your-secrets class=md-nav__link> <span class=md-ellipsis> Set Up Your Secrets </span> </a> </li> <li class=md-nav__item> <a href=#clone-nanochat class=md-nav__link> <span class=md-ellipsis> Clone Nanochat </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-pipeline class=md-nav__link> <span class=md-ellipsis> Understanding the Pipeline </span> </a> <nav class=md-nav aria-label="Understanding the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-full-speedrun class=md-nav__link> <span class=md-ellipsis> The Full Speedrun </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#configuration-and-setup class=md-nav__link> <span class=md-ellipsis> Configuration and Setup </span> </a> <nav class=md-nav aria-label="Configuration and Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-and-volumes class=md-nav__link> <span class=md-ellipsis> App and Volumes </span> </a> </li> <li class=md-nav__item> <a href=#configuration-constants class=md-nav__link> <span class=md-ellipsis> Configuration Constants </span> </a> </li> <li class=md-nav__item> <a href=#secrets-setup class=md-nav__link> <span class=md-ellipsis> Secrets Setup </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#building-the-container-image class=md-nav__link> <span class=md-ellipsis> Building the Container Image </span> </a> <nav class=md-nav aria-label="Building the Container Image"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-this-image-is-different class=md-nav__link> <span class=md-ellipsis> Why This Image is Different </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#helper-functions class=md-nav__link> <span class=md-ellipsis> Helper Functions </span> </a> <nav class=md-nav aria-label="Helper Functions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup-functions class=md-nav__link> <span class=md-ellipsis> Setup Functions </span> </a> </li> <li class=md-nav__item> <a href=#torchrun-helper class=md-nav__link> <span class=md-ellipsis> Torchrun Helper </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-1-dataset-download class=md-nav__link> <span class=md-ellipsis> Stage 1: Dataset Download </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-tokenizer-training class=md-nav__link> <span class=md-ellipsis> Stage 2: Tokenizer Training </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-base-model-pretraining class=md-nav__link> <span class=md-ellipsis> Stage 3: Base Model Pretraining </span> </a> <nav class=md-nav aria-label="Stage 3: Base Model Pretraining"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-architecture class=md-nav__link> <span class=md-ellipsis> Model Architecture </span> </a> </li> <li class=md-nav__item> <a href=#the-training-function class=md-nav__link> <span class=md-ellipsis> The Training Function </span> </a> </li> <li class=md-nav__item> <a href=#training-duration-and-cost class=md-nav__link> <span class=md-ellipsis> Training Duration and Cost </span> </a> </li> <li class=md-nav__item> <a href=#evaluation class=md-nav__link> <span class=md-ellipsis> Evaluation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#stage-4-midtraining class=md-nav__link> <span class=md-ellipsis> Stage 4: Midtraining </span> </a> </li> <li class=md-nav__item> <a href=#stage-5-supervised-fine-tuning class=md-nav__link> <span class=md-ellipsis> Stage 5: Supervised Fine-tuning </span> </a> </li> <li class=md-nav__item> <a href=#stage-6-reinforcement-learning-optional class=md-nav__link> <span class=md-ellipsis> Stage 6: Reinforcement Learning (Optional) </span> </a> </li> <li class=md-nav__item> <a href=#stage-7-evaluation class=md-nav__link> <span class=md-ellipsis> Stage 7: Evaluation </span> </a> </li> <li class=md-nav__item> <a href=#stage-8-inference class=md-nav__link> <span class=md-ellipsis> Stage 8: Inference </span> </a> <nav class=md-nav aria-label="Stage 8: Inference"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chat-cli class=md-nav__link> <span class=md-ellipsis> Chat CLI </span> </a> </li> <li class=md-nav__item> <a href=#chat-web-ui class=md-nav__link> <span class=md-ellipsis> Chat Web UI </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-the-complete-pipeline class=md-nav__link> <span class=md-ellipsis> Running the Complete Pipeline </span> </a> <nav class=md-nav aria-label="Running the Complete Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#the-main-pipeline class=md-nav__link> <span class=md-ellipsis> The Main Pipeline </span> </a> </li> <li class=md-nav__item> <a href=#quick-test-run-1-hour-24 class=md-nav__link> <span class=md-ellipsis> Quick Test Run (1 hour, $24) </span> </a> </li> <li class=md-nav__item> <a href=#full-speedrun-4-hours-96 class=md-nav__link> <span class=md-ellipsis> Full Speedrun (4 hours, $96) </span> </a> </li> <li class=md-nav__item> <a href=#gpt-2-grade-model-12-hours-288 class=md-nav__link> <span class=md-ellipsis> GPT-2 Grade Model (12 hours, $288) </span> </a> </li> <li class=md-nav__item> <a href=#running-stages-individually class=md-nav__link> <span class=md-ellipsis> Running Stages Individually </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hyperparameter-tuning class=md-nav__link> <span class=md-ellipsis> Hyperparameter Tuning </span> </a> <nav class=md-nav aria-label="Hyperparameter Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-size class=md-nav__link> <span class=md-ellipsis> Model Size </span> </a> </li> <li class=md-nav__item> <a href=#batch-size class=md-nav__link> <span class=md-ellipsis> Batch Size </span> </a> </li> <li class=md-nav__item> <a href=#learning-rate class=md-nav__link> <span class=md-ellipsis> Learning Rate </span> </a> </li> <li class=md-nav__item> <a href=#dataset-size class=md-nav__link> <span class=md-ellipsis> Dataset Size </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cost-breakdown class=md-nav__link> <span class=md-ellipsis> Cost Breakdown </span> </a> <nav class=md-nav aria-label="Cost Breakdown"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#full-speedrun-d20-240-shards-4-gpus class=md-nav__link> <span class=md-ellipsis> Full Speedrun (d20, 240 shards, 4 GPUs) </span> </a> </li> <li class=md-nav__item> <a href=#quick-test-d12-8-shards-4-gpus class=md-nav__link> <span class=md-ellipsis> Quick Test (d12, 8 shards, 4 GPUs) </span> </a> </li> <li class=md-nav__item> <a href=#storage-costs class=md-nav__link> <span class=md-ellipsis> Storage Costs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#monitoring-and-debugging class=md-nav__link> <span class=md-ellipsis> Monitoring and Debugging </span> </a> <nav class=md-nav aria-label="Monitoring and Debugging"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#real-time-monitoring class=md-nav__link> <span class=md-ellipsis> Real-time Monitoring </span> </a> </li> <li class=md-nav__item> <a href=#weights-biases class=md-nav__link> <span class=md-ellipsis> Weights &amp; Biases </span> </a> </li> <li class=md-nav__item> <a href=#checking-outputs class=md-nav__link> <span class=md-ellipsis> Checking Outputs </span> </a> </li> <li class=md-nav__item> <a href=#gpu-utilization class=md-nav__link> <span class=md-ellipsis> GPU Utilization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-issues-and-solutions class=md-nav__link> <span class=md-ellipsis> Common Issues and Solutions </span> </a> <nav class=md-nav aria-label="Common Issues and Solutions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nanochat-directory-not-found class=md-nav__link> <span class=md-ellipsis> "nanochat directory not found" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> CUDA Out of Memory </span> </a> </li> <li class=md-nav__item> <a href=#rust-compilation-fails class=md-nav__link> <span class=md-ellipsis> Rust Compilation Fails </span> </a> </li> <li class=md-nav__item> <a href=#training-loss-not-decreasing class=md-nav__link> <span class=md-ellipsis> Training Loss Not Decreasing </span> </a> </li> <li class=md-nav__item> <a href=#secrets-not-found class=md-nav__link> <span class=md-ellipsis> Secrets Not Found </span> </a> </li> <li class=md-nav__item> <a href=#image-build-timeout class=md-nav__link> <span class=md-ellipsis> Image Build Timeout </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-tips-and-tricks class=md-nav__link> <span class=md-ellipsis> Advanced Tips and Tricks </span> </a> <nav class=md-nav aria-label="Advanced Tips and Tricks"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#resume-from-checkpoint class=md-nav__link> <span class=md-ellipsis> Resume from Checkpoint </span> </a> </li> <li class=md-nav__item> <a href=#custom-datasets class=md-nav__link> <span class=md-ellipsis> Custom Datasets </span> </a> </li> <li class=md-nav__item> <a href=#experiment-with-optimizers class=md-nav__link> <span class=md-ellipsis> Experiment with Optimizers </span> </a> </li> <li class=md-nav__item> <a href=#multi-node-training class=md-nav__link> <span class=md-ellipsis> Multi-Node Training </span> </a> </li> <li class=md-nav__item> <a href=#quantization class=md-nav__link> <span class=md-ellipsis> Quantization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#expected-results class=md-nav__link> <span class=md-ellipsis> Expected Results </span> </a> <nav class=md-nav aria-label="Expected Results"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#base-model-after-pretraining class=md-nav__link> <span class=md-ellipsis> Base Model (after pretraining) </span> </a> </li> <li class=md-nav__item> <a href=#after-sft class=md-nav__link> <span class=md-ellipsis> After SFT </span> </a> </li> <li class=md-nav__item> <a href=#after-rl-optional class=md-nav__link> <span class=md-ellipsis> After RL (optional) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> <nav class=md-nav aria-label="What's Next?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-scale-up class=md-nav__link> <span class=md-ellipsis> 1. Scale Up </span> </a> </li> <li class=md-nav__item> <a href=#2-custom-data class=md-nav__link> <span class=md-ellipsis> 2. Custom Data </span> </a> </li> <li class=md-nav__item> <a href=#3-longer-training class=md-nav__link> <span class=md-ellipsis> 3. Longer Training </span> </a> </li> <li class=md-nav__item> <a href=#4-deploy-for-production class=md-nav__link> <span class=md-ellipsis> 4. Deploy for Production </span> </a> </li> <li class=md-nav__item> <a href=#5-experiment-with-architecture class=md-nav__link> <span class=md-ellipsis> 5. Experiment with Architecture </span> </a> </li> <li class=md-nav__item> <a href=#6-advanced-fine-tuning class=md-nav__link> <span class=md-ellipsis> 6. Advanced Fine-tuning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> <li class=md-nav__item> <a href=#wrapping-up class=md-nav__link> <span class=md-ellipsis> Wrapping Up </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/LLM/ServerLessFinetuning/TrainNanochatModalTutorial.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/LLM/ServerLessFinetuning/TrainNanochatModalTutorial.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=training-nanochat-on-modal-build-your-own-chatgpt-from-scratch>Training Nanochat on Modal: Build Your Own ChatGPT from Scratch<a class=headerlink href=#training-nanochat-on-modal-build-your-own-chatgpt-from-scratch title="Permanent link"></a></h1> <p> <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/TrainNanochatModal.py>View Complete Python Script</a></strong></p> <p>So you've fine-tuned models with LoRA, trained small GPTs, even tackled multi-GPU training. Now let's go full circle and build ChatGPT from absolute scratch - tokenizer training, base model pretraining, conversation fine-tuning, the works.</p> <p>We're talking about the complete Andrej Karpathy nanochat speedrun. Everything from "raw text on the internet" to "functioning ChatGPT clone that can have conversations and use tools."</p> <h2 id=why-nanochat>Why Nanochat?<a class=headerlink href=#why-nanochat title="Permanent link"></a></h2> <p>Here's the thing - if you want to truly understand how ChatGPT works, you can't just fine-tune a pre-trained model. You need to see the entire pipeline.</p> <p>Andrej Karpathy built nanochat as the most comprehensive educational implementation of modern LLM training. It's not a toy - it's the real deal, just scaled down to be understandable and trainable on reasonable hardware.</p> <p><strong>What makes nanochat special:</strong> - <strong>Complete pipeline</strong> - Every single step from tokenizer to deployment - <strong>Production techniques</strong> - Same methods used by OpenAI, Anthropic, etc. - <strong>Educational focus</strong> - Clean, readable code with excellent documentation - <strong>Proven results</strong> - Actually produces working chat models with tool use - <strong>Reasonable scale</strong> - Train on 4-8 GPUs instead of thousands</p> <p>This is basically "here's how we built ChatGPT" but in a form you can actually run and understand. The original repo assumes you have a local GPU cluster. We're taking that exact pipeline and making it run on Modal's serverless infrastructure.</p> <h2 id=what-were-building>What We're Building<a class=headerlink href=#what-were-building title="Permanent link"></a></h2> <p>This isn't just training a model. We're building the entire stack:</p> <p><strong>Stage 1: Download Dataset</strong> - Grab FineWeb-edu (100B tokens of high-quality text) <strong>Stage 2: Train Tokenizer</strong> - Build a custom BPE tokenizer (like GPT-4 uses) <strong>Stage 3: Base Pretraining</strong> - Train a GPT on raw internet text <strong>Stage 4: Midtraining</strong> - Teach conversation format and tool use <strong>Stage 5: Supervised Fine-tuning</strong> - Train on specific tasks (code, math, chat) <strong>Stage 6: Reinforcement Learning</strong> - Optional GRPO on math problems <strong>Stage 7: Evaluation</strong> - Measure performance on real benchmarks <strong>Stage 8: Inference</strong> - Chat with your model (CLI and web UI)</p> <p>The beauty of this pipeline? Each stage is independent. Screw up fine-tuning? Just re-run that step. Want to try different hyperparameters? Preprocessing is already done.</p> <p>Here's what the complete flow looks like:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>  Download FineWeb     (CPU - cheap, run once)
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>  100B tokens        
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>           
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>  Train Tokenizer      (1 GPU - 30-60 min)
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>  Custom BPE 65K     
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>           
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>  Pretrain Base        (4-8 GPUs - 2-4 hours)
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>  Language Model        The big one
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>           
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>  Midtrain             (4 GPUs - 30-45 min)
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>  Conversation       
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>           
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>  SFT                  (4 GPUs - 30-45 min)
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>  Task-specific      
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a>           
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a>
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>  RL (Optional)        (4 GPUs - 30-45 min)
</span><span id=__span-0-28><a id=__codelineno-0-28 name=__codelineno-0-28 href=#__codelineno-0-28></a>  Math reasoning     
</span><span id=__span-0-29><a id=__codelineno-0-29 name=__codelineno-0-29 href=#__codelineno-0-29></a>
</span><span id=__span-0-30><a id=__codelineno-0-30 name=__codelineno-0-30 href=#__codelineno-0-30></a>           
</span><span id=__span-0-31><a id=__codelineno-0-31 name=__codelineno-0-31 href=#__codelineno-0-31></a>      
</span><span id=__span-0-32><a id=__codelineno-0-32 name=__codelineno-0-32 href=#__codelineno-0-32></a>               
</span><span id=__span-0-33><a id=__codelineno-0-33 name=__codelineno-0-33 href=#__codelineno-0-33></a> 
</span><span id=__span-0-34><a id=__codelineno-0-34 name=__codelineno-0-34 href=#__codelineno-0-34></a>  Chat      Eval   
</span><span id=__span-0-35><a id=__codelineno-0-35 name=__codelineno-0-35 href=#__codelineno-0-35></a>  CLI/Web   Metrics
</span><span id=__span-0-36><a id=__codelineno-0-36 name=__codelineno-0-36 href=#__codelineno-0-36></a> 
</span></code></pre></div> <p><strong>Total time for full speedrun:</strong> ~4-5 hours on 8 A100-80GB <strong>Total cost:</strong> ~$100-150 for the complete pipeline</p> <p>Compare this to OpenAI spending millions... yeah, we're doing pretty well.</p> <h2 id=getting-started>Getting Started<a class=headerlink href=#getting-started title="Permanent link"></a></h2> <h3 id=install-modal>Install Modal<a class=headerlink href=#install-modal title="Permanent link"></a></h3> <p>You know the drill:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>pip<span class=w> </span>install<span class=w> </span>modal
</span></code></pre></div> <h3 id=authenticate>Authenticate<a class=headerlink href=#authenticate title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>modal<span class=w> </span>setup
</span></code></pre></div> <p>Or with API keys:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_ID</span><span class=o>=</span>&lt;your_token_id&gt;
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_SECRET</span><span class=o>=</span>&lt;your_token_secret&gt;
</span></code></pre></div> <h3 id=set-up-your-secrets>Set Up Your Secrets<a class=headerlink href=#set-up-your-secrets title="Permanent link"></a></h3> <p>For this pipeline, you'll want: - <strong>Hugging Face token</strong> - For downloading datasets - <strong>Weights &amp; Biases API key</strong> - For tracking training (highly recommended!)</p> <p><strong>Create the Modal secret:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a>modal<span class=w> </span>secret<span class=w> </span>create<span class=w> </span>nanochat-secrets<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=w>  </span><span class=nv>WANDB_API_KEY</span><span class=o>=</span>xxxxxxxxxxxxx<span class=w> </span><span class=se>\</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a><span class=w>  </span><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_xxxxxxxxxxxxx
</span></code></pre></div> <p><strong>Get your tokens:</strong> - HF token: <a href=https://huggingface.co/settings/tokens>hf.co/settings/tokens</a> - W&amp;B key: <a href=https://wandb.ai/authorize>wandb.ai/authorize</a></p> <p><strong>Or use a .env file (local development):</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=nv>WANDB_API_KEY</span><span class=o>=</span>your_key
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_your_token
</span></code></pre></div> <p>The script tries <code>.env</code> first, then falls back to Modal secrets.</p> <h3 id=clone-nanochat>Clone Nanochat<a class=headerlink href=#clone-nanochat title="Permanent link"></a></h3> <p>This is important - we need the nanochat repo locally:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=nb>cd</span><span class=w> </span>/path/to/ServerLessFinetuning
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/karpathy/nanochat.git
</span></code></pre></div> <p>Your folder structure should be:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a>ServerLessFinetuning/
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a> TrainNanochatModal.py    # Your Modal script
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a> nanochat/                 # Cloned repo
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>     scripts/
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>     nanochat/
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>     rustbpe/
</span></code></pre></div> <p><strong>Why clone it?</strong> Modal copies this entire directory into the container image. This way we have all of nanochat's scripts and utilities available.</p> <h2 id=understanding-the-pipeline>Understanding the Pipeline<a class=headerlink href=#understanding-the-pipeline title="Permanent link"></a></h2> <p>Let me walk you through what makes this different from the other tutorials. This isn't fine-tuning - this is building everything from scratch.</p> <h3 id=the-full-speedrun>The Full Speedrun<a class=headerlink href=#the-full-speedrun title="Permanent link"></a></h3> <p>Nanochat is designed as a "speedrun" - train a working ChatGPT in one go. Here's what each stage does:</p> <p><strong>Stage 1: Dataset Download</strong> - Downloads FineWeb-edu-100B from HuggingFace - 240 shards  250M characters = ~60B characters - Enough to train a 561M parameter model (Chinchilla optimal)</p> <p><strong>Stage 2: Tokenizer Training</strong> - Trains a BPE tokenizer on 2B characters - Creates a 65K vocab (2^16 tokens) - Same approach as GPT-4</p> <p><strong>Stage 3: Base Pretraining</strong> - Trains a GPT from random initialization - Uses Muon optimizer (better than Adam for LLMs) - Learns language from raw text</p> <p><strong>Stage 4: Midtraining</strong> - Teaches conversation format (user/assistant turns) - Adds tool use (calculator) - Trains on SmolTalk + MMLU + GSM8K</p> <p><strong>Stage 5: Supervised Fine-tuning</strong> - Task-specific training - MMLU (knowledge), ARC (reasoning), GSM8K (math), HumanEval (code)</p> <p><strong>Stage 6: Reinforcement Learning (Optional)</strong> - GRPO/REINFORCE on math problems - Improves reasoning through self-play</p> <p><strong>Stage 7: Evaluation</strong> - CORE metric (comprehensive benchmark) - Task-specific evals (ARC, GSM8K, HumanEval, MMLU)</p> <p><strong>Stage 8: Inference</strong> - Chat CLI for interactive testing - FastAPI web UI for demos</p> <h2 id=configuration-and-setup>Configuration and Setup<a class=headerlink href=#configuration-and-setup title="Permanent link"></a></h2> <p>Alright, let's dive into the code. The configuration is straightforward but important.</p> <h3 id=app-and-volumes>App and Volumes<a class=headerlink href=#app-and-volumes title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=kn>from</span><span class=w> </span><span class=nn>modal</span><span class=w> </span><span class=kn>import</span> <span class=n>App</span><span class=p>,</span> <span class=n>Image</span> <span class=k>as</span> <span class=n>ModalImage</span><span class=p>,</span> <span class=n>Volume</span><span class=p>,</span> <span class=n>Secret</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a><span class=n>app</span> <span class=o>=</span> <span class=n>App</span><span class=p>(</span><span class=s2>"nanochat-training"</span><span class=p>)</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a><span class=c1># Two volumes: one for data, one for checkpoints</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=n>data_volume</span> <span class=o>=</span> <span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"nanochat-data"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=n>checkpoint_volume</span> <span class=o>=</span> <span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"nanochat-checkpoints"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a><span class=n>VOLUME_CONFIG</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=s2>"/data"</span><span class=p>:</span> <span class=n>data_volume</span><span class=p>,</span>          <span class=c1># Dataset and cache</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=s2>"/checkpoints"</span><span class=p>:</span> <span class=n>checkpoint_volume</span><span class=p>,</span>  <span class=c1># Model checkpoints</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a><span class=p>}</span>
</span></code></pre></div> <p><strong>Why two volumes?</strong> - Data volume: FineWeb shards, tokenizer, eval data (~30GB) - Checkpoint volume: Model weights, training state (~20GB) - Separation makes it easier to manage and debug</p> <h3 id=configuration-constants>Configuration Constants<a class=headerlink href=#configuration-constants title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=n>MINUTES</span> <span class=o>=</span> <span class=mi>60</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=n>HOURS</span> <span class=o>=</span> <span class=mi>60</span> <span class=o>*</span> <span class=mi>60</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=c1># GPU type - can be changed based on your needs</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=n>GPU_TYPE</span> <span class=o>=</span> <span class=s2>"a100-80gb"</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=c1># Multi-GPU configuration (nanochat supports 1-8 GPUs)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a><span class=n>NUM_GPUS_BASE</span> <span class=o>=</span> <span class=mi>4</span>        <span class=c1># Base pretraining</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=n>NUM_GPUS_MID</span> <span class=o>=</span> <span class=mi>4</span>         <span class=c1># Midtraining</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a><span class=n>NUM_GPUS_SFT</span> <span class=o>=</span> <span class=mi>4</span>         <span class=c1># Supervised fine-tuning</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a><span class=n>NUM_GPUS_RL</span> <span class=o>=</span> <span class=mi>4</span>          <span class=c1># Reinforcement learning</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=n>NUM_GPUS_EVAL</span> <span class=o>=</span> <span class=mi>4</span>        <span class=c1># Evaluation</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=n>NUM_GPUS_TOKENIZER</span> <span class=o>=</span> <span class=mi>1</span>   <span class=c1># Tokenizer (single GPU)</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a><span class=n>NUM_GPUS_INFERENCE</span> <span class=o>=</span> <span class=mi>1</span>   <span class=c1># Inference (single GPU)</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a><span class=n>BASE_DIR</span> <span class=o>=</span> <span class=s2>"/data/.cache/nanochat"</span>  <span class=c1># Everything goes here</span>
</span></code></pre></div> <p><strong>GPU scaling:</strong> - 1 GPU: Full pipeline takes ~24 hours (~<span class=arithmatex>\(84) - 4 GPUs: Full pipeline takes ~6 hours (~\)</span>96) - 8 GPUs: Full pipeline takes ~4 hours (~$112)</p> <p>The sweet spot is 4 GPUs - good parallelism without too much communication overhead.</p> <h3 id=secrets-setup>Secrets Setup<a class=headerlink href=#secrets-setup title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Try .env first, then Modal secrets</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=k>try</span><span class=p>:</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=n>nanochat_secret</span> <span class=o>=</span> <span class=n>Secret</span><span class=o>.</span><span class=n>from_dotenv</span><span class=p>()</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Loaded secrets from .env file"</span><span class=p>)</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=k>try</span><span class=p>:</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>        <span class=n>nanochat_secret</span> <span class=o>=</span> <span class=n>Secret</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"nanochat-secrets"</span><span class=p>)</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Loaded secrets from Modal"</span><span class=p>)</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=k>except</span> <span class=ne>Exception</span><span class=p>:</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>        <span class=n>nanochat_secret</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"No secrets found - WandB logging disabled"</span><span class=p>)</span>
</span></code></pre></div> <p>This is graceful - works with or without secrets. If you don't have W&amp;B, training still works, you just don't get the nice dashboards.</p> <h2 id=building-the-container-image>Building the Container Image<a class=headerlink href=#building-the-container-image title="Permanent link"></a></h2> <p>This is the most complex image we've built yet. We need CUDA, PyTorch, Rust (for the tokenizer), and all of nanochat's dependencies.</p> <h3 id=why-this-image-is-different>Why This Image is Different<a class=headerlink href=#why-this-image-is-different title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=n>NANOCHAT_IMAGE</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>    <span class=c1># NVIDIA CUDA 12.8 with Python 3.11</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=n>ModalImage</span><span class=o>.</span><span class=n>from_registry</span><span class=p>(</span><span class=s2>"nvidia/cuda:12.8.1-devel-ubuntu24.04"</span><span class=p>,</span> <span class=n>add_python</span><span class=o>=</span><span class=s2>"3.11"</span><span class=p>)</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=c1># System dependencies</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=o>.</span><span class=n>apt_install</span><span class=p>(</span><span class=s2>"git"</span><span class=p>,</span> <span class=s2>"build-essential"</span><span class=p>,</span> <span class=s2>"curl"</span><span class=p>,</span> <span class=s2>"wget"</span><span class=p>,</span> <span class=s2>"unzip"</span><span class=p>)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>    <span class=c1># Install Rust (needed for tokenizer)</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>        <span class=s2>"curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"</span><span class=p>,</span>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a>        <span class=s2>"echo 'source $HOME/.cargo/env' &gt;&gt; $HOME/.bashrc"</span><span class=p>,</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a>    <span class=p>)</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a>    <span class=c1># Install uv (fast Python package installer)</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a>        <span class=s2>"curl -LsSf https://astral.sh/uv/install.sh | sh"</span><span class=p>,</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a>        <span class=s2>"echo 'export PATH=</span><span class=se>\"</span><span class=s2>$HOME/.cargo/bin:$PATH</span><span class=se>\"</span><span class=s2>' &gt;&gt; $HOME/.bashrc"</span><span class=p>,</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a>    <span class=p>)</span>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a>
</span><span id=__span-11-20><a id=__codelineno-11-20 name=__codelineno-11-20 href=#__codelineno-11-20></a>    <span class=c1># Copy nanochat repo into the image</span>
</span><span id=__span-11-21><a id=__codelineno-11-21 name=__codelineno-11-21 href=#__codelineno-11-21></a>    <span class=o>.</span><span class=n>add_local_dir</span><span class=p>(</span><span class=n>local_path</span><span class=o>=</span><span class=s2>"nanochat"</span><span class=p>,</span> <span class=n>remote_path</span><span class=o>=</span><span class=s2>"/root/nanochat"</span><span class=p>,</span> <span class=n>copy</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-11-22><a id=__codelineno-11-22 name=__codelineno-11-22 href=#__codelineno-11-22></a>
</span><span id=__span-11-23><a id=__codelineno-11-23 name=__codelineno-11-23 href=#__codelineno-11-23></a>    <span class=c1># Set working directory</span>
</span><span id=__span-11-24><a id=__codelineno-11-24 name=__codelineno-11-24 href=#__codelineno-11-24></a>    <span class=o>.</span><span class=n>workdir</span><span class=p>(</span><span class=s2>"/root/nanochat"</span><span class=p>)</span>
</span><span id=__span-11-25><a id=__codelineno-11-25 name=__codelineno-11-25 href=#__codelineno-11-25></a>
</span><span id=__span-11-26><a id=__codelineno-11-26 name=__codelineno-11-26 href=#__codelineno-11-26></a>    <span class=c1># Install Python dependencies AND build Rust tokenizer</span>
</span><span id=__span-11-27><a id=__codelineno-11-27 name=__codelineno-11-27 href=#__codelineno-11-27></a>    <span class=o>.</span><span class=n>run_commands</span><span class=p>(</span>
</span><span id=__span-11-28><a id=__codelineno-11-28 name=__codelineno-11-28 href=#__codelineno-11-28></a>        <span class=s2>"bash -c 'source $HOME/.cargo/env &amp;&amp; uv sync &amp;&amp; uv run maturin develop --release --manifest-path rustbpe/Cargo.toml'"</span>
</span><span id=__span-11-29><a id=__codelineno-11-29 name=__codelineno-11-29 href=#__codelineno-11-29></a>    <span class=p>)</span>
</span><span id=__span-11-30><a id=__codelineno-11-30 name=__codelineno-11-30 href=#__codelineno-11-30></a>
</span><span id=__span-11-31><a id=__codelineno-11-31 name=__codelineno-11-31 href=#__codelineno-11-31></a>    <span class=c1># Environment variables</span>
</span><span id=__span-11-32><a id=__codelineno-11-32 name=__codelineno-11-32 href=#__codelineno-11-32></a>    <span class=o>.</span><span class=n>env</span><span class=p>({</span>
</span><span id=__span-11-33><a id=__codelineno-11-33 name=__codelineno-11-33 href=#__codelineno-11-33></a>        <span class=s2>"OMP_NUM_THREADS"</span><span class=p>:</span> <span class=s2>"1"</span><span class=p>,</span>
</span><span id=__span-11-34><a id=__codelineno-11-34 name=__codelineno-11-34 href=#__codelineno-11-34></a>        <span class=s2>"NANOCHAT_BASE_DIR"</span><span class=p>:</span> <span class=s2>"/data/.cache/nanochat"</span><span class=p>,</span>
</span><span id=__span-11-35><a id=__codelineno-11-35 name=__codelineno-11-35 href=#__codelineno-11-35></a>        <span class=s2>"HF_HOME"</span><span class=p>:</span> <span class=s2>"/data/.cache/huggingface"</span><span class=p>,</span>
</span><span id=__span-11-36><a id=__codelineno-11-36 name=__codelineno-11-36 href=#__codelineno-11-36></a>    <span class=p>})</span>
</span><span id=__span-11-37><a id=__codelineno-11-37 name=__codelineno-11-37 href=#__codelineno-11-37></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Key points:</strong></p> <ol> <li> <p><strong>Rust installation:</strong> Nanochat's tokenizer is written in Rust for speed. We need the full Rust toolchain.</p> </li> <li> <p><strong>uv sync:</strong> This reads <code>pyproject.toml</code> and installs all dependencies in a virtual environment. Much faster than pip.</p> </li> <li> <p><strong>maturin develop:</strong> Builds the Rust tokenizer and makes it importable from Python. This is the magic that makes nanochat's tokenizer so fast.</p> </li> <li> <p><strong>add_local_dir:</strong> Copies your local nanochat clone into the image. This is why you need to clone it first.</p> </li> </ol> <blockquote> <p><strong> Build time warning:</strong> First build takes 15-20 minutes. The Rust tokenizer compilation is the slow part. But Modal caches everything - subsequent runs are instant.</p> </blockquote> <h2 id=helper-functions>Helper Functions<a class=headerlink href=#helper-functions title="Permanent link"></a></h2> <p>Before we get to the stages, let's look at the helper functions that make everything work.</p> <h3 id=setup-functions>Setup Functions<a class=headerlink href=#setup-functions title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=k>def</span><span class=w> </span><span class=nf>setup_base_dir</span><span class=p>():</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=w>    </span><span class=sd>"""Create directory structure for nanochat artifacts."""</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>BASE_DIR</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/base_data"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/tokenizer"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/eval_bundle"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/report"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a><span class=k>def</span><span class=w> </span><span class=nf>setup_secrets</span><span class=p>():</span>
</span><span id=__span-12-13><a id=__codelineno-12-13 name=__codelineno-12-13 href=#__codelineno-12-13></a><span class=w>    </span><span class=sd>"""Set up environment variables from secrets."""</span>
</span><span id=__span-12-14><a id=__codelineno-12-14 name=__codelineno-12-14 href=#__codelineno-12-14></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-12-15><a id=__codelineno-12-15 name=__codelineno-12-15 href=#__codelineno-12-15></a>
</span><span id=__span-12-16><a id=__codelineno-12-16 name=__codelineno-12-16 href=#__codelineno-12-16></a>    <span class=k>if</span> <span class=s2>"WANDB_API_KEY"</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>:</span>
</span><span id=__span-12-17><a id=__codelineno-12-17 name=__codelineno-12-17 href=#__codelineno-12-17></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"WandB API key found"</span><span class=p>)</span>
</span><span id=__span-12-18><a id=__codelineno-12-18 name=__codelineno-12-18 href=#__codelineno-12-18></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-12-19><a id=__codelineno-12-19 name=__codelineno-12-19 href=#__codelineno-12-19></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"WandB API key not found - logging disabled"</span><span class=p>)</span>
</span><span id=__span-12-20><a id=__codelineno-12-20 name=__codelineno-12-20 href=#__codelineno-12-20></a>
</span><span id=__span-12-21><a id=__codelineno-12-21 name=__codelineno-12-21 href=#__codelineno-12-21></a>    <span class=k>if</span> <span class=s2>"HUGGINGFACE_TOKEN"</span> <span class=ow>in</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>:</span>
</span><span id=__span-12-22><a id=__codelineno-12-22 name=__codelineno-12-22 href=#__codelineno-12-22></a>        <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HUGGINGFACE_TOKEN"</span><span class=p>]</span>
</span><span id=__span-12-23><a id=__codelineno-12-23 name=__codelineno-12-23 href=#__codelineno-12-23></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"HuggingFace token found"</span><span class=p>)</span>
</span><span id=__span-12-24><a id=__codelineno-12-24 name=__codelineno-12-24 href=#__codelineno-12-24></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-12-25><a id=__codelineno-12-25 name=__codelineno-12-25 href=#__codelineno-12-25></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"HuggingFace token not found"</span><span class=p>)</span>
</span></code></pre></div> <p>Simple but important - creates all the directories nanochat expects and sets up authentication.</p> <h3 id=torchrun-helper>Torchrun Helper<a class=headerlink href=#torchrun-helper title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=k>def</span><span class=w> </span><span class=nf>run_torchrun_command</span><span class=p>(</span><span class=n>script</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>num_gpus</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>:</span> <span class=nb>list</span> <span class=o>=</span> <span class=kc>None</span><span class=p>):</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=w>    </span><span class=sd>"""Run nanochat script with torchrun for multi-GPU training."""</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>    <span class=k>if</span> <span class=n>extra_args</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>        <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>    <span class=n>extra_args_str</span> <span class=o>=</span> <span class=s2>" "</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>extra_args</span><span class=p>)</span> <span class=k>if</span> <span class=n>extra_args</span> <span class=k>else</span> <span class=s2>""</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"cd /root/nanochat &amp;&amp; uv run torchrun --standalone --nproc_per_node=</span><span class=si>{</span><span class=n>num_gpus</span><span class=si>}</span><span class=s2> -m </span><span class=si>{</span><span class=n>script</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>    <span class=k>if</span> <span class=n>extra_args</span><span class=p>:</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>        <span class=n>cmd</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>" -- </span><span class=si>{</span><span class=n>extra_args_str</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=n>cmd</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"bash"</span><span class=p>,</span> <span class=s2>"-c"</span><span class=p>,</span> <span class=n>cmd</span><span class=p>],</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Command failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>    <span class=k>return</span> <span class=n>result</span>
</span></code></pre></div> <p><strong>What torchrun does:</strong> - Spawns one process per GPU - Sets up distributed training (NCCL backend) - Handles rank assignment and synchronization - Makes multi-GPU training "just work"</p> <p>This is how nanochat does distributed training without writing custom distributed code.</p> <h2 id=stage-1-dataset-download>Stage 1: Dataset Download<a class=headerlink href=#stage-1-dataset-download title="Permanent link"></a></h2> <p>Let's start with the data. We're downloading FineWeb-edu, which is basically "the good parts of the internet."</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>    <span class=c1># No GPU - saves money!</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=p>)</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a><span class=k>def</span><span class=w> </span><span class=nf>download_dataset</span><span class=p>(</span><span class=n>num_shards</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>240</span><span class=p>):</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a><span class=sd>    Download FineWeb dataset shards from HuggingFace.</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a><span class=sd>    Each shard is ~250M characters (~100MB compressed).</span>
</span><span id=__span-14-12><a id=__codelineno-14-12 name=__codelineno-14-12 href=#__codelineno-14-12></a><span class=sd>    - Full speedrun: 240 shards (~60B characters, ~24GB)</span>
</span><span id=__span-14-13><a id=__codelineno-14-13 name=__codelineno-14-13 href=#__codelineno-14-13></a><span class=sd>    - Testing: 8 shards (~2B characters, ~800MB)</span>
</span><span id=__span-14-14><a id=__codelineno-14-14 name=__codelineno-14-14 href=#__codelineno-14-14></a><span class=sd>    """</span>
</span><span id=__span-14-15><a id=__codelineno-14-15 name=__codelineno-14-15 href=#__codelineno-14-15></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-14-16><a id=__codelineno-14-16 name=__codelineno-14-16 href=#__codelineno-14-16></a>
</span><span id=__span-14-17><a id=__codelineno-14-17 name=__codelineno-14-17 href=#__codelineno-14-17></a>    <span class=n>setup_base_dir</span><span class=p>()</span>
</span><span id=__span-14-18><a id=__codelineno-14-18 name=__codelineno-14-18 href=#__codelineno-14-18></a>
</span><span id=__span-14-19><a id=__codelineno-14-19 name=__codelineno-14-19 href=#__codelineno-14-19></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-14-20><a id=__codelineno-14-20 name=__codelineno-14-20 href=#__codelineno-14-20></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"DOWNLOADING FINEWEB DATASET - </span><span class=si>{</span><span class=n>num_shards</span><span class=si>}</span><span class=s2> SHARDS"</span><span class=p>)</span>
</span><span id=__span-14-21><a id=__codelineno-14-21 name=__codelineno-14-21 href=#__codelineno-14-21></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-14-22><a id=__codelineno-14-22 name=__codelineno-14-22 href=#__codelineno-14-22></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Total data: ~</span><span class=si>{</span><span class=n>num_shards</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>250</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mi>1000</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>B characters (~</span><span class=si>{</span><span class=n>num_shards</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>100</span><span class=w> </span><span class=o>/</span><span class=w> </span><span class=mi>1024</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>GB)"</span><span class=p>)</span>
</span><span id=__span-14-23><a id=__codelineno-14-23 name=__codelineno-14-23 href=#__codelineno-14-23></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-14-24><a id=__codelineno-14-24 name=__codelineno-14-24 href=#__codelineno-14-24></a>
</span><span id=__span-14-25><a id=__codelineno-14-25 name=__codelineno-14-25 href=#__codelineno-14-25></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span><span id=__span-14-26><a id=__codelineno-14-26 name=__codelineno-14-26 href=#__codelineno-14-26></a>        <span class=p>[</span><span class=s2>"bash"</span><span class=p>,</span> <span class=s2>"-c"</span><span class=p>,</span> <span class=sa>f</span><span class=s2>"cd /root/nanochat &amp;&amp; uv run python -m nanochat.dataset -n </span><span class=si>{</span><span class=n>num_shards</span><span class=si>}</span><span class=s2>"</span><span class=p>],</span>
</span><span id=__span-14-27><a id=__codelineno-14-27 name=__codelineno-14-27 href=#__codelineno-14-27></a>        <span class=n>capture_output</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-14-28><a id=__codelineno-14-28 name=__codelineno-14-28 href=#__codelineno-14-28></a>        <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-14-29><a id=__codelineno-14-29 name=__codelineno-14-29 href=#__codelineno-14-29></a>    <span class=p>)</span>
</span><span id=__span-14-30><a id=__codelineno-14-30 name=__codelineno-14-30 href=#__codelineno-14-30></a>
</span><span id=__span-14-31><a id=__codelineno-14-31 name=__codelineno-14-31 href=#__codelineno-14-31></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=p>)</span>
</span><span id=__span-14-32><a id=__codelineno-14-32 name=__codelineno-14-32 href=#__codelineno-14-32></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>:</span>
</span><span id=__span-14-33><a id=__codelineno-14-33 name=__codelineno-14-33 href=#__codelineno-14-33></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"STDERR:"</span><span class=p>,</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>)</span>
</span><span id=__span-14-34><a id=__codelineno-14-34 name=__codelineno-14-34 href=#__codelineno-14-34></a>
</span><span id=__span-14-35><a id=__codelineno-14-35 name=__codelineno-14-35 href=#__codelineno-14-35></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-14-36><a id=__codelineno-14-36 name=__codelineno-14-36 href=#__codelineno-14-36></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Dataset download failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-14-37><a id=__codelineno-14-37 name=__codelineno-14-37 href=#__codelineno-14-37></a>
</span><span id=__span-14-38><a id=__codelineno-14-38 name=__codelineno-14-38 href=#__codelineno-14-38></a>    <span class=n>data_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-14-39><a id=__codelineno-14-39 name=__codelineno-14-39 href=#__codelineno-14-39></a>
</span><span id=__span-14-40><a id=__codelineno-14-40 name=__codelineno-14-40 href=#__codelineno-14-40></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-14-41><a id=__codelineno-14-41 name=__codelineno-14-41 href=#__codelineno-14-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Downloaded </span><span class=si>{</span><span class=n>num_shards</span><span class=si>}</span><span class=s2> shards successfully"</span><span class=p>)</span>
</span><span id=__span-14-42><a id=__codelineno-14-42 name=__codelineno-14-42 href=#__codelineno-14-42></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-14-43><a id=__codelineno-14-43 name=__codelineno-14-43 href=#__codelineno-14-43></a>
</span><span id=__span-14-44><a id=__codelineno-14-44 name=__codelineno-14-44 href=#__codelineno-14-44></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-14-45><a id=__codelineno-14-45 name=__codelineno-14-45 href=#__codelineno-14-45></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-14-46><a id=__codelineno-14-46 name=__codelineno-14-46 href=#__codelineno-14-46></a>        <span class=s2>"num_shards"</span><span class=p>:</span> <span class=n>num_shards</span><span class=p>,</span>
</span><span id=__span-14-47><a id=__codelineno-14-47 name=__codelineno-14-47 href=#__codelineno-14-47></a>        <span class=s2>"data_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/base_data"</span><span class=p>,</span>
</span><span id=__span-14-48><a id=__codelineno-14-48 name=__codelineno-14-48 href=#__codelineno-14-48></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>How many shards do you need?</strong></p> <table> <thead> <tr> <th>Model Size</th> <th>Parameters</th> <th>Chinchilla Tokens</th> <th>Characters Needed</th> <th>Shards</th> </tr> </thead> <tbody> <tr> <td>Tiny test</td> <td>~100M</td> <td>2B</td> <td>~10B</td> <td>40</td> </tr> <tr> <td>Quick test</td> <td>~200M</td> <td>4B</td> <td>~20B</td> <td>80</td> </tr> <tr> <td>Speedrun</td> <td>561M (d20)</td> <td>11B</td> <td>~54B</td> <td>240</td> </tr> <tr> <td>GPT-2 grade</td> <td>~1B (d26)</td> <td>20B</td> <td>~96B</td> <td>400</td> </tr> </tbody> </table> <p>For testing, use 8 shards. For the real speedrun, use 240.</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Full speedrun dataset</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::download_dataset
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=c1># Quick test dataset</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::download_dataset<span class=w> </span>--num-shards<span class=o>=</span><span class=m>8</span>
</span></code></pre></div> <p>First download takes 30-60 minutes depending on internet speed. Cached after that.</p> <h2 id=stage-2-tokenizer-training>Stage 2: Tokenizer Training<a class=headerlink href=#stage-2-tokenizer-training title="Permanent link"></a></h2> <p>Now we train a custom tokenizer on the FineWeb data. This is similar to how GPT-4's tokenizer was trained.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_TOKENIZER</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a><span class=p>)</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=k>def</span><span class=w> </span><span class=nf>train_tokenizer</span><span class=p>(</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>    <span class=n>max_chars</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>2_000_000_000</span><span class=p>,</span>  <span class=c1># 2 billion characters</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>    <span class=n>vocab_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>65536</span><span class=p>,</span>          <span class=c1># 65K vocab (2^16)</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>    <span class=n>doc_cap</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>10000</span><span class=p>,</span>              <span class=c1># Max chars per document</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a><span class=p>):</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a><span class=sd>    Train a custom BPE tokenizer on FineWeb data.</span>
</span><span id=__span-16-14><a id=__codelineno-16-14 name=__codelineno-16-14 href=#__codelineno-16-14></a><span class=sd>    Training takes 30-60 minutes on a single GPU.</span>
</span><span id=__span-16-15><a id=__codelineno-16-15 name=__codelineno-16-15 href=#__codelineno-16-15></a><span class=sd>    """</span>
</span><span id=__span-16-16><a id=__codelineno-16-16 name=__codelineno-16-16 href=#__codelineno-16-16></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-16-17><a id=__codelineno-16-17 name=__codelineno-16-17 href=#__codelineno-16-17></a>
</span><span id=__span-16-18><a id=__codelineno-16-18 name=__codelineno-16-18 href=#__codelineno-16-18></a>    <span class=n>setup_base_dir</span><span class=p>()</span>
</span><span id=__span-16-19><a id=__codelineno-16-19 name=__codelineno-16-19 href=#__codelineno-16-19></a>
</span><span id=__span-16-20><a id=__codelineno-16-20 name=__codelineno-16-20 href=#__codelineno-16-20></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-16-21><a id=__codelineno-16-21 name=__codelineno-16-21 href=#__codelineno-16-21></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"TRAINING CUSTOM BPE TOKENIZER"</span><span class=p>)</span>
</span><span id=__span-16-22><a id=__codelineno-16-22 name=__codelineno-16-22 href=#__codelineno-16-22></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-16-23><a id=__codelineno-16-23 name=__codelineno-16-23 href=#__codelineno-16-23></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Max characters: </span><span class=si>{</span><span class=n>max_chars</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-16-24><a id=__codelineno-16-24 name=__codelineno-16-24 href=#__codelineno-16-24></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Vocabulary size: </span><span class=si>{</span><span class=n>vocab_size</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-16-25><a id=__codelineno-16-25 name=__codelineno-16-25 href=#__codelineno-16-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Document cap: </span><span class=si>{</span><span class=n>doc_cap</span><span class=si>:</span><span class=s2>,</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-16-26><a id=__codelineno-16-26 name=__codelineno-16-26 href=#__codelineno-16-26></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-16-27><a id=__codelineno-16-27 name=__codelineno-16-27 href=#__codelineno-16-27></a>
</span><span id=__span-16-28><a id=__codelineno-16-28 name=__codelineno-16-28 href=#__codelineno-16-28></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"cd /root/nanochat &amp;&amp; uv run python -m scripts.tok_train --max_chars=</span><span class=si>{</span><span class=n>max_chars</span><span class=si>}</span><span class=s2> --vocab_size=</span><span class=si>{</span><span class=n>vocab_size</span><span class=si>}</span><span class=s2> --doc_cap=</span><span class=si>{</span><span class=n>doc_cap</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-16-29><a id=__codelineno-16-29 name=__codelineno-16-29 href=#__codelineno-16-29></a>
</span><span id=__span-16-30><a id=__codelineno-16-30 name=__codelineno-16-30 href=#__codelineno-16-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=n>cmd</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-16-31><a id=__codelineno-16-31 name=__codelineno-16-31 href=#__codelineno-16-31></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"bash"</span><span class=p>,</span> <span class=s2>"-c"</span><span class=p>,</span> <span class=n>cmd</span><span class=p>],</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-16-32><a id=__codelineno-16-32 name=__codelineno-16-32 href=#__codelineno-16-32></a>
</span><span id=__span-16-33><a id=__codelineno-16-33 name=__codelineno-16-33 href=#__codelineno-16-33></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-16-34><a id=__codelineno-16-34 name=__codelineno-16-34 href=#__codelineno-16-34></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Tokenizer training failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-16-35><a id=__codelineno-16-35 name=__codelineno-16-35 href=#__codelineno-16-35></a>
</span><span id=__span-16-36><a id=__codelineno-16-36 name=__codelineno-16-36 href=#__codelineno-16-36></a>    <span class=n>data_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-16-37><a id=__codelineno-16-37 name=__codelineno-16-37 href=#__codelineno-16-37></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-16-38><a id=__codelineno-16-38 name=__codelineno-16-38 href=#__codelineno-16-38></a>
</span><span id=__span-16-39><a id=__codelineno-16-39 name=__codelineno-16-39 href=#__codelineno-16-39></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-16-40><a id=__codelineno-16-40 name=__codelineno-16-40 href=#__codelineno-16-40></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Tokenizer training completed"</span><span class=p>)</span>
</span><span id=__span-16-41><a id=__codelineno-16-41 name=__codelineno-16-41 href=#__codelineno-16-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Tokenizer saved to </span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/tokenizer/"</span><span class=p>)</span>
</span><span id=__span-16-42><a id=__codelineno-16-42 name=__codelineno-16-42 href=#__codelineno-16-42></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-16-43><a id=__codelineno-16-43 name=__codelineno-16-43 href=#__codelineno-16-43></a>
</span><span id=__span-16-44><a id=__codelineno-16-44 name=__codelineno-16-44 href=#__codelineno-16-44></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-16-45><a id=__codelineno-16-45 name=__codelineno-16-45 href=#__codelineno-16-45></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-16-46><a id=__codelineno-16-46 name=__codelineno-16-46 href=#__codelineno-16-46></a>        <span class=s2>"max_chars"</span><span class=p>:</span> <span class=n>max_chars</span><span class=p>,</span>
</span><span id=__span-16-47><a id=__codelineno-16-47 name=__codelineno-16-47 href=#__codelineno-16-47></a>        <span class=s2>"vocab_size"</span><span class=p>:</span> <span class=n>vocab_size</span><span class=p>,</span>
</span><span id=__span-16-48><a id=__codelineno-16-48 name=__codelineno-16-48 href=#__codelineno-16-48></a>        <span class=s2>"tokenizer_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/tokenizer"</span><span class=p>,</span>
</span><span id=__span-16-49><a id=__codelineno-16-49 name=__codelineno-16-49 href=#__codelineno-16-49></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Why train a custom tokenizer?</strong></p> <p>You might wonder "why not use GPT-2's tokenizer?" Here's why:</p> <ol> <li><strong>Domain-specific:</strong> FineWeb has different token distributions than GPT-2's training data</li> <li><strong>Efficiency:</strong> Custom tokenizers compress better (lower bits per byte)</li> <li><strong>Control:</strong> You decide vocab size, special tokens, etc.</li> <li><strong>Learning:</strong> Understanding tokenization is crucial for understanding LLMs</li> </ol> <p><strong>The training process:</strong> - Samples 2B characters from FineWeb - Runs Byte Pair Encoding (BPE) to find common subwords - Creates a 65K vocabulary - Saves tokenizer model and merges</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_tokenizer
</span></code></pre></div> <p>Takes 30-60 minutes on a single GPU. You can also evaluate it:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_tokenizer
</span></code></pre></div> <p>This shows you the compression ratio and other metrics.</p> <h2 id=stage-3-base-model-pretraining>Stage 3: Base Model Pretraining<a class=headerlink href=#stage-3-base-model-pretraining title="Permanent link"></a></h2> <p>Here's the big one. We're training a GPT from scratch on internet text. This is where most of the compute goes.</p> <h3 id=model-architecture>Model Architecture<a class=headerlink href=#model-architecture title="Permanent link"></a></h3> <p>Nanochat uses a simple but effective architecture:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=n>depth</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span>  <span class=c1># Model depth parameter</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=c1># Derived dimensions:</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=n>model_dim</span> <span class=o>=</span> <span class=n>depth</span> <span class=o>*</span> <span class=mi>64</span>      <span class=c1># 20 * 64 = 1280</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=n>num_heads</span> <span class=o>=</span> <span class=n>model_dim</span> <span class=o>/</span> <span class=mi>128</span> <span class=c1># 1280 / 128 = 10</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a><span class=n>num_layers</span> <span class=o>=</span> <span class=n>depth</span>          <span class=c1># 20 layers</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=c1># Total parameters: ~561M</span>
</span></code></pre></div> <p><strong>Model sizes:</strong> - depth=12: ~200M params (quick test) - depth=20: ~561M params (default speedrun) - depth=26: ~1B params (GPT-2 grade)</p> <h3 id=the-training-function>The Training Function<a class=headerlink href=#the-training-function title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_BASE</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>nanochat_secret</span><span class=p>]</span> <span class=k>if</span> <span class=n>nanochat_secret</span> <span class=k>else</span> <span class=p>[],</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>8</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=p>)</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a><span class=k>def</span><span class=w> </span><span class=nf>train_base_model</span><span class=p>(</span>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a>    <span class=n>depth</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span><span class=p>,</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a>    <span class=n>device_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>32</span><span class=p>,</span>
</span><span id=__span-20-11><a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a>    <span class=n>max_iterations</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span>  <span class=c1># -1 = auto from Chinchilla</span>
</span><span id=__span-20-12><a id=__codelineno-20-12 name=__codelineno-20-12 href=#__codelineno-20-12></a>    <span class=n>wandb_run</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"dummy"</span><span class=p>,</span>
</span><span id=__span-20-13><a id=__codelineno-20-13 name=__codelineno-20-13 href=#__codelineno-20-13></a><span class=p>):</span>
</span><span id=__span-20-14><a id=__codelineno-20-14 name=__codelineno-20-14 href=#__codelineno-20-14></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-20-15><a id=__codelineno-20-15 name=__codelineno-20-15 href=#__codelineno-20-15></a><span class=sd>    Pretrain the base GPT model on FineWeb.</span>
</span><span id=__span-20-16><a id=__codelineno-20-16 name=__codelineno-20-16 href=#__codelineno-20-16></a>
</span><span id=__span-20-17><a id=__codelineno-20-17 name=__codelineno-20-17 href=#__codelineno-20-17></a><span class=sd>    Model sizes: depth=20 (561M params), depth=26 (1B params)</span>
</span><span id=__span-20-18><a id=__codelineno-20-18 name=__codelineno-20-18 href=#__codelineno-20-18></a><span class=sd>    Training duration: ~2-3 hours on 8 GPUs, ~16-24 hours on 1 GPU</span>
</span><span id=__span-20-19><a id=__codelineno-20-19 name=__codelineno-20-19 href=#__codelineno-20-19></a><span class=sd>    """</span>
</span><span id=__span-20-20><a id=__codelineno-20-20 name=__codelineno-20-20 href=#__codelineno-20-20></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-20-21><a id=__codelineno-20-21 name=__codelineno-20-21 href=#__codelineno-20-21></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-20-22><a id=__codelineno-20-22 name=__codelineno-20-22 href=#__codelineno-20-22></a>
</span><span id=__span-20-23><a id=__codelineno-20-23 name=__codelineno-20-23 href=#__codelineno-20-23></a>    <span class=n>setup_base_dir</span><span class=p>()</span>
</span><span id=__span-20-24><a id=__codelineno-20-24 name=__codelineno-20-24 href=#__codelineno-20-24></a>    <span class=n>setup_secrets</span><span class=p>()</span>
</span><span id=__span-20-25><a id=__codelineno-20-25 name=__codelineno-20-25 href=#__codelineno-20-25></a>
</span><span id=__span-20-26><a id=__codelineno-20-26 name=__codelineno-20-26 href=#__codelineno-20-26></a>    <span class=c1># Download eval bundle if needed (for CORE metric)</span>
</span><span id=__span-20-27><a id=__codelineno-20-27 name=__codelineno-20-27 href=#__codelineno-20-27></a>    <span class=n>eval_bundle_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/eval_bundle"</span>
</span><span id=__span-20-28><a id=__codelineno-20-28 name=__codelineno-20-28 href=#__codelineno-20-28></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>eval_bundle_path</span><span class=p>):</span>
</span><span id=__span-20-29><a id=__codelineno-20-29 name=__codelineno-20-29 href=#__codelineno-20-29></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Downloading eval bundle..."</span><span class=p>)</span>
</span><span id=__span-20-30><a id=__codelineno-20-30 name=__codelineno-20-30 href=#__codelineno-20-30></a>        <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span>
</span><span id=__span-20-31><a id=__codelineno-20-31 name=__codelineno-20-31 href=#__codelineno-20-31></a>            <span class=s2>"curl"</span><span class=p>,</span> <span class=s2>"-L"</span><span class=p>,</span> <span class=s2>"-o"</span><span class=p>,</span> <span class=s2>"eval_bundle.zip"</span><span class=p>,</span>
</span><span id=__span-20-32><a id=__codelineno-20-32 name=__codelineno-20-32 href=#__codelineno-20-32></a>            <span class=s2>"https://karpathy-public.s3.us-west-2.amazonaws.com/eval_bundle.zip"</span><span class=p>,</span>
</span><span id=__span-20-33><a id=__codelineno-20-33 name=__codelineno-20-33 href=#__codelineno-20-33></a>        <span class=p>],</span> <span class=n>check</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-20-34><a id=__codelineno-20-34 name=__codelineno-20-34 href=#__codelineno-20-34></a>        <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"unzip"</span><span class=p>,</span> <span class=s2>"-q"</span><span class=p>,</span> <span class=s2>"eval_bundle.zip"</span><span class=p>],</span> <span class=n>check</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-20-35><a id=__codelineno-20-35 name=__codelineno-20-35 href=#__codelineno-20-35></a>        <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"mv"</span><span class=p>,</span> <span class=s2>"eval_bundle"</span><span class=p>,</span> <span class=n>eval_bundle_path</span><span class=p>],</span> <span class=n>check</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-20-36><a id=__codelineno-20-36 name=__codelineno-20-36 href=#__codelineno-20-36></a>        <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"rm"</span><span class=p>,</span> <span class=s2>"eval_bundle.zip"</span><span class=p>],</span> <span class=n>check</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-20-37><a id=__codelineno-20-37 name=__codelineno-20-37 href=#__codelineno-20-37></a>
</span><span id=__span-20-38><a id=__codelineno-20-38 name=__codelineno-20-38 href=#__codelineno-20-38></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-20-39><a id=__codelineno-20-39 name=__codelineno-20-39 href=#__codelineno-20-39></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"PRETRAINING BASE MODEL ON FINEWEB"</span><span class=p>)</span>
</span><span id=__span-20-40><a id=__codelineno-20-40 name=__codelineno-20-40 href=#__codelineno-20-40></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-20-41><a id=__codelineno-20-41 name=__codelineno-20-41 href=#__codelineno-20-41></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model depth: </span><span class=si>{</span><span class=n>depth</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-20-42><a id=__codelineno-20-42 name=__codelineno-20-42 href=#__codelineno-20-42></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Estimated parameters: </span><span class=si>{</span><span class=n>depth</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=n>depth</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>64</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=mi>12</span><span class=w> </span><span class=o>//</span><span class=w> </span><span class=mi>1_000_000</span><span class=si>}</span><span class=s2>M"</span><span class=p>)</span>
</span><span id=__span-20-43><a id=__codelineno-20-43 name=__codelineno-20-43 href=#__codelineno-20-43></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Device batch size: </span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-20-44><a id=__codelineno-20-44 name=__codelineno-20-44 href=#__codelineno-20-44></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Number of GPUs: </span><span class=si>{</span><span class=n>NUM_GPUS_BASE</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-20-45><a id=__codelineno-20-45 name=__codelineno-20-45 href=#__codelineno-20-45></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"WandB run: </span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-20-46><a id=__codelineno-20-46 name=__codelineno-20-46 href=#__codelineno-20-46></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-20-47><a id=__codelineno-20-47 name=__codelineno-20-47 href=#__codelineno-20-47></a>
</span><span id=__span-20-48><a id=__codelineno-20-48 name=__codelineno-20-48 href=#__codelineno-20-48></a>    <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-20-49><a id=__codelineno-20-49 name=__codelineno-20-49 href=#__codelineno-20-49></a>        <span class=sa>f</span><span class=s2>"--depth=</span><span class=si>{</span><span class=n>depth</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-20-50><a id=__codelineno-20-50 name=__codelineno-20-50 href=#__codelineno-20-50></a>        <span class=sa>f</span><span class=s2>"--device_batch_size=</span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-20-51><a id=__codelineno-20-51 name=__codelineno-20-51 href=#__codelineno-20-51></a>        <span class=sa>f</span><span class=s2>"--run=</span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-20-52><a id=__codelineno-20-52 name=__codelineno-20-52 href=#__codelineno-20-52></a>    <span class=p>]</span>
</span><span id=__span-20-53><a id=__codelineno-20-53 name=__codelineno-20-53 href=#__codelineno-20-53></a>
</span><span id=__span-20-54><a id=__codelineno-20-54 name=__codelineno-20-54 href=#__codelineno-20-54></a>    <span class=k>if</span> <span class=n>max_iterations</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-20-55><a id=__codelineno-20-55 name=__codelineno-20-55 href=#__codelineno-20-55></a>        <span class=n>extra_args</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=sa>f</span><span class=s2>"--num_iterations=</span><span class=si>{</span><span class=n>max_iterations</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-20-56><a id=__codelineno-20-56 name=__codelineno-20-56 href=#__codelineno-20-56></a>
</span><span id=__span-20-57><a id=__codelineno-20-57 name=__codelineno-20-57 href=#__codelineno-20-57></a>    <span class=n>run_torchrun_command</span><span class=p>(</span><span class=s2>"scripts.base_train"</span><span class=p>,</span> <span class=n>NUM_GPUS_BASE</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>)</span>
</span><span id=__span-20-58><a id=__codelineno-20-58 name=__codelineno-20-58 href=#__codelineno-20-58></a>
</span><span id=__span-20-59><a id=__codelineno-20-59 name=__codelineno-20-59 href=#__codelineno-20-59></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-20-60><a id=__codelineno-20-60 name=__codelineno-20-60 href=#__codelineno-20-60></a>
</span><span id=__span-20-61><a id=__codelineno-20-61 name=__codelineno-20-61 href=#__codelineno-20-61></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-20-62><a id=__codelineno-20-62 name=__codelineno-20-62 href=#__codelineno-20-62></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Base model training completed"</span><span class=p>)</span>
</span><span id=__span-20-63><a id=__codelineno-20-63 name=__codelineno-20-63 href=#__codelineno-20-63></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Checkpoints saved to </span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/base/"</span><span class=p>)</span>
</span><span id=__span-20-64><a id=__codelineno-20-64 name=__codelineno-20-64 href=#__codelineno-20-64></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-20-65><a id=__codelineno-20-65 name=__codelineno-20-65 href=#__codelineno-20-65></a>
</span><span id=__span-20-66><a id=__codelineno-20-66 name=__codelineno-20-66 href=#__codelineno-20-66></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-20-67><a id=__codelineno-20-67 name=__codelineno-20-67 href=#__codelineno-20-67></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-20-68><a id=__codelineno-20-68 name=__codelineno-20-68 href=#__codelineno-20-68></a>        <span class=s2>"depth"</span><span class=p>:</span> <span class=n>depth</span><span class=p>,</span>
</span><span id=__span-20-69><a id=__codelineno-20-69 name=__codelineno-20-69 href=#__codelineno-20-69></a>        <span class=s2>"device_batch_size"</span><span class=p>:</span> <span class=n>device_batch_size</span><span class=p>,</span>
</span><span id=__span-20-70><a id=__codelineno-20-70 name=__codelineno-20-70 href=#__codelineno-20-70></a>        <span class=s2>"num_gpus"</span><span class=p>:</span> <span class=n>NUM_GPUS_BASE</span><span class=p>,</span>
</span><span id=__span-20-71><a id=__codelineno-20-71 name=__codelineno-20-71 href=#__codelineno-20-71></a>        <span class=s2>"checkpoint_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/base"</span><span class=p>,</span>
</span><span id=__span-20-72><a id=__codelineno-20-72 name=__codelineno-20-72 href=#__codelineno-20-72></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>What happens during training:</strong></p> <ol> <li><strong>Initialization:</strong> Random weights, Muon optimizer setup</li> <li><strong>Training loop:</strong> Read batches, forward pass, backward pass, update weights</li> <li><strong>Evaluation:</strong> Every N steps, compute validation loss and CORE metric</li> <li><strong>Checkpointing:</strong> Save model state every N steps</li> <li><strong>Logging:</strong> Send metrics to W&amp;B (if configured)</li> </ol> <p><strong>The Muon Optimizer:</strong></p> <p>Nanochat uses Muon for linear layers and AdamW for embeddings. Muon is a new optimizer that: - Converges faster than Adam for transformers - Uses less memory (no momentum for linear layers) - More stable for large learning rates</p> <p>It's basically "what if we applied optimizer improvements from recent research?"</p> <h3 id=training-duration-and-cost>Training Duration and Cost<a class=headerlink href=#training-duration-and-cost title="Permanent link"></a></h3> <table> <thead> <tr> <th>Setup</th> <th>GPUs</th> <th>Time</th> <th>Cost</th> </tr> </thead> <tbody> <tr> <td>Quick test (d12, 8 shards)</td> <td>1</td> <td>~2 hours</td> <td>~$7</td> </tr> <tr> <td>Quick test (d12, 8 shards)</td> <td>4</td> <td>~30 min</td> <td>~$7</td> </tr> <tr> <td>Full speedrun (d20, 240 shards)</td> <td>1</td> <td>~20 hours</td> <td>~$70</td> </tr> <tr> <td>Full speedrun (d20, 240 shards)</td> <td>4</td> <td>~5 hours</td> <td>~$70</td> </tr> <tr> <td>Full speedrun (d20, 240 shards)</td> <td>8</td> <td>~3 hours</td> <td>~$84</td> </tr> <tr> <td>GPT-2 grade (d26, 400 shards)</td> <td>8</td> <td>~10 hours</td> <td>~$280</td> </tr> </tbody> </table> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=c1># Quick test (make sure it works)</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>12</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a><span class=w>  </span>--device-batch-size<span class=o>=</span><span class=m>32</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a><span class=w>  </span>--max-iterations<span class=o>=</span><span class=m>1000</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a><span class=c1># Full speedrun</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>20</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a><span class=w>  </span>--device-batch-size<span class=o>=</span><span class=m>32</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a><span class=w>  </span>--wandb-run<span class=o>=</span><span class=s2>"my-speedrun-</span><span class=k>$(</span>date<span class=w> </span>+%Y%m%d<span class=k>)</span><span class=s2>"</span>
</span></code></pre></div> <p><strong>Monitor training:</strong> - Modal dashboard shows real-time logs and GPU utilization - W&amp;B shows loss curves, learning rate schedule, CORE metric - All 4 (or 8) GPUs should be at ~95-100% utilization</p> <h3 id=evaluation>Evaluation<a class=headerlink href=#evaluation title="Permanent link"></a></h3> <p>After training (or during), you can evaluate:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=c1># CORE metric (comprehensive benchmark)</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_base_model
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=c1># Validation loss (bits per byte)</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_base_loss
</span></code></pre></div> <p>CORE metric measures general language understanding. A good d20 model gets ~0.35-0.40. For comparison: - Random: 0.0 - Llama 3 8B: ~0.50 - GPT-4: ~0.60</p> <h2 id=stage-4-midtraining>Stage 4: Midtraining<a class=headerlink href=#stage-4-midtraining title="Permanent link"></a></h2> <p>Now we teach the model how to have conversations. This is where it learns special tokens like <code>&lt;|user_start|&gt;</code>, <code>&lt;|assistant_end|&gt;</code>, etc.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_MID</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>nanochat_secret</span><span class=p>]</span> <span class=k>if</span> <span class=n>nanochat_secret</span> <span class=k>else</span> <span class=p>[],</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=p>)</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a><span class=k>def</span><span class=w> </span><span class=nf>train_mid_model</span><span class=p>(</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a>    <span class=n>device_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>32</span><span class=p>,</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a>    <span class=n>wandb_run</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"dummy"</span><span class=p>,</span>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a><span class=p>):</span>
</span><span id=__span-23-12><a id=__codelineno-23-12 name=__codelineno-23-12 href=#__codelineno-23-12></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-23-13><a id=__codelineno-23-13 name=__codelineno-23-13 href=#__codelineno-23-13></a><span class=sd>    Midtrain the model on conversation data.</span>
</span><span id=__span-23-14><a id=__codelineno-23-14 name=__codelineno-23-14 href=#__codelineno-23-14></a>
</span><span id=__span-23-15><a id=__codelineno-23-15 name=__codelineno-23-15 href=#__codelineno-23-15></a><span class=sd>    Teaches conversation tokens, tool use, and multiple choice format.</span>
</span><span id=__span-23-16><a id=__codelineno-23-16 name=__codelineno-23-16 href=#__codelineno-23-16></a><span class=sd>    Duration: ~30-45 minutes on 8 GPUs</span>
</span><span id=__span-23-17><a id=__codelineno-23-17 name=__codelineno-23-17 href=#__codelineno-23-17></a><span class=sd>    """</span>
</span><span id=__span-23-18><a id=__codelineno-23-18 name=__codelineno-23-18 href=#__codelineno-23-18></a>    <span class=n>setup_secrets</span><span class=p>()</span>
</span><span id=__span-23-19><a id=__codelineno-23-19 name=__codelineno-23-19 href=#__codelineno-23-19></a>
</span><span id=__span-23-20><a id=__codelineno-23-20 name=__codelineno-23-20 href=#__codelineno-23-20></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-21><a id=__codelineno-23-21 name=__codelineno-23-21 href=#__codelineno-23-21></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"MIDTRAINING - TEACHING CONVERSATION TOKENS"</span><span class=p>)</span>
</span><span id=__span-23-22><a id=__codelineno-23-22 name=__codelineno-23-22 href=#__codelineno-23-22></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-23><a id=__codelineno-23-23 name=__codelineno-23-23 href=#__codelineno-23-23></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Device batch size: </span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-24><a id=__codelineno-23-24 name=__codelineno-23-24 href=#__codelineno-23-24></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Number of GPUs: </span><span class=si>{</span><span class=n>NUM_GPUS_MID</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-23-25><a id=__codelineno-23-25 name=__codelineno-23-25 href=#__codelineno-23-25></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-23-26><a id=__codelineno-23-26 name=__codelineno-23-26 href=#__codelineno-23-26></a>
</span><span id=__span-23-27><a id=__codelineno-23-27 name=__codelineno-23-27 href=#__codelineno-23-27></a>    <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-23-28><a id=__codelineno-23-28 name=__codelineno-23-28 href=#__codelineno-23-28></a>        <span class=sa>f</span><span class=s2>"--device_batch_size=</span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-23-29><a id=__codelineno-23-29 name=__codelineno-23-29 href=#__codelineno-23-29></a>        <span class=sa>f</span><span class=s2>"--run=</span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-23-30><a id=__codelineno-23-30 name=__codelineno-23-30 href=#__codelineno-23-30></a>    <span class=p>]</span>
</span><span id=__span-23-31><a id=__codelineno-23-31 name=__codelineno-23-31 href=#__codelineno-23-31></a>
</span><span id=__span-23-32><a id=__codelineno-23-32 name=__codelineno-23-32 href=#__codelineno-23-32></a>    <span class=n>run_torchrun_command</span><span class=p>(</span><span class=s2>"scripts.mid_train"</span><span class=p>,</span> <span class=n>NUM_GPUS_MID</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>)</span>
</span><span id=__span-23-33><a id=__codelineno-23-33 name=__codelineno-23-33 href=#__codelineno-23-33></a>
</span><span id=__span-23-34><a id=__codelineno-23-34 name=__codelineno-23-34 href=#__codelineno-23-34></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-23-35><a id=__codelineno-23-35 name=__codelineno-23-35 href=#__codelineno-23-35></a>
</span><span id=__span-23-36><a id=__codelineno-23-36 name=__codelineno-23-36 href=#__codelineno-23-36></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-37><a id=__codelineno-23-37 name=__codelineno-23-37 href=#__codelineno-23-37></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Midtraining completed"</span><span class=p>)</span>
</span><span id=__span-23-38><a id=__codelineno-23-38 name=__codelineno-23-38 href=#__codelineno-23-38></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Checkpoints saved to </span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/mid/"</span><span class=p>)</span>
</span><span id=__span-23-39><a id=__codelineno-23-39 name=__codelineno-23-39 href=#__codelineno-23-39></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-23-40><a id=__codelineno-23-40 name=__codelineno-23-40 href=#__codelineno-23-40></a>
</span><span id=__span-23-41><a id=__codelineno-23-41 name=__codelineno-23-41 href=#__codelineno-23-41></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-23-42><a id=__codelineno-23-42 name=__codelineno-23-42 href=#__codelineno-23-42></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-23-43><a id=__codelineno-23-43 name=__codelineno-23-43 href=#__codelineno-23-43></a>        <span class=s2>"checkpoint_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/mid"</span><span class=p>,</span>
</span><span id=__span-23-44><a id=__codelineno-23-44 name=__codelineno-23-44 href=#__codelineno-23-44></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>What midtraining teaches:</strong></p> <ol> <li> <p><strong>Conversation format:</strong> </p><div class="language-text highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a>&lt;|user_start|&gt;What is 2+2?&lt;|user_end|&gt;
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>&lt;|assistant_start|&gt;2+2 equals 4.&lt;|assistant_end|&gt;
</span></code></pre></div> </li> <li> <p><strong>Tool use:</strong> </p><div class="language-text highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a>&lt;|user_start|&gt;What is 123 * 456?&lt;|user_end|&gt;
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>&lt;|assistant_start|&gt;&lt;calculator&gt;123*456&lt;/calculator&gt;
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a>The answer is 56088.&lt;|assistant_end|&gt;
</span></code></pre></div> </li> <li> <p><strong>Multiple choice:</strong> </p><div class="language-text highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a>Question: What is the capital of France?
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a>A) London  B) Paris  C) Berlin  D) Madrid
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a>Answer: B
</span></code></pre></div> </li> </ol> <p><strong>Training data:</strong> - SmolTalk: 460K conversations - MMLU auxiliary: 100K multiple choice - GSM8K: 8K math problems with calculator</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_mid_model
</span></code></pre></div> <p>Takes 30-45 minutes on 4-8 GPUs, costs ~$5-7.</p> <h2 id=stage-5-supervised-fine-tuning>Stage 5: Supervised Fine-tuning<a class=headerlink href=#stage-5-supervised-fine-tuning title="Permanent link"></a></h2> <p>Now we specialize the model on specific tasks: knowledge, reasoning, math, code, and chat.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_SFT</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>nanochat_secret</span><span class=p>]</span> <span class=k>if</span> <span class=n>nanochat_secret</span> <span class=k>else</span> <span class=p>[],</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a><span class=p>)</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a><span class=k>def</span><span class=w> </span><span class=nf>train_sft_model</span><span class=p>(</span>
</span><span id=__span-28-9><a id=__codelineno-28-9 name=__codelineno-28-9 href=#__codelineno-28-9></a>    <span class=n>device_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>
</span><span id=__span-28-10><a id=__codelineno-28-10 name=__codelineno-28-10 href=#__codelineno-28-10></a>    <span class=n>num_epochs</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>
</span><span id=__span-28-11><a id=__codelineno-28-11 name=__codelineno-28-11 href=#__codelineno-28-11></a>    <span class=n>wandb_run</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"dummy"</span><span class=p>,</span>
</span><span id=__span-28-12><a id=__codelineno-28-12 name=__codelineno-28-12 href=#__codelineno-28-12></a>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"mid"</span><span class=p>,</span>
</span><span id=__span-28-13><a id=__codelineno-28-13 name=__codelineno-28-13 href=#__codelineno-28-13></a><span class=p>):</span>
</span><span id=__span-28-14><a id=__codelineno-28-14 name=__codelineno-28-14 href=#__codelineno-28-14></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-28-15><a id=__codelineno-28-15 name=__codelineno-28-15 href=#__codelineno-28-15></a><span class=sd>    Supervised fine-tuning on task-specific data.</span>
</span><span id=__span-28-16><a id=__codelineno-28-16 name=__codelineno-28-16 href=#__codelineno-28-16></a>
</span><span id=__span-28-17><a id=__codelineno-28-17 name=__codelineno-28-17 href=#__codelineno-28-17></a><span class=sd>    Trains on MMLU, ARC, GSM8K, HumanEval, and SmolTalk.</span>
</span><span id=__span-28-18><a id=__codelineno-28-18 name=__codelineno-28-18 href=#__codelineno-28-18></a><span class=sd>    Duration: ~30-45 minutes on 8 GPUs</span>
</span><span id=__span-28-19><a id=__codelineno-28-19 name=__codelineno-28-19 href=#__codelineno-28-19></a><span class=sd>    """</span>
</span><span id=__span-28-20><a id=__codelineno-28-20 name=__codelineno-28-20 href=#__codelineno-28-20></a>    <span class=n>setup_secrets</span><span class=p>()</span>
</span><span id=__span-28-21><a id=__codelineno-28-21 name=__codelineno-28-21 href=#__codelineno-28-21></a>
</span><span id=__span-28-22><a id=__codelineno-28-22 name=__codelineno-28-22 href=#__codelineno-28-22></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-28-23><a id=__codelineno-28-23 name=__codelineno-28-23 href=#__codelineno-28-23></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"SUPERVISED FINE-TUNING"</span><span class=p>)</span>
</span><span id=__span-28-24><a id=__codelineno-28-24 name=__codelineno-28-24 href=#__codelineno-28-24></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-28-25><a id=__codelineno-28-25 name=__codelineno-28-25 href=#__codelineno-28-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Source: </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-28-26><a id=__codelineno-28-26 name=__codelineno-28-26 href=#__codelineno-28-26></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Device batch size: </span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-28-27><a id=__codelineno-28-27 name=__codelineno-28-27 href=#__codelineno-28-27></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Number of GPUs: </span><span class=si>{</span><span class=n>NUM_GPUS_SFT</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-28-28><a id=__codelineno-28-28 name=__codelineno-28-28 href=#__codelineno-28-28></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epochs: </span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-28-29><a id=__codelineno-28-29 name=__codelineno-28-29 href=#__codelineno-28-29></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-28-30><a id=__codelineno-28-30 name=__codelineno-28-30 href=#__codelineno-28-30></a>
</span><span id=__span-28-31><a id=__codelineno-28-31 name=__codelineno-28-31 href=#__codelineno-28-31></a>    <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-28-32><a id=__codelineno-28-32 name=__codelineno-28-32 href=#__codelineno-28-32></a>        <span class=sa>f</span><span class=s2>"--device_batch_size=</span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-28-33><a id=__codelineno-28-33 name=__codelineno-28-33 href=#__codelineno-28-33></a>        <span class=sa>f</span><span class=s2>"--num_epochs=</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-28-34><a id=__codelineno-28-34 name=__codelineno-28-34 href=#__codelineno-28-34></a>        <span class=sa>f</span><span class=s2>"--run=</span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-28-35><a id=__codelineno-28-35 name=__codelineno-28-35 href=#__codelineno-28-35></a>        <span class=sa>f</span><span class=s2>"--source=</span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-28-36><a id=__codelineno-28-36 name=__codelineno-28-36 href=#__codelineno-28-36></a>    <span class=p>]</span>
</span><span id=__span-28-37><a id=__codelineno-28-37 name=__codelineno-28-37 href=#__codelineno-28-37></a>
</span><span id=__span-28-38><a id=__codelineno-28-38 name=__codelineno-28-38 href=#__codelineno-28-38></a>    <span class=n>run_torchrun_command</span><span class=p>(</span><span class=s2>"scripts.chat_sft"</span><span class=p>,</span> <span class=n>NUM_GPUS_SFT</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>)</span>
</span><span id=__span-28-39><a id=__codelineno-28-39 name=__codelineno-28-39 href=#__codelineno-28-39></a>
</span><span id=__span-28-40><a id=__codelineno-28-40 name=__codelineno-28-40 href=#__codelineno-28-40></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-28-41><a id=__codelineno-28-41 name=__codelineno-28-41 href=#__codelineno-28-41></a>
</span><span id=__span-28-42><a id=__codelineno-28-42 name=__codelineno-28-42 href=#__codelineno-28-42></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-28-43><a id=__codelineno-28-43 name=__codelineno-28-43 href=#__codelineno-28-43></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"SFT completed"</span><span class=p>)</span>
</span><span id=__span-28-44><a id=__codelineno-28-44 name=__codelineno-28-44 href=#__codelineno-28-44></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Checkpoints saved to </span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/sft/"</span><span class=p>)</span>
</span><span id=__span-28-45><a id=__codelineno-28-45 name=__codelineno-28-45 href=#__codelineno-28-45></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-28-46><a id=__codelineno-28-46 name=__codelineno-28-46 href=#__codelineno-28-46></a>
</span><span id=__span-28-47><a id=__codelineno-28-47 name=__codelineno-28-47 href=#__codelineno-28-47></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-28-48><a id=__codelineno-28-48 name=__codelineno-28-48 href=#__codelineno-28-48></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-28-49><a id=__codelineno-28-49 name=__codelineno-28-49 href=#__codelineno-28-49></a>        <span class=s2>"checkpoint_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/sft"</span><span class=p>,</span>
</span><span id=__span-28-50><a id=__codelineno-28-50 name=__codelineno-28-50 href=#__codelineno-28-50></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Training mixture:</strong></p> <table> <thead> <tr> <th>Dataset</th> <th>Examples</th> <th>Task</th> <th>Weight</th> </tr> </thead> <tbody> <tr> <td>MMLU</td> <td>~14K</td> <td>General knowledge</td> <td>25%</td> </tr> <tr> <td>ARC-Easy</td> <td>~2.4K</td> <td>Science reasoning</td> <td>15%</td> </tr> <tr> <td>ARC-Challenge</td> <td>~1.2K</td> <td>Hard science</td> <td>15%</td> </tr> <tr> <td>GSM8K</td> <td>~7.5K</td> <td>Math with tools</td> <td>20%</td> </tr> <tr> <td>HumanEval</td> <td>~164</td> <td>Code generation</td> <td>5%</td> </tr> <tr> <td>SmolTalk</td> <td>~50K</td> <td>Conversations</td> <td>20%</td> </tr> </tbody> </table> <p>The mixture is designed to produce a well-rounded model that can chat, reason, do math, and write code.</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a><span class=c1># Start from midtrained model (recommended)</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_sft_model<span class=w> </span>--source<span class=o>=</span>mid
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a><span class=c1># Or start from base model (skip midtraining)</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_sft_model<span class=w> </span>--source<span class=o>=</span>base
</span></code></pre></div> <p>Takes 30-45 minutes on 4-8 GPUs, costs ~$5-7.</p> <h2 id=stage-6-reinforcement-learning-optional>Stage 6: Reinforcement Learning (Optional)<a class=headerlink href=#stage-6-reinforcement-learning-optional title="Permanent link"></a></h2> <p>This is optional but improves math reasoning significantly.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1 href=#__codelineno-30-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2 href=#__codelineno-30-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3 href=#__codelineno-30-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_RL</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4 href=#__codelineno-30-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5 href=#__codelineno-30-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>nanochat_secret</span><span class=p>]</span> <span class=k>if</span> <span class=n>nanochat_secret</span> <span class=k>else</span> <span class=p>[],</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6 href=#__codelineno-30-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-30-7><a id=__codelineno-30-7 name=__codelineno-30-7 href=#__codelineno-30-7></a><span class=p>)</span>
</span><span id=__span-30-8><a id=__codelineno-30-8 name=__codelineno-30-8 href=#__codelineno-30-8></a><span class=k>def</span><span class=w> </span><span class=nf>train_rl_model</span><span class=p>(</span>
</span><span id=__span-30-9><a id=__codelineno-30-9 name=__codelineno-30-9 href=#__codelineno-30-9></a>    <span class=n>device_batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8</span><span class=p>,</span>
</span><span id=__span-30-10><a id=__codelineno-30-10 name=__codelineno-30-10 href=#__codelineno-30-10></a>    <span class=n>num_epochs</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>
</span><span id=__span-30-11><a id=__codelineno-30-11 name=__codelineno-30-11 href=#__codelineno-30-11></a>    <span class=n>wandb_run</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"dummy"</span><span class=p>,</span>
</span><span id=__span-30-12><a id=__codelineno-30-12 name=__codelineno-30-12 href=#__codelineno-30-12></a>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"sft"</span><span class=p>,</span>
</span><span id=__span-30-13><a id=__codelineno-30-13 name=__codelineno-30-13 href=#__codelineno-30-13></a><span class=p>):</span>
</span><span id=__span-30-14><a id=__codelineno-30-14 name=__codelineno-30-14 href=#__codelineno-30-14></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-30-15><a id=__codelineno-30-15 name=__codelineno-30-15 href=#__codelineno-30-15></a><span class=sd>    Reinforcement learning on GSM8K (optional).</span>
</span><span id=__span-30-16><a id=__codelineno-30-16 name=__codelineno-30-16 href=#__codelineno-30-16></a>
</span><span id=__span-30-17><a id=__codelineno-30-17 name=__codelineno-30-17 href=#__codelineno-30-17></a><span class=sd>    Uses GRPO/REINFORCE to improve math reasoning.</span>
</span><span id=__span-30-18><a id=__codelineno-30-18 name=__codelineno-30-18 href=#__codelineno-30-18></a><span class=sd>    Duration: ~30-45 minutes on 8 GPUs</span>
</span><span id=__span-30-19><a id=__codelineno-30-19 name=__codelineno-30-19 href=#__codelineno-30-19></a><span class=sd>    """</span>
</span><span id=__span-30-20><a id=__codelineno-30-20 name=__codelineno-30-20 href=#__codelineno-30-20></a>    <span class=n>setup_secrets</span><span class=p>()</span>
</span><span id=__span-30-21><a id=__codelineno-30-21 name=__codelineno-30-21 href=#__codelineno-30-21></a>
</span><span id=__span-30-22><a id=__codelineno-30-22 name=__codelineno-30-22 href=#__codelineno-30-22></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-30-23><a id=__codelineno-30-23 name=__codelineno-30-23 href=#__codelineno-30-23></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"REINFORCEMENT LEARNING ON GSM8K"</span><span class=p>)</span>
</span><span id=__span-30-24><a id=__codelineno-30-24 name=__codelineno-30-24 href=#__codelineno-30-24></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-30-25><a id=__codelineno-30-25 name=__codelineno-30-25 href=#__codelineno-30-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Source: </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-26><a id=__codelineno-30-26 name=__codelineno-30-26 href=#__codelineno-30-26></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Device batch size: </span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-27><a id=__codelineno-30-27 name=__codelineno-30-27 href=#__codelineno-30-27></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Number of GPUs: </span><span class=si>{</span><span class=n>NUM_GPUS_RL</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-28><a id=__codelineno-30-28 name=__codelineno-30-28 href=#__codelineno-30-28></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Epochs: </span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-30-29><a id=__codelineno-30-29 name=__codelineno-30-29 href=#__codelineno-30-29></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-30-30><a id=__codelineno-30-30 name=__codelineno-30-30 href=#__codelineno-30-30></a>
</span><span id=__span-30-31><a id=__codelineno-30-31 name=__codelineno-30-31 href=#__codelineno-30-31></a>    <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-30-32><a id=__codelineno-30-32 name=__codelineno-30-32 href=#__codelineno-30-32></a>        <span class=sa>f</span><span class=s2>"--device_batch_size=</span><span class=si>{</span><span class=n>device_batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-30-33><a id=__codelineno-30-33 name=__codelineno-30-33 href=#__codelineno-30-33></a>        <span class=sa>f</span><span class=s2>"--num_epochs=</span><span class=si>{</span><span class=n>num_epochs</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-30-34><a id=__codelineno-30-34 name=__codelineno-30-34 href=#__codelineno-30-34></a>        <span class=sa>f</span><span class=s2>"--run=</span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-30-35><a id=__codelineno-30-35 name=__codelineno-30-35 href=#__codelineno-30-35></a>        <span class=sa>f</span><span class=s2>"--source=</span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-30-36><a id=__codelineno-30-36 name=__codelineno-30-36 href=#__codelineno-30-36></a>    <span class=p>]</span>
</span><span id=__span-30-37><a id=__codelineno-30-37 name=__codelineno-30-37 href=#__codelineno-30-37></a>
</span><span id=__span-30-38><a id=__codelineno-30-38 name=__codelineno-30-38 href=#__codelineno-30-38></a>    <span class=n>run_torchrun_command</span><span class=p>(</span><span class=s2>"scripts.chat_rl"</span><span class=p>,</span> <span class=n>NUM_GPUS_RL</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>)</span>
</span><span id=__span-30-39><a id=__codelineno-30-39 name=__codelineno-30-39 href=#__codelineno-30-39></a>
</span><span id=__span-30-40><a id=__codelineno-30-40 name=__codelineno-30-40 href=#__codelineno-30-40></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-30-41><a id=__codelineno-30-41 name=__codelineno-30-41 href=#__codelineno-30-41></a>
</span><span id=__span-30-42><a id=__codelineno-30-42 name=__codelineno-30-42 href=#__codelineno-30-42></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-30-43><a id=__codelineno-30-43 name=__codelineno-30-43 href=#__codelineno-30-43></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"RL training completed"</span><span class=p>)</span>
</span><span id=__span-30-44><a id=__codelineno-30-44 name=__codelineno-30-44 href=#__codelineno-30-44></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Checkpoints saved to </span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/rl/"</span><span class=p>)</span>
</span><span id=__span-30-45><a id=__codelineno-30-45 name=__codelineno-30-45 href=#__codelineno-30-45></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-30-46><a id=__codelineno-30-46 name=__codelineno-30-46 href=#__codelineno-30-46></a>
</span><span id=__span-30-47><a id=__codelineno-30-47 name=__codelineno-30-47 href=#__codelineno-30-47></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-30-48><a id=__codelineno-30-48 name=__codelineno-30-48 href=#__codelineno-30-48></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-30-49><a id=__codelineno-30-49 name=__codelineno-30-49 href=#__codelineno-30-49></a>        <span class=s2>"checkpoint_dir"</span><span class=p>:</span> <span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>BASE_DIR</span><span class=si>}</span><span class=s2>/checkpoints/rl"</span><span class=p>,</span>
</span><span id=__span-30-50><a id=__codelineno-30-50 name=__codelineno-30-50 href=#__codelineno-30-50></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>How RL works here:</strong></p> <ol> <li>Model generates multiple answers to a math problem</li> <li>Answers that get the right solution get positive reward</li> <li>Answers that get the wrong solution get negative reward</li> <li>Update model to generate more correct answers</li> </ol> <p>This is simplified GRPO (Group Relative Policy Optimization). It's like PPO but simpler and works well for math.</p> <p><strong>Expected improvement:</strong> - GSM8K accuracy: 60%  75% after RL - ARC/MMLU: Stays about the same (RL only trains on math)</p> <p><strong>Run it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1 href=#__codelineno-31-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_rl_model
</span></code></pre></div> <p>Takes 30-45 minutes on 4-8 GPUs, costs ~$5-7.</p> <h2 id=stage-7-evaluation>Stage 7: Evaluation<a class=headerlink href=#stage-7-evaluation title="Permanent link"></a></h2> <p>Now let's measure how good our model actually is. Nanochat includes comprehensive evaluation on real benchmarks.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1 href=#__codelineno-32-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2 href=#__codelineno-32-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3 href=#__codelineno-32-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_EVAL</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-32-4><a id=__codelineno-32-4 name=__codelineno-32-4 href=#__codelineno-32-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-32-5><a id=__codelineno-32-5 name=__codelineno-32-5 href=#__codelineno-32-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-32-6><a id=__codelineno-32-6 name=__codelineno-32-6 href=#__codelineno-32-6></a><span class=p>)</span>
</span><span id=__span-32-7><a id=__codelineno-32-7 name=__codelineno-32-7 href=#__codelineno-32-7></a><span class=k>def</span><span class=w> </span><span class=nf>evaluate_chat_model</span><span class=p>(</span>
</span><span id=__span-32-8><a id=__codelineno-32-8 name=__codelineno-32-8 href=#__codelineno-32-8></a>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"sft"</span><span class=p>,</span>
</span><span id=__span-32-9><a id=__codelineno-32-9 name=__codelineno-32-9 href=#__codelineno-32-9></a>    <span class=n>tasks</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"all"</span><span class=p>,</span>
</span><span id=__span-32-10><a id=__codelineno-32-10 name=__codelineno-32-10 href=#__codelineno-32-10></a><span class=p>):</span>
</span><span id=__span-32-11><a id=__codelineno-32-11 name=__codelineno-32-11 href=#__codelineno-32-11></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-32-12><a id=__codelineno-32-12 name=__codelineno-32-12 href=#__codelineno-32-12></a><span class=sd>    Evaluate the chat model on benchmark tasks.</span>
</span><span id=__span-32-13><a id=__codelineno-32-13 name=__codelineno-32-13 href=#__codelineno-32-13></a>
</span><span id=__span-32-14><a id=__codelineno-32-14 name=__codelineno-32-14 href=#__codelineno-32-14></a><span class=sd>    Available tasks: ARC-Easy, ARC-Challenge, GSM8K, HumanEval, MMLU, ChatCORE</span>
</span><span id=__span-32-15><a id=__codelineno-32-15 name=__codelineno-32-15 href=#__codelineno-32-15></a><span class=sd>    """</span>
</span><span id=__span-32-16><a id=__codelineno-32-16 name=__codelineno-32-16 href=#__codelineno-32-16></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-32-17><a id=__codelineno-32-17 name=__codelineno-32-17 href=#__codelineno-32-17></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"EVALUATING CHAT MODEL - </span><span class=si>{</span><span class=n>source</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-32-18><a id=__codelineno-32-18 name=__codelineno-32-18 href=#__codelineno-32-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-32-19><a id=__codelineno-32-19 name=__codelineno-32-19 href=#__codelineno-32-19></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Tasks: </span><span class=si>{</span><span class=n>tasks</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-32-20><a id=__codelineno-32-20 name=__codelineno-32-20 href=#__codelineno-32-20></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-32-21><a id=__codelineno-32-21 name=__codelineno-32-21 href=#__codelineno-32-21></a>
</span><span id=__span-32-22><a id=__codelineno-32-22 name=__codelineno-32-22 href=#__codelineno-32-22></a>    <span class=n>extra_args</span> <span class=o>=</span> <span class=p>[</span><span class=s2>"-i"</span><span class=p>,</span> <span class=n>source</span><span class=p>]</span>
</span><span id=__span-32-23><a id=__codelineno-32-23 name=__codelineno-32-23 href=#__codelineno-32-23></a>
</span><span id=__span-32-24><a id=__codelineno-32-24 name=__codelineno-32-24 href=#__codelineno-32-24></a>    <span class=k>if</span> <span class=n>tasks</span> <span class=o>!=</span> <span class=s2>"all"</span><span class=p>:</span>
</span><span id=__span-32-25><a id=__codelineno-32-25 name=__codelineno-32-25 href=#__codelineno-32-25></a>        <span class=n>extra_args</span><span class=o>.</span><span class=n>extend</span><span class=p>([</span><span class=s2>"-a"</span><span class=p>,</span> <span class=n>tasks</span><span class=p>])</span>
</span><span id=__span-32-26><a id=__codelineno-32-26 name=__codelineno-32-26 href=#__codelineno-32-26></a>
</span><span id=__span-32-27><a id=__codelineno-32-27 name=__codelineno-32-27 href=#__codelineno-32-27></a>    <span class=n>run_torchrun_command</span><span class=p>(</span><span class=s2>"scripts.chat_eval"</span><span class=p>,</span> <span class=n>NUM_GPUS_EVAL</span><span class=p>,</span> <span class=n>extra_args</span><span class=p>)</span>
</span><span id=__span-32-28><a id=__codelineno-32-28 name=__codelineno-32-28 href=#__codelineno-32-28></a>
</span><span id=__span-32-29><a id=__codelineno-32-29 name=__codelineno-32-29 href=#__codelineno-32-29></a>    <span class=n>checkpoint_volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-32-30><a id=__codelineno-32-30 name=__codelineno-32-30 href=#__codelineno-32-30></a>
</span><span id=__span-32-31><a id=__codelineno-32-31 name=__codelineno-32-31 href=#__codelineno-32-31></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-32-32><a id=__codelineno-32-32 name=__codelineno-32-32 href=#__codelineno-32-32></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Evaluation of </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2> model completed"</span><span class=p>)</span>
</span><span id=__span-32-33><a id=__codelineno-32-33 name=__codelineno-32-33 href=#__codelineno-32-33></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-32-34><a id=__codelineno-32-34 name=__codelineno-32-34 href=#__codelineno-32-34></a>
</span><span id=__span-32-35><a id=__codelineno-32-35 name=__codelineno-32-35 href=#__codelineno-32-35></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-32-36><a id=__codelineno-32-36 name=__codelineno-32-36 href=#__codelineno-32-36></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-32-37><a id=__codelineno-32-37 name=__codelineno-32-37 href=#__codelineno-32-37></a>        <span class=s2>"source"</span><span class=p>:</span> <span class=n>source</span><span class=p>,</span>
</span><span id=__span-32-38><a id=__codelineno-32-38 name=__codelineno-32-38 href=#__codelineno-32-38></a>        <span class=s2>"tasks"</span><span class=p>:</span> <span class=n>tasks</span><span class=p>,</span>
</span><span id=__span-32-39><a id=__codelineno-32-39 name=__codelineno-32-39 href=#__codelineno-32-39></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Available benchmarks:</strong></p> <table> <thead> <tr> <th>Benchmark</th> <th>What it measures</th> <th>Good score</th> </tr> </thead> <tbody> <tr> <td>ARC-Easy</td> <td>Elementary science</td> <td>&gt;60%</td> </tr> <tr> <td>ARC-Challenge</td> <td>Hard science</td> <td>&gt;35%</td> </tr> <tr> <td>GSM8K</td> <td>Grade school math</td> <td>&gt;60%</td> </tr> <tr> <td>HumanEval</td> <td>Code generation</td> <td>&gt;20%</td> </tr> <tr> <td>MMLU</td> <td>General knowledge</td> <td>&gt;50%</td> </tr> <tr> <td>ChatCORE</td> <td>Conversation quality</td> <td>&gt;0.40</td> </tr> </tbody> </table> <p><strong>Run evaluation:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1 href=#__codelineno-33-1></a><span class=c1># Evaluate all tasks</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2 href=#__codelineno-33-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span>--source<span class=o>=</span>sft
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3 href=#__codelineno-33-3></a>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4 href=#__codelineno-33-4></a><span class=c1># Evaluate specific tasks</span>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5 href=#__codelineno-33-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6 href=#__codelineno-33-6></a><span class=w>  </span>--source<span class=o>=</span>rl<span class=w> </span><span class=se>\</span>
</span><span id=__span-33-7><a id=__codelineno-33-7 name=__codelineno-33-7 href=#__codelineno-33-7></a><span class=w>  </span>--tasks<span class=o>=</span><span class=s2>"GSM8K,ARC-Challenge"</span>
</span><span id=__span-33-8><a id=__codelineno-33-8 name=__codelineno-33-8 href=#__codelineno-33-8></a>
</span><span id=__span-33-9><a id=__codelineno-33-9 name=__codelineno-33-9 href=#__codelineno-33-9></a><span class=c1># Compare mid vs sft vs rl</span>
</span><span id=__span-33-10><a id=__codelineno-33-10 name=__codelineno-33-10 href=#__codelineno-33-10></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span>--source<span class=o>=</span>mid
</span><span id=__span-33-11><a id=__codelineno-33-11 name=__codelineno-33-11 href=#__codelineno-33-11></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span>--source<span class=o>=</span>sft
</span><span id=__span-33-12><a id=__codelineno-33-12 name=__codelineno-33-12 href=#__codelineno-33-12></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span>--source<span class=o>=</span>rl
</span></code></pre></div> <p>Takes 30-60 minutes depending on which tasks you run. Results are saved to the volume and logged to W&amp;B.</p> <h2 id=stage-8-inference>Stage 8: Inference<a class=headerlink href=#stage-8-inference title="Permanent link"></a></h2> <p>Finally, let's chat with our model! Nanochat provides both a CLI and a web UI.</p> <h3 id=chat-cli>Chat CLI<a class=headerlink href=#chat-cli title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1 href=#__codelineno-34-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2 href=#__codelineno-34-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-34-3><a id=__codelineno-34-3 name=__codelineno-34-3 href=#__codelineno-34-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_INFERENCE</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-34-4><a id=__codelineno-34-4 name=__codelineno-34-4 href=#__codelineno-34-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-34-5><a id=__codelineno-34-5 name=__codelineno-34-5 href=#__codelineno-34-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>1</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-34-6><a id=__codelineno-34-6 name=__codelineno-34-6 href=#__codelineno-34-6></a><span class=p>)</span>
</span><span id=__span-34-7><a id=__codelineno-34-7 name=__codelineno-34-7 href=#__codelineno-34-7></a><span class=k>def</span><span class=w> </span><span class=nf>chat_cli</span><span class=p>(</span>
</span><span id=__span-34-8><a id=__codelineno-34-8 name=__codelineno-34-8 href=#__codelineno-34-8></a>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"sft"</span><span class=p>,</span>
</span><span id=__span-34-9><a id=__codelineno-34-9 name=__codelineno-34-9 href=#__codelineno-34-9></a>    <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>""</span><span class=p>,</span>
</span><span id=__span-34-10><a id=__codelineno-34-10 name=__codelineno-34-10 href=#__codelineno-34-10></a>    <span class=n>temperature</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.6</span><span class=p>,</span>
</span><span id=__span-34-11><a id=__codelineno-34-11 name=__codelineno-34-11 href=#__codelineno-34-11></a>    <span class=n>top_k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>50</span><span class=p>,</span>
</span><span id=__span-34-12><a id=__codelineno-34-12 name=__codelineno-34-12 href=#__codelineno-34-12></a><span class=p>):</span>
</span><span id=__span-34-13><a id=__codelineno-34-13 name=__codelineno-34-13 href=#__codelineno-34-13></a><span class=w>    </span><span class=sd>"""Chat with the model via command line interface."""</span>
</span><span id=__span-34-14><a id=__codelineno-34-14 name=__codelineno-34-14 href=#__codelineno-34-14></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-34-15><a id=__codelineno-34-15 name=__codelineno-34-15 href=#__codelineno-34-15></a>
</span><span id=__span-34-16><a id=__codelineno-34-16 name=__codelineno-34-16 href=#__codelineno-34-16></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-17><a id=__codelineno-34-17 name=__codelineno-34-17 href=#__codelineno-34-17></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"CHAT CLI - </span><span class=si>{</span><span class=n>source</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span><span class=si>}</span><span class=s2> MODEL"</span><span class=p>)</span>
</span><span id=__span-34-18><a id=__codelineno-34-18 name=__codelineno-34-18 href=#__codelineno-34-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-34-19><a id=__codelineno-34-19 name=__codelineno-34-19 href=#__codelineno-34-19></a>
</span><span id=__span-34-20><a id=__codelineno-34-20 name=__codelineno-34-20 href=#__codelineno-34-20></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"cd /root/nanochat &amp;&amp; uv run python -m scripts.chat_cli -i </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2> -t </span><span class=si>{</span><span class=n>temperature</span><span class=si>}</span><span class=s2> -k </span><span class=si>{</span><span class=n>top_k</span><span class=si>}</span><span class=s2>"</span>
</span><span id=__span-34-21><a id=__codelineno-34-21 name=__codelineno-34-21 href=#__codelineno-34-21></a>
</span><span id=__span-34-22><a id=__codelineno-34-22 name=__codelineno-34-22 href=#__codelineno-34-22></a>    <span class=k>if</span> <span class=n>prompt</span><span class=p>:</span>
</span><span id=__span-34-23><a id=__codelineno-34-23 name=__codelineno-34-23 href=#__codelineno-34-23></a>        <span class=n>escaped_prompt</span> <span class=o>=</span> <span class=n>prompt</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s1>'"'</span><span class=p>,</span> <span class=s1>'</span><span class=se>\\</span><span class=s1>"'</span><span class=p>)</span>
</span><span id=__span-34-24><a id=__codelineno-34-24 name=__codelineno-34-24 href=#__codelineno-34-24></a>        <span class=n>cmd</span> <span class=o>+=</span> <span class=sa>f</span><span class=s1>' -p "</span><span class=si>{</span><span class=n>escaped_prompt</span><span class=si>}</span><span class=s1>"'</span>
</span><span id=__span-34-25><a id=__codelineno-34-25 name=__codelineno-34-25 href=#__codelineno-34-25></a>
</span><span id=__span-34-26><a id=__codelineno-34-26 name=__codelineno-34-26 href=#__codelineno-34-26></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=n>cmd</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-27><a id=__codelineno-34-27 name=__codelineno-34-27 href=#__codelineno-34-27></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"bash"</span><span class=p>,</span> <span class=s2>"-c"</span><span class=p>,</span> <span class=n>cmd</span><span class=p>],</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-34-28><a id=__codelineno-34-28 name=__codelineno-34-28 href=#__codelineno-34-28></a>
</span><span id=__span-34-29><a id=__codelineno-34-29 name=__codelineno-34-29 href=#__codelineno-34-29></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-34-30><a id=__codelineno-34-30 name=__codelineno-34-30 href=#__codelineno-34-30></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Chat CLI failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-34-31><a id=__codelineno-34-31 name=__codelineno-34-31 href=#__codelineno-34-31></a>
</span><span id=__span-34-32><a id=__codelineno-34-32 name=__codelineno-34-32 href=#__codelineno-34-32></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-34-33><a id=__codelineno-34-33 name=__codelineno-34-33 href=#__codelineno-34-33></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-34-34><a id=__codelineno-34-34 name=__codelineno-34-34 href=#__codelineno-34-34></a>        <span class=s2>"source"</span><span class=p>:</span> <span class=n>source</span><span class=p>,</span>
</span><span id=__span-34-35><a id=__codelineno-34-35 name=__codelineno-34-35 href=#__codelineno-34-35></a>        <span class=s2>"prompt"</span><span class=p>:</span> <span class=n>prompt</span><span class=p>,</span>
</span><span id=__span-34-36><a id=__codelineno-34-36 name=__codelineno-34-36 href=#__codelineno-34-36></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Use it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1 href=#__codelineno-35-1></a><span class=c1># Single question</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2 href=#__codelineno-35-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::chat_cli<span class=w> </span><span class=se>\</span>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3 href=#__codelineno-35-3></a><span class=w>  </span>--source<span class=o>=</span>sft<span class=w> </span><span class=se>\</span>
</span><span id=__span-35-4><a id=__codelineno-35-4 name=__codelineno-35-4 href=#__codelineno-35-4></a><span class=w>  </span>--prompt<span class=o>=</span><span class=s2>"Why is the sky blue?"</span>
</span><span id=__span-35-5><a id=__codelineno-35-5 name=__codelineno-35-5 href=#__codelineno-35-5></a>
</span><span id=__span-35-6><a id=__codelineno-35-6 name=__codelineno-35-6 href=#__codelineno-35-6></a><span class=c1># Interactive mode (empty prompt)</span>
</span><span id=__span-35-7><a id=__codelineno-35-7 name=__codelineno-35-7 href=#__codelineno-35-7></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::chat_cli<span class=w> </span>--source<span class=o>=</span>sft
</span><span id=__span-35-8><a id=__codelineno-35-8 name=__codelineno-35-8 href=#__codelineno-35-8></a>
</span><span id=__span-35-9><a id=__codelineno-35-9 name=__codelineno-35-9 href=#__codelineno-35-9></a><span class=c1># With different sampling</span>
</span><span id=__span-35-10><a id=__codelineno-35-10 name=__codelineno-35-10 href=#__codelineno-35-10></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::chat_cli<span class=w> </span><span class=se>\</span>
</span><span id=__span-35-11><a id=__codelineno-35-11 name=__codelineno-35-11 href=#__codelineno-35-11></a><span class=w>  </span>--source<span class=o>=</span>rl<span class=w> </span><span class=se>\</span>
</span><span id=__span-35-12><a id=__codelineno-35-12 name=__codelineno-35-12 href=#__codelineno-35-12></a><span class=w>  </span>--temperature<span class=o>=</span><span class=m>0</span>.8<span class=w> </span><span class=se>\</span>
</span><span id=__span-35-13><a id=__codelineno-35-13 name=__codelineno-35-13 href=#__codelineno-35-13></a><span class=w>  </span>--top-k<span class=o>=</span><span class=m>100</span>
</span></code></pre></div> <h3 id=chat-web-ui>Chat Web UI<a class=headerlink href=#chat-web-ui title="Permanent link"></a></h3> <p>For a more user-friendly interface:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1 href=#__codelineno-36-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-36-2><a id=__codelineno-36-2 name=__codelineno-36-2 href=#__codelineno-36-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOCHAT_IMAGE</span><span class=p>,</span>
</span><span id=__span-36-3><a id=__codelineno-36-3 name=__codelineno-36-3 href=#__codelineno-36-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=sa>f</span><span class=s2>"</span><span class=si>{</span><span class=n>GPU_TYPE</span><span class=si>}</span><span class=s2>:</span><span class=si>{</span><span class=n>NUM_GPUS_INFERENCE</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-36-4><a id=__codelineno-36-4 name=__codelineno-36-4 href=#__codelineno-36-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-36-5><a id=__codelineno-36-5 name=__codelineno-36-5 href=#__codelineno-36-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>4</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-36-6><a id=__codelineno-36-6 name=__codelineno-36-6 href=#__codelineno-36-6></a>    <span class=n>max_containers</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span>
</span><span id=__span-36-7><a id=__codelineno-36-7 name=__codelineno-36-7 href=#__codelineno-36-7></a><span class=p>)</span>
</span><span id=__span-36-8><a id=__codelineno-36-8 name=__codelineno-36-8 href=#__codelineno-36-8></a><span class=k>def</span><span class=w> </span><span class=nf>chat_web</span><span class=p>(</span>
</span><span id=__span-36-9><a id=__codelineno-36-9 name=__codelineno-36-9 href=#__codelineno-36-9></a>    <span class=n>source</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"sft"</span><span class=p>,</span>
</span><span id=__span-36-10><a id=__codelineno-36-10 name=__codelineno-36-10 href=#__codelineno-36-10></a>    <span class=n>port</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>8000</span><span class=p>,</span>
</span><span id=__span-36-11><a id=__codelineno-36-11 name=__codelineno-36-11 href=#__codelineno-36-11></a>    <span class=n>temperature</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.8</span><span class=p>,</span>
</span><span id=__span-36-12><a id=__codelineno-36-12 name=__codelineno-36-12 href=#__codelineno-36-12></a>    <span class=n>top_k</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>50</span><span class=p>,</span>
</span><span id=__span-36-13><a id=__codelineno-36-13 name=__codelineno-36-13 href=#__codelineno-36-13></a>    <span class=n>max_tokens</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>512</span><span class=p>,</span>
</span><span id=__span-36-14><a id=__codelineno-36-14 name=__codelineno-36-14 href=#__codelineno-36-14></a><span class=p>):</span>
</span><span id=__span-36-15><a id=__codelineno-36-15 name=__codelineno-36-15 href=#__codelineno-36-15></a><span class=w>    </span><span class=sd>"""Serve the chat model via a web UI."""</span>
</span><span id=__span-36-16><a id=__codelineno-36-16 name=__codelineno-36-16 href=#__codelineno-36-16></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-36-17><a id=__codelineno-36-17 name=__codelineno-36-17 href=#__codelineno-36-17></a>
</span><span id=__span-36-18><a id=__codelineno-36-18 name=__codelineno-36-18 href=#__codelineno-36-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-36-19><a id=__codelineno-36-19 name=__codelineno-36-19 href=#__codelineno-36-19></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"STARTING WEB UI - </span><span class=si>{</span><span class=n>source</span><span class=o>.</span><span class=n>upper</span><span class=p>()</span><span class=si>}</span><span class=s2> MODEL"</span><span class=p>)</span>
</span><span id=__span-36-20><a id=__codelineno-36-20 name=__codelineno-36-20 href=#__codelineno-36-20></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-36-21><a id=__codelineno-36-21 name=__codelineno-36-21 href=#__codelineno-36-21></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Port: </span><span class=si>{</span><span class=n>port</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-22><a id=__codelineno-36-22 name=__codelineno-36-22 href=#__codelineno-36-22></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Temperature: </span><span class=si>{</span><span class=n>temperature</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-23><a id=__codelineno-36-23 name=__codelineno-36-23 href=#__codelineno-36-23></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Top-k: </span><span class=si>{</span><span class=n>top_k</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-24><a id=__codelineno-36-24 name=__codelineno-36-24 href=#__codelineno-36-24></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Max tokens: </span><span class=si>{</span><span class=n>max_tokens</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-25><a id=__codelineno-36-25 name=__codelineno-36-25 href=#__codelineno-36-25></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-36-26><a id=__codelineno-36-26 name=__codelineno-36-26 href=#__codelineno-36-26></a>
</span><span id=__span-36-27><a id=__codelineno-36-27 name=__codelineno-36-27 href=#__codelineno-36-27></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>"cd /root/nanochat &amp;&amp; uv run python -m scripts.chat_web -i </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2> -p </span><span class=si>{</span><span class=n>port</span><span class=si>}</span><span class=s2> -t </span><span class=si>{</span><span class=n>temperature</span><span class=si>}</span><span class=s2> -k </span><span class=si>{</span><span class=n>top_k</span><span class=si>}</span><span class=s2> -m </span><span class=si>{</span><span class=n>max_tokens</span><span class=si>}</span><span class=s2> --host 0.0.0.0"</span>
</span><span id=__span-36-28><a id=__codelineno-36-28 name=__codelineno-36-28 href=#__codelineno-36-28></a>
</span><span id=__span-36-29><a id=__codelineno-36-29 name=__codelineno-36-29 href=#__codelineno-36-29></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=n>cmd</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-30><a id=__codelineno-36-30 name=__codelineno-36-30 href=#__codelineno-36-30></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-36-31><a id=__codelineno-36-31 name=__codelineno-36-31 href=#__codelineno-36-31></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Web UI will be available at: http://localhost:</span><span class=si>{</span><span class=n>port</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-32><a id=__codelineno-36-32 name=__codelineno-36-32 href=#__codelineno-36-32></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-36-33><a id=__codelineno-36-33 name=__codelineno-36-33 href=#__codelineno-36-33></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-36-34><a id=__codelineno-36-34 name=__codelineno-36-34 href=#__codelineno-36-34></a>
</span><span id=__span-36-35><a id=__codelineno-36-35 name=__codelineno-36-35 href=#__codelineno-36-35></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=s2>"bash"</span><span class=p>,</span> <span class=s2>"-c"</span><span class=p>,</span> <span class=n>cmd</span><span class=p>],</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-36-36><a id=__codelineno-36-36 name=__codelineno-36-36 href=#__codelineno-36-36></a>
</span><span id=__span-36-37><a id=__codelineno-36-37 name=__codelineno-36-37 href=#__codelineno-36-37></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-36-38><a id=__codelineno-36-38 name=__codelineno-36-38 href=#__codelineno-36-38></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Web server failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-36-39><a id=__codelineno-36-39 name=__codelineno-36-39 href=#__codelineno-36-39></a>
</span><span id=__span-36-40><a id=__codelineno-36-40 name=__codelineno-36-40 href=#__codelineno-36-40></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-36-41><a id=__codelineno-36-41 name=__codelineno-36-41 href=#__codelineno-36-41></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-36-42><a id=__codelineno-36-42 name=__codelineno-36-42 href=#__codelineno-36-42></a>        <span class=s2>"source"</span><span class=p>:</span> <span class=n>source</span><span class=p>,</span>
</span><span id=__span-36-43><a id=__codelineno-36-43 name=__codelineno-36-43 href=#__codelineno-36-43></a>        <span class=s2>"port"</span><span class=p>:</span> <span class=n>port</span><span class=p>,</span>
</span><span id=__span-36-44><a id=__codelineno-36-44 name=__codelineno-36-44 href=#__codelineno-36-44></a>    <span class=p>}</span>
</span></code></pre></div> <p><strong>Deploy it:</strong></p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1 href=#__codelineno-37-1></a>modal<span class=w> </span>deploy<span class=w> </span>TrainNanochatModal.py
</span></code></pre></div> <p>Modal gives you a URL. Open it in your browser and you have a ChatGPT-like interface!</p> <h2 id=running-the-complete-pipeline>Running the Complete Pipeline<a class=headerlink href=#running-the-complete-pipeline title="Permanent link"></a></h2> <p>Alright, let's put it all together. Here's how to run the full speedrun from scratch.</p> <h3 id=the-main-pipeline>The Main Pipeline<a class=headerlink href=#the-main-pipeline title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1 href=#__codelineno-38-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>local_entrypoint</span><span class=p>()</span>
</span><span id=__span-38-2><a id=__codelineno-38-2 name=__codelineno-38-2 href=#__codelineno-38-2></a><span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>(</span>
</span><span id=__span-38-3><a id=__codelineno-38-3 name=__codelineno-38-3 href=#__codelineno-38-3></a>    <span class=n>run_download</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-4><a id=__codelineno-38-4 name=__codelineno-38-4 href=#__codelineno-38-4></a>    <span class=n>run_tokenizer</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-5><a id=__codelineno-38-5 name=__codelineno-38-5 href=#__codelineno-38-5></a>    <span class=n>run_base</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-6><a id=__codelineno-38-6 name=__codelineno-38-6 href=#__codelineno-38-6></a>    <span class=n>run_mid</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-7><a id=__codelineno-38-7 name=__codelineno-38-7 href=#__codelineno-38-7></a>    <span class=n>run_sft</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-8><a id=__codelineno-38-8 name=__codelineno-38-8 href=#__codelineno-38-8></a>    <span class=n>run_rl</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>,</span>
</span><span id=__span-38-9><a id=__codelineno-38-9 name=__codelineno-38-9 href=#__codelineno-38-9></a>    <span class=n>run_eval</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-10><a id=__codelineno-38-10 name=__codelineno-38-10 href=#__codelineno-38-10></a>    <span class=n>run_inference</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>
</span><span id=__span-38-11><a id=__codelineno-38-11 name=__codelineno-38-11 href=#__codelineno-38-11></a>    <span class=n>num_data_shards</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>240</span><span class=p>,</span>
</span><span id=__span-38-12><a id=__codelineno-38-12 name=__codelineno-38-12 href=#__codelineno-38-12></a>    <span class=n>depth</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>20</span><span class=p>,</span>
</span><span id=__span-38-13><a id=__codelineno-38-13 name=__codelineno-38-13 href=#__codelineno-38-13></a>    <span class=n>device_batch_size_base</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>32</span><span class=p>,</span>
</span><span id=__span-38-14><a id=__codelineno-38-14 name=__codelineno-38-14 href=#__codelineno-38-14></a>    <span class=n>device_batch_size_sft</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>
</span><span id=__span-38-15><a id=__codelineno-38-15 name=__codelineno-38-15 href=#__codelineno-38-15></a>    <span class=n>wandb_run</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"dummy"</span><span class=p>,</span>
</span><span id=__span-38-16><a id=__codelineno-38-16 name=__codelineno-38-16 href=#__codelineno-38-16></a><span class=p>):</span>
</span><span id=__span-38-17><a id=__codelineno-38-17 name=__codelineno-38-17 href=#__codelineno-38-17></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-38-18><a id=__codelineno-38-18 name=__codelineno-38-18 href=#__codelineno-38-18></a><span class=sd>    Run the complete nanochat pipeline from scratch.</span>
</span><span id=__span-38-19><a id=__codelineno-38-19 name=__codelineno-38-19 href=#__codelineno-38-19></a>
</span><span id=__span-38-20><a id=__codelineno-38-20 name=__codelineno-38-20 href=#__codelineno-38-20></a><span class=sd>    Configuration modes:</span>
</span><span id=__span-38-21><a id=__codelineno-38-21 name=__codelineno-38-21 href=#__codelineno-38-21></a><span class=sd>    - Full Speedrun (4h, $96): num_data_shards=240, depth=20</span>
</span><span id=__span-38-22><a id=__codelineno-38-22 name=__codelineno-38-22 href=#__codelineno-38-22></a><span class=sd>    - Quick Test (1h, $24): num_data_shards=8, depth=12</span>
</span><span id=__span-38-23><a id=__codelineno-38-23 name=__codelineno-38-23 href=#__codelineno-38-23></a><span class=sd>    - GPT-2 Grade (12h, $288): num_data_shards=450, depth=26</span>
</span><span id=__span-38-24><a id=__codelineno-38-24 name=__codelineno-38-24 href=#__codelineno-38-24></a><span class=sd>    """</span>
</span><span id=__span-38-25><a id=__codelineno-38-25 name=__codelineno-38-25 href=#__codelineno-38-25></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-38-26><a id=__codelineno-38-26 name=__codelineno-38-26 href=#__codelineno-38-26></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"NANOCHAT TRAINING PIPELINE"</span><span class=p>)</span>
</span><span id=__span-38-27><a id=__codelineno-38-27 name=__codelineno-38-27 href=#__codelineno-38-27></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-38-28><a id=__codelineno-38-28 name=__codelineno-38-28 href=#__codelineno-38-28></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Mode: </span><span class=si>{</span><span class=s1>'Speedrun'</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>num_data_shards</span><span class=w> </span><span class=o>&gt;=</span><span class=w> </span><span class=mi>240</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s1>'Quick Test'</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-38-29><a id=__codelineno-38-29 name=__codelineno-38-29 href=#__codelineno-38-29></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Data shards: </span><span class=si>{</span><span class=n>num_data_shards</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-38-30><a id=__codelineno-38-30 name=__codelineno-38-30 href=#__codelineno-38-30></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Model depth: </span><span class=si>{</span><span class=n>depth</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-38-31><a id=__codelineno-38-31 name=__codelineno-38-31 href=#__codelineno-38-31></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"WandB run: </span><span class=si>{</span><span class=n>wandb_run</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-38-32><a id=__codelineno-38-32 name=__codelineno-38-32 href=#__codelineno-38-32></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-38-33><a id=__codelineno-38-33 name=__codelineno-38-33 href=#__codelineno-38-33></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-38-34><a id=__codelineno-38-34 name=__codelineno-38-34 href=#__codelineno-38-34></a>
</span><span id=__span-38-35><a id=__codelineno-38-35 name=__codelineno-38-35 href=#__codelineno-38-35></a>    <span class=k>if</span> <span class=n>run_download</span><span class=p>:</span>
</span><span id=__span-38-36><a id=__codelineno-38-36 name=__codelineno-38-36 href=#__codelineno-38-36></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Stage 1/8: Downloading dataset..."</span><span class=p>)</span>
</span><span id=__span-38-37><a id=__codelineno-38-37 name=__codelineno-38-37 href=#__codelineno-38-37></a>        <span class=n>download_dataset</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>num_shards</span><span class=o>=</span><span class=n>num_data_shards</span><span class=p>)</span>
</span><span id=__span-38-38><a id=__codelineno-38-38 name=__codelineno-38-38 href=#__codelineno-38-38></a>
</span><span id=__span-38-39><a id=__codelineno-38-39 name=__codelineno-38-39 href=#__codelineno-38-39></a>    <span class=k>if</span> <span class=n>run_tokenizer</span><span class=p>:</span>
</span><span id=__span-38-40><a id=__codelineno-38-40 name=__codelineno-38-40 href=#__codelineno-38-40></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 2/8: Training tokenizer..."</span><span class=p>)</span>
</span><span id=__span-38-41><a id=__codelineno-38-41 name=__codelineno-38-41 href=#__codelineno-38-41></a>        <span class=n>train_tokenizer</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>
</span><span id=__span-38-42><a id=__codelineno-38-42 name=__codelineno-38-42 href=#__codelineno-38-42></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating tokenizer..."</span><span class=p>)</span>
</span><span id=__span-38-43><a id=__codelineno-38-43 name=__codelineno-38-43 href=#__codelineno-38-43></a>        <span class=n>evaluate_tokenizer</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>
</span><span id=__span-38-44><a id=__codelineno-38-44 name=__codelineno-38-44 href=#__codelineno-38-44></a>
</span><span id=__span-38-45><a id=__codelineno-38-45 name=__codelineno-38-45 href=#__codelineno-38-45></a>    <span class=k>if</span> <span class=n>run_base</span><span class=p>:</span>
</span><span id=__span-38-46><a id=__codelineno-38-46 name=__codelineno-38-46 href=#__codelineno-38-46></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 3/8: Training base model..."</span><span class=p>)</span>
</span><span id=__span-38-47><a id=__codelineno-38-47 name=__codelineno-38-47 href=#__codelineno-38-47></a>        <span class=n>train_base_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span><span id=__span-38-48><a id=__codelineno-38-48 name=__codelineno-38-48 href=#__codelineno-38-48></a>            <span class=n>depth</span><span class=o>=</span><span class=n>depth</span><span class=p>,</span> <span class=n>device_batch_size</span><span class=o>=</span><span class=n>device_batch_size_base</span><span class=p>,</span> <span class=n>wandb_run</span><span class=o>=</span><span class=n>wandb_run</span>
</span><span id=__span-38-49><a id=__codelineno-38-49 name=__codelineno-38-49 href=#__codelineno-38-49></a>        <span class=p>)</span>
</span><span id=__span-38-50><a id=__codelineno-38-50 name=__codelineno-38-50 href=#__codelineno-38-50></a>        <span class=k>if</span> <span class=n>run_eval</span><span class=p>:</span>
</span><span id=__span-38-51><a id=__codelineno-38-51 name=__codelineno-38-51 href=#__codelineno-38-51></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating base model (CORE)..."</span><span class=p>)</span>
</span><span id=__span-38-52><a id=__codelineno-38-52 name=__codelineno-38-52 href=#__codelineno-38-52></a>            <span class=n>evaluate_base_model</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>
</span><span id=__span-38-53><a id=__codelineno-38-53 name=__codelineno-38-53 href=#__codelineno-38-53></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating base model (loss)..."</span><span class=p>)</span>
</span><span id=__span-38-54><a id=__codelineno-38-54 name=__codelineno-38-54 href=#__codelineno-38-54></a>            <span class=n>evaluate_base_loss</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>
</span><span id=__span-38-55><a id=__codelineno-38-55 name=__codelineno-38-55 href=#__codelineno-38-55></a>
</span><span id=__span-38-56><a id=__codelineno-38-56 name=__codelineno-38-56 href=#__codelineno-38-56></a>    <span class=k>if</span> <span class=n>run_mid</span><span class=p>:</span>
</span><span id=__span-38-57><a id=__codelineno-38-57 name=__codelineno-38-57 href=#__codelineno-38-57></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 4/8: Midtraining (conversation tokens)..."</span><span class=p>)</span>
</span><span id=__span-38-58><a id=__codelineno-38-58 name=__codelineno-38-58 href=#__codelineno-38-58></a>        <span class=n>train_mid_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span><span id=__span-38-59><a id=__codelineno-38-59 name=__codelineno-38-59 href=#__codelineno-38-59></a>            <span class=n>device_batch_size</span><span class=o>=</span><span class=n>device_batch_size_base</span><span class=p>,</span> <span class=n>wandb_run</span><span class=o>=</span><span class=n>wandb_run</span>
</span><span id=__span-38-60><a id=__codelineno-38-60 name=__codelineno-38-60 href=#__codelineno-38-60></a>        <span class=p>)</span>
</span><span id=__span-38-61><a id=__codelineno-38-61 name=__codelineno-38-61 href=#__codelineno-38-61></a>        <span class=k>if</span> <span class=n>run_eval</span><span class=p>:</span>
</span><span id=__span-38-62><a id=__codelineno-38-62 name=__codelineno-38-62 href=#__codelineno-38-62></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating mid model..."</span><span class=p>)</span>
</span><span id=__span-38-63><a id=__codelineno-38-63 name=__codelineno-38-63 href=#__codelineno-38-63></a>            <span class=n>evaluate_chat_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>source</span><span class=o>=</span><span class=s2>"mid"</span><span class=p>)</span>
</span><span id=__span-38-64><a id=__codelineno-38-64 name=__codelineno-38-64 href=#__codelineno-38-64></a>
</span><span id=__span-38-65><a id=__codelineno-38-65 name=__codelineno-38-65 href=#__codelineno-38-65></a>    <span class=k>if</span> <span class=n>run_sft</span><span class=p>:</span>
</span><span id=__span-38-66><a id=__codelineno-38-66 name=__codelineno-38-66 href=#__codelineno-38-66></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 5/8: Supervised fine-tuning..."</span><span class=p>)</span>
</span><span id=__span-38-67><a id=__codelineno-38-67 name=__codelineno-38-67 href=#__codelineno-38-67></a>        <span class=n>train_sft_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span><span id=__span-38-68><a id=__codelineno-38-68 name=__codelineno-38-68 href=#__codelineno-38-68></a>            <span class=n>device_batch_size</span><span class=o>=</span><span class=n>device_batch_size_sft</span><span class=p>,</span> <span class=n>wandb_run</span><span class=o>=</span><span class=n>wandb_run</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=s2>"mid"</span>
</span><span id=__span-38-69><a id=__codelineno-38-69 name=__codelineno-38-69 href=#__codelineno-38-69></a>        <span class=p>)</span>
</span><span id=__span-38-70><a id=__codelineno-38-70 name=__codelineno-38-70 href=#__codelineno-38-70></a>        <span class=k>if</span> <span class=n>run_eval</span><span class=p>:</span>
</span><span id=__span-38-71><a id=__codelineno-38-71 name=__codelineno-38-71 href=#__codelineno-38-71></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating SFT model..."</span><span class=p>)</span>
</span><span id=__span-38-72><a id=__codelineno-38-72 name=__codelineno-38-72 href=#__codelineno-38-72></a>            <span class=n>evaluate_chat_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>source</span><span class=o>=</span><span class=s2>"sft"</span><span class=p>)</span>
</span><span id=__span-38-73><a id=__codelineno-38-73 name=__codelineno-38-73 href=#__codelineno-38-73></a>
</span><span id=__span-38-74><a id=__codelineno-38-74 name=__codelineno-38-74 href=#__codelineno-38-74></a>    <span class=k>if</span> <span class=n>run_rl</span><span class=p>:</span>
</span><span id=__span-38-75><a id=__codelineno-38-75 name=__codelineno-38-75 href=#__codelineno-38-75></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 6/8: Reinforcement learning..."</span><span class=p>)</span>
</span><span id=__span-38-76><a id=__codelineno-38-76 name=__codelineno-38-76 href=#__codelineno-38-76></a>        <span class=n>train_rl_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>wandb_run</span><span class=o>=</span><span class=n>wandb_run</span><span class=p>)</span>
</span><span id=__span-38-77><a id=__codelineno-38-77 name=__codelineno-38-77 href=#__codelineno-38-77></a>        <span class=k>if</span> <span class=n>run_eval</span><span class=p>:</span>
</span><span id=__span-38-78><a id=__codelineno-38-78 name=__codelineno-38-78 href=#__codelineno-38-78></a>            <span class=nb>print</span><span class=p>(</span><span class=s2>"Evaluating RL model..."</span><span class=p>)</span>
</span><span id=__span-38-79><a id=__codelineno-38-79 name=__codelineno-38-79 href=#__codelineno-38-79></a>            <span class=n>evaluate_chat_model</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>source</span><span class=o>=</span><span class=s2>"rl"</span><span class=p>,</span> <span class=n>tasks</span><span class=o>=</span><span class=s2>"GSM8K"</span><span class=p>)</span>
</span><span id=__span-38-80><a id=__codelineno-38-80 name=__codelineno-38-80 href=#__codelineno-38-80></a>
</span><span id=__span-38-81><a id=__codelineno-38-81 name=__codelineno-38-81 href=#__codelineno-38-81></a>    <span class=k>if</span> <span class=n>run_inference</span><span class=p>:</span>
</span><span id=__span-38-82><a id=__codelineno-38-82 name=__codelineno-38-82 href=#__codelineno-38-82></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>Stage 7/8: Testing inference..."</span><span class=p>)</span>
</span><span id=__span-38-83><a id=__codelineno-38-83 name=__codelineno-38-83 href=#__codelineno-38-83></a>        <span class=n>final_source</span> <span class=o>=</span> <span class=s2>"rl"</span> <span class=k>if</span> <span class=n>run_rl</span> <span class=k>else</span> <span class=s2>"sft"</span>
</span><span id=__span-38-84><a id=__codelineno-38-84 name=__codelineno-38-84 href=#__codelineno-38-84></a>        <span class=n>chat_cli</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span><span class=n>source</span><span class=o>=</span><span class=n>final_source</span><span class=p>,</span> <span class=n>prompt</span><span class=o>=</span><span class=s2>"Why is the sky blue?"</span><span class=p>)</span>
</span><span id=__span-38-85><a id=__codelineno-38-85 name=__codelineno-38-85 href=#__codelineno-38-85></a>
</span><span id=__span-38-86><a id=__codelineno-38-86 name=__codelineno-38-86 href=#__codelineno-38-86></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-38-87><a id=__codelineno-38-87 name=__codelineno-38-87 href=#__codelineno-38-87></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"PIPELINE COMPLETED"</span><span class=p>)</span>
</span><span id=__span-38-88><a id=__codelineno-38-88 name=__codelineno-38-88 href=#__codelineno-38-88></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-38-89><a id=__codelineno-38-89 name=__codelineno-38-89 href=#__codelineno-38-89></a>    <span class=nb>print</span><span class=p>()</span>
</span><span id=__span-38-90><a id=__codelineno-38-90 name=__codelineno-38-90 href=#__codelineno-38-90></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"Next steps:"</span><span class=p>)</span>
</span><span id=__span-38-91><a id=__codelineno-38-91 name=__codelineno-38-91 href=#__codelineno-38-91></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"1. Chat via CLI: modal run TrainNanochatModal.py::chat_cli --source=sft"</span><span class=p>)</span>
</span><span id=__span-38-92><a id=__codelineno-38-92 name=__codelineno-38-92 href=#__codelineno-38-92></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"2. Launch Web UI: modal run TrainNanochatModal.py::chat_web --source=sft"</span><span class=p>)</span>
</span><span id=__span-38-93><a id=__codelineno-38-93 name=__codelineno-38-93 href=#__codelineno-38-93></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"3. Run more evals: modal run TrainNanochatModal.py::evaluate_chat_model --source=sft"</span><span class=p>)</span>
</span><span id=__span-38-94><a id=__codelineno-38-94 name=__codelineno-38-94 href=#__codelineno-38-94></a>    <span class=nb>print</span><span class=p>()</span>
</span></code></pre></div> <h3 id=quick-test-run-1-hour-24>Quick Test Run (1 hour, $24)<a class=headerlink href=#quick-test-run-1-hour-24 title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1 href=#__codelineno-39-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-39-2><a id=__codelineno-39-2 name=__codelineno-39-2 href=#__codelineno-39-2></a><span class=w>  </span>--num-data-shards<span class=o>=</span><span class=m>8</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-39-3><a id=__codelineno-39-3 name=__codelineno-39-3 href=#__codelineno-39-3></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>12</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-39-4><a id=__codelineno-39-4 name=__codelineno-39-4 href=#__codelineno-39-4></a><span class=w>  </span>--run-rl<span class=o>=</span>False
</span></code></pre></div> <p>This trains a tiny model on a small dataset. Good for making sure everything works.</p> <h3 id=full-speedrun-4-hours-96>Full Speedrun (4 hours, $96)<a class=headerlink href=#full-speedrun-4-hours-96 title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-40-1><a id=__codelineno-40-1 name=__codelineno-40-1 href=#__codelineno-40-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-40-2><a id=__codelineno-40-2 name=__codelineno-40-2 href=#__codelineno-40-2></a><span class=w>  </span>--num-data-shards<span class=o>=</span><span class=m>240</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-40-3><a id=__codelineno-40-3 name=__codelineno-40-3 href=#__codelineno-40-3></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>20</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-40-4><a id=__codelineno-40-4 name=__codelineno-40-4 href=#__codelineno-40-4></a><span class=w>  </span>--wandb-run<span class=o>=</span><span class=s2>"speedrun-</span><span class=k>$(</span>date<span class=w> </span>+%Y%m%d<span class=k>)</span><span class=s2>"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-40-5><a id=__codelineno-40-5 name=__codelineno-40-5 href=#__codelineno-40-5></a><span class=w>  </span>--run-rl<span class=o>=</span>False
</span></code></pre></div> <p>This is the default nanochat speedrun. Produces a working ChatGPT with good performance.</p> <h3 id=gpt-2-grade-model-12-hours-288>GPT-2 Grade Model (12 hours, $288)<a class=headerlink href=#gpt-2-grade-model-12-hours-288 title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-41-1><a id=__codelineno-41-1 name=__codelineno-41-1 href=#__codelineno-41-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-41-2><a id=__codelineno-41-2 name=__codelineno-41-2 href=#__codelineno-41-2></a><span class=w>  </span>--num-data-shards<span class=o>=</span><span class=m>450</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-3><a id=__codelineno-41-3 name=__codelineno-41-3 href=#__codelineno-41-3></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>26</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-4><a id=__codelineno-41-4 name=__codelineno-41-4 href=#__codelineno-41-4></a><span class=w>  </span>--wandb-run<span class=o>=</span><span class=s2>"gpt2-grade-</span><span class=k>$(</span>date<span class=w> </span>+%Y%m%d<span class=k>)</span><span class=s2>"</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-41-5><a id=__codelineno-41-5 name=__codelineno-41-5 href=#__codelineno-41-5></a><span class=w>  </span>--run-rl<span class=o>=</span>True
</span></code></pre></div> <p>This trains a 1B parameter model. Comparable to GPT-2 in quality.</p> <h3 id=running-stages-individually>Running Stages Individually<a class=headerlink href=#running-stages-individually title="Permanent link"></a></h3> <p>You can also run each stage separately:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-42-1><a id=__codelineno-42-1 name=__codelineno-42-1 href=#__codelineno-42-1></a><span class=c1># 1. Download dataset</span>
</span><span id=__span-42-2><a id=__codelineno-42-2 name=__codelineno-42-2 href=#__codelineno-42-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::download_dataset<span class=w> </span>--num-shards<span class=o>=</span><span class=m>240</span>
</span><span id=__span-42-3><a id=__codelineno-42-3 name=__codelineno-42-3 href=#__codelineno-42-3></a>
</span><span id=__span-42-4><a id=__codelineno-42-4 name=__codelineno-42-4 href=#__codelineno-42-4></a><span class=c1># 2. Train tokenizer</span>
</span><span id=__span-42-5><a id=__codelineno-42-5 name=__codelineno-42-5 href=#__codelineno-42-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_tokenizer
</span><span id=__span-42-6><a id=__codelineno-42-6 name=__codelineno-42-6 href=#__codelineno-42-6></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_tokenizer
</span><span id=__span-42-7><a id=__codelineno-42-7 name=__codelineno-42-7 href=#__codelineno-42-7></a>
</span><span id=__span-42-8><a id=__codelineno-42-8 name=__codelineno-42-8 href=#__codelineno-42-8></a><span class=c1># 3. Train base model</span>
</span><span id=__span-42-9><a id=__codelineno-42-9 name=__codelineno-42-9 href=#__codelineno-42-9></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-42-10><a id=__codelineno-42-10 name=__codelineno-42-10 href=#__codelineno-42-10></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>20</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-42-11><a id=__codelineno-42-11 name=__codelineno-42-11 href=#__codelineno-42-11></a><span class=w>  </span>--wandb-run<span class=o>=</span><span class=s2>"my-run"</span>
</span><span id=__span-42-12><a id=__codelineno-42-12 name=__codelineno-42-12 href=#__codelineno-42-12></a>
</span><span id=__span-42-13><a id=__codelineno-42-13 name=__codelineno-42-13 href=#__codelineno-42-13></a><span class=c1># 4. Evaluate base</span>
</span><span id=__span-42-14><a id=__codelineno-42-14 name=__codelineno-42-14 href=#__codelineno-42-14></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_base_model
</span><span id=__span-42-15><a id=__codelineno-42-15 name=__codelineno-42-15 href=#__codelineno-42-15></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_base_loss
</span><span id=__span-42-16><a id=__codelineno-42-16 name=__codelineno-42-16 href=#__codelineno-42-16></a>
</span><span id=__span-42-17><a id=__codelineno-42-17 name=__codelineno-42-17 href=#__codelineno-42-17></a><span class=c1># 5. Midtraining</span>
</span><span id=__span-42-18><a id=__codelineno-42-18 name=__codelineno-42-18 href=#__codelineno-42-18></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_mid_model
</span><span id=__span-42-19><a id=__codelineno-42-19 name=__codelineno-42-19 href=#__codelineno-42-19></a>
</span><span id=__span-42-20><a id=__codelineno-42-20 name=__codelineno-42-20 href=#__codelineno-42-20></a><span class=c1># 6. SFT</span>
</span><span id=__span-42-21><a id=__codelineno-42-21 name=__codelineno-42-21 href=#__codelineno-42-21></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_sft_model
</span><span id=__span-42-22><a id=__codelineno-42-22 name=__codelineno-42-22 href=#__codelineno-42-22></a>
</span><span id=__span-42-23><a id=__codelineno-42-23 name=__codelineno-42-23 href=#__codelineno-42-23></a><span class=c1># 7. Optional RL</span>
</span><span id=__span-42-24><a id=__codelineno-42-24 name=__codelineno-42-24 href=#__codelineno-42-24></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_rl_model
</span><span id=__span-42-25><a id=__codelineno-42-25 name=__codelineno-42-25 href=#__codelineno-42-25></a>
</span><span id=__span-42-26><a id=__codelineno-42-26 name=__codelineno-42-26 href=#__codelineno-42-26></a><span class=c1># 8. Evaluate chat model</span>
</span><span id=__span-42-27><a id=__codelineno-42-27 name=__codelineno-42-27 href=#__codelineno-42-27></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::evaluate_chat_model<span class=w> </span>--source<span class=o>=</span>sft
</span><span id=__span-42-28><a id=__codelineno-42-28 name=__codelineno-42-28 href=#__codelineno-42-28></a>
</span><span id=__span-42-29><a id=__codelineno-42-29 name=__codelineno-42-29 href=#__codelineno-42-29></a><span class=c1># 9. Chat with it</span>
</span><span id=__span-42-30><a id=__codelineno-42-30 name=__codelineno-42-30 href=#__codelineno-42-30></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::chat_cli<span class=w> </span>--source<span class=o>=</span>sft
</span><span id=__span-42-31><a id=__codelineno-42-31 name=__codelineno-42-31 href=#__codelineno-42-31></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::chat_web<span class=w> </span>--source<span class=o>=</span>sft
</span></code></pre></div> <p>This is great for development - run expensive stages once, then iterate on later stages.</p> <h2 id=hyperparameter-tuning>Hyperparameter Tuning<a class=headerlink href=#hyperparameter-tuning title="Permanent link"></a></h2> <h3 id=model-size>Model Size<a class=headerlink href=#model-size title="Permanent link"></a></h3> <p>The <code>depth</code> parameter controls model size:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-43-1><a id=__codelineno-43-1 name=__codelineno-43-1 href=#__codelineno-43-1></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>12</span>  <span class=c1># ~200M params (quick test)</span>
</span><span id=__span-43-2><a id=__codelineno-43-2 name=__codelineno-43-2 href=#__codelineno-43-2></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>16</span>  <span class=c1># ~350M params</span>
</span><span id=__span-43-3><a id=__codelineno-43-3 name=__codelineno-43-3 href=#__codelineno-43-3></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>20</span>  <span class=c1># ~561M params (default speedrun)</span>
</span><span id=__span-43-4><a id=__codelineno-43-4 name=__codelineno-43-4 href=#__codelineno-43-4></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>24</span>  <span class=c1># ~800M params</span>
</span><span id=__span-43-5><a id=__codelineno-43-5 name=__codelineno-43-5 href=#__codelineno-43-5></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>26</span>  <span class=c1># ~1B params (GPT-2 grade)</span>
</span><span id=__span-43-6><a id=__codelineno-43-6 name=__codelineno-43-6 href=#__codelineno-43-6></a><span class=n>depth</span> <span class=o>=</span> <span class=mi>32</span>  <span class=c1># ~1.8B params (requires more GPUs)</span>
</span></code></pre></div> <p><strong>Scaling laws:</strong> - Parameters  depth  64  12 - Training tokens  parameters  20 (Chinchilla optimal)</p> <h3 id=batch-size>Batch Size<a class=headerlink href=#batch-size title="Permanent link"></a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-44-1><a id=__codelineno-44-1 name=__codelineno-44-1 href=#__codelineno-44-1></a><span class=n>device_batch_size</span> <span class=o>=</span> <span class=mi>32</span>  <span class=c1># Per GPU batch size</span>
</span><span id=__span-44-2><a id=__codelineno-44-2 name=__codelineno-44-2 href=#__codelineno-44-2></a>
</span><span id=__span-44-3><a id=__codelineno-44-3 name=__codelineno-44-3 href=#__codelineno-44-3></a><span class=c1># Effective batch size = device_batch_size  num_gpus  gradient_accumulation</span>
</span><span id=__span-44-4><a id=__codelineno-44-4 name=__codelineno-44-4 href=#__codelineno-44-4></a><span class=c1># nanochat uses gradient_accumulation=1 by default</span>
</span></code></pre></div> <p><strong>Guidelines:</strong> - 1 GPU: batch_size=16-32 - 4 GPUs: batch_size=32-64 (per device) - 8 GPUs: batch_size=32-64 (per device)</p> <h3 id=learning-rate>Learning Rate<a class=headerlink href=#learning-rate title="Permanent link"></a></h3> <p>Base model uses Muon optimizer with these defaults: </p><div class="language-python highlight"><pre><span></span><code><span id=__span-45-1><a id=__codelineno-45-1 name=__codelineno-45-1 href=#__codelineno-45-1></a><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.01</span>  <span class=c1># Muon (much higher than Adam!)</span>
</span><span id=__span-45-2><a id=__codelineno-45-2 name=__codelineno-45-2 href=#__codelineno-45-2></a><span class=n>lr_schedule</span> <span class=o>=</span> <span class=s2>"cosine"</span>  <span class=c1># Cosine decay to 10% of peak</span>
</span><span id=__span-45-3><a id=__codelineno-45-3 name=__codelineno-45-3 href=#__codelineno-45-3></a><span class=n>warmup_ratio</span> <span class=o>=</span> <span class=mf>0.1</span>  <span class=c1># Warm up for 10% of training</span>
</span></code></pre></div> <p>SFT and RL use AdamW: </p><div class="language-python highlight"><pre><span></span><code><span id=__span-46-1><a id=__codelineno-46-1 name=__codelineno-46-1 href=#__codelineno-46-1></a><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>3e-4</span>  <span class=c1># Standard for fine-tuning</span>
</span></code></pre></div> <h3 id=dataset-size>Dataset Size<a class=headerlink href=#dataset-size title="Permanent link"></a></h3> <table> <thead> <tr> <th>Model</th> <th>Parameters</th> <th>Optimal Tokens</th> <th>Shards Needed</th> </tr> </thead> <tbody> <tr> <td>d12</td> <td>200M</td> <td>4B</td> <td>~80</td> </tr> <tr> <td>d16</td> <td>350M</td> <td>7B</td> <td>~140</td> </tr> <tr> <td>d20</td> <td>561M</td> <td>11B</td> <td>~220</td> </tr> <tr> <td>d26</td> <td>1B</td> <td>20B</td> <td>~400</td> </tr> </tbody> </table> <p>Add 10-20% buffer because some tokens are filtered out.</p> <h2 id=cost-breakdown>Cost Breakdown<a class=headerlink href=#cost-breakdown title="Permanent link"></a></h2> <p>Based on Modal pricing (~$3.50/hr for A100-80GB):</p> <h3 id=full-speedrun-d20-240-shards-4-gpus>Full Speedrun (d20, 240 shards, 4 GPUs)<a class=headerlink href=#full-speedrun-d20-240-shards-4-gpus title="Permanent link"></a></h3> <table> <thead> <tr> <th>Stage</th> <th>GPUs</th> <th>Duration</th> <th>Cost</th> </tr> </thead> <tbody> <tr> <td>Download dataset</td> <td>CPU</td> <td>30 min</td> <td>$0.01</td> </tr> <tr> <td>Train tokenizer</td> <td>1</td> <td>45 min</td> <td>$2.50</td> </tr> <tr> <td>Base pretraining</td> <td>4</td> <td>5 hours</td> <td>$70</td> </tr> <tr> <td>Midtraining</td> <td>4</td> <td>30 min</td> <td>$7</td> </tr> <tr> <td>SFT</td> <td>4</td> <td>30 min</td> <td>$7</td> </tr> <tr> <td>RL (optional)</td> <td>4</td> <td>30 min</td> <td>$7</td> </tr> <tr> <td>Evaluation</td> <td>4</td> <td>30 min</td> <td>$7</td> </tr> <tr> <td><strong>Total</strong></td> <td></td> <td><strong>~8 hours</strong></td> <td><strong>~$100</strong></td> </tr> </tbody> </table> <h3 id=quick-test-d12-8-shards-4-gpus>Quick Test (d12, 8 shards, 4 GPUs)<a class=headerlink href=#quick-test-d12-8-shards-4-gpus title="Permanent link"></a></h3> <table> <thead> <tr> <th>Stage</th> <th>GPUs</th> <th>Duration</th> <th>Cost</th> </tr> </thead> <tbody> <tr> <td>Download dataset</td> <td>CPU</td> <td>5 min</td> <td>$0.01</td> </tr> <tr> <td>Train tokenizer</td> <td>1</td> <td>30 min</td> <td>$1.75</td> </tr> <tr> <td>Base pretraining</td> <td>4</td> <td>30 min</td> <td>$7</td> </tr> <tr> <td>Midtraining</td> <td>4</td> <td>15 min</td> <td>$3.50</td> </tr> <tr> <td>SFT</td> <td>4</td> <td>15 min</td> <td>$3.50</td> </tr> <tr> <td><strong>Total</strong></td> <td></td> <td><strong>~2 hours</strong></td> <td><strong>~$16</strong></td> </tr> </tbody> </table> <h3 id=storage-costs>Storage Costs<a class=headerlink href=#storage-costs title="Permanent link"></a></h3> <ul> <li>Volumes: Free up to 50GB</li> <li>This project: ~30-40GB = $0/month</li> </ul> <h2 id=monitoring-and-debugging>Monitoring and Debugging<a class=headerlink href=#monitoring-and-debugging title="Permanent link"></a></h2> <h3 id=real-time-monitoring>Real-time Monitoring<a class=headerlink href=#real-time-monitoring title="Permanent link"></a></h3> <p>When you run training, Modal gives you a URL:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-47-1><a id=__codelineno-47-1 name=__codelineno-47-1 href=#__codelineno-47-1></a>View run at https://modal.com/apps/...
</span></code></pre></div> <p><strong>The dashboard shows:</strong> - Real-time logs from all GPUs - GPU utilization (should be 95-100%) - Memory usage - Cost accumulation - Function status</p> <h3 id=weights-biases>Weights &amp; Biases<a class=headerlink href=#weights-biases title="Permanent link"></a></h3> <p>If you set up W&amp;B, check <code>wandb.ai/&lt;username&gt;/nanochat-modal</code></p> <p><strong>Charts to watch:</strong></p> <p><strong>Base training:</strong> - Training loss (should decrease smoothly) - Validation loss (should track training loss) - CORE metric (should increase over time) - Learning rate (should follow cosine schedule)</p> <p><strong>SFT/RL:</strong> - Task-specific metrics (ARC accuracy, GSM8K accuracy, etc.) - Loss curves - Gradient norms</p> <h3 id=checking-outputs>Checking Outputs<a class=headerlink href=#checking-outputs title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-48-1><a id=__codelineno-48-1 name=__codelineno-48-1 href=#__codelineno-48-1></a><span class=c1># List what's in the volume</span>
</span><span id=__span-48-2><a id=__codelineno-48-2 name=__codelineno-48-2 href=#__codelineno-48-2></a>modal<span class=w> </span>volume<span class=w> </span>ls<span class=w> </span>nanochat-data<span class=w> </span>/data/.cache/nanochat
</span><span id=__span-48-3><a id=__codelineno-48-3 name=__codelineno-48-3 href=#__codelineno-48-3></a>
</span><span id=__span-48-4><a id=__codelineno-48-4 name=__codelineno-48-4 href=#__codelineno-48-4></a><span class=c1># Check checkpoints</span>
</span><span id=__span-48-5><a id=__codelineno-48-5 name=__codelineno-48-5 href=#__codelineno-48-5></a>modal<span class=w> </span>volume<span class=w> </span>ls<span class=w> </span>nanochat-checkpoints<span class=w> </span>/data/.cache/nanochat/checkpoints
</span><span id=__span-48-6><a id=__codelineno-48-6 name=__codelineno-48-6 href=#__codelineno-48-6></a>
</span><span id=__span-48-7><a id=__codelineno-48-7 name=__codelineno-48-7 href=#__codelineno-48-7></a><span class=c1># Download something</span>
</span><span id=__span-48-8><a id=__codelineno-48-8 name=__codelineno-48-8 href=#__codelineno-48-8></a>modal<span class=w> </span>volume<span class=w> </span>get<span class=w> </span>nanochat-checkpoints<span class=w> </span><span class=se>\</span>
</span><span id=__span-48-9><a id=__codelineno-48-9 name=__codelineno-48-9 href=#__codelineno-48-9></a><span class=w>  </span>/data/.cache/nanochat/checkpoints/sft<span class=w> </span><span class=se>\</span>
</span><span id=__span-48-10><a id=__codelineno-48-10 name=__codelineno-48-10 href=#__codelineno-48-10></a><span class=w>  </span>./local-checkpoint
</span></code></pre></div> <h3 id=gpu-utilization>GPU Utilization<a class=headerlink href=#gpu-utilization title="Permanent link"></a></h3> <p>For multi-GPU training, all GPUs should be utilized. If only 1 GPU shows activity:</p> <ol> <li>Check that <code>NUM_GPUS_BASE</code> is set correctly</li> <li>Check torchrun is spawning multiple processes</li> <li>Check for errors in the logs</li> </ol> <h2 id=common-issues-and-solutions>Common Issues and Solutions<a class=headerlink href=#common-issues-and-solutions title="Permanent link"></a></h2> <h3 id=nanochat-directory-not-found>"nanochat directory not found"<a class=headerlink href=#nanochat-directory-not-found title="Permanent link"></a></h3> <p><strong>Error:</strong> <code>FileNotFoundError: nanochat</code></p> <p><strong>Fix:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-49-1><a id=__codelineno-49-1 name=__codelineno-49-1 href=#__codelineno-49-1></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/karpathy/nanochat.git
</span></code></pre></div> <p>Make sure it's in the same directory as <code>TrainNanochatModal.py</code>.</p> <h3 id=cuda-out-of-memory>CUDA Out of Memory<a class=headerlink href=#cuda-out-of-memory title="Permanent link"></a></h3> <p><strong>Error:</strong> <code>CUDA out of memory</code></p> <p><strong>Solutions:</strong></p> <ol> <li> <p><strong>Reduce batch size:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-50-1><a id=__codelineno-50-1 name=__codelineno-50-1 href=#__codelineno-50-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span>--device-batch-size<span class=o>=</span><span class=m>16</span>
</span></code></pre></div> </li> <li> <p><strong>Use fewer GPUs</strong> (counter-intuitive, but each GPU needs memory): </p><div class="language-python highlight"><pre><span></span><code><span id=__span-51-1><a id=__codelineno-51-1 name=__codelineno-51-1 href=#__codelineno-51-1></a><span class=n>NUM_GPUS_BASE</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># Instead of 4</span>
</span></code></pre></div> </li> <li> <p><strong>Reduce model size:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-52-1><a id=__codelineno-52-1 name=__codelineno-52-1 href=#__codelineno-52-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span>--depth<span class=o>=</span><span class=m>16</span>
</span></code></pre></div> </li> <li> <p><strong>Use A100-80GB</strong> instead of A100-40GB</p> </li> </ol> <h3 id=rust-compilation-fails>Rust Compilation Fails<a class=headerlink href=#rust-compilation-fails title="Permanent link"></a></h3> <p><strong>Error:</strong> Errors during rustbpe compilation</p> <p><strong>Fix:</strong> Usually means Rust wasn't installed correctly. The image build includes Rust installation, so this should work. If it doesn't:</p> <ol> <li>Check the image build logs for Rust installation errors</li> <li>Make sure you're using the <code>devel</code> CUDA image (not <code>runtime</code>)</li> <li>Try rebuilding: <code>modal build TrainNanochatModal.py</code></li> </ol> <h3 id=training-loss-not-decreasing>Training Loss Not Decreasing<a class=headerlink href=#training-loss-not-decreasing title="Permanent link"></a></h3> <p><strong>Symptoms:</strong> Loss stays flat or increases</p> <p><strong>Checks:</strong></p> <ol> <li><strong>Verify data is loading:</strong></li> <li>Check logs for "Loaded N batches"</li> <li> <p>Verify dataset was downloaded</p> </li> <li> <p><strong>Check learning rate:</strong></p> </li> <li>Might be too low (increase it)</li> <li> <p>Check W&amp;B for LR schedule</p> </li> <li> <p><strong>Model size vs dataset size:</strong></p> </li> <li>Tiny model + huge dataset = might not converge</li> <li> <p>Huge model + tiny dataset = will overfit</p> </li> <li> <p><strong>Multi-GPU issues:</strong></p> </li> <li>Verify all GPUs are being used</li> <li>Check for NCCL errors in logs</li> </ol> <h3 id=secrets-not-found>Secrets Not Found<a class=headerlink href=#secrets-not-found title="Permanent link"></a></h3> <p><strong>Error:</strong> <code>Modal Secret "nanochat-secrets" not found</code></p> <p><strong>Fix:</strong> </p><div class="language-bash highlight"><pre><span></span><code><span id=__span-53-1><a id=__codelineno-53-1 name=__codelineno-53-1 href=#__codelineno-53-1></a>modal<span class=w> </span>secret<span class=w> </span>create<span class=w> </span>nanochat-secrets<span class=w> </span><span class=se>\</span>
</span><span id=__span-53-2><a id=__codelineno-53-2 name=__codelineno-53-2 href=#__codelineno-53-2></a><span class=w>  </span><span class=nv>WANDB_API_KEY</span><span class=o>=</span>your_key<span class=w> </span><span class=se>\</span>
</span><span id=__span-53-3><a id=__codelineno-53-3 name=__codelineno-53-3 href=#__codelineno-53-3></a><span class=w>  </span><span class=nv>HUGGINGFACE_TOKEN</span><span class=o>=</span>hf_your_token
</span></code></pre></div> <p>Or use a <code>.env</code> file (script tries that first).</p> <h3 id=image-build-timeout>Image Build Timeout<a class=headerlink href=#image-build-timeout title="Permanent link"></a></h3> <p><strong>Error:</strong> Image build exceeds timeout</p> <p><strong>Fix:</strong> First build takes 15-20 minutes (Rust compilation). This is normal. If it times out:</p> <ol> <li>Increase timeout in Modal dashboard settings</li> <li>Or just wait - Modal caches completed layers, so re-running continues from where it failed</li> </ol> <h2 id=advanced-tips-and-tricks>Advanced Tips and Tricks<a class=headerlink href=#advanced-tips-and-tricks title="Permanent link"></a></h2> <h3 id=resume-from-checkpoint>Resume from Checkpoint<a class=headerlink href=#resume-from-checkpoint title="Permanent link"></a></h3> <p>If training crashes, resume from the last checkpoint:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-54-1><a id=__codelineno-54-1 name=__codelineno-54-1 href=#__codelineno-54-1></a><span class=c1># Nanochat automatically saves checkpoints</span>
</span><span id=__span-54-2><a id=__codelineno-54-2 name=__codelineno-54-2 href=#__codelineno-54-2></a><span class=c1># Just re-run the same command - it resumes automatically</span>
</span><span id=__span-54-3><a id=__codelineno-54-3 name=__codelineno-54-3 href=#__codelineno-54-3></a><span class=n>modal</span> <span class=n>run</span> <span class=n>TrainNanochatModal</span><span class=o>.</span><span class=n>py</span><span class=p>::</span><span class=n>train_base_model</span> <span class=o>--</span><span class=n>depth</span><span class=o>=</span><span class=mi>20</span>
</span></code></pre></div> <h3 id=custom-datasets>Custom Datasets<a class=headerlink href=#custom-datasets title="Permanent link"></a></h3> <p>To train on your own data:</p> <ol> <li><strong>Format as FineWeb shards</strong> (parquet files)</li> <li><strong>Place in <code>/data/.cache/nanochat/base_data</code></strong></li> <li><strong>Update num_shards</strong> to match your data</li> </ol> <p>Or modify <code>nanochat/dataset.py</code> to load from your source.</p> <h3 id=experiment-with-optimizers>Experiment with Optimizers<a class=headerlink href=#experiment-with-optimizers title="Permanent link"></a></h3> <p>Edit <code>nanochat/scripts/base_train.py</code> to try different optimizers: - Muon (default, best for base training) - AdamW (standard, works everywhere) - Lion (newer, sometimes faster)</p> <h3 id=multi-node-training>Multi-Node Training<a class=headerlink href=#multi-node-training title="Permanent link"></a></h3> <p>For models &gt;2B parameters, you might want multiple machines. Modal supports this with <code>multi_node</code> parameter. Check Modal docs for details.</p> <h3 id=quantization>Quantization<a class=headerlink href=#quantization title="Permanent link"></a></h3> <p>For inference, you can quantize the model:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-55-1><a id=__codelineno-55-1 name=__codelineno-55-1 href=#__codelineno-55-1></a><span class=c1># int8 quantization</span>
</span><span id=__span-55-2><a id=__codelineno-55-2 name=__codelineno-55-2 href=#__codelineno-55-2></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-55-3><a id=__codelineno-55-3 name=__codelineno-55-3 href=#__codelineno-55-3></a>    <span class=n>checkpoint_path</span><span class=p>,</span>
</span><span id=__span-55-4><a id=__codelineno-55-4 name=__codelineno-55-4 href=#__codelineno-55-4></a>    <span class=n>load_in_8bit</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-55-5><a id=__codelineno-55-5 name=__codelineno-55-5 href=#__codelineno-55-5></a><span class=p>)</span>
</span><span id=__span-55-6><a id=__codelineno-55-6 name=__codelineno-55-6 href=#__codelineno-55-6></a>
</span><span id=__span-55-7><a id=__codelineno-55-7 name=__codelineno-55-7 href=#__codelineno-55-7></a><span class=c1># int4 quantization (even faster)</span>
</span><span id=__span-55-8><a id=__codelineno-55-8 name=__codelineno-55-8 href=#__codelineno-55-8></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-55-9><a id=__codelineno-55-9 name=__codelineno-55-9 href=#__codelineno-55-9></a>    <span class=n>checkpoint_path</span><span class=p>,</span>
</span><span id=__span-55-10><a id=__codelineno-55-10 name=__codelineno-55-10 href=#__codelineno-55-10></a>    <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-55-11><a id=__codelineno-55-11 name=__codelineno-55-11 href=#__codelineno-55-11></a><span class=p>)</span>
</span></code></pre></div> <h2 id=expected-results>Expected Results<a class=headerlink href=#expected-results title="Permanent link"></a></h2> <p>After training the full speedrun (d20, 240 shards), you should get approximately:</p> <h3 id=base-model-after-pretraining>Base Model (after pretraining)<a class=headerlink href=#base-model-after-pretraining title="Permanent link"></a></h3> <table> <thead> <tr> <th>Metric</th> <th>Expected</th> <th>Good</th> <th>Excellent</th> </tr> </thead> <tbody> <tr> <td>CORE</td> <td>0.35</td> <td>0.38</td> <td>0.40</td> </tr> <tr> <td>Validation loss</td> <td>2.5</td> <td>2.4</td> <td>2.3</td> </tr> <tr> <td>Bits per byte</td> <td>1.2</td> <td>1.15</td> <td>1.10</td> </tr> </tbody> </table> <h3 id=after-sft>After SFT<a class=headerlink href=#after-sft title="Permanent link"></a></h3> <table> <thead> <tr> <th>Benchmark</th> <th>Expected</th> <th>Good</th> <th>Excellent</th> </tr> </thead> <tbody> <tr> <td>ARC-Easy</td> <td>60%</td> <td>65%</td> <td>70%</td> </tr> <tr> <td>ARC-Challenge</td> <td>30%</td> <td>35%</td> <td>40%</td> </tr> <tr> <td>GSM8K</td> <td>40%</td> <td>50%</td> <td>60%</td> </tr> <tr> <td>HumanEval</td> <td>15%</td> <td>20%</td> <td>25%</td> </tr> <tr> <td>MMLU</td> <td>45%</td> <td>50%</td> <td>55%</td> </tr> </tbody> </table> <h3 id=after-rl-optional>After RL (optional)<a class=headerlink href=#after-rl-optional title="Permanent link"></a></h3> <table> <thead> <tr> <th>Benchmark</th> <th>Expected Improvement</th> </tr> </thead> <tbody> <tr> <td>GSM8K</td> <td>+10-15%</td> </tr> <tr> <td>Others</td> <td>No change (RL only trains on math)</td> </tr> </tbody> </table> <p><strong>For context:</strong> - GPT-2 (1.5B): MMLU ~35%, GSM8K ~10% - Llama 2 7B: MMLU ~45%, GSM8K ~15% - Your d20 model (561M): MMLU ~50%, GSM8K ~40-60%</p> <p>Not bad for a model you trained in 4 hours!</p> <h2 id=whats-next>What's Next?<a class=headerlink href=#whats-next title="Permanent link"></a></h2> <p>You've built a complete LLM training pipeline from scratch. Here's what you can do next:</p> <h3 id=1-scale-up>1. Scale Up<a class=headerlink href=#1-scale-up title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-56-1><a id=__codelineno-56-1 name=__codelineno-56-1 href=#__codelineno-56-1></a><span class=c1># Train a 1B parameter model</span>
</span><span id=__span-56-2><a id=__codelineno-56-2 name=__codelineno-56-2 href=#__codelineno-56-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py<span class=w> </span><span class=se>\</span>
</span><span id=__span-56-3><a id=__codelineno-56-3 name=__codelineno-56-3 href=#__codelineno-56-3></a><span class=w>  </span>--num-data-shards<span class=o>=</span><span class=m>450</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-56-4><a id=__codelineno-56-4 name=__codelineno-56-4 href=#__codelineno-56-4></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>26</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-56-5><a id=__codelineno-56-5 name=__codelineno-56-5 href=#__codelineno-56-5></a><span class=w>  </span>--wandb-run<span class=o>=</span><span class=s2>"gpt2-grade"</span>
</span></code></pre></div> <h3 id=2-custom-data>2. Custom Data<a class=headerlink href=#2-custom-data title="Permanent link"></a></h3> <ul> <li>Collect your own dataset</li> <li>Train a domain-specific model</li> <li>E.g., code-only model, medical model, creative writing model</li> </ul> <h3 id=3-longer-training>3. Longer Training<a class=headerlink href=#3-longer-training title="Permanent link"></a></h3> <div class="language-bash highlight"><pre><span></span><code><span id=__span-57-1><a id=__codelineno-57-1 name=__codelineno-57-1 href=#__codelineno-57-1></a><span class=c1># Train for 2x tokens (better convergence)</span>
</span><span id=__span-57-2><a id=__codelineno-57-2 name=__codelineno-57-2 href=#__codelineno-57-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanochatModal.py::train_base_model<span class=w> </span><span class=se>\</span>
</span><span id=__span-57-3><a id=__codelineno-57-3 name=__codelineno-57-3 href=#__codelineno-57-3></a><span class=w>  </span>--depth<span class=o>=</span><span class=m>20</span><span class=w> </span><span class=se>\</span>
</span><span id=__span-57-4><a id=__codelineno-57-4 name=__codelineno-57-4 href=#__codelineno-57-4></a><span class=w>  </span>--max-iterations<span class=o>=</span><span class=m>20000</span>
</span></code></pre></div> <h3 id=4-deploy-for-production>4. Deploy for Production<a class=headerlink href=#4-deploy-for-production title="Permanent link"></a></h3> <p>Add vLLM serving (like in the Gemma tutorial): - OpenAI-compatible API - Auto-scaling - High throughput</p> <h3 id=5-experiment-with-architecture>5. Experiment with Architecture<a class=headerlink href=#5-experiment-with-architecture title="Permanent link"></a></h3> <ul> <li>Try different model widths</li> <li>Add mixture of experts</li> <li>Experiment with different attention mechanisms</li> </ul> <h3 id=6-advanced-fine-tuning>6. Advanced Fine-tuning<a class=headerlink href=#6-advanced-fine-tuning title="Permanent link"></a></h3> <ul> <li>DPO (Direct Preference Optimization)</li> <li>ORPO (Odds Ratio Preference Optimization)</li> <li>Longer RL training</li> </ul> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link"></a></h2> <ul> <li><strong><a href=https://github.com/karpathy/nanochat>Nanochat GitHub</a></strong> - The original repo</li> <li><strong><a href="https://www.youtube.com/watch?v=l8pRSuU81PU">Andrej's Video</a></strong> - Building GPT from scratch</li> <li><strong><a href=https://modal.com/docs>Modal Documentation</a></strong> - Everything about Modal</li> <li><strong><a href=https://modal.com/docs/guide/gpu>Modal GPU Types</a></strong> - All available GPUs and pricing</li> <li><strong><a href=https://pytorch.org/tutorials/intermediate/ddp_tutorial.html>PyTorch Distributed</a></strong> - Understanding multi-GPU training</li> <li><strong><a href=https://arxiv.org/abs/2203.15556>Chinchilla Paper</a></strong> - Optimal compute budget scaling</li> </ul> <h2 id=wrapping-up>Wrapping Up<a class=headerlink href=#wrapping-up title="Permanent link"></a></h2> <p>You just did what most people think requires a PhD and millions in compute: you trained a language model from absolute scratch.</p> <p>Not fine-tuning. Not adapter training. Full pretraining - tokenizer, base model, everything.</p> <p>And you did it in ~4 hours for ~$100. On Modal's serverless infrastructure. No cluster to manage, no DevOps nightmares, no month-long training runs.</p> <p>The Unsloth tutorial showed you highly optimized fine-tuning. The Axolotl tutorial showed you production-scale multi-GPU training. This tutorial showed you the complete pipeline - everything from raw text to functioning ChatGPT.</p> <p>This is the deepest you can go in understanding LLMs. You now know exactly how GPT works because you built one yourself.</p> <p>The nanochat pipeline is used by researchers, educators, and companies. It's the real deal, just scaled to be accessible. And Modal made it trivial to run.</p> <p>Got questions? Hit me up on Twitter <a href=https://x.com/adithya_s_k>@adithya_s_k</a>!</p> <p>Now go train your own ChatGPT. You have the power. </p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../TrainNanoGPTModalTutorial/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Training NanoGPT on Modal"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Training NanoGPT on Modal </div> </div> </a> <a href=../FinetuneGemmaUnslothModalTutorial/ class="md-footer__link md-footer__link--next" aria-label="Next: Fine-tuning Gemma with Unsloth"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Fine-tuning Gemma with Unsloth </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>