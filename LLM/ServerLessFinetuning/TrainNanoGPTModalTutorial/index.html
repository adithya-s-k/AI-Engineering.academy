<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Mastering Applied AI, One Concept at a Time"><meta name=author content="Adithya S Kolavi"><link href=https://aiengineering.academy/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial/ rel=canonical><link href=../ rel=prev><link href=../TrainNanochatModalTutorial/ rel=next><link rel=icon href=../../../assets/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.0"><title>Training NanoGPT on Modal - AI Engineering Academy</title><link rel=stylesheet href=../../../assets/stylesheets/main.618322db.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-JP3605WT7D"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-JP3605WT7D",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-JP3605WT7D",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../../../assets/stylesheets/custom.7c86dd97.min.css><!-- PostHog Analytics --><script>
  !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.crossOrigin="anonymous",p.async=!0,p.src=s.api_host.replace(".i.posthog.com","-assets.i.posthog.com")+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="init capture register register_once register_for_session unregister unregister_for_session getFeatureFlag getFeatureFlagPayload isFeatureEnabled reloadFeatureFlags updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures on onFeatureFlags onSurveysLoaded onSessionId getSurveys getActiveMatchingSurveys renderSurvey canRenderSurvey identify setPersonProperties group resetGroups setPersonPropertiesForFlags resetPersonPropertiesForFlags setGroupPropertiesForFlags resetGroupPropertiesForFlags reset get_distinct_id getGroups get_session_id get_session_replay_url alias set_config startSessionRecording stopSessionRecording sessionRecordingStarted captureException loadToolbar get_property getSessionProperty createPersonProfile opt_in_capturing opt_out_capturing has_opted_in_capturing has_opted_out_capturing clear_opt_in_out_capturing debug getPageViewId captureTraceFeedback captureTraceMetric".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
  posthog.init('phc_OL7nUCVeKtVJe8eHSKGs8zPTQAyr0hm8opAPFdFlkBz', {
      api_host: 'https://us.i.posthog.com',
      person_profiles: 'identified_only', // or 'always' to create profiles for anonymous users as well
  })
</script><meta property=og:type content=website><meta property=og:title content="Training NanoGPT on Modal - AI Engineering Academy"><meta property=og:description content="Mastering Applied AI, One Concept at a Time"><meta property=og:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial.png><meta property=og:image:type content=image/png><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta content=https://aiengineering.academy/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial/ property=og:url><meta property=twitter:card content=summary_large_image><meta property=twitter:title content="Training NanoGPT on Modal - AI Engineering Academy"><meta property=twitter:description content="Mastering Applied AI, One Concept at a Time"><meta property=twitter:image content=https://aiengineering.academy/assets/images/social/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial.png></head> <body dir=ltr data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#training-nanogpt-on-modal-your-first-gpu-training-pipeline class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@adithya_s_k</strong> on <a href=https://x.com/adithya_s_k> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M459.4 151.7c.3 4.5.3 9.1.3 13.6 0 138.7-105.6 298.6-298.6 298.6-59.5 0-114.7-17.2-161.1-47.1 8.4 1 16.6 1.3 25.3 1.3 49.1 0 94.2-16.6 130.3-44.8-46.1-1-84.8-31.2-98.1-72.8 6.5 1 13 1.6 19.8 1.6 9.4 0 18.8-1.3 27.6-3.6-48.1-9.7-84.1-52-84.1-103v-1.3c14 7.8 30.2 12.7 47.4 13.3-28.3-18.8-46.8-51-46.8-87.4 0-19.5 5.2-37.4 14.3-53C87.4 130.8 165 172.4 252.1 176.9c-1.6-7.8-2.6-15.9-2.6-24C249.5 95.1 296.3 48 354.4 48c30.2 0 57.5 12.7 76.7 33.1 23.7-4.5 46.5-13.3 66.6-25.3-7.8 24.4-24.4 44.8-46.1 57.8 21.1-2.3 41.6-8.1 60.4-16.2-14.3 20.8-32.2 39.3-52.6 54.3"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="AI Engineering Academy" class="md-header__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> AI Engineering Academy </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Training NanoGPT on Modal </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=cyan aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../../PromptEngineering/ class=md-tabs__link> Prompt Engineering </a> </li> <li class=md-tabs__item> <a href=../../../RAG/ class=md-tabs__link> RAG </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> LLM </a> </li> <li class=md-tabs__item> <a href=../../../Deployment/ class=md-tabs__link> Deployment </a> </li> <li class=md-tabs__item> <a href=../../../Agents/ class=md-tabs__link> Agents </a> </li> <li class=md-tabs__item> <a href=../../../Projects/ class=md-tabs__link> Projects </a> </li> <li class=md-tabs__item> <a href=../../../AIBreakDown/TRM/ class=md-tabs__link> AI BreakDown </a> </li> <li class=md-tabs__item> <a href=../../../blog/ class=md-tabs__link> Blog </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="AI Engineering Academy" class="md-nav__button md-logo" aria-label="AI Engineering Academy" data-md-component=logo> <img src=../../../assets/logo.png alt=logo> </a> AI Engineering Academy </label> <div class=md-nav__source> <a href=https://github.com/adithya-s-k/AI-Engineering.academy title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> adithya-s-k/AI-Engineering.academy </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../PromptEngineering/ class=md-nav__link> <span class=md-ellipsis> Prompt Engineering </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../RAG/ class=md-nav__link> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> LLM </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> LLM </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex> <span class=md-ellipsis> Finetuning Techniques </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Finetuning Techniques </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PreTrain/ class=md-nav__link> <span class=md-ellipsis> PreTraining LLMs </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/SFT/ class=md-nav__link> <span class=md-ellipsis> SFT </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/PPO/ class=md-nav__link> <span class=md-ellipsis> PPO(Proximal Policy Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/DPO/ class=md-nav__link> <span class=md-ellipsis> DPO(Direct Preference Optimization) </span> </a> </li> <li class=md-nav__item> <a href=../../TheoryBehindFinetuning/ORPO/ class=md-nav__link> <span class=md-ellipsis> ORPO(Odds Ratio Preference Optimization) </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../TheoryBehindFinetuning/GRPO/ class=md-nav__link> <span class=md-ellipsis> GRPO(Group Relative Policy Optimization) </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_3> <label class=md-nav__link for=__nav_4_3 id=__nav_4_3_label tabindex> <span class=md-ellipsis> LLM Finetuning Hands on </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_3_label aria-expanded=false> <label class=md-nav__title for=__nav_4_3> <span class="md-nav__icon md-icon"></span> LLM Finetuning Hands on </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Gemma/ class=md-nav__link> <span class=md-ellipsis> Gemma </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../LLama2/Llama2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Llama2 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Llama3_finetuning_notebook.ipynb class=md-nav__link> <span class=md-ellipsis> Llama3 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../Mistral-7b/ class=md-nav__link> <span class=md-ellipsis> Mistral </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_4> <label class=md-nav__link for=__nav_4_4 id=__nav_4_4_label tabindex> <span class=md-ellipsis> VLM </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4_4> <span class="md-nav__icon md-icon"></span> VLM </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../VLM/Florence2_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> Florence2 </span> </a> </li> <li class=md-nav__item> <a href=../../VLM/PaliGemma_finetuning_notebook/ class=md-nav__link> <span class=md-ellipsis> PaliGemma </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_5 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> Serverless Finetuning with Modal </span> </a> <label class="md-nav__link " for=__nav_4_5 id=__nav_4_5_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_5_label aria-expanded=true> <label class=md-nav__title for=__nav_4_5> <span class="md-nav__icon md-icon"></span> Serverless Finetuning with Modal </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Training NanoGPT on Modal </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Training NanoGPT on Modal </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-start-with-nanogpt class=md-nav__link> <span class=md-ellipsis> Why Start with NanoGPT? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-set-up class=md-nav__link> <span class=md-ellipsis> Getting Set Up </span> </a> <nav class=md-nav aria-label="Getting Set Up"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#clone-nanogpt class=md-nav__link> <span class=md-ellipsis> Clone NanoGPT </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-modal-script class=md-nav__link> <span class=md-ellipsis> Understanding the Modal Script </span> </a> <nav class=md-nav aria-label="Understanding the Modal Script"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-and-volume-setup class=md-nav__link> <span class=md-ellipsis> App and Volume Setup </span> </a> </li> <li class=md-nav__item> <a href=#the-container-image class=md-nav__link> <span class=md-ellipsis> The Container Image </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-three-stage-pipeline class=md-nav__link> <span class=md-ellipsis> The Three-Stage Pipeline </span> </a> <nav class=md-nav aria-label="The Three-Stage Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stage-1-preparing-the-data class=md-nav__link> <span class=md-ellipsis> Stage 1: Preparing the Data </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-training class=md-nav__link> <span class=md-ellipsis> Stage 2: Training </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-generating-samples class=md-nav__link> <span class=md-ellipsis> Stage 3: Generating Samples </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-the-pipeline class=md-nav__link> <span class=md-ellipsis> Running the Pipeline </span> </a> <nav class=md-nav aria-label="Running the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-run-everything-at-once class=md-nav__link> <span class=md-ellipsis> Option 1: Run Everything at Once </span> </a> </li> <li class=md-nav__item> <a href=#option-2-run-steps-individually class=md-nav__link> <span class=md-ellipsis> Option 2: Run Steps Individually </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#playing-with-configuration class=md-nav__link> <span class=md-ellipsis> Playing with Configuration </span> </a> <nav class=md-nav aria-label="Playing with Configuration"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-types class=md-nav__link> <span class=md-ellipsis> GPU Types </span> </a> </li> <li class=md-nav__item> <a href=#training-hyperparameters class=md-nav__link> <span class=md-ellipsis> Training Hyperparameters </span> </a> </li> <li class=md-nav__item> <a href=#sampling-parameters class=md-nav__link> <span class=md-ellipsis> Sampling Parameters </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#local-vs-remote-execution class=md-nav__link> <span class=md-ellipsis> Local vs Remote Execution </span> </a> </li> <li class=md-nav__item> <a href=#adding-secrets class=md-nav__link> <span class=md-ellipsis> Adding Secrets </span> </a> <nav class=md-nav aria-label="Adding Secrets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-env-file class=md-nav__link> <span class=md-ellipsis> Option 1: .env file </span> </a> </li> <li class=md-nav__item> <a href=#option-2-modal-secrets class=md-nav__link> <span class=md-ellipsis> Option 2: Modal Secrets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#when-things-go-wrong class=md-nav__link> <span class=md-ellipsis> When Things Go Wrong </span> </a> <nav class=md-nav aria-label="When Things Go Wrong"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nanogpt-directory-not-found class=md-nav__link> <span class=md-ellipsis> "nanoGPT directory not found" </span> </a> </li> <li class=md-nav__item> <a href=#checkpoint-not-found-during-sampling class=md-nav__link> <span class=md-ellipsis> "Checkpoint not found during sampling" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> "CUDA out of memory" </span> </a> </li> <li class=md-nav__item> <a href=#training-taking-forever class=md-nav__link> <span class=md-ellipsis> Training Taking Forever </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#monitoring-your-training class=md-nav__link> <span class=md-ellipsis> Monitoring Your Training </span> </a> </li> <li class=md-nav__item> <a href=#cost-optimization-tips class=md-nav__link> <span class=md-ellipsis> Cost Optimization Tips </span> </a> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../TrainNanochatModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Training Nanochat on Modal </span> </a> </li> <li class=md-nav__item> <a href=../FinetuneGemmaUnslothModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Fine-tuning Gemma with Unsloth </span> </a> </li> <li class=md-nav__item> <a href=../FinetuneLlamaAxolotlGPUModalTutorial/ class=md-nav__link> <span class=md-ellipsis> Multi-GPU Training with Axolotl </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4_6> <div class="md-nav__link md-nav__container"> <a href=../../LLMArchitecture/ParameterCount/ class="md-nav__link "> <span class=md-ellipsis> LLM Architecture </span> </a> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_6_label aria-expanded=false> <label class=md-nav__title for=__nav_4_6> <span class="md-nav__icon md-icon"></span> LLM Architecture </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Deployment/ class=md-nav__link> <span class=md-ellipsis> Deployment </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Agents/ class=md-nav__link> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../Projects/ class=md-nav__link> <span class=md-ellipsis> Projects </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../AIBreakDown/TRM/ class=md-nav__link> <span class=md-ellipsis> AI BreakDown </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../blog/ class=md-nav__link> <span class=md-ellipsis> Blog </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-start-with-nanogpt class=md-nav__link> <span class=md-ellipsis> Why Start with NanoGPT? </span> </a> </li> <li class=md-nav__item> <a href=#what-were-building class=md-nav__link> <span class=md-ellipsis> What We're Building </span> </a> </li> <li class=md-nav__item> <a href=#getting-set-up class=md-nav__link> <span class=md-ellipsis> Getting Set Up </span> </a> <nav class=md-nav aria-label="Getting Set Up"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#install-modal class=md-nav__link> <span class=md-ellipsis> Install Modal </span> </a> </li> <li class=md-nav__item> <a href=#authenticate class=md-nav__link> <span class=md-ellipsis> Authenticate </span> </a> </li> <li class=md-nav__item> <a href=#clone-nanogpt class=md-nav__link> <span class=md-ellipsis> Clone NanoGPT </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#understanding-the-modal-script class=md-nav__link> <span class=md-ellipsis> Understanding the Modal Script </span> </a> <nav class=md-nav aria-label="Understanding the Modal Script"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#app-and-volume-setup class=md-nav__link> <span class=md-ellipsis> App and Volume Setup </span> </a> </li> <li class=md-nav__item> <a href=#the-container-image class=md-nav__link> <span class=md-ellipsis> The Container Image </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#the-three-stage-pipeline class=md-nav__link> <span class=md-ellipsis> The Three-Stage Pipeline </span> </a> <nav class=md-nav aria-label="The Three-Stage Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#stage-1-preparing-the-data class=md-nav__link> <span class=md-ellipsis> Stage 1: Preparing the Data </span> </a> </li> <li class=md-nav__item> <a href=#stage-2-training class=md-nav__link> <span class=md-ellipsis> Stage 2: Training </span> </a> </li> <li class=md-nav__item> <a href=#stage-3-generating-samples class=md-nav__link> <span class=md-ellipsis> Stage 3: Generating Samples </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#running-the-pipeline class=md-nav__link> <span class=md-ellipsis> Running the Pipeline </span> </a> <nav class=md-nav aria-label="Running the Pipeline"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-run-everything-at-once class=md-nav__link> <span class=md-ellipsis> Option 1: Run Everything at Once </span> </a> </li> <li class=md-nav__item> <a href=#option-2-run-steps-individually class=md-nav__link> <span class=md-ellipsis> Option 2: Run Steps Individually </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#playing-with-configuration class=md-nav__link> <span class=md-ellipsis> Playing with Configuration </span> </a> <nav class=md-nav aria-label="Playing with Configuration"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gpu-types class=md-nav__link> <span class=md-ellipsis> GPU Types </span> </a> </li> <li class=md-nav__item> <a href=#training-hyperparameters class=md-nav__link> <span class=md-ellipsis> Training Hyperparameters </span> </a> </li> <li class=md-nav__item> <a href=#sampling-parameters class=md-nav__link> <span class=md-ellipsis> Sampling Parameters </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#local-vs-remote-execution class=md-nav__link> <span class=md-ellipsis> Local vs Remote Execution </span> </a> </li> <li class=md-nav__item> <a href=#adding-secrets class=md-nav__link> <span class=md-ellipsis> Adding Secrets </span> </a> <nav class=md-nav aria-label="Adding Secrets"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#option-1-env-file class=md-nav__link> <span class=md-ellipsis> Option 1: .env file </span> </a> </li> <li class=md-nav__item> <a href=#option-2-modal-secrets class=md-nav__link> <span class=md-ellipsis> Option 2: Modal Secrets </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#when-things-go-wrong class=md-nav__link> <span class=md-ellipsis> When Things Go Wrong </span> </a> <nav class=md-nav aria-label="When Things Go Wrong"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#nanogpt-directory-not-found class=md-nav__link> <span class=md-ellipsis> "nanoGPT directory not found" </span> </a> </li> <li class=md-nav__item> <a href=#checkpoint-not-found-during-sampling class=md-nav__link> <span class=md-ellipsis> "Checkpoint not found during sampling" </span> </a> </li> <li class=md-nav__item> <a href=#cuda-out-of-memory class=md-nav__link> <span class=md-ellipsis> "CUDA out of memory" </span> </a> </li> <li class=md-nav__item> <a href=#training-taking-forever class=md-nav__link> <span class=md-ellipsis> Training Taking Forever </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#monitoring-your-training class=md-nav__link> <span class=md-ellipsis> Monitoring Your Training </span> </a> </li> <li class=md-nav__item> <a href=#cost-optimization-tips class=md-nav__link> <span class=md-ellipsis> Cost Optimization Tips </span> </a> </li> <li class=md-nav__item> <a href=#whats-next class=md-nav__link> <span class=md-ellipsis> What's Next? </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/edit/master/docs/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial.md title="Edit this page" class="md-content__button md-icon" rel=edit> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy/raw/master/docs/LLM/ServerLessFinetuning/TrainNanoGPTModalTutorial.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <div><h1 id=training-nanogpt-on-modal-your-first-gpu-training-pipeline>Training NanoGPT on Modal: Your First GPU Training Pipeline<a class=headerlink href=#training-nanogpt-on-modal-your-first-gpu-training-pipeline title="Permanent link">Â¶</a></h1> <p>ðŸ“„ <strong><a href=https://github.com/adithya-s-k/AI-Engineering.academy/blob/main/docs/LLM/ServerLessFinetuning/TrainNanoGPTModal.py>View Complete Python Script</a></strong></p> <p>So you want to train a GPT model but don't want to deal with the headache of setting up infrastructure? Let me show you how I do it with Modal and nanoGPT.</p> <h2 id=why-start-with-nanogpt>Why Start with NanoGPT?<a class=headerlink href=#why-start-with-nanogpt title="Permanent link">Â¶</a></h2> <p>Here's the thing about nanoGPT - if you've ever wondered how GPT actually works under the hood, this is the best place to start. Andrej Karpathy built this as an educational implementation that's simple enough to understand but powerful enough to actually train real models.</p> <p>It's only ~300 lines of clean PyTorch code. No abstractions hiding what's really happening. Just pure, understandable transformer training.</p> <p>And honestly? It's become the go-to for anyone learning how to train language models from scratch. Plus, since it's just a regular Python repo, it's perfect for showing you how to take <em>any</em> existing codebase and run it on Modal's GPUs.</p> <p>Think of this as your "Hello World" for GPU training on Modal. Once you get this working, you'll know how to run pretty much anything on serverless GPUs.</p> <h2 id=what-were-building>What We're Building<a class=headerlink href=#what-were-building title="Permanent link">Â¶</a></h2> <p>We'll train a character-level GPT on Shakespeare's collected works (because why not make our model speak like the Bard?). The pipeline has three stages:</p> <ol> <li><strong>Prep the data</strong> - Download and tokenize Shakespeare (runs on CPU, saves money)</li> <li><strong>Train the model</strong> - Fire up a GPU and train our tiny GPT</li> <li><strong>Generate text</strong> - Watch our model write Shakespeare-esque text</li> </ol> <p>The best part? You write all this code locally, and with one command, it runs on a beefy A100 GPU in the cloud. No SSH, no Docker, no infrastructure headaches.</p> <h2 id=getting-set-up>Getting Set Up<a class=headerlink href=#getting-set-up title="Permanent link">Â¶</a></h2> <h3 id=install-modal>Install Modal<a class=headerlink href=#install-modal title="Permanent link">Â¶</a></h3> <p>First things first:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>pip<span class=w> </span>install<span class=w> </span>modal
</span></code></pre></div> <h3 id=authenticate>Authenticate<a class=headerlink href=#authenticate title="Permanent link">Â¶</a></h3> <p>Then authenticate (only need to do this once):</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>modal<span class=w> </span>setup
</span></code></pre></div> <p>This opens your browser and handles the OAuth flow. If you're running this in CI/CD or prefer API keys:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_ID</span><span class=o>=</span>&lt;your_token_id&gt;
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=nb>export</span><span class=w> </span><span class=nv>MODAL_TOKEN_SECRET</span><span class=o>=</span>&lt;your_token_secret&gt;
</span></code></pre></div> <h3 id=clone-nanogpt>Clone NanoGPT<a class=headerlink href=#clone-nanogpt title="Permanent link">Â¶</a></h3> <p>Now grab nanoGPT. We need it locally because we're going to copy it into our Modal container:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=nb>cd</span><span class=w> </span>/path/to/your/project
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/karpathy/nanoGPT.git
</span></code></pre></div> <p>Your folder should look like this:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a>ServerLessFinetuning/
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>â”œâ”€â”€ TrainNanoGPTModal.py    # Your Modal script (we'll create this)
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>â””â”€â”€ nanoGPT/                 # The cloned repo
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    â”œâ”€â”€ train.py
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a>    â”œâ”€â”€ sample.py
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>    â”œâ”€â”€ data/
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a>    â””â”€â”€ config/
</span></code></pre></div> <blockquote> <p><strong>Important:</strong> The Modal script needs to see the <code>nanoGPT/</code> folder in the same directory. When Modal builds your container image, it'll copy this entire directory into it.</p> </blockquote> <h2 id=understanding-the-modal-script>Understanding the Modal Script<a class=headerlink href=#understanding-the-modal-script title="Permanent link">Â¶</a></h2> <p>Alright, let me walk you through how this works. I'll explain each piece and why it matters.</p> <h3 id=app-and-volume-setup>App and Volume Setup<a class=headerlink href=#app-and-volume-setup title="Permanent link">Â¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>modal</span><span class=w> </span><span class=kn>import</span> <span class=n>App</span><span class=p>,</span> <span class=n>Image</span> <span class=k>as</span> <span class=n>ModalImage</span><span class=p>,</span> <span class=n>Volume</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a><span class=c1># Create the Modal app - this is your project's namespace</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>app</span> <span class=o>=</span> <span class=n>App</span><span class=p>(</span><span class=s2>"nanogpt-training"</span><span class=p>)</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a><span class=c1># Create or get existing volume for persistent storage</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=c1># If "nanogpt-outputs" doesn't exist, Modal creates it for you</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=n>volume</span> <span class=o>=</span> <span class=n>Volume</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"nanogpt-outputs"</span><span class=p>,</span> <span class=n>create_if_missing</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=c1># Define where to mount the volume in our containers</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a><span class=c1># This dict maps container paths to Modal volumes</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=n>VOLUME_CONFIG</span> <span class=o>=</span> <span class=p>{</span>
</span><span id=__span-5-13><a id=__codelineno-5-13 name=__codelineno-5-13 href=#__codelineno-5-13></a>    <span class=s2>"/data"</span><span class=p>:</span> <span class=n>volume</span><span class=p>,</span>  <span class=c1># Mount 'volume' at /data inside the container</span>
</span><span id=__span-5-14><a id=__codelineno-5-14 name=__codelineno-5-14 href=#__codelineno-5-14></a><span class=p>}</span>
</span></code></pre></div> <p>So here's what's happening:</p> <ul> <li><strong>App</strong>: Every Modal project needs an app. Think of it as your project container - all your functions live under this app.</li> <li><strong>Volume</strong>: This is persistent storage that survives across runs. When your GPU instance shuts down (and it will, to save you money), you need somewhere to keep your model checkpoints. Volumes stick around even after your functions finish.</li> <li><strong>VOLUME_CONFIG</strong>: This dict tells Modal "hey, mount this volume at <code>/data</code> in my containers". You can mount multiple volumes at different paths if you want.</li> </ul> <p>The cool thing about volumes? They persist across function calls. So when you train your model and save it to <code>/data/out</code>, you can load it later in a completely different function. It just works.</p> <h3 id=the-container-image>The Container Image<a class=headerlink href=#the-container-image title="Permanent link">Â¶</a></h3> <p>This is crucial - we need to tell Modal what our container should look like:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=n>NANOGPT_IMAGE</span> <span class=o>=</span> <span class=p>(</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>    <span class=c1># Start with a lightweight Debian base + Python 3.11</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=n>ModalImage</span><span class=o>.</span><span class=n>debian_slim</span><span class=p>(</span><span class=n>python_version</span><span class=o>=</span><span class=s2>"3.11"</span><span class=p>)</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=c1># Install all the Python packages nanoGPT needs</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=c1># Modal uses pip under the hood</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=o>.</span><span class=n>pip_install</span><span class=p>(</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>        <span class=s2>"torch"</span><span class=p>,</span>          <span class=c1># PyTorch for the model</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>        <span class=s2>"numpy"</span><span class=p>,</span>          <span class=c1># Numerical operations</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>        <span class=s2>"transformers"</span><span class=p>,</span>   <span class=c1># Hugging Face utilities</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>        <span class=s2>"datasets"</span><span class=p>,</span>       <span class=c1># For loading datasets</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>        <span class=s2>"tiktoken"</span><span class=p>,</span>       <span class=c1># OpenAI's tokenizer</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=s2>"tqdm"</span><span class=p>,</span>          <span class=c1># Progress bars</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>    <span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>    <span class=c1># Copy your local nanoGPT directory into the container</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17 href=#__codelineno-6-17></a>    <span class=c1># local_path: where it is on your machine</span>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18 href=#__codelineno-6-18></a>    <span class=c1># remote_path: where it goes in the container</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19 href=#__codelineno-6-19></a>    <span class=c1># copy=True: actually copy the files (vs just mounting)</span>
</span><span id=__span-6-20><a id=__codelineno-6-20 name=__codelineno-6-20 href=#__codelineno-6-20></a>    <span class=o>.</span><span class=n>add_local_dir</span><span class=p>(</span><span class=n>local_path</span><span class=o>=</span><span class=s2>"nanoGPT"</span><span class=p>,</span> <span class=n>remote_path</span><span class=o>=</span><span class=s2>"/root/nanoGPT"</span><span class=p>,</span> <span class=n>copy</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-6-21><a id=__codelineno-6-21 name=__codelineno-6-21 href=#__codelineno-6-21></a>
</span><span id=__span-6-22><a id=__codelineno-6-22 name=__codelineno-6-22 href=#__codelineno-6-22></a>    <span class=c1># Set the working directory - all commands run from here</span>
</span><span id=__span-6-23><a id=__codelineno-6-23 name=__codelineno-6-23 href=#__codelineno-6-23></a>    <span class=o>.</span><span class=n>workdir</span><span class=p>(</span><span class=s2>"/root/nanoGPT"</span><span class=p>)</span>
</span><span id=__span-6-24><a id=__codelineno-6-24 name=__codelineno-6-24 href=#__codelineno-6-24></a><span class=p>)</span>
</span></code></pre></div> <p>Let me break this down:</p> <ol> <li><strong>Start with a minimal base</strong> - Debian slim keeps things lightweight and fast</li> <li><strong>Install dependencies</strong> - Everything nanoGPT needs to run</li> <li><strong>Copy your local code</strong> - This is the magic! <code>.add_local_dir()</code> takes the nanoGPT repo from your machine and bakes it into the container image</li> <li><strong>Set working directory</strong> - So when we run <code>python train.py</code>, we're already in <code>/root/nanoGPT</code></li> </ol> <p>The first time Modal builds this, it'll take a few minutes (installing PyTorch takes time). But Modal caches the entire image, so every subsequent run is instant. You only rebuild when you change the image definition - like adding a new package or updating nanoGPT.</p> <h2 id=the-three-stage-pipeline>The Three-Stage Pipeline<a class=headerlink href=#the-three-stage-pipeline title="Permanent link">Â¶</a></h2> <h3 id=stage-1-preparing-the-data>Stage 1: Preparing the Data<a class=headerlink href=#stage-1-preparing-the-data title="Permanent link">Â¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOGPT_IMAGE</span><span class=p>,</span>      <span class=c1># Use the image we defined above</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span> <span class=o>*</span> <span class=mi>60</span><span class=p>,</span>           <span class=c1># 10 minutes timeout (in seconds)</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=c1># Notice: No GPU specified! This runs on CPU to save money</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a><span class=p>)</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=k>def</span><span class=w> </span><span class=nf>prepare_data</span><span class=p>():</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a><span class=w>    </span><span class=sd>"""</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=sd>    Download and prep the Shakespeare dataset.</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a><span class=sd>    Creates train.bin and val.bin files.</span>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=sd>    """</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"PREPARING SHAKESPEARE DATASET"</span><span class=p>)</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a>    <span class=c1># Run nanoGPT's data preparation script</span>
</span><span id=__span-7-18><a id=__codelineno-7-18 name=__codelineno-7-18 href=#__codelineno-7-18></a>    <span class=c1># This downloads Shakespeare text and tokenizes it</span>
</span><span id=__span-7-19><a id=__codelineno-7-19 name=__codelineno-7-19 href=#__codelineno-7-19></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span><span id=__span-7-20><a id=__codelineno-7-20 name=__codelineno-7-20 href=#__codelineno-7-20></a>        <span class=p>[</span><span class=s2>"python"</span><span class=p>,</span> <span class=s2>"data/shakespeare_char/prepare.py"</span><span class=p>],</span>
</span><span id=__span-7-21><a id=__codelineno-7-21 name=__codelineno-7-21 href=#__codelineno-7-21></a>        <span class=n>capture_output</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># Capture output so we can print it</span>
</span><span id=__span-7-22><a id=__codelineno-7-22 name=__codelineno-7-22 href=#__codelineno-7-22></a>        <span class=n>text</span><span class=o>=</span><span class=kc>True</span>             <span class=c1># Get output as string, not bytes</span>
</span><span id=__span-7-23><a id=__codelineno-7-23 name=__codelineno-7-23 href=#__codelineno-7-23></a>    <span class=p>)</span>
</span><span id=__span-7-24><a id=__codelineno-7-24 name=__codelineno-7-24 href=#__codelineno-7-24></a>
</span><span id=__span-7-25><a id=__codelineno-7-25 name=__codelineno-7-25 href=#__codelineno-7-25></a>    <span class=c1># Print what happened</span>
</span><span id=__span-7-26><a id=__codelineno-7-26 name=__codelineno-7-26 href=#__codelineno-7-26></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=p>)</span>
</span><span id=__span-7-27><a id=__codelineno-7-27 name=__codelineno-7-27 href=#__codelineno-7-27></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>:</span>
</span><span id=__span-7-28><a id=__codelineno-7-28 name=__codelineno-7-28 href=#__codelineno-7-28></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"STDERR:"</span><span class=p>,</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>)</span>
</span><span id=__span-7-29><a id=__codelineno-7-29 name=__codelineno-7-29 href=#__codelineno-7-29></a>
</span><span id=__span-7-30><a id=__codelineno-7-30 name=__codelineno-7-30 href=#__codelineno-7-30></a>    <span class=c1># If the script failed, raise an error</span>
</span><span id=__span-7-31><a id=__codelineno-7-31 name=__codelineno-7-31 href=#__codelineno-7-31></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-7-32><a id=__codelineno-7-32 name=__codelineno-7-32 href=#__codelineno-7-32></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Data preparation failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-7-33><a id=__codelineno-7-33 name=__codelineno-7-33 href=#__codelineno-7-33></a>
</span><span id=__span-7-34><a id=__codelineno-7-34 name=__codelineno-7-34 href=#__codelineno-7-34></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ“ Data preparation completed!"</span><span class=p>)</span>
</span><span id=__span-7-35><a id=__codelineno-7-35 name=__codelineno-7-35 href=#__codelineno-7-35></a>
</span><span id=__span-7-36><a id=__codelineno-7-36 name=__codelineno-7-36 href=#__codelineno-7-36></a>    <span class=c1># Return a dict with status info</span>
</span><span id=__span-7-37><a id=__codelineno-7-37 name=__codelineno-7-37 href=#__codelineno-7-37></a>    <span class=c1># (Modal functions can return JSON-serializable data)</span>
</span><span id=__span-7-38><a id=__codelineno-7-38 name=__codelineno-7-38 href=#__codelineno-7-38></a>    <span class=k>return</span> <span class=p>{</span><span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span> <span class=s2>"dataset"</span><span class=p>:</span> <span class=s2>"shakespeare_char"</span><span class=p>}</span>
</span></code></pre></div> <p>Notice what we're NOT specifying? A GPU. This function runs on CPU because we don't need a GPU just to download and tokenize text. Why pay for GPU time when we don't need it?</p> <p>This function: 1. Downloads the Shakespeare text (~1MB) 2. Tokenizes it at the character level 3. Creates <code>train.bin</code> and <code>val.bin</code> files</p> <p>These files stay in the container's filesystem (not the volume) since they're small and the training function needs them.</p> <h3 id=stage-2-training>Stage 2: Training<a class=headerlink href=#stage-2-training title="Permanent link">Â¶</a></h3> <p>Now here's where the fun begins:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOGPT_IMAGE</span><span class=p>,</span>           <span class=c1># Our container image with nanoGPT</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>GPU_TYPE</span><span class=p>,</span>                   <span class=c1># "a100-40gb" by default - NOW we need a GPU!</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>          <span class=c1># Mount our volume at /data</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>              <span class=c1># Give it 2 hours max</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=p>)</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a><span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>    <span class=c1># All hyperparameters as function arguments - makes experimenting easy!</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=n>max_iters</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>1000</span><span class=p>,</span>          <span class=c1># How many training steps</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>    <span class=n>eval_interval</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>500</span><span class=p>,</span>       <span class=c1># Check validation loss every N steps</span>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=n>batch_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>64</span><span class=p>,</span>           <span class=c1># Samples per batch</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>    <span class=n>block_size</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>256</span><span class=p>,</span>          <span class=c1># Context length (characters)</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>    <span class=n>n_layer</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>6</span><span class=p>,</span>               <span class=c1># Number of transformer layers</span>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a>    <span class=n>n_head</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>6</span><span class=p>,</span>                <span class=c1># Attention heads per layer</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a>    <span class=n>n_embd</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>384</span><span class=p>,</span>              <span class=c1># Hidden dimension size</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a>    <span class=n>learning_rate</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>1e-3</span><span class=p>,</span>    <span class=c1># Optimizer learning rate</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a><span class=p>):</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=w>    </span><span class=sd>"""Train a character-level GPT on Shakespeare."""</span>
</span><span id=__span-8-19><a id=__codelineno-8-19 name=__codelineno-8-19 href=#__codelineno-8-19></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-8-20><a id=__codelineno-8-20 name=__codelineno-8-20 href=#__codelineno-8-20></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-8-21><a id=__codelineno-8-21 name=__codelineno-8-21 href=#__codelineno-8-21></a>    <span class=kn>import</span><span class=w> </span><span class=nn>shutil</span>
</span><span id=__span-8-22><a id=__codelineno-8-22 name=__codelineno-8-22 href=#__codelineno-8-22></a>
</span><span id=__span-8-23><a id=__codelineno-8-23 name=__codelineno-8-23 href=#__codelineno-8-23></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-8-24><a id=__codelineno-8-24 name=__codelineno-8-24 href=#__codelineno-8-24></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"TRAINING NANOGPT ON SHAKESPEARE"</span><span class=p>)</span>
</span><span id=__span-8-25><a id=__codelineno-8-25 name=__codelineno-8-25 href=#__codelineno-8-25></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-8-26><a id=__codelineno-8-26 name=__codelineno-8-26 href=#__codelineno-8-26></a>
</span><span id=__span-8-27><a id=__codelineno-8-27 name=__codelineno-8-27 href=#__codelineno-8-27></a>    <span class=c1># Safety check: make sure data is prepared</span>
</span><span id=__span-8-28><a id=__codelineno-8-28 name=__codelineno-8-28 href=#__codelineno-8-28></a>    <span class=c1># If not, run prepare_data locally in this container</span>
</span><span id=__span-8-29><a id=__codelineno-8-29 name=__codelineno-8-29 href=#__codelineno-8-29></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=s2>"data/shakespeare_char/train.bin"</span><span class=p>):</span>
</span><span id=__span-8-30><a id=__codelineno-8-30 name=__codelineno-8-30 href=#__codelineno-8-30></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"Data not found, preparing it first..."</span><span class=p>)</span>
</span><span id=__span-8-31><a id=__codelineno-8-31 name=__codelineno-8-31 href=#__codelineno-8-31></a>        <span class=n>prepare_data</span><span class=o>.</span><span class=n>local</span><span class=p>()</span>  <span class=c1># .local() runs in this same container</span>
</span><span id=__span-8-32><a id=__codelineno-8-32 name=__codelineno-8-32 href=#__codelineno-8-32></a>
</span><span id=__span-8-33><a id=__codelineno-8-33 name=__codelineno-8-33 href=#__codelineno-8-33></a>    <span class=c1># Build the training command with all our hyperparameters</span>
</span><span id=__span-8-34><a id=__codelineno-8-34 name=__codelineno-8-34 href=#__codelineno-8-34></a>    <span class=c1># We're basically calling: python train.py config.py --max_iters=1000 ...</span>
</span><span id=__span-8-35><a id=__codelineno-8-35 name=__codelineno-8-35 href=#__codelineno-8-35></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-8-36><a id=__codelineno-8-36 name=__codelineno-8-36 href=#__codelineno-8-36></a>        <span class=s2>"python"</span><span class=p>,</span>
</span><span id=__span-8-37><a id=__codelineno-8-37 name=__codelineno-8-37 href=#__codelineno-8-37></a>        <span class=s2>"train.py"</span><span class=p>,</span>                              <span class=c1># nanoGPT's training script</span>
</span><span id=__span-8-38><a id=__codelineno-8-38 name=__codelineno-8-38 href=#__codelineno-8-38></a>        <span class=s2>"config/train_shakespeare_char.py"</span><span class=p>,</span>      <span class=c1># Base config file</span>
</span><span id=__span-8-39><a id=__codelineno-8-39 name=__codelineno-8-39 href=#__codelineno-8-39></a>        <span class=sa>f</span><span class=s2>"--max_iters=</span><span class=si>{</span><span class=n>max_iters</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>              <span class=c1># Override config with our params</span>
</span><span id=__span-8-40><a id=__codelineno-8-40 name=__codelineno-8-40 href=#__codelineno-8-40></a>        <span class=sa>f</span><span class=s2>"--eval_interval=</span><span class=si>{</span><span class=n>eval_interval</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-41><a id=__codelineno-8-41 name=__codelineno-8-41 href=#__codelineno-8-41></a>        <span class=sa>f</span><span class=s2>"--batch_size=</span><span class=si>{</span><span class=n>batch_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-42><a id=__codelineno-8-42 name=__codelineno-8-42 href=#__codelineno-8-42></a>        <span class=sa>f</span><span class=s2>"--block_size=</span><span class=si>{</span><span class=n>block_size</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-43><a id=__codelineno-8-43 name=__codelineno-8-43 href=#__codelineno-8-43></a>        <span class=sa>f</span><span class=s2>"--n_layer=</span><span class=si>{</span><span class=n>n_layer</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-44><a id=__codelineno-8-44 name=__codelineno-8-44 href=#__codelineno-8-44></a>        <span class=sa>f</span><span class=s2>"--n_head=</span><span class=si>{</span><span class=n>n_head</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-45><a id=__codelineno-8-45 name=__codelineno-8-45 href=#__codelineno-8-45></a>        <span class=sa>f</span><span class=s2>"--n_embd=</span><span class=si>{</span><span class=n>n_embd</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-46><a id=__codelineno-8-46 name=__codelineno-8-46 href=#__codelineno-8-46></a>        <span class=sa>f</span><span class=s2>"--learning_rate=</span><span class=si>{</span><span class=n>learning_rate</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>
</span><span id=__span-8-47><a id=__codelineno-8-47 name=__codelineno-8-47 href=#__codelineno-8-47></a>        <span class=s2>"--out_dir=/data/out"</span><span class=p>,</span>                   <span class=c1># Save to volume (persists!)</span>
</span><span id=__span-8-48><a id=__codelineno-8-48 name=__codelineno-8-48 href=#__codelineno-8-48></a>        <span class=s2>"--dataset=shakespeare_char"</span><span class=p>,</span>            <span class=c1># Which dataset to use</span>
</span><span id=__span-8-49><a id=__codelineno-8-49 name=__codelineno-8-49 href=#__codelineno-8-49></a>        <span class=s2>"--compile=False"</span><span class=p>,</span>                       <span class=c1># Skip torch.compile for faster startup</span>
</span><span id=__span-8-50><a id=__codelineno-8-50 name=__codelineno-8-50 href=#__codelineno-8-50></a>    <span class=p>]</span>
</span><span id=__span-8-51><a id=__codelineno-8-51 name=__codelineno-8-51 href=#__codelineno-8-51></a>
</span><span id=__span-8-52><a id=__codelineno-8-52 name=__codelineno-8-52 href=#__codelineno-8-52></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=s1>' '</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-8-53><a id=__codelineno-8-53 name=__codelineno-8-53 href=#__codelineno-8-53></a>    <span class=c1># Run the training - output streams to console in real-time</span>
</span><span id=__span-8-54><a id=__codelineno-8-54 name=__codelineno-8-54 href=#__codelineno-8-54></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>cmd</span><span class=p>,</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-8-55><a id=__codelineno-8-55 name=__codelineno-8-55 href=#__codelineno-8-55></a>
</span><span id=__span-8-56><a id=__codelineno-8-56 name=__codelineno-8-56 href=#__codelineno-8-56></a>    <span class=c1># Check if training succeeded</span>
</span><span id=__span-8-57><a id=__codelineno-8-57 name=__codelineno-8-57 href=#__codelineno-8-57></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-8-58><a id=__codelineno-8-58 name=__codelineno-8-58 href=#__codelineno-8-58></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Training failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-8-59><a id=__codelineno-8-59 name=__codelineno-8-59 href=#__codelineno-8-59></a>
</span><span id=__span-8-60><a id=__codelineno-8-60 name=__codelineno-8-60 href=#__codelineno-8-60></a>    <span class=c1># Copy meta.pkl (character encoding info) to output dir</span>
</span><span id=__span-8-61><a id=__codelineno-8-61 name=__codelineno-8-61 href=#__codelineno-8-61></a>    <span class=c1># We'll need this for sampling later</span>
</span><span id=__span-8-62><a id=__codelineno-8-62 name=__codelineno-8-62 href=#__codelineno-8-62></a>    <span class=n>meta_src</span> <span class=o>=</span> <span class=s2>"data/shakespeare_char/meta.pkl"</span>
</span><span id=__span-8-63><a id=__codelineno-8-63 name=__codelineno-8-63 href=#__codelineno-8-63></a>    <span class=n>meta_dst</span> <span class=o>=</span> <span class=s2>"/data/out/meta.pkl"</span>
</span><span id=__span-8-64><a id=__codelineno-8-64 name=__codelineno-8-64 href=#__codelineno-8-64></a>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>meta_src</span><span class=p>):</span>
</span><span id=__span-8-65><a id=__codelineno-8-65 name=__codelineno-8-65 href=#__codelineno-8-65></a>        <span class=n>shutil</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=n>meta_src</span><span class=p>,</span> <span class=n>meta_dst</span><span class=p>)</span>
</span><span id=__span-8-66><a id=__codelineno-8-66 name=__codelineno-8-66 href=#__codelineno-8-66></a>
</span><span id=__span-8-67><a id=__codelineno-8-67 name=__codelineno-8-67 href=#__codelineno-8-67></a>    <span class=c1># THIS IS CRITICAL - persist everything to the volume!</span>
</span><span id=__span-8-68><a id=__codelineno-8-68 name=__codelineno-8-68 href=#__codelineno-8-68></a>    <span class=c1># Without this, your checkpoint disappears when the container shuts down</span>
</span><span id=__span-8-69><a id=__codelineno-8-69 name=__codelineno-8-69 href=#__codelineno-8-69></a>    <span class=n>volume</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span><span id=__span-8-70><a id=__codelineno-8-70 name=__codelineno-8-70 href=#__codelineno-8-70></a>
</span><span id=__span-8-71><a id=__codelineno-8-71 name=__codelineno-8-71 href=#__codelineno-8-71></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-8-72><a id=__codelineno-8-72 name=__codelineno-8-72 href=#__codelineno-8-72></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ“ Training completed! Model saved to /data/out"</span><span class=p>)</span>
</span><span id=__span-8-73><a id=__codelineno-8-73 name=__codelineno-8-73 href=#__codelineno-8-73></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-8-74><a id=__codelineno-8-74 name=__codelineno-8-74 href=#__codelineno-8-74></a>
</span><span id=__span-8-75><a id=__codelineno-8-75 name=__codelineno-8-75 href=#__codelineno-8-75></a>    <span class=c1># Return info about the training run</span>
</span><span id=__span-8-76><a id=__codelineno-8-76 name=__codelineno-8-76 href=#__codelineno-8-76></a>    <span class=k>return</span> <span class=p>{</span>
</span><span id=__span-8-77><a id=__codelineno-8-77 name=__codelineno-8-77 href=#__codelineno-8-77></a>        <span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span>
</span><span id=__span-8-78><a id=__codelineno-8-78 name=__codelineno-8-78 href=#__codelineno-8-78></a>        <span class=s2>"max_iters"</span><span class=p>:</span> <span class=n>max_iters</span><span class=p>,</span>
</span><span id=__span-8-79><a id=__codelineno-8-79 name=__codelineno-8-79 href=#__codelineno-8-79></a>        <span class=s2>"output_dir"</span><span class=p>:</span> <span class=s2>"/data/out"</span><span class=p>,</span>
</span><span id=__span-8-80><a id=__codelineno-8-80 name=__codelineno-8-80 href=#__codelineno-8-80></a>    <span class=p>}</span>
</span></code></pre></div> <p>Few things to note here:</p> <ol> <li><strong>GPU specification</strong>: We're requesting an A100-40GB. Modal spins one up just for this function.</li> <li><strong>Hyperparameters as arguments</strong>: Makes it super easy to experiment - just pass different values when you call the function.</li> <li><strong><code>volume.commit()</code></strong>: This is crucial! It persists everything you wrote to <code>/data</code> back to the volume. Forget this and your checkpoint disappears when the container shuts down.</li> <li><strong>Fallback data prep</strong>: If the data isn't ready, we call <code>prepare_data.local()</code> to run it first.</li> </ol> <p>The training runs just like it would locally, except it's happening on a beefy GPU in the cloud.</p> <h3 id=stage-3-generating-samples>Stage 3: Generating Samples<a class=headerlink href=#stage-3-generating-samples title="Permanent link">Â¶</a></h3> <p>Now let's see what our model learned:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOGPT_IMAGE</span><span class=p>,</span>      <span class=c1># Same image as training</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>GPU_TYPE</span><span class=p>,</span>              <span class=c1># Need GPU for inference</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>     <span class=c1># Mount volume to access saved checkpoint</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>10</span> <span class=o>*</span> <span class=mi>60</span><span class=p>,</span>           <span class=c1># 10 minutes should be plenty</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a><span class=p>)</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=k>def</span><span class=w> </span><span class=nf>sample</span><span class=p>(</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>    <span class=n>num_samples</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>5</span><span class=p>,</span>           <span class=c1># How many texts to generate</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>    <span class=n>max_new_tokens</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>500</span><span class=p>,</span>      <span class=c1># Length of each sample</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=n>temperature</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.8</span><span class=p>,</span>        <span class=c1># Randomness (0.1=boring, 1.5=wild)</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>    <span class=n>start</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=s2>"</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span>               <span class=c1># Starting prompt</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a><span class=p>):</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=w>    </span><span class=sd>"""Generate text samples from our trained model."""</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>    <span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-9-16><a id=__codelineno-9-16 name=__codelineno-9-16 href=#__codelineno-9-16></a>    <span class=kn>import</span><span class=w> </span><span class=nn>shutil</span>
</span><span id=__span-9-17><a id=__codelineno-9-17 name=__codelineno-9-17 href=#__codelineno-9-17></a>
</span><span id=__span-9-18><a id=__codelineno-9-18 name=__codelineno-9-18 href=#__codelineno-9-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-9-19><a id=__codelineno-9-19 name=__codelineno-9-19 href=#__codelineno-9-19></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"GENERATING SAMPLES FROM TRAINED MODEL"</span><span class=p>)</span>
</span><span id=__span-9-20><a id=__codelineno-9-20 name=__codelineno-9-20 href=#__codelineno-9-20></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-9-21><a id=__codelineno-9-21 name=__codelineno-9-21 href=#__codelineno-9-21></a>
</span><span id=__span-9-22><a id=__codelineno-9-22 name=__codelineno-9-22 href=#__codelineno-9-22></a>    <span class=c1># Sanity check: make sure the checkpoint exists</span>
</span><span id=__span-9-23><a id=__codelineno-9-23 name=__codelineno-9-23 href=#__codelineno-9-23></a>    <span class=c1># (It should be in the volume from training)</span>
</span><span id=__span-9-24><a id=__codelineno-9-24 name=__codelineno-9-24 href=#__codelineno-9-24></a>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=s2>"/data/out/ckpt.pt"</span><span class=p>):</span>
</span><span id=__span-9-25><a id=__codelineno-9-25 name=__codelineno-9-25 href=#__codelineno-9-25></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ“ Found checkpoint: /data/out/ckpt.pt"</span><span class=p>)</span>
</span><span id=__span-9-26><a id=__codelineno-9-26 name=__codelineno-9-26 href=#__codelineno-9-26></a>    <span class=k>else</span><span class=p>:</span>
</span><span id=__span-9-27><a id=__codelineno-9-27 name=__codelineno-9-27 href=#__codelineno-9-27></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ— Checkpoint not found: /data/out/ckpt.pt"</span><span class=p>)</span>
</span><span id=__span-9-28><a id=__codelineno-9-28 name=__codelineno-9-28 href=#__codelineno-9-28></a>        <span class=c1># Could raise an error here, but we'll let sample.py handle it</span>
</span><span id=__span-9-29><a id=__codelineno-9-29 name=__codelineno-9-29 href=#__codelineno-9-29></a>
</span><span id=__span-9-30><a id=__codelineno-9-30 name=__codelineno-9-30 href=#__codelineno-9-30></a>    <span class=c1># nanoGPT's sample.py looks for meta.pkl in the data directory</span>
</span><span id=__span-9-31><a id=__codelineno-9-31 name=__codelineno-9-31 href=#__codelineno-9-31></a>    <span class=c1># So we need to copy it from the volume to where it expects it</span>
</span><span id=__span-9-32><a id=__codelineno-9-32 name=__codelineno-9-32 href=#__codelineno-9-32></a>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=s2>"data/shakespeare_char"</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-9-33><a id=__codelineno-9-33 name=__codelineno-9-33 href=#__codelineno-9-33></a>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=s2>"/data/out/meta.pkl"</span><span class=p>)</span> <span class=ow>and</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span>
</span><span id=__span-9-34><a id=__codelineno-9-34 name=__codelineno-9-34 href=#__codelineno-9-34></a>        <span class=s2>"data/shakespeare_char/meta.pkl"</span>
</span><span id=__span-9-35><a id=__codelineno-9-35 name=__codelineno-9-35 href=#__codelineno-9-35></a>    <span class=p>):</span>
</span><span id=__span-9-36><a id=__codelineno-9-36 name=__codelineno-9-36 href=#__codelineno-9-36></a>        <span class=n>shutil</span><span class=o>.</span><span class=n>copy</span><span class=p>(</span><span class=s2>"/data/out/meta.pkl"</span><span class=p>,</span> <span class=s2>"data/shakespeare_char/meta.pkl"</span><span class=p>)</span>
</span><span id=__span-9-37><a id=__codelineno-9-37 name=__codelineno-9-37 href=#__codelineno-9-37></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ“ Copied meta.pkl to expected location"</span><span class=p>)</span>
</span><span id=__span-9-38><a id=__codelineno-9-38 name=__codelineno-9-38 href=#__codelineno-9-38></a>
</span><span id=__span-9-39><a id=__codelineno-9-39 name=__codelineno-9-39 href=#__codelineno-9-39></a>    <span class=c1># Build the sampling command</span>
</span><span id=__span-9-40><a id=__codelineno-9-40 name=__codelineno-9-40 href=#__codelineno-9-40></a>    <span class=n>cmd</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-9-41><a id=__codelineno-9-41 name=__codelineno-9-41 href=#__codelineno-9-41></a>        <span class=s2>"python"</span><span class=p>,</span>
</span><span id=__span-9-42><a id=__codelineno-9-42 name=__codelineno-9-42 href=#__codelineno-9-42></a>        <span class=s2>"sample.py"</span><span class=p>,</span>                           <span class=c1># nanoGPT's sampling script</span>
</span><span id=__span-9-43><a id=__codelineno-9-43 name=__codelineno-9-43 href=#__codelineno-9-43></a>        <span class=s2>"--out_dir=/data/out"</span><span class=p>,</span>                 <span class=c1># Where to find the checkpoint</span>
</span><span id=__span-9-44><a id=__codelineno-9-44 name=__codelineno-9-44 href=#__codelineno-9-44></a>        <span class=sa>f</span><span class=s2>"--num_samples=</span><span class=si>{</span><span class=n>num_samples</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>        <span class=c1># How many samples to generate</span>
</span><span id=__span-9-45><a id=__codelineno-9-45 name=__codelineno-9-45 href=#__codelineno-9-45></a>        <span class=sa>f</span><span class=s2>"--max_new_tokens=</span><span class=si>{</span><span class=n>max_new_tokens</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>  <span class=c1># Length of each sample</span>
</span><span id=__span-9-46><a id=__codelineno-9-46 name=__codelineno-9-46 href=#__codelineno-9-46></a>        <span class=sa>f</span><span class=s2>"--temperature=</span><span class=si>{</span><span class=n>temperature</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>         <span class=c1># Sampling temperature</span>
</span><span id=__span-9-47><a id=__codelineno-9-47 name=__codelineno-9-47 href=#__codelineno-9-47></a>        <span class=sa>f</span><span class=s2>"--start=</span><span class=si>{</span><span class=n>start</span><span class=si>}</span><span class=s2>"</span><span class=p>,</span>                    <span class=c1># Starting prompt</span>
</span><span id=__span-9-48><a id=__codelineno-9-48 name=__codelineno-9-48 href=#__codelineno-9-48></a>        <span class=s2>"--compile=False"</span><span class=p>,</span>                     <span class=c1># Skip compilation</span>
</span><span id=__span-9-49><a id=__codelineno-9-49 name=__codelineno-9-49 href=#__codelineno-9-49></a>    <span class=p>]</span>
</span><span id=__span-9-50><a id=__codelineno-9-50 name=__codelineno-9-50 href=#__codelineno-9-50></a>
</span><span id=__span-9-51><a id=__codelineno-9-51 name=__codelineno-9-51 href=#__codelineno-9-51></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Running: </span><span class=si>{</span><span class=s1>' '</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>cmd</span><span class=p>)</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-9-52><a id=__codelineno-9-52 name=__codelineno-9-52 href=#__codelineno-9-52></a>    <span class=c1># Run sampling and capture output (we want to return it)</span>
</span><span id=__span-9-53><a id=__codelineno-9-53 name=__codelineno-9-53 href=#__codelineno-9-53></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>cmd</span><span class=p>,</span> <span class=n>capture_output</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-9-54><a id=__codelineno-9-54 name=__codelineno-9-54 href=#__codelineno-9-54></a>
</span><span id=__span-9-55><a id=__codelineno-9-55 name=__codelineno-9-55 href=#__codelineno-9-55></a>    <span class=c1># Print the generated text</span>
</span><span id=__span-9-56><a id=__codelineno-9-56 name=__codelineno-9-56 href=#__codelineno-9-56></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=p>)</span>
</span><span id=__span-9-57><a id=__codelineno-9-57 name=__codelineno-9-57 href=#__codelineno-9-57></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>:</span>
</span><span id=__span-9-58><a id=__codelineno-9-58 name=__codelineno-9-58 href=#__codelineno-9-58></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>"STDERR:"</span><span class=p>,</span> <span class=n>result</span><span class=o>.</span><span class=n>stderr</span><span class=p>)</span>
</span><span id=__span-9-59><a id=__codelineno-9-59 name=__codelineno-9-59 href=#__codelineno-9-59></a>
</span><span id=__span-9-60><a id=__codelineno-9-60 name=__codelineno-9-60 href=#__codelineno-9-60></a>    <span class=c1># Check if sampling succeeded</span>
</span><span id=__span-9-61><a id=__codelineno-9-61 name=__codelineno-9-61 href=#__codelineno-9-61></a>    <span class=k>if</span> <span class=n>result</span><span class=o>.</span><span class=n>returncode</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-9-62><a id=__codelineno-9-62 name=__codelineno-9-62 href=#__codelineno-9-62></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>"Sampling failed with code </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>returncode</span><span class=si>}</span><span class=s2>"</span><span class=p>)</span>
</span><span id=__span-9-63><a id=__codelineno-9-63 name=__codelineno-9-63 href=#__codelineno-9-63></a>
</span><span id=__span-9-64><a id=__codelineno-9-64 name=__codelineno-9-64 href=#__codelineno-9-64></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>"</span> <span class=o>+</span> <span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-9-65><a id=__codelineno-9-65 name=__codelineno-9-65 href=#__codelineno-9-65></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ“ Sampling completed!"</span><span class=p>)</span>
</span><span id=__span-9-66><a id=__codelineno-9-66 name=__codelineno-9-66 href=#__codelineno-9-66></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"="</span> <span class=o>*</span> <span class=mi>80</span><span class=p>)</span>
</span><span id=__span-9-67><a id=__codelineno-9-67 name=__codelineno-9-67 href=#__codelineno-9-67></a>
</span><span id=__span-9-68><a id=__codelineno-9-68 name=__codelineno-9-68 href=#__codelineno-9-68></a>    <span class=c1># Return the generated samples</span>
</span><span id=__span-9-69><a id=__codelineno-9-69 name=__codelineno-9-69 href=#__codelineno-9-69></a>    <span class=k>return</span> <span class=p>{</span><span class=s2>"status"</span><span class=p>:</span> <span class=s2>"completed"</span><span class=p>,</span> <span class=s2>"samples"</span><span class=p>:</span> <span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=p>}</span>
</span></code></pre></div> <p>This loads the checkpoint from our volume and generates text. The <code>temperature</code> parameter controls creativity - higher values mean more random (and often more interesting) outputs. At 0.1, the model plays it safe and picks the most likely next character. At 1.5, it gets wild and experimental.</p> <h2 id=running-the-pipeline>Running the Pipeline<a class=headerlink href=#running-the-pipeline title="Permanent link">Â¶</a></h2> <p>There are two ways to run this:</p> <h3 id=option-1-run-everything-at-once>Option 1: Run Everything at Once<a class=headerlink href=#option-1-run-everything-at-once title="Permanent link">Â¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>local_entrypoint</span><span class=p>()</span>  <span class=c1># This decorator makes it the main entry point</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=k>def</span><span class=w> </span><span class=nf>main</span><span class=p>():</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=w>    </span><span class=sd>"""Run the complete pipeline: data prep -&gt; train -&gt; sample"""</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"ðŸš€ Starting nanoGPT pipeline..."</span><span class=p>)</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=c1># Step 1: Prepare data (runs on CPU)</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"ðŸ“ Preparing dataset..."</span><span class=p>)</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    <span class=n>prepare_data</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>  <span class=c1># .remote() runs this on Modal's infrastructure</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=c1># Step 2: Train model (runs on GPU)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"ðŸ‹ï¸ Training model..."</span><span class=p>)</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=n>train</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>        <span class=n>max_iters</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>      <span class=c1># Override default params</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>        <span class=n>eval_interval</span><span class=o>=</span><span class=mi>250</span><span class=p>,</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>        <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>    <span class=p>)</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>    <span class=c1># Step 3: Generate samples (runs on GPU)</span>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"âœ¨ Generating samples..."</span><span class=p>)</span>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>    <span class=n>sample</span><span class=o>.</span><span class=n>remote</span><span class=p>(</span>
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>        <span class=n>num_samples</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>        <span class=c1># Just 3 samples</span>
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>300</span>    <span class=c1># 300 characters each</span>
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>    <span class=p>)</span>
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>
</span><span id=__span-10-25><a id=__codelineno-10-25 name=__codelineno-10-25 href=#__codelineno-10-25></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"ðŸŽ‰ Pipeline completed!"</span><span class=p>)</span>
</span></code></pre></div> <p>Then just:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py
</span></code></pre></div> <p>The <code>.remote()</code> calls tell Modal to run these functions on their infrastructure, not locally. Modal handles spinning up containers, mounting volumes, and tearing everything down when done.</p> <h3 id=option-2-run-steps-individually>Option 2: Run Steps Individually<a class=headerlink href=#option-2-run-steps-individually title="Permanent link">Â¶</a></h3> <p>Sometimes you want more control:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Just prepare the data</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py::prepare_data
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a><span class=c1># Train with custom parameters</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py::train<span class=w> </span>--max-iters<span class=o>=</span><span class=m>2000</span><span class=w> </span>--batch-size<span class=o>=</span><span class=m>128</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a><span class=c1># Generate samples</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py::sample
</span></code></pre></div> <p>This is great for experimentation. You can prepare data once, then train multiple times with different hyperparameters.</p> <h2 id=playing-with-configuration>Playing with Configuration<a class=headerlink href=#playing-with-configuration title="Permanent link">Â¶</a></h2> <h3 id=gpu-types>GPU Types<a class=headerlink href=#gpu-types title="Permanent link">Â¶</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=n>GPU_TYPE</span> <span class=o>=</span> <span class=s2>"a100-40gb"</span>  <span class=c1># Default - fast and powerful</span>
</span></code></pre></div> <p>Your options: - <strong>T4</strong>: ~<span class=arithmatex>\(0.50/hr - Great for testing, slower training - **L40S**: ~\)</span>1/hr - Good price/performance balance - <strong>A100-40GB</strong>: ~<span class=arithmatex>\(2.50/hr - Fast training - **A100-80GB**: ~\)</span>3.50/hr - For larger models</p> <p>For testing nanoGPT, honestly a T4 is fine. Switch to A100 when you're doing real runs.</p> <h3 id=training-hyperparameters>Training Hyperparameters<a class=headerlink href=#training-hyperparameters title="Permanent link">Â¶</a></h3> <table> <thead> <tr> <th>Parameter</th> <th>Default</th> <th>What it does</th> </tr> </thead> <tbody> <tr> <td><code>max_iters</code></td> <td>1000</td> <td>How many training steps</td> </tr> <tr> <td><code>eval_interval</code></td> <td>500</td> <td>Check validation loss every N steps</td> </tr> <tr> <td><code>batch_size</code></td> <td>64</td> <td>Samples per batch</td> </tr> <tr> <td><code>block_size</code></td> <td>256</td> <td>Context length (chars the model sees)</td> </tr> <tr> <td><code>n_layer</code></td> <td>6</td> <td>Number of transformer layers</td> </tr> <tr> <td><code>n_head</code></td> <td>6</td> <td>Attention heads per layer</td> </tr> <tr> <td><code>n_embd</code></td> <td>384</td> <td>Hidden dimension size</td> </tr> <tr> <td><code>learning_rate</code></td> <td>1e-3</td> <td>Step size for optimizer</td> </tr> </tbody> </table> <p>Want to train faster? Reduce <code>max_iters</code> to 100 while testing. Want better results? Increase <code>n_layer</code> and <code>n_embd</code> (but you'll need more memory).</p> <h3 id=sampling-parameters>Sampling Parameters<a class=headerlink href=#sampling-parameters title="Permanent link">Â¶</a></h3> <table> <thead> <tr> <th>Parameter</th> <th>Default</th> <th>What it does</th> </tr> </thead> <tbody> <tr> <td><code>num_samples</code></td> <td>5</td> <td>How many texts to generate</td> </tr> <tr> <td><code>max_new_tokens</code></td> <td>500</td> <td>Length of each sample</td> </tr> <tr> <td><code>temperature</code></td> <td>0.8</td> <td>Randomness (0.1=boring, 1.5=wild)</td> </tr> <tr> <td><code>start</code></td> <td>"\n"</td> <td>Starting prompt</td> </tr> </tbody> </table> <h2 id=local-vs-remote-execution>Local vs Remote Execution<a class=headerlink href=#local-vs-remote-execution title="Permanent link">Â¶</a></h2> <p>Inside your functions, you can choose where things run:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># Run locally on your machine</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>prepare_data</span><span class=o>.</span><span class=n>local</span><span class=p>()</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=c1># Run remotely on Modal</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=n>prepare_data</span><span class=o>.</span><span class=n>remote</span><span class=p>()</span>
</span></code></pre></div> <p><strong>Use local when:</strong> - Debugging - Testing small changes - You have a GPU locally and want to use it</p> <p><strong>Use remote when:</strong> - Production training - You need specific GPU types - You don't want to manage infrastructure (most of the time!)</p> <h2 id=adding-secrets>Adding Secrets<a class=headerlink href=#adding-secrets title="Permanent link">Â¶</a></h2> <p>Need Hugging Face tokens or WandB API keys?</p> <h3 id=option-1-env-file>Option 1: .env file<a class=headerlink href=#option-1-env-file title="Permanent link">Â¶</a></h3> <p>Create a <code>.env</code> file:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=nv>HF_TOKEN</span><span class=o>=</span>your_huggingface_token
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=nv>WANDB_API_KEY</span><span class=o>=</span>your_wandb_key
</span></code></pre></div> <p>Then update your function:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=nd>@app</span><span class=o>.</span><span class=n>function</span><span class=p>(</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=n>image</span><span class=o>=</span><span class=n>NANOGPT_IMAGE</span><span class=p>,</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>gpu</span><span class=o>=</span><span class=n>GPU_TYPE</span><span class=p>,</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>volumes</span><span class=o>=</span><span class=n>VOLUME_CONFIG</span><span class=p>,</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>modal</span><span class=o>.</span><span class=n>Secret</span><span class=o>.</span><span class=n>from_dotenv</span><span class=p>()],</span>  <span class=c1># Add this</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=n>timeout</span><span class=o>=</span><span class=mi>2</span> <span class=o>*</span> <span class=n>HOURS</span><span class=p>,</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=k>def</span><span class=w> </span><span class=nf>train</span><span class=p>(</span><span class=o>...</span><span class=p>):</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>    <span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a>    <span class=n>hf_token</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>"HF_TOKEN"</span><span class=p>]</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>    <span class=o>...</span>
</span></code></pre></div> <h3 id=option-2-modal-secrets>Option 2: Modal Secrets<a class=headerlink href=#option-2-modal-secrets title="Permanent link">Â¶</a></h3> <p>More secure for production:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>modal<span class=w> </span>secret<span class=w> </span>create<span class=w> </span>my-secrets<span class=w> </span><span class=nv>HF_TOKEN</span><span class=o>=</span>xxx<span class=w> </span><span class=nv>WANDB_API_KEY</span><span class=o>=</span>yyy
</span></code></pre></div> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=n>secrets</span><span class=o>=</span><span class=p>[</span><span class=n>modal</span><span class=o>.</span><span class=n>Secret</span><span class=o>.</span><span class=n>from_name</span><span class=p>(</span><span class=s2>"my-secrets"</span><span class=p>)]</span>
</span></code></pre></div> <h2 id=when-things-go-wrong>When Things Go Wrong<a class=headerlink href=#when-things-go-wrong title="Permanent link">Â¶</a></h2> <h3 id=nanogpt-directory-not-found>"nanoGPT directory not found"<a class=headerlink href=#nanogpt-directory-not-found title="Permanent link">Â¶</a></h3> <p>Make sure you cloned it in the right place:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>git<span class=w> </span>clone<span class=w> </span>https://github.com/karpathy/nanoGPT.git
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>ls<span class=w>  </span><span class=c1># Should show: nanoGPT/  TrainNanoGPTModal.py</span>
</span></code></pre></div> <h3 id=checkpoint-not-found-during-sampling>"Checkpoint not found during sampling"<a class=headerlink href=#checkpoint-not-found-during-sampling title="Permanent link">Â¶</a></h3> <p>Training didn't complete or you forgot <code>volume.commit()</code>. Check your training logs.</p> <h3 id=cuda-out-of-memory>"CUDA out of memory"<a class=headerlink href=#cuda-out-of-memory title="Permanent link">Â¶</a></h3> <p>Your batch size is too big for the GPU:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py::train<span class=w> </span>--batch-size<span class=o>=</span><span class=m>32</span>
</span></code></pre></div> <p>Or switch to a bigger GPU by changing <code>GPU_TYPE = "a100-80gb"</code>.</p> <h3 id=training-taking-forever>Training Taking Forever<a class=headerlink href=#training-taking-forever title="Permanent link">Â¶</a></h3> <p>For testing, reduce iterations:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>modal<span class=w> </span>run<span class=w> </span>TrainNanoGPTModal.py::train<span class=w> </span>--max-iters<span class=o>=</span><span class=m>100</span>
</span></code></pre></div> <p>100 iterations won't give you great results, but it'll let you verify everything works.</p> <h2 id=monitoring-your-training>Monitoring Your Training<a class=headerlink href=#monitoring-your-training title="Permanent link">Â¶</a></h2> <p>When you run <code>modal run</code>, you'll get a URL like:</p> <div class="language-text highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a>View run at https://modal.com/apps/...
</span></code></pre></div> <p>Click it to see: - Real-time logs streaming - GPU utilization graphs - How much you're spending - Function status</p> <p>It's actually a really nice dashboard. I keep it open while training to make sure my GPU utilization is high (means I'm not wasting money).</p> <h2 id=cost-optimization-tips>Cost Optimization Tips<a class=headerlink href=#cost-optimization-tips title="Permanent link">Â¶</a></h2> <ol> <li> <p><strong>Use CPU for data prep</strong>: We already do this! Data preparation on CPU, training on GPU.</p> </li> <li> <p><strong>Start with cheap GPUs</strong>: Use T4 for testing, A100 for real runs.</p> </li> <li> <p><strong>Set timeouts</strong>: Don't let a buggy script run forever: </p><div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=n>timeout</span><span class=o>=</span><span class=mi>1</span> <span class=o>*</span> <span class=n>HOURS</span>  <span class=c1># Kill it after an hour</span>
</span></code></pre></div> </li> <li> <p><strong>Clean up old checkpoints</strong>: Volumes are free up to 50GB, but still, no need to hoard.</p> </li> </ol> <h2 id=whats-next>What's Next?<a class=headerlink href=#whats-next title="Permanent link">Â¶</a></h2> <p>Now that you've got the basics down with nanoGPT, you can:</p> <ul> <li><strong>Experiment with hyperparameters</strong>: Try different learning rates, model sizes</li> <li><strong>Use your own data</strong>: Replace Shakespeare with your favorite books, code, whatever</li> <li><strong>Add WandB tracking</strong>: Log your experiments properly</li> <li><strong>Try the other tutorials</strong>: The Gemma tutorial shows production-scale fine-tuning with LoRA, and the Llama tutorial covers multi-GPU training</li> </ul> <p>The pattern is always the same: 1. Write your code locally 2. Define your Modal image 3. Wrap your functions with <code>@app.function()</code> 4. Run with <code>modal run</code></p> <p>That's it. No Docker, no Kubernetes, no infrastructure headaches. Just write Python and run it on GPUs.</p> <hr> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">Â¶</a></h2> <ul> <li><a href=https://github.com/karpathy/nanoGPT>NanoGPT GitHub</a> - The repo we're using</li> <li><a href=https://modal.com/docs>Modal Documentation</a> - When you want to dig deeper</li> <li><a href=https://modal.com/docs/guide/gpu>Modal GPU Types</a> - All available GPUs and pricing</li> <li><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Andrej Karpathy's Tutorial</a> - Watch him build nanoGPT from scratch</li> </ul> <hr> <p>Got questions? Hit me up on Twitter <a href=https://x.com/adithya_s_k>@adithya_s_k</a> or check out the other tutorials in this series!</p></div> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title="Last update"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> <span class=md-source-file__fact> <span class=md-icon title=Created> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="November 27, 2025 17:29:26 UTC">November 27, 2025</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ class="md-footer__link md-footer__link--prev" aria-label="Previous: Write Deep Learning Code Locally and Run on GPUs Instantly"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Write Deep Learning Code Locally and Run on GPUs Instantly </div> </div> </a> <a href=../TrainNanochatModalTutorial/ class="md-footer__link md-footer__link--next" aria-label="Next: Training Nanochat on Modal"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Training Nanochat on Modal </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024 Adithya S Kolavi </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://github.com/adithya-s-k/AI-Engineering.academy target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg> </a> <a href=https://x.com/adithya_s_k target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"annotate": null, "base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.footnote.tooltips", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.progress", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.e71a0d61.min.js></script> <script src=../../../assets/javascripts/custom.9e5da760.min.js></script> <!-- Rich Snippets / Structured Data --> <script type=application/ld+json>
  {
    "@context": "https://schema.org",
    "@type": "EducationalOrganization",
    "name": "AI Engineering Academy",
    "url": "https://aiengineering.academy",
    "logo": "https://aiengineering.academy/assets/logo.png",
    "description": "A structured learning platform for AI engineers with clear paths in prompt engineering, RAG, fine-tuning, deployment, and agent development.",
    "sameAs": [
      "https://github.com/adithya-s-k/AI-Engineering.academy",
      "https://x.com/adithya_s_k"
    ],
    "founder": {
      "@type": "Person",
      "name": "Adithya S Kolavi"
    },
    "offers": {
      "@type": "Offer",
      "price": "0",
      "priceCurrency": "USD"
    }
  }
</script> </body> </html>